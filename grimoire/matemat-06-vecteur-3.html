<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2023-05-10 mer 16:44 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 06 : Vecteurs - 3</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style>
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat 06 : Vecteurs - 3</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org8296eaa">1. Applications linéaires</a></li>
<li><a href="#org28f574d">2. Géométrie</a></li>
<li><a href="#org5180276">3. Formes linéaires</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-org8296eaa" class="outline-2">
<h2 id="org8296eaa"><span class="section-number-2">1.</span> Applications linéaires</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org504fdbd">1.1. Dépendances</a></li>
<li><a href="#org21b14e8">1.2. Définition</a></li>
<li><a href="#orgeecf9cf">1.3. Identité</a></li>
<li><a href="#orgc062c1c">1.4. Inverse</a></li>
<li><a href="#org2e6a74e">1.5. Valeur au vecteur nul</a></li>
<li><a href="#org3c5fe71">1.6. Norme des applications linéaires</a></li>
<li><a href="#org162c3d1">1.7. Norme d'une composée</a></li>
<li><a href="#org2520ab8">1.8. Norme d'une puissance</a></li>
<li><a href="#org9f0821a">1.9. Continuité</a></li>
<li><a href="#orgfc2ef17">1.10. $n$-linéarité</a></li>
<li><a href="#orgdbb710f">1.11. Représentation matricielle</a></li>
<li><a href="#org3fd5b61">1.12. Produit matriciel</a></li>
<li><a href="#org0bbc97d">1.13. Blocs</a></li>
<li><a href="#org907ff0f">1.14. Matrice identité</a></li>
<li><a href="#orgfd6011a">1.15. Inverse</a></li>
<li><a href="#org0906242">1.16. Inverse d'un produit</a></li>
<li><a href="#org574f0df">1.17. Puissance</a></li>
<li><a href="#org3624999">1.18. Polynômes matriciels</a></li>
</ul>
</div>

<p>
\label{chap:lineaire}
</p>
</div>


<div id="outline-container-org504fdbd" class="outline-3">
<h3 id="org504fdbd"><span class="section-number-3">1.1.</span> Dépendances</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:fonction} : Les fonctions</li>
</ul>
</div>
</div>


<div id="outline-container-org21b14e8" class="outline-3">
<h3 id="org21b14e8"><span class="section-number-3">1.2.</span> Définition</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Soit les espaces vectoriels \(E\) et \(F\) sur \(\corps\) et la fonction \(f : E \mapsto F\). On dit que \(f\) est linéaire si, pour tout \(x,y \in E\) et \(\alpha, \beta \in \corps\), on a :
</p>

<p>
\[f(\alpha \cdot x + \beta \cdot y) = \alpha \cdot f(x) + \beta \cdot f(y)\]
</p>

<p>
On note \(\lineaire(E,F)\) l'ensemble des fonctions linéaires de \(E\) vers \(F\).
</p>
</div>
</div>


<div id="outline-container-orgeecf9cf" class="outline-3">
<h3 id="orgeecf9cf"><span class="section-number-3">1.3.</span> Identité</h3>
<div class="outline-text-3" id="text-1-3">
<p>
L'application identité est clairement linéaire.
</p>
</div>
</div>


<div id="outline-container-orgc062c1c" class="outline-3">
<h3 id="orgc062c1c"><span class="section-number-3">1.4.</span> Inverse</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Soit \(u = f(x)\) et \(v = f(y)\). Si l'application inverse existe, on a \(x = f^{-1}(u)\) et \(y = f^{-1}(v)\). En composant à gauche par \(f^{-1}\) la définition de la linéarité, on obtient :
</p>

<p>
\[\alpha \cdot f^{-1}(u) + \beta \cdot f^{-1}(v) = f^{-1}(\alpha \cdot u + \beta \cdot v)\]
</p>

<p>
ce qui montre que l'inverse est également linéaire.
</p>
</div>
</div>


<div id="outline-container-org2e6a74e" class="outline-3">
<h3 id="org2e6a74e"><span class="section-number-3">1.5.</span> Valeur au vecteur nul</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Choisissons un \(x \in E\). on voit que :
</p>

<p>
\[f(0) = f(0 \cdot x) = 0 \cdot f(x) = 0\]
</p>

<p>
La valeur d'une application linéaire s'annule au vecteur nul.
</p>
</div>
</div>


<div id="outline-container-org3c5fe71" class="outline-3">
<h3 id="org3c5fe71"><span class="section-number-3">1.6.</span> Norme des applications linéaires</h3>
<div class="outline-text-3" id="text-1-6">
<p>
La norme d'une application linéaire est définie comme étant l'extension maximale qu'elle produit :
</p>

<p>
\[\norme{f} = \sup \left\{ \frac{ \norme{f(x)} }{ \norme{x} } : x \in E, \ x \ne 0 \right\}\]
</p>

<p>
On a donc :
</p>

<p>
\[\norme{f(x)} \le \norme{f} \cdot \norme{x}\]
</p>

<p>
pour tout \(x \in E \setminus \{ 0 \}\).
</p>
</div>


<div id="outline-container-org4081d67" class="outline-4">
<h4 id="org4081d67"><span class="section-number-4">1.6.1.</span> Vérification</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
Nous allons vérifier qu'il s'agit bien d'une norme. On a \(\norme{f} \ge 0\) par positivité de la norme sur \(E\) et \(F\). La condition \(\norme{f} = 0\) implique \(\norme{f(x)} = 0\) et donc \(f(x) = 0\) pour tout \(x \ne 0\). Comme \(f\) est linéaire, on a aussi \(f(0) = 0\) et \(f = 0\).
</p>

<p>
Si \(f,g\) sont linéaires, on a :
</p>

<p>
\[\norme{f(x) + g(x)} \le \norme{f(x)} + \norme{g(x)} \le \norme{f} \cdot \norme{x} + \norme{g} \cdot \norme{x} = (\norme{f} + \norme{g}) \cdot \norme{x}\]
</p>

<p>
pour tout \(x \ne 0\). En divisant par \(\norme{x}\) et en passant au supremum, on obtient :
</p>

<p>
\[\norme{f + g} \le \norme{f} + \norme{g}\]
</p>

<p>
Enfin, si \(\alpha \in \corps\), on a :
</p>

<p>
\[\frac{ \norme{\alpha \cdot f(x)} }{ \norme{x} } = \abs{\alpha} \cdot \frac{ \norme{f(x)} }{ \norme{x} }\]
</p>

<p>
En passant au supremum, on obtient :
</p>

<p>
\[\norme{\alpha \cdot f} = \abs{\alpha} \cdot \norme{f}\]
</p>
</div>
</div>


<div id="outline-container-org4cb96a0" class="outline-4">
<h4 id="org4cb96a0"><span class="section-number-4">1.6.2.</span> Notation</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
Lorsqu'il est nécessaire de différentier la norme au sens des applications linéaires d'autres types de normes utilisées, on note :
</p>

<p>
\[\norme{f}_\lineaire = \norme{f}\]
</p>
</div>
</div>


<div id="outline-container-orga4c9777" class="outline-4">
<h4 id="orga4c9777"><span class="section-number-4">1.6.3.</span> Définition alternative</h4>
<div class="outline-text-4" id="text-1-6-3">
<p>
Soit \(N \in \corps\), avec \(N \strictsuperieur 0\) et :
</p>

<p>
\[B = \{ u \in E : \norme{u} = N \}\]
</p>

<p>
Soit \(x \in E\) avec \(x \ne 0\) et :
</p>

<p>
\[\lambda = \frac{ \norme{x} }{N}\]
</p>

<p>
Définissons :
</p>

<p>
\[u = \frac{x}{\lambda}\]
</p>

<p>
On voit que :
</p>

<p>
\[\norme{u} = \norme{\unsur{\lambda} \cdot x} = \unsur{\lambda} \cdot \norme{x} = \frac{N}{ \norme{x} } \cdot \norme{x} = N\]
</p>

<p>
On a donc \(u \in B\). Le rapport des normes s'écrit :
</p>

<p>
\[\frac{ \norme{f(x)} }{ \norme{x} } = \frac{ \norme{f(x)} }{ N \cdot \lambda } = \unsur{N} \norme{ \frac{f(x)}{ \lambda } } = \unsur{ \norme{u} } \cdot \norme{ f\left( \frac{x}{ \lambda } \right) } = \frac{ \norme{f(u)} }{ \norme{u} }\]
</p>

<p>
On en conclut que :
</p>

<p>
\[\frac{ \norme{f(x)} }{ \norme{x} } = \frac{ \norme{f(u)} }{ \norme{u} } \le \sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\}\]
</p>

<p>
Comme ce doit être valable quelque soit \(x \ne 0\), on obtient :
</p>

<p>
\[\norme{f} \le \sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\}\]
</p>

<p>
en passant au supremum sur \(x\).
</p>

<p>
Choisissons à présent \(u \in B\). On a alors :
</p>

<p>
\[\frac{ \norme{f(u)} }{ \norme{u} } \le \norme{f}\]
</p>

<p>
En passant au supremum sur \(u\), on obtient :
</p>

<p>
\[\sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\} \le \norme{f}\]
</p>

<p>
On en conclut que les deux supremums sont égaux :
</p>

<p>
\[\sup \left\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \right\} = \norme{f}\]
</p>
</div>
</div>


<div id="outline-container-org0d6c64a" class="outline-4">
<h4 id="org0d6c64a"><span class="section-number-4">1.6.4.</span> Norme unitaire</h4>
<div class="outline-text-4" id="text-1-6-4">
<p>
Une conséquence importante du résultat ci-dessus est le cas particulier \(N = 1\). On a alors :
</p>

<p>
\[\norme{f} = \sup \left\{ \norme{f(v)} : v \in E, \ \norme{v} = 1 \right\}\]
</p>
</div>
</div>
</div>


<div id="outline-container-org162c3d1" class="outline-3">
<h3 id="org162c3d1"><span class="section-number-3">1.7.</span> Norme d'une composée</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Soit \(f : E \mapsto F\) et \(g : F \mapsto G\) deux applications linéaires de normes finies. Si \(x \in E\) avec \(x \ne 0\) on a \(f(x) \in F\) et :
</p>

<p>
\[\norme{g \circ f(x)} \le \norme{g} \cdot \norme{f(x)} \le \norme{g} \cdot \norme{f} \cdot \norme{x}\]
</p>

<p>
En divisant par \(\norme{x} \ne 0\) :
</p>

<p>
\[\frac{ \norme{g \circ f(x)} }{ \norme{x} } \le \norme{g} \cdot \norme{f}\]
</p>

<p>
et en passant au supremum sur \(x \ne 0\), on en conclut que :
</p>

<p>
\[\norme{g \circ f} \le \norme{g} \cdot \norme{f}\]
</p>
</div>
</div>


<div id="outline-container-org2520ab8" class="outline-3">
<h3 id="org2520ab8"><span class="section-number-3">1.8.</span> Norme d'une puissance</h3>
<div class="outline-text-3" id="text-1-8">
<p>
On a clairement :
</p>

<p>
\[\norme{f^n} = \norme{f \circ ... \circ f} \le \norme{f}^n\]
</p>
</div>
</div>


<div id="outline-container-org9f0821a" class="outline-3">
<h3 id="org9f0821a"><span class="section-number-3">1.9.</span> Continuité</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Nous allons montrer que, pour tout \(f \in \lineaire(A,B)\), on a l'équivalence entre l'hypothèse d'une norme de \(f\) finie et l'hypothèse de \(f\) continue.
</p>

<p>
Si la norme est finie, on a :
</p>

<p>
\[\norme{f(x) - f(a)} = \norme{f(x - a)} \le \norme{f} \cdot \norme{x-a}\]
</p>

<p>
qui tend bien vers \(0\) lorsque \(x\) tend vers \(a\). Inversément, si \(f\) est continue, on peut trouver un \(\delta \strictsuperieur 0\) tel que :
</p>

<p>
\[\norme{f(x) - f(0)} \le 1\]
</p>

<p>
pour tout \(x\) vérifiant \(\distance(x,0) = \norme{x} \le \delta\). Posons \(B = \{ x \in A : \norme{x} = \delta \}\). On a alors :
</p>

<p>
\[\sup_{x \in B} \frac{\norme{f(x)}}{\norme{x}} = \unsur{\delta} \sup_{x \in B} \norme{f(x) - f(0)} \le \unsur{\delta}\]
</p>

<p>
La norme est donc finie :
</p>

<p>
\[\norme{f} = \sup_{x \in B} \frac{\norme{f(x)}}{\norme{x}} \le \unsur{\delta} \strictinferieur +\infty\]
</p>
</div>
</div>


<div id="outline-container-orgfc2ef17" class="outline-3">
<h3 id="orgfc2ef17"><span class="section-number-3">1.10.</span> $n$-linéarité</h3>
<div class="outline-text-3" id="text-1-10">
<p>
On dit que la fonction \(f : E_1 \times ... \times E_n \mapsto F\) est $n$-linéaire si elle est linéaire par rapport à chacune des composantes de son argument, les autres composantes restant inchangées :
</p>

<p>
\[f(...,\alpha x + \beta y,...) = \alpha \cdot f(...,x,...) + \beta \cdot f(...,y,...)\]
</p>

<p>
pour tout \(\alpha,\beta \in \corps\) et \(x,y \in E\). On note \(\lineaire_n(E_1,...,E_n,F)\) l'ensemble des fonctions $n$-linéaires de \(E_1 \times ... \times E_n\) vers \(F\).
</p>
</div>


<div id="outline-container-org5140508" class="outline-4">
<h4 id="org5140508"><span class="section-number-4">1.10.1.</span> Norme</h4>
<div class="outline-text-4" id="text-1-10-1">
<p>
La norme est définie dans ce cas par :
</p>

<p>
\[\norme{f} = \sup \left\{ \frac{ \norme{f(x_1,...,x_n)} }{ \prod_{i = 1}^n \norme{x_i} } : (x_1,...,x_n) \in E_1 \times ... \times E_n \right\}\]
</p>

<p>
Si cette norme est finie, on a :
</p>

<p>
\[\norme{f(x_1,...,x_n)} \le \norme{f} \cdot \prod_{i = 1}^n \norme{x_i}\]
</p>

<p>
pour tout \((x_1,...,x_n) \in E_1 \times ... \times E_n\).
</p>
</div>
</div>


<div id="outline-container-orgfbd26cb" class="outline-4">
<h4 id="orgfbd26cb"><span class="section-number-4">1.10.2.</span> Bilinéarité</h4>
<div class="outline-text-4" id="text-1-10-2">
<p>
On dit aussi des fonctions $2$-linéaires qu'elles sont bilinéaires. La norme d'une fonction \(f : E_1 \times E_2 \mapsto F\) bilinéaire est définie par :
</p>

<p>
\[\norme{f} = \sup \left\{ \frac{ \norme{f(u,v)} }{ \norme{u} \cdot \norme{v} } : (u,v) \in E_1 \times E_2 \right\}\]
</p>

<p>
Si cette norme est finie, on a :
</p>

<p>
\[\norme{f(u,v)} \le \norme{f} \cdot \norme{u} \cdot \norme{v}\]
</p>

<p>
pour tout \((u,v) \in E_1 \times E_2\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgdbb710f" class="outline-3">
<h3 id="orgdbb710f"><span class="section-number-3">1.11.</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-1-11">
<p>
Soit une application linéaire \(\mathcal{A} : E \to F\). Choisissons \(x \in E\) et posons :
</p>

<p>
\[y = \mathcal{A}(x)\]
</p>

<p>
Si on dispose d'une base \((e_1,...,e_n)\) de \(E\) et d'une base \((f_1,...,f_m)\) de \(F\), on a :
</p>

<div class="org-center">
<p>
\(
x = \sum_{i = 1}^n x_i \cdot e_i \\
y = \sum_{i = 1}^m y_i \cdot f_i
\)
</p>
</div>

<p>
pour certains \(x_i,y_i \in \corps\). La linéarité de \(\mathcal{A}\) implique que :
</p>

<p>
\[y = \sum_{j = 1}^n \mathcal{A}(e_j) \cdot x_j\]
</p>

<p>
Si les \(a_{ij} \in \corps\) sont les coordonnées de \(\mathcal{A}(e_j)\) dans la base des \(f_i\), on a :
</p>

<p>
\[\mathcal{A}(e_j) = \sum_{i = 1}^m a_{ij} \cdot f_i\]
</p>

<p>
En substituant cette expression, on obtient :
</p>

<p>
\[y = \sum_{i = 1}^m f_i \sum_{j = 1}^n a_{ij} \cdot x_j\]
</p>

<p>
La \(i^{ème}\) coordonnée de \(y\) est donc donnée par :
</p>

<p>
\[y_i = \sum_{j = 1}^n a_{ij} \cdot x_j\]
</p>

<p>
On définit la matrice \(A \in \matrice(\corps,m,n)\) associée à \(\mathcal{A}\) en posant :
</p>

<p>
\[A = ( a_{ij} )_{i,j}\]
</p>

<p>
Nous définissons ensuite le produit d'une matrice avec le « vecteur » \(x\) équivalent de \(\corps^n\) :
</p>

<p>
\[A \cdot x = \left( \sum_j a_{ij} \cdot x_j  \right)_i\]
</p>

<p>
de telle sorte que :
</p>

<p>
\[A \cdot x = \mathcal{A}(x)\]
</p>
</div>


<div id="outline-container-orgd845723" class="outline-4">
<h4 id="orgd845723"><span class="section-number-4">1.11.1.</span> Norme</h4>
<div class="outline-text-4" id="text-1-11-1">
<p>
La norme d'une matrice est la norme de l'application linéaire associée, c'est-à-dire :
</p>

<p>
\[\norme{A}_2 = \sup \left\{ \frac{ \norme{A \cdot x} }{ \norme{x} } : x \in \corps^n, \ x \ne 0 \right\}\]
</p>

<p>
Soit :
</p>

<p>
\[M = \max_{i,j} \abs{\composante_{ij} A}\]
</p>

<p>
On a alors :
</p>

<p>
\[\norme{A \cdot x} \le M \cdot m \cdot n \cdot \max_i x_i \le M \cdot m \cdot n \cdot \norme{x}\]
</p>

<p>
ce qui montre que :
</p>

<p>
\[\norme{A} \le M \cdot m \cdot n \strictinferieur \infty\]
</p>

<p>
La norme d'une matrice finie (\(m,n \strictinferieur \infty\)) existe toujours.
</p>
</div>
</div>


<div id="outline-container-org02da27d" class="outline-4">
<h4 id="org02da27d"><span class="section-number-4">1.11.2.</span> Image</h4>
<div class="outline-text-4" id="text-1-11-2">
<p>
L'image d'une matrice est l'image de l'application linéaire associée, c'est-à-dire :
</p>

<p>
\[\image A = \{ A \cdot x : x \in \corps^n \}\]
</p>

<p>
Si \(c_i = \colonne_i A\), on a :
</p>

<p>
\[A = [ c_1 \ c_2 \ ... \ c_n ]\]
</p>

<p>
On voit que :
</p>

<p>
\[A \cdot x = \sum_i c_i \cdot x_i\]
</p>

<p>
autrement dit l'image de \(A\) est l'espace vectoriel engendré par ses colonnes :
</p>

<p>
\[\image A = \combilin{c_1,c_2,...,c_n}\]
</p>
</div>
</div>


<div id="outline-container-org304d281" class="outline-4">
<h4 id="org304d281"><span class="section-number-4">1.11.3.</span> Noyau</h4>
<div class="outline-text-4" id="text-1-11-3">
<p>
Le noyau d'une matrice est le noyau de l'application linéaire associée, c'est-à-dire :
</p>

<p>
\[\noyau A = \{ x \in \corps^n : A \cdot x = 0 \}\]
</p>
</div>
</div>
</div>


<div id="outline-container-org3fd5b61" class="outline-3">
<h3 id="org3fd5b61"><span class="section-number-3">1.12.</span> Produit matriciel</h3>
<div class="outline-text-3" id="text-1-12">
<p>
Soit à présent les matrices \(A \in \matrice(\corps,m,n)\) et \(B \in \matrice(\corps,n,p)\) données par :
</p>

<div class="org-center">
<p>
\(
A = ( a_{ij} )_{i,j} \\
B = ( b_{ij} )_{i,j}
\)
</p>
</div>

<p>
où les \(a_{ij},b_{ij} \in K\). Soit les applications linéaires \(\mathcal{B} : \corps^p \to \corps^n\) et \(\mathcal{A} : \corps^n \to \corps^m\) définies par :
</p>

<div class="org-center">
<p>
\(
\mathcal{B}(x) = B \cdot x \\
\mathcal{A}(y) = A \cdot y
\)
</p>
</div>

<p>
pour tout \(x \in \corps^p\), \(y \in \corps^n\). Choisissons \(z \in \corps^m\) et relions \(x,y,z\) par :
</p>

<div class="org-center">
<p>
\(
y = \mathcal{B}(x) \\
z = \mathcal{A}(y) = \big( \mathcal{A} \circ \mathcal{B} \big)(x)
\)
</p>
</div>

<p>
Examinons les composantes de \(z\) en fonction de celles de \(x\) :
</p>

<p>
\[z_i = \sum_k a_{ik} \cdot y_k = \sum_k a_{ik} \sum_j b_{kj} \cdot x_j = \sum_{k,j} a_{ik} \cdot b_{kj} \cdot x_j\]
</p>

<p>
On en déduit que la composée \(\mathcal{C} = \mathcal{A} \circ \mathcal{B}\) est représentée par la matrice \(C \in \matrice(\corps,m,p)\) de composantes :
</p>

<p>
\[\composante_{ij} C = c_{ij} = \sum_k a_{ik} \cdot b_{kj}\]
</p>

<p>
Il suffit donc de définir le produit matriciel \(A \cdot B\) par :
</p>

<p>
\[A \cdot B = \left(\sum_{k=1}^n a_{ik} \cdot b_{kj}\right)_{i,j}\]
</p>

<p>
pour avoir :
</p>

<p>
\[(A \cdot B) \cdot x = \big( \mathcal{A} \circ \mathcal{B} \big)(x)\]
</p>

<p>
Le produit matriciel représente donc une composée d'applications linéaires. Pour que ce produit soit bien défini, il est nécessaire que le nombre
de colonnes \(n\) de \(A\) et le nombre de lignes de \(B\) soient identiques.
</p>

<p>
On voit également que le produit matrice - vecteur défini précédemment en est un cas particulier lorsque \(p = 1\).
</p>
</div>


<div id="outline-container-orgbc09a43" class="outline-4">
<h4 id="orgbc09a43"><span class="section-number-4">1.12.1.</span> Notation</h4>
<div class="outline-text-4" id="text-1-12-1">
<p>
En pratique, on laisse souvent tomber le ``\(\cdot\)'' et on note \(A B\)
au lieu de \(A \cdot B\) lorsqu'il est évident que \(A\) et \(B\) sont deux
matrices différentes.
</p>
</div>
</div>


<div id="outline-container-org51aa215" class="outline-4">
<h4 id="org51aa215"><span class="section-number-4">1.12.2.</span> Taille</h4>
<div class="outline-text-4" id="text-1-12-2">
<p>
Le produit d'une matrice de taille \((m,n)\) par une matrice de taille \((n,p)\) est une matrice de taille \((m,p)\).
</p>
</div>
</div>


<div id="outline-container-org34c6d81" class="outline-4">
<h4 id="org34c6d81"><span class="section-number-4">1.12.3.</span> Lignes et colonnes</h4>
<div class="outline-text-4" id="text-1-12-3">
<p>
Si \(x_i^T = \ligne_i(A)\) et \(y_j = \colonne_j(B)\), on voit que :
</p>

<p>
\[\composante_{ij} (A \cdot B) = x_i^T \cdot y_j\]
</p>
</div>
</div>


<div id="outline-container-org7b26ba6" class="outline-4">
<h4 id="org7b26ba6"><span class="section-number-4">1.12.4.</span> Associativité</h4>
<div class="outline-text-4" id="text-1-12-4">
<p>
Soit les matrices \(A \in \matrice(\corps,m,n)\), \(B \in \matrice(\corps,n,p)\) et \(C \in \matrice(\corps,p,q)\) données par :
</p>

<div class="org-center">
<p>
\(
A = ( a_{ij} )_{i,j} \\
B = ( b_{ij} )_{i,j} \\
C = ( c_{ij} )_{i,j}
\)
</p>
</div>

<p>
où les \(a_{ij},b_{ij},c_{ij} \in K\). La relation :
</p>

<p>
\[A \cdot (B \cdot C) = \left( \sum_{k,l} a_{ik} \cdot b_{kl} \cdot c_{lj} \right)_{i,j} = (A \cdot B) \cdot C\]
</p>

<p>
nous montre que la multiplication entre matrices est associative. On définit :
</p>

<p>
\[A \cdot B \cdot C = A \cdot (B \cdot C) = (A \cdot B) \cdot C\]
</p>
</div>
</div>


<div id="outline-container-orgedaec76" class="outline-4">
<h4 id="orgedaec76"><span class="section-number-4">1.12.5.</span> Distributivité</h4>
<div class="outline-text-4" id="text-1-12-5">
<p>
On a aussi les propriétés de distribution :
</p>

<div class="org-center">
<p>
\(
A \cdot (B + C) = A \cdot B + A \cdot C \\
(B + C) \cdot D = B \cdot D + C \cdot D
\)
</p>
</div>

<p>
où \(A \in \matrice(\corps,m,n)\), \(B,C \in \matrice(\corps,n,p)\) et \(D \in \matrice(\corps,p,q)\).
</p>
</div>
</div>


<div id="outline-container-org2411dbf" class="outline-4">
<h4 id="org2411dbf"><span class="section-number-4">1.12.6.</span> Non commutativité</h4>
<div class="outline-text-4" id="text-1-12-6">
<p>
Par contre, on peut trouver des matrices \(A\) et \(B\) telles que :
</p>

<p>
\[A \cdot B \ne B \cdot A\]
</p>

<p>
La multiplication matricielle n'est donc en général pas commutative. D'ailleurs, pour que ces deux produits existent simultanément, il faut que \(A\) et \(B\) soient toutes deux carrées, ce qui n'est pas forcément le cas.
</p>
</div>
</div>


<div id="outline-container-org8569677" class="outline-4">
<h4 id="org8569677"><span class="section-number-4">1.12.7.</span> Commutateur</h4>
<div class="outline-text-4" id="text-1-12-7">
<p>
La matrice associée au commutateur :
</p>

<p>
\[[\mathcal{A},\mathcal{B}] = \mathcal{A} \circ \mathcal{B} - \mathcal{B} \circ \mathcal{A}\]
</p>

<p>
est donnée par le commutateur équivalent :
</p>

<p>
\[[A,B] = A \cdot B - B \cdot A\]
</p>
</div>
</div>


<div id="outline-container-org4a4d3ad" class="outline-4">
<h4 id="org4a4d3ad"><span class="section-number-4">1.12.8.</span> Transposée</h4>
<div class="outline-text-4" id="text-1-12-8">
<p>
On vérifie que :
</p>

<p>
\[(A \cdot B)^T = B^T \cdot A^T\]
</p>
</div>
</div>
</div>


<div id="outline-container-org0bbc97d" class="outline-3">
<h3 id="org0bbc97d"><span class="section-number-3">1.13.</span> Blocs</h3>
<div class="outline-text-3" id="text-1-13">
<p>
En utilisant l'associativité de l'addition, on peut facilement vérifier que la formule de multiplication reste valable lorsqu'on considère des blocs de matrices au lieu des éléments, à condition de respecter l'ordre de multiplication. Un exemple fréquemment utilisé :
</p>

<div class="org-center">
<p>
\(
</p>
\begin{Matrix}{cc}
A_{11} & A_{12} \\ A_{21} & A_{22}
\end{Matrix}
<p>
&sdot;
</p>
\begin{Matrix}{cc}
B_{11} & B_{12} \\ B_{21} & B_{22}
\end{Matrix}
<p>
=
</p>
\begin{Matrix}{cc}
A_{11} \cdot B_{11} +  A_{12} \cdot B_{21} & A_{11} \cdot B_{12} +  A_{12} \cdot B_{22} \\
A_{21} \cdot B_{11} +  A_{22} \cdot B_{21} & A_{21} \cdot B_{12} +  A_{22} \cdot B_{22}
\end{Matrix}
<p>
\)
</p>
</div>
</div>


<div id="outline-container-org86cfaa0" class="outline-4">
<h4 id="org86cfaa0"><span class="section-number-4">1.13.1.</span> Bloc-diagonale</h4>
<div class="outline-text-4" id="text-1-13-1">
<p>
Un cas particulier important :
</p>

<div class="org-center">
<p>
\(
</p>
\begin{Matrix}{cc}
A_1 & 0 \\ 0 & A_2
\end{Matrix}
<p>
&sdot;
</p>
\begin{Matrix}{cc}
B_1 & 0 \\ 0 & B_2
\end{Matrix}
<p>
=
</p>
\begin{Matrix}{cc}
A_1 \cdot B_1 & 0 \\
0 & A_2 \cdot B_2
\end{Matrix}
<p>
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org907ff0f" class="outline-3">
<h3 id="org907ff0f"><span class="section-number-3">1.14.</span> Matrice identité</h3>
<div class="outline-text-3" id="text-1-14">
<p>
La matrice identité \(I \in \matrice(\corps,n,n)\) correspond à la fonction \(\identité\). On a donc :
</p>

<p>
\[I \cdot x = x\]
</p>

<p>
pour tout \(x \in \corps^n\). Si \((\canonique_1,...\canonique_n)\) est la base canonique de \(\corps^n\), on a donc :
</p>

<p>
\[I \cdot \canonique_i = \canonique_i\]
</p>

<p>
ce qui entraîne directement :
</p>

<p>
\[I = ( \indicatrice_{ij} )_{i,j}\]
</p>

<p>
On remarque que :
</p>

<p>
\[I = [\canonique_1 \ \hdots \ \canonique_n]\]
</p>
</div>


<div id="outline-container-org3e14385" class="outline-4">
<h4 id="org3e14385"><span class="section-number-4">1.14.1.</span> Neutre</h4>
<div class="outline-text-4" id="text-1-14-1">
<p>
Comme la fonction identité est neutre pour la composition, la matrice unité correspondante \(I \in \matrice(\corps,m,n)\) doit être neutre pour la multiplication avec toutes les matrices de dimensions compatibles. Soit \(A \in \matrice(\corps,m,n)\) et \(B \in \matrice(\corps,n,p)\). On vérifie que l'on a bien :
</p>

<div class="org-center">
<p>
\(
A \cdot I = A \\
I \cdot B = B
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org15cf0ec" class="outline-4">
<h4 id="org15cf0ec"><span class="section-number-4">1.14.2.</span> Notation</h4>
<div class="outline-text-4" id="text-1-14-2">
<p>
On note aussi \(I_n\) pour préciser que \(I\) est de taille \((n,n)\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgfd6011a" class="outline-3">
<h3 id="orgfd6011a"><span class="section-number-3">1.15.</span> Inverse</h3>
<div class="outline-text-3" id="text-1-15">
<p>
Lorsqu'elle existe, la matrice inverse de \(A\), notée \(A^{-1}\), reflète l'application linéaire inverse sous-jacente. Elle est donc l'unique matrice telle que :
</p>

<p>
\[A^{-1} \cdot A = A \cdot A^{-1} = I\]
</p>
</div>
</div>


<div id="outline-container-org0906242" class="outline-3">
<h3 id="org0906242"><span class="section-number-3">1.16.</span> Inverse d'un produit</h3>
<div class="outline-text-3" id="text-1-16">
<p>
Soit \(A\) et \(B\) deux matrices inversibles. Les relations \(C \cdot (A \cdot B) = I\) et \((A \cdot B) \cdot D = I\) nous donnent :
</p>

<p>
\[C = D = B^{-1} \cdot A^{-1}\]
</p>

<p>
et donc :
</p>

<p>
\[(A \cdot B)^{-1} = B^{-1} \cdot A^{-1}\]
</p>
</div>


<div id="outline-container-orga1f587d" class="outline-4">
<h4 id="orga1f587d"><span class="section-number-4">1.16.1.</span> Inverse à gauche et à droite</h4>
<div class="outline-text-4" id="text-1-16-1">
<p>
On dit que \(L\) est un inverse à gauche de \(A\) si \(L \cdot A = I\). On dit que \(R\) est un inverse à droite de \(A\) si \(A \cdot R = I\).
</p>
</div>
</div>
</div>


<div id="outline-container-org574f0df" class="outline-3">
<h3 id="org574f0df"><span class="section-number-3">1.17.</span> Puissance</h3>
<div class="outline-text-3" id="text-1-17">
<p>
Il est possible de multiplier une matrice carrée \(A\) avec elle-même.
On peut donc définir l'exposant par :
</p>

<div class="org-center">
<p>
\(
A^0 = I \\
A^k = A \cdot A^{k-1}
\)
</p>
</div>
</div>


<div id="outline-container-org7d9c48e" class="outline-4">
<h4 id="org7d9c48e"><span class="section-number-4">1.17.1.</span> Négative</h4>
<div class="outline-text-4" id="text-1-17-1">
<p>
Si l'inverse \(A^{-1}\) existe, on définit également :
</p>

<p>
\[A^{-k} = (A^{-1})^k\]
</p>
</div>
</div>
</div>


<div id="outline-container-org3624999" class="outline-3">
<h3 id="org3624999"><span class="section-number-3">1.18.</span> Polynômes matriciels</h3>
<div class="outline-text-3" id="text-1-18">
<p>
Ici, \(\corps\) n'est plus un corps mais l'anneau des matrices \(X\) de taille \((N,N)\). On dit que \(p : \matrice(\corps,N,N) \mapsto \matrice(\corps,N,N)\) est un polynôme matriciel si il existe \(a_0,...,a_n \in \corps\) tels que :
</p>

<p>
\[p(X) = \sum_{i = 0}^n a_i \cdot X^i\]
</p>

<p>
pour tout \(X \in \matrice(\corps,N,N)\).
</p>
</div>
</div>
</div>


<div id="outline-container-org28f574d" class="outline-2">
<h2 id="org28f574d"><span class="section-number-2">2.</span> Géométrie</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org59c8dce">2.1. Courbe</a></li>
<li><a href="#org481bb1b">2.2. Segment</a></li>
<li><a href="#orgc4be5cd">2.3. Enveloppe convexe</a></li>
<li><a href="#org324e0d8">2.4. Surface</a></li>
</ul>
</div>
</div>


<div id="outline-container-org59c8dce" class="outline-3">
<h3 id="org59c8dce"><span class="section-number-3">2.1.</span> Courbe</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Une courbe sur un espace vectoriel \(E\) (par exemple \(\setR^n\)) est de la forme :
</p>

<div class="org-center">
<p>
\(
\Lambda = \{ \lambda(s) : s \in [\alpha,\beta] \}
\)
</p>
</div>

<p>
où \(\lambda : [\alpha,\beta] \mapsto E\) est une fonction continue et où \(\alpha,\beta \in \setR\) vérifient \(\alpha \le \beta\).
</p>
</div>
</div>


<div id="outline-container-org481bb1b" class="outline-3">
<h3 id="org481bb1b"><span class="section-number-3">2.2.</span> Segment</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Les segments sont une généralisation des intervalles. Un segment de \(u \in E\) vers \(v \in E\) est un cas particulier de courbe où \(\lambda : [0,1] \subseteq \setR \mapsto E\) est une fonction linéaire définie par :
</p>

<div class="org-center">
<p>
\(
\lambda(s) = u + s \cdot (v - u)
\)
</p>
</div>

<p>
pour tout \(s \in [0,1] \subseteq \setR\). On voit que \(\lambda(0) = u\) et que \(\lambda(1) = v\). On note aussi :
</p>

<div class="org-center">
<p>
\(\relax
[u,v] = \lambda([0,1]) = \{ u + s \cdot (v - u) : s \in [0,1] \} \subseteq E
\)
</p>
</div>
</div>


<div id="outline-container-org30b6e91" class="outline-4">
<h4 id="org30b6e91"><span class="section-number-4">2.2.1.</span> Alternative</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
On dispose aussi d'une définition alternative. On utilise :
</p>

<div class="org-center">
<p>
\(
L = \{ (s,t) \in \setR^2 : (s,t) \ge 0 \text{ et } s + t = 1 \}
\)
</p>
</div>

<p>
et la fonction \(\sigma : L \mapsto E\) définie par :
</p>

<div class="org-center">
<p>
\(\relax
\sigma(s,t) = s \cdot u + t \cdot v
\)
</p>
</div>

<p>
On a alors \([u,v] = \sigma(L)\). On voit aussi que \(\sigma(1,0) = u\) et \(\sigma(0,1) = v\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgc4be5cd" class="outline-3">
<h3 id="orgc4be5cd"><span class="section-number-3">2.3.</span> Enveloppe convexe</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Soit \(A \subseteq E\) et la collection des segments reliant deux points quelconques de \(A\) :
</p>

<div class="org-center">
<p>
\(
\mathcal{S} = \{ [u,v] : u,v \in A \}
\)
</p>
</div>

<p>
L'enveloppe convexe de \(A\) est l'union de tous ces segments :
</p>

<div class="org-center">
<p>
\(
\convexe(A) = \bigcup \mathcal{S}
\)
</p>
</div>

<p>
Pour tout \(u,v \in A\) et \((s,t) \in \setR^2\) tels que \(s,t \ge 0\) et \(s + t = 1\), on a donc :
</p>

<div class="org-center">
<p>
\(
s \cdot u + t \cdot v \in \convexe(A)
\)
</p>
</div>
</div>


<div id="outline-container-org8e9e18d" class="outline-4">
<h4 id="org8e9e18d"><span class="section-number-4">2.3.1.</span> Inclusion</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
Il suffit de considérer le choix \((s,t) = (1,0)\) pour voir que tout \(u \in A\) appartient à \(\convexe(A)\). On a donc \(A \subseteq \convexe(A)\).
</p>
</div>
</div>


<div id="outline-container-org5e56e79" class="outline-4">
<h4 id="org5e56e79"><span class="section-number-4">2.3.2.</span> Ensemble convexe</h4>
<div class="outline-text-4" id="text-2-3-2">
<p>
On dit qu'un ensemble \(C \subseteq E\) est convexe si \(\convexe(C) = C\).
</p>
</div>
</div>
</div>


<div id="outline-container-org324e0d8" class="outline-3">
<h3 id="org324e0d8"><span class="section-number-3">2.4.</span> Surface</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Une surface de \(E\) est de la forme :
</p>

<div class="org-center">
<p>
\(
\Phi = \{ \varphi(s,t) : (s,t) \in [a,b] \times [c,d] \}
\)
</p>
</div>

<p>
où \(\varphi : [a,b] \times [c,d] \mapsto E\) est une fonction continue et où \(a,b,c,d \in \setR\) vérifient \(a \le b\) et \(c \le d\).
</p>
</div>
</div>
</div>


<div id="outline-container-org5180276" class="outline-2">
<h2 id="org5180276"><span class="section-number-2">3.</span> Formes linéaires</h2>
<div class="outline-text-2" id="text-3">
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org59bb034">3.1. Dépendances</a></li>
<li><a href="#org46670c1">3.2. Définition</a></li>
<li><a href="#orgd75b048">3.3. Espace dual</a></li>
<li><a href="#org69802e4">3.4. Notation</a></li>
<li><a href="#org363bc29">3.5. Linéarité</a></li>
<li><a href="#orgc736e53">3.6. Biorthonormalité</a></li>
<li><a href="#org3db84fd">3.7. Similitude</a></li>
<li><a href="#org467653f">3.8. Espace bidual</a></li>
<li><a href="#orge33c7d9">3.9. Application duale</a></li>
<li><a href="#orgec59c21">3.10. Formes bilinéaires</a></li>
<li><a href="#org81de163">3.11. Formes quadratiques</a></li>
<li><a href="#orgcd77bf3">3.12. Représentation matricielle</a></li>
</ul>
</div>

<p>
\label{chap:forme}
</p>
</div>


<div id="outline-container-org59bb034" class="outline-3">
<h3 id="org59bb034"><span class="section-number-3">3.1.</span> Dépendances</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:relation} : Les fonctions</li>
<li>Chapitre \ref{chap:lineaire} : Les fonctions linéaires</li>
</ul>
</div>
</div>


<div id="outline-container-org46670c1" class="outline-3">
<h3 id="org46670c1"><span class="section-number-3">3.2.</span> Définition</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Soit un espace vectoriel \(E\) sur \(\corps\). Une forme linéaire est une fonction linéaire continue
\(\varphi : E \mapsto \corps\).
</p>
</div>
</div>


<div id="outline-container-orgd75b048" class="outline-3">
<h3 id="orgd75b048"><span class="section-number-3">3.3.</span> Espace dual</h3>
<div class="outline-text-3" id="text-3-3">
<p>
L'espace dual \(E^\dual\) de \(E\) est l'ensemble des formes linéaires sur \(E\) , autrement dit
l'ensemble des fonctions linéaires continues de \(E\) vers \(\corps\) :
</p>

<p>
\[E^\dual = \{ \varphi \in \lineaire(E,\corps) : \norme{\varphi}_\lineaire \strictinferieur +\infty \}\]
</p>

<p>
Il s'agit d'un espace vectoriel pour les opérations d'addition et de multiplication mixte définies sur les fonctions.
</p>
</div>
</div>


<div id="outline-container-org69802e4" class="outline-3">
<h3 id="org69802e4"><span class="section-number-3">3.4.</span> Notation</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Pour toute forme \(\varphi \in E^\dual\) et tout vecteur \(v \in E\), on note :
</p>

<p>
\[\forme{\varphi}{v} = \varphi(v)\]
</p>

<p>
ce qui définit implicitement la fonction \(\forme{}{} : E^\dual \times E \mapsto \corps\).
</p>
</div>
</div>


<div id="outline-container-org363bc29" class="outline-3">
<h3 id="org363bc29"><span class="section-number-3">3.5.</span> Linéarité</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Soit \(\varphi,\psi \in E^\dual\), \(u,v \in E\) et \(\alpha,\beta \in S\). Comme \(\varphi\) est linéaire, on a :
</p>

<p>
\[\forme{\varphi}{\alpha \cdot u + \beta \cdot v}  = \alpha \cdot \forme{\varphi}{u} + \beta \cdot \forme{\varphi}{v}\]
</p>

<p>
Symétriquement, la définition des opérations sur les fonctions nous donne également :
</p>

<p>
\[\forme{\alpha \cdot \varphi + \beta \cdot \psi}{u}  = \alpha \cdot \forme{\varphi}{u} + \beta \cdot \forme{\psi}{u}\]
</p>

<p>
L'application \(\forme{}{}\) est donc bilinéaire.
</p>
</div>
</div>


<div id="outline-container-orgc736e53" class="outline-3">
<h3 id="orgc736e53"><span class="section-number-3">3.6.</span> Biorthonormalité</h3>
<div class="outline-text-3" id="text-3-6">
<p>
On dit que les suites \((\Phi_1,...,\Phi_m)\) de \(E^\dual\) et
\((e_1,...,e_n)\) de \(E\) sont biorthonormées si :
</p>

<p>
\[\forme{\Phi_i}{e_j} = \indicatrice_{ij}\]
</p>

<p>
pour tout \((i,j) \in \setZ(0,m) \times \setZ(0,n)\). De telles suites permettent d'évaluer facilement les coefficients des développements en série du type :
</p>

<p>
\[\varphi = \sum_{i = 1}^m \alpha_i \cdot \Phi_i\]
</p>

<p>
où \(\alpha_1,...,\alpha_m \in S\). En effet, il suffit d'évaluer :
</p>

<p>
\[\varphi(e_j) = \forme{\varphi}{e_j} = \sum_{i = 1}^m \alpha_i \cdot \forme{\Phi_i}{e_j} = \sum_{i = 1}^m \alpha_i \cdot \indicatrice_{ij} = \alpha_j\]
</p>

<p>
pour obtenir les valeurs des \(\alpha_j\).
</p>

<p>
Réciproquement, si :
</p>

<p>
\[u = \sum_{i = 1}^n \beta_i \cdot e_i\]
</p>

<p>
avec \(\beta_1,...,\beta_n \in S\), on a :
</p>

<p>
\[\Phi_j(u) = \forme{\Phi_j}{u} = \sum_{i = 1}^n \beta_i \cdot \forme{\Phi_j}{e_i} = \sum_{i = 1}^n \beta_i \cdot \indicatrice_{ij} = \beta_j\]
</p>

<p>
ce qui nous donne les valeurs des \(\beta_j\).
</p>

<p>
Forts de ces résultats, il est aisé d'évaluer :
</p>

<p>
\[\forme{\varphi}{u} = \sum_{i,j} \alpha_i \cdot \forme{\Phi_i}{u_j} \cdot \beta_j = \sum_{i,j} \alpha_i \cdot \indicatrice_{ij} \cdot \beta_j = \sum_i \alpha_i \cdot \beta_i\]
</p>

<p>
On a donc en définitive :
</p>

<p>
\[\forme{\varphi}{u} = \sum_i \forme{\varphi}{e_i} \cdot \forme{\Phi_i}{u}\]
</p>
</div>
</div>


<div id="outline-container-org3db84fd" class="outline-3">
<h3 id="org3db84fd"><span class="section-number-3">3.7.</span> Similitude</h3>
<div class="outline-text-3" id="text-3-7">
<p>
On dit que deux fonctions \(u,v \in E\) sont identique au sens des distributions si :
</p>

<p>
\[\forme{\varphi}{u} = \forme{\varphi}{v}\]
</p>

<p>
pour tout \(\varphi \in E^\dual\).
</p>

<p>
Symétriquement, les deux formes \(\varphi,\psi \in E^\dual\) sont identiques par définition si et seulement si :
</p>

<p>
\[\forme{\varphi}{u} = \forme{\psi}{u}\]
</p>

<p>
pour tout \(u \in E\).
</p>
</div>
</div>


<div id="outline-container-org467653f" class="outline-3">
<h3 id="org467653f"><span class="section-number-3">3.8.</span> Espace bidual</h3>
<div class="outline-text-3" id="text-3-8">
<p>
On définit l'espace bidual de \(E\), noté \(E^{\dual \dual}\), par :
</p>

<p>
\[E^{\dual \dual} = (E^\dual)^\dual\]
</p>

<p>
On associe à chaque élément \(u \in E\) un élément \(\hat{u} \in E^{\dual \dual}\) par la condition :
</p>

<p>
\[\hat{u}(\varphi) = \varphi(u)\]
</p>

<p>
qui doit être vérifiée pour tout \(\varphi \in E^\dual\). On a donc :
</p>

<p>
\[\forme{\hat{u}}{\varphi} = \forme{\varphi}{u}\]
</p>
</div>
</div>


<div id="outline-container-orge33c7d9" class="outline-3">
<h3 id="orge33c7d9"><span class="section-number-3">3.9.</span> Application duale</h3>
<div class="outline-text-3" id="text-3-9">
<p>
Soit les espaces vectoriels \(E\) et \(F\) sur \(\corps\) et une fonction \(A : E \mapsto F\). Le dual de \(A\) au sens des formes, s'il existe, est l'unique fonction \(A^\dual : F^\dual \mapsto E^\dual\) telle que :
</p>

<p>
\[\forme{ A^\dual(\varphi) }{u} = \forme{\varphi}{ A(u) }\]
</p>

<p>
pour tout \(u \in E\) et \(\varphi \in F^\dual\).
</p>
</div>
</div>


<div id="outline-container-orgec59c21" class="outline-3">
<h3 id="orgec59c21"><span class="section-number-3">3.10.</span> Formes bilinéaires</h3>
<div class="outline-text-3" id="text-3-10">
<p>
Soit les espaces vectoriels \(E\) et \(F\) sur \(\corps\). Une forme bilinéaire est une fonction bilinéaire continue \(\vartheta : F \times E \mapsto \corps\). On utilise une notation analogue à celle des formes :
</p>

<p>
\[\biforme{x}{\vartheta}{u} = \vartheta(x,u)\]
</p>

<p>
pour tout \(x \in F\) et \(u \in E\). On voit que :
</p>

<div class="org-center">
<p>
\(
\biforme{\alpha \cdot x + \beta \cdot y}{\vartheta}{u} = \alpha \cdot \biforme{x}{\vartheta}{u} + \beta \cdot \biforme{y}{\vartheta}{u} \\
\biforme{x}{\vartheta}{\alpha \cdot u + \beta \cdot v} = \alpha \cdot \biforme{x}{\vartheta}{u} + \beta \cdot \biforme{x}{\vartheta}{v}
\)
</p>
</div>

<p>
pour tout \(\alpha,\beta \in \corps\), \(u,v \in E\) et \(x,y \in F\).
</p>
</div>
</div>


<div id="outline-container-org81de163" class="outline-3">
<h3 id="org81de163"><span class="section-number-3">3.11.</span> Formes quadratiques</h3>
<div class="outline-text-3" id="text-3-11">
<p>
Soit la forme bilinéaire $ &thetasym; : E &times; E \mapsto \corps$. Une forme quadratique \(\mathcal{Q} : E \mapsto \corps\) est une fonction de la forme :
</p>

<p>
\[\mathcal{Q}(x) = \biforme{x}{\vartheta}{x}\]
</p>
</div>
</div>


<div id="outline-container-orgcd77bf3" class="outline-3">
<h3 id="orgcd77bf3"><span class="section-number-3">3.12.</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-3-12">
<p>
On peut représenter toute forme linéaire \(\varphi \in \lineaire(\corps^n,\corps)\) par un vecteur matriciel \(\hat{\varphi} \in \corps^n\). Etant donné la base canonique \((e_1,...,e_n)\) de \(\corps^n\), il suffit de poser :
</p>

<p>
\[\hat{\varphi}_i = \forme{\varphi}{e_i}\]
</p>

<p>
pour avoir :
</p>

<p>
\[\forme{\varphi}{u} = \hat{\varphi}^T \cdot u\]
</p>

<p>
pour tout \(u \in \corps^n\).
</p>
</div>


<div id="outline-container-org7e689ce" class="outline-4">
<h4 id="org7e689ce"><span class="section-number-4">3.12.1.</span> Formes bilinéaires</h4>
<div class="outline-text-4" id="text-3-12-1">
<p>
On peut représenter toute forme bilinéaire \(\vartheta \in \lineaire(\corps^m \times \corps^n,\corps)\) par une matrice \(\Theta \in \matrice(K,m,n)\). Etant donné les bases canoniques \((f_1,...,f_m)\) de \(\corps^m\) et \((e_1,...,e_n)\) de \(\corps^n\), il suffit de poser :
</p>

<p>
\[\composante_{ij} \Theta = \biforme{f_i}{\vartheta}{e_j}\]
</p>

<p>
pour avoir :
</p>

<p>
\[\biforme{v}{\vartheta}{u} = v^T \cdot \Theta \cdot u\]
</p>

<p>
pour tout \(u \in \corps^n\) et tout \(v \in \corps^m\).
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2023-05-10 mer 16:44</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
