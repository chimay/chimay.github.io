<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-09-19 ven 09:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 09 : Analyse - 2</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat 09 : Analyse - 2</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org511ab38">1. Développements de Taylor</a></li>
<li><a href="#org22a929f">2. Développements d'Hadamard</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>
<div id="outline-container-org511ab38" class="outline-2">
<h2 id="org511ab38"><span class="section-number-2">1.</span> Développements de Taylor</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents-1" role="doc-toc">
<ul>
<li><a href="#org9cecbd5">1.1. Polynômes de Taylor</a></li>
<li><a href="#orgb65fad2">1.2. Opérateur de Taylor</a></li>
<li><a href="#orgfb6bd4b">1.3. Forme intégrale</a></li>
<li><a href="#org42c13ff">1.4. Erreur</a></li>
<li><a href="#org3bc1ba3">1.5. Forme différentielle</a></li>
<li><a href="#orge913a2d">1.6. Borne</a></li>
<li><a href="#orga39e10a">1.7. Convergence</a></li>
<li><a href="#orgdf564e6">1.8. Dimension \(n\)</a></li>
<li><a href="#org52becd8">1.9. Notation</a></li>
<li><a href="#org725773e">1.10. Extrapolation de Richardson</a></li>
</ul>
</div>
</div>
<div id="outline-container-org9cecbd5" class="outline-3">
<h3 id="org9cecbd5"><span class="section-number-3">1.1.</span> Polynômes de Taylor</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Considérons un polynôme \(p : \setR \mapsto \setR\) de degré \(n\) défini par :
</p>

<p>
\[p(x) = \sum_{i = 0}^n \gamma_i \cdot x^i\]
</p>

<p>
pour tout \(x \in \setR\). Calculons ses dérivées :
</p>

\begin{align}
\partial p(x) &= \sum_{i = 1}^n \gamma_i \cdot i \cdot x^{i - 1} \\
\partial^2 p(x) &= \sum_{i = 2}^n \gamma_i \cdot i \cdot (i - 1) \cdot x^{i - 2} \\
\vdots \\
\partial^k p(x) &= \sum_{i = k}^n \gamma_i \cdot \frac{i !}{(i - k) !} \cdot x^{i - k} \\
\vdots \\
\partial^n p(x) &= n! \cdot \gamma_n
\end{align}

<p>
Lorsqu'on évalue ces dérivées en \(0\), seuls les termes en \(x^{k - k} = 1\) ne s'annulent pas. On obtient donc :
</p>

<p>
\[\partial^k p(0) = \frac{k !}{0 !} \cdot \gamma_k = k ! \cdot \gamma_k\]
</p>

<p>
ce qui nous donne l'expression des coefficients de \(p\) en fonction de ses dérivées en \(0\) :
</p>

<p>
\[\gamma_k = \unsur{k !} \cdot \partial^k p(0)\]
</p>

<p>
Le polynôme peut donc se réécrire :
</p>

<p>
\[p(x) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(0) \cdot x^i\]
</p>

<p>
Cette expression est appelée développement de Taylor de \(p\) autour de \(0\).
</p>
</div>
<div id="outline-container-org72ed880" class="outline-4">
<h4 id="org72ed880"><span class="section-number-4">1.1.1.</span> Généralisation</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
Soit \(a \in \setR\). La fonction \(r\) définie par :
</p>

<p>
\[r(t) = p(t + a) = \sum_{i = 0}^n \gamma_i \cdot (t + a)^i\]
</p>

<p>
pour tout \(t \in \setR\) est clairement un polynôme de degré \(n\). On a \(r(0) = p(a)\) et plus généralement :
</p>

<p>
\[\partial^i r(0) = \partial^i p(a)\]
</p>

<p>
pout tout \(i \ge 0\). Le développement de Taylor de \(r\) autour de \(0\) s'écrit :
</p>

<p>
\[r(t) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i r(0) \cdot t^i\]
</p>

<p>
ou encore :
</p>

<p>
\[r(t) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(a) \cdot t^i\]
</p>

<p>
En posant \(x = t + a\), on a \(t = x - a\) et :
</p>

<p>
\[p(x) = p(t + a) = r(t)\]
</p>

<p>
Le développement devient :
</p>

<p>
\[p(x) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(a) \cdot (x - a)^i\]
</p>

<p>
Cette expression est nommée développement de Taylor de \(p\) autour de \(a\).
</p>
</div>
</div>
</div>
<div id="outline-container-orgb65fad2" class="outline-3">
<h3 id="orgb65fad2"><span class="section-number-3">1.2.</span> Opérateur de Taylor</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Soit \(\alpha, \beta \in \setR\) avec \(\alpha \strictinferieur \beta\), une fonction \(f \in \continue^N([\alpha,\beta],\setR)\) et \(a \in [\alpha,\beta]\). Par analogie avec le développement de Taylor des polynômes, on définit l'opérateur de Taylor \(T_a^N\) par :
</p>

<p>
\[T_a^N(f)(x) = \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(a) \cdot (x - a)^k\]
</p>

<p>
pour tout \(x \in [\alpha,\beta]\).
</p>
</div>
<div id="outline-container-orge8b4cff" class="outline-4">
<h4 id="orge8b4cff"><span class="section-number-4">1.2.1.</span> Erreur</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
L'erreur \(E_a^N\) de l'opérateur \(T_a^N\) est donnée par :
</p>

<p>
\[E_a^N(f)(x) = f(x) - T_a^N(f)(x)\]
</p>

<p>
pour tout \(x \in [\alpha,\beta]\).
</p>
</div>
</div>
<div id="outline-container-org020f6fb" class="outline-4">
<h4 id="org020f6fb"><span class="section-number-4">1.2.2.</span> Polynômes</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
Si \(p\) est un polynôme de degré \(N\), on a bien entendu \(T_a^N(p) = p\) pour tout \(a \in \setR\) et \(E_a^N(p) = 0\).
</p>
</div>
</div>
</div>
<div id="outline-container-orgfb6bd4b" class="outline-3">
<h3 id="orgfb6bd4b"><span class="section-number-3">1.3.</span> Forme intégrale</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org2f2bb76" class="outline-4">
<h4 id="org2f2bb76"><span class="section-number-4">1.3.1.</span> Premier ordre</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
Soit \(\alpha, \beta \in \setR\) avec \(\alpha \strictinferieur \beta\) et la fonction \(f \in \continue^2([\alpha,\beta],\setR)\). Le théorème fondamental nous dit que :
</p>

<p>
\[\int_a^x \partial f(t) \ dt = f(x) - f(a)\]
</p>

<p>
pour tout \(a,x \in [\alpha,\beta]\). Appliquant le même théorème à la dérivée \(\partial f\), on a aussi :
</p>

<p>
\[\int_a^x \partial^2 f(t) \ dt = \partial f(x) - \partial f(a)\]
</p>
</div>
<div id="outline-container-org1adb7d4" class="outline-5">
<h5 id="org1adb7d4"><span class="section-number-5">1.3.1.1.</span> Intégration par parties</h5>
<div class="outline-text-5" id="text-1-3-1-1">
<p>
Soit \(u = \partial f\) et \(v = \identite\). on a :
</p>

<p>
\[\int_a^x u(x) \ \partial v(x) \ dx = \int_a^x \partial f(t) \cdot 1 \ dt = \int_a^x \partial f(t) \ dt\]
</p>

<p>
L'intégration par parties nous donne :
</p>

<p>
\[\int_a^x u(x) \ \partial v(x) \ dx = v(x) \ u(x) - v(a) \ u(a) - \int_a^x v(t) \ \partial u(t) \ dt\]
</p>

<p>
En tenant compte des définitions de \(u\) et \(v\), on obtient :
</p>

<p>
\[\int_a^x \partial f(t) \ dt = x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt\]
</p>


<p>
Appliquons le théorème fondamental au membre de gauche :
</p>

<p>
\[f(x) - f(a) = x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt\]
</p>

<p>
ou encore :
</p>

<p>
\[f(x) = f(a) + x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt\]
</p>

<p>
En multipliant la relation :
</p>

<p>
\[\partial f(x) - \partial f(a) = \int_a^x \partial^2 f(t) \ dt\]
</p>

<p>
par \(x\), on arrive au résultat :
</p>

<p>
\[x \ \partial f(x) = x \ \partial f(a) + \int_a^x x \ \partial^2 f(t) \ dt\]
</p>

<p>
L'expression de \(f(x)\) devient alors :
</p>

<p>
\[f(x) = f(a) + x \ \partial f(a) + \int_a^x x \ \partial^2 f(t) \ dt - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt\]
</p>

<p>
et finalement :
</p>

<p>
\[f(x) = f(a) + (x - a) \cdot \partial f(a) + \int_a^x (x - t) \cdot \partial^2 f(t) \ dt\]
</p>

<p>
Le membre de droite est appelé développement de Taylor du premier ordre de \(f\) sous forme intégrale.
</p>
</div>
</div>
</div>
<div id="outline-container-org0f04976" class="outline-4">
<h4 id="org0f04976"><span class="section-number-4">1.3.2.</span> Second ordre</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
Soit \(f \in \continue^3([\alpha,\beta],\setR)\). Comme \(\continue^3 \subseteq \continue^2\), \(f\) admet un développement de Taylor du premier ordre sous forme intégrale. Nous allons intégrer par parties le terme :
</p>

<p>
\[\int_a^x (x - t) \cdot \partial^2 f(t) \ dt\]
</p>

<p>
On sait que :
</p>

<p>
\[\OD{}{ŧ} \left[ \unsur{2} (x - t)^2 \right] = (x - t) \cdot (-1) = - (x - t)\]
</p>

<p>
Posons \(u = \partial^2 f\) et :
</p>

<p>
\[v : t \mapsto \unsur{2} (x - t)^2\]
</p>

<p>
On a :
</p>

<p>
\[\int_a^x \partial v(t) \ u(t) \ dt = - \int_a^x (x - t) \ \partial^2 f(t) \ dt\]
</p>

<p>
et :
</p>

<p>
\[\int_a^x v(t) \ \partial u(t) \ dt = \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt\]
</p>

<p>
Enfin :
</p>

\begin{align}
\int_a^x \partial (v \cdot u)(t) \ dt &= \unsur{2} \ (x - x)^2 \ \partial^2 f(x) - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) \\
&= 0 - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) \\
&= - \unsur{2} \ (x - a)^2 \ \partial^2 f(a)
\end{align}

<p>
On en conclut que :
</p>

<p>
\[- \int_a^x (x - t) \ \partial^2 f(t) \ dt = - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) - \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt\]
</p>

<p>
ou encore :
</p>

<p>
\[\int_a^x (x - t) \ \partial^2 f(t) \ dt = \unsur{2} \ (x - a)^2 \ \partial^2 f(a) + \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt\]
</p>

<p>
Le développement du premier ordre peut dont se réécrire :
</p>

<p>
\[f(x) = f(a) + (x - a) \ \partial f(a) + \unsur{2} \ (x - a)^2 \ \partial^2 f(a) + \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt\]
</p>

<p>
Le membre de droite est appelé développement du second ordre de \(f\) sous forme intégrale.
</p>
</div>
</div>
<div id="outline-container-org7346b8c" class="outline-4">
<h4 id="org7346b8c"><span class="section-number-4">1.3.3.</span> Ordre \(N\)</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
Soit \(f \in \continue^{N + 1}([\alpha,\beta],\setR)\). On montre en intégrant par parties que :
</p>

<p>
\[\int_a^x (x - t)^{k - 1} \ \partial^k f(t) \ dt = \unsur{k} \ (x - a)^k \ \partial^k f(a) + \unsur{k} \int_a^x (x - t)^k \ \partial^{k + 1} f(t) \ dt\]
</p>

<p>
pour tout \(k \in \setZ[2,N]\). On en déduit par récurrence le développement de Taylor d'ordre \(N\) de \(f\) sous forme intégrale :
</p>

<p>
\[f(x) = \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(a) \cdot (x - a)^k + \unsur{N !} \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt\]
</p>
</div>
</div>
</div>
<div id="outline-container-org42c13ff" class="outline-3">
<h3 id="org42c13ff"><span class="section-number-3">1.4.</span> Erreur</h3>
<div class="outline-text-3" id="text-1-4">
<p>
On a :
</p>

<p>
\[E_a^N(f)(x) = f(x) - T_a^N(f)(x) = \unsur{N !} \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt\]
</p>

<p>
En appliquant le théorème de Cauchy entre \(a\) et \(x\) aux fonctions \(F,G\) définies par :
</p>

\begin{align}
F(z) &= \int_a^z (x - t)^N \ \partial^{N + 1} f(t) \ dt \\
G(z) &= \int_a^z (x - t)^N \ dt
\end{align}

<p>
pour tout \(z \in [\alpha,\beta]\), on voit que l'on peut trouver un \(c \in \intervalleouvert{a}{x}\) si \(a \strictinferieur x\) ou un \(c \in \intervalleouvert{x}{a}\) si \(x \strictinferieur a\) tel que :
</p>

<p>
\[(x - c)^N \ F(x) = (x - c)^N \ \partial^{N + 1} f(c) \ G(x)\]
</p>

<p>
ou encore :
</p>

<p>
\[\partial^{N + 1} f(c) \ G(x) = F(x)\]
</p>

<p>
Comme :
</p>

\begin{align}
G(x) = \int_a^x (x - t)^N \ dt &= - \big[ (x - x)^{N + 1} - (x - a)^{N + 1} \big] / (N + 1) \\
&= - \big[ 0 - (x - a)^{N + 1} \big] / (N + 1) \\
&= (x - a)^{N + 1} / (N + 1)
\end{align}

<p>
on a :
</p>

<p>
\[\partial^{N + 1} f(c) \ \frac{ (x - a)^{N + 1} }{N + 1} = F(x) = \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt\]
</p>

<p>
On en déduit que :
</p>

<p>
\[E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{ (x - a)^{N + 1} }{(N + 1) !}\]
</p>
</div>
</div>
<div id="outline-container-org3bc1ba3" class="outline-3">
<h3 id="org3bc1ba3"><span class="section-number-3">1.5.</span> Forme différentielle</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Soit une fonction \(f \in \continue^{N+1}([\alpha,\beta],\setR)\) et \(a,x \in [\alpha,\beta]\). On définit la fonction \(F : [\alpha,\beta] \mapsto \setR\) par :
</p>

\begin{align}
F(t) &= \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(t) \cdot (x - t)^k \\
&= f(t) + \partial f(t) \ (x - t) + \partial^2 f(t) \ \frac{(x - t)^2}{2} + ...
\end{align}

<p>
pour tout \(t \in [\alpha,\beta]\). On a :
</p>

<p>
\[F(x) = f(x) + \partial f(x) \ (x - x) + \partial^2 f(x) \frac{(x - x)^2}{2} + ... = f(x) + 0 = f(x)\]
</p>

<p>
et :
</p>

<p>
\[F(a) = f(a) + \partial f(a) \ (x - a) + \partial^2 f(a) \frac{(x - a)^2}{2} + ... = T_a^N(f)(x)\]
</p>

<p>
La dérivée de \(F\) s'écrit :
</p>

<div class="org-center">
<p>
\(
&part; F(t) = &part; f(t) + \big[ \partial f(t) \ (-1) + \partial^2 f(t) \ (x - t) \big] <br />
</p>
<ul class="org-ul">
<li>\left[ - &part;<sup>2</sup> f(t) \ (x - t) + &part;<sup>3</sup> f(t) \ \frac{(x-t)^2}{2} \right] <br /></li>
</ul>
<p>
&#x2026; <br />
</p>
<ul class="org-ul">
<li>\left[ - &part;<sup>N - 1</sup> f(t) \ \frac{(x - t)<sup>N - 2</sup>}{(N - 2) !} + &part;<sup>N</sup> f(t) \ \frac{(x-t)<sup>N - 1</sup>}{(N - 1) !} \right] <br /></li>
<li>\left[ - &part;<sup>N</sup> f(t) \ \frac{(x-t)<sup>N - 1</sup>}{(N - 1) !} + &part;<sup>N + 1</sup> f(t) \ \frac{(x-t)^N}{N !} \right]</li>
</ul>
<p>
\)
</p>
</div>

<p>
On voit que tous les termes s'annulent sauf le dernier, et :
</p>

<p>
\[\partial F(t) = \partial^{N + 1} f(t) \ \frac{(x-t)^N}{N !}\]
</p>

<p>
Soit \(G \in \continue^1([\alpha,\beta],\setR)\). On peut appliquer le théorème de Cauchy à \(F\) et \(G\) entre \(a\) et \(x\). On dispose alors d'un \(c \in \intervalleouver{a}{x}\) si \(a \strictinferieur x\) ou d'un \(c \in \intervalleouvert{x}{a}\) si \(x \strictinferieur a\) tel que :
</p>

<p>
\[\partial F(c) \ \big[G(x) - G(a)\big] = \big[F(x) - F(a)\big] \ \partial G(c)\]
</p>

<p>
On a :
</p>

<p>
\[F(x) - F(a) = f(x) - T_a^N(f)(x) = E_a^N(f)(x)\]
</p>

<p>
On en conclut que :
</p>

<p>
\[E_a^N(f)(x) \ \partial G(c) = \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ \big[G(x) - G(a)\big]\]
</p>
</div>
<div id="outline-container-orgbf446bc" class="outline-4">
<h4 id="orgbf446bc"><span class="section-number-4">1.5.1.</span> Forme de Lagrange</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
Soit le choix :
</p>

<p>
\[G : t \mapsto (x - t)^{N + 1}\]
</p>

<p>
on a :
</p>

<p>
\[G(x) = (x - x)^{N + 1} = 0\]
</p>

<p>
et :
</p>

<p>
\[G(a) = (x - a)^{N + 1}\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\partial G(t) = - (N  + 1) \ (x - t)^N\]
</p>

<p>
La relation de Cauchy devient :
</p>

<p>
\[- E_a^N(f)(x) \ (N  + 1) \ (x - c)^N = - \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ (x - a)^{N + 1}\]
</p>

<p>
On a donc l'expression de l'erreur :
</p>

<p>
\[E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{(x - a)^{N + 1}}{(N + 1) !}\]
</p>
</div>
</div>
<div id="outline-container-org4e2506e" class="outline-4">
<h4 id="org4e2506e"><span class="section-number-4">1.5.2.</span> Forme de Cauchy</h4>
<div class="outline-text-4" id="text-1-5-2">
<p>
Soit le choix :
</p>

<p>
\[G : t \mapsto t - a\]
</p>

<p>
on a :
</p>

<p>
\[G(x) = x - a\]
</p>

<p>
et :
</p>

<p>
\[G(a) = a - a = 0\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\partial G(t) = 1\]
</p>

<p>
La relation de Cauchy devient :
</p>

<p>
\[E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ (x - a)\]
</p>
</div>
</div>
</div>
<div id="outline-container-orge913a2d" class="outline-3">
<h3 id="orge913a2d"><span class="section-number-3">1.6.</span> Borne</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Soit \(f \in \continue^{N + 1}([\alpha,\beta],\setR)\). Comme \(\partial^{N+1} f\) est continue, sa norme \(\norme{.}_\infty\) sur \([\alpha,\beta]\) est finie et on a :
</p>

<p>
\[\abs{E_a^N(f)(x)} \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{x - a}^{N + 1} }{(N + 1) !}\]
</p>

<p>
On peut majorer cette expression en constatant que :
</p>

<p>
\[\abs{x - a} \le \abs{\beta - \alpha}\]
</p>

<p>
La borne de l'erreur devient alors :
</p>

<p>
\[\abs{E_a^N(f)(x)} \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}\]
</p>

<p>
Le membre de droite ne dépendant pas de \(x\), on a :
</p>

<p>
\[\norme{E_a^N(f)}_\infty \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}\]
</p>
</div>
</div>
<div id="outline-container-orga39e10a" class="outline-3">
<h3 id="orga39e10a"><span class="section-number-3">1.7.</span> Convergence</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Soit \(f \in \continue^\infty([\alpha,\beta],\setR)\). Si on peut trouver un \(\sigma \in \setR\) tel que :
</p>

<p>
\[\norme{\partial^n f}_\infty \le \sigma\]
</p>

<p>
pour tout \(n \in \setN\), on a :
</p>

<p>
\[\norme{E_a^N(f)}_\infty \le \sigma \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}\]
</p>

<p>
On en conclut que :
</p>

<p>
\[0 \le \lim_{N \to \infty} \norme{E_a^N(f)}_\infty \le \sigma \ \lim_{N \to \infty} \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !} = 0\]
</p>

<p>
L'erreur converge vers zéro quand \(N\) tend vers l'infini :
</p>

<p>
\[\lim_{N \to \infty} \norme{E_a^N(f)}_\infty = 0\]
</p>
</div>
</div>
<div id="outline-container-orgdf564e6" class="outline-3">
<h3 id="orgdf564e6"><span class="section-number-3">1.8.</span> Dimension \(n\)</h3>
<div class="outline-text-3" id="text-1-8">
</div>
<div id="outline-container-org42cc460" class="outline-4">
<h4 id="org42cc460"><span class="section-number-4">1.8.1.</span> Premier ordre</h4>
<div class="outline-text-4" id="text-1-8-1">
<p>
Soit \(\Omega \subseteq \setR^n\), la fonction \(f \in \continue^1(\Omega,\setR)\) et les vecteurs \(u,v \in \setR^n\) tels que le segment \([u,v]\) est inclus dans \(\Omega\). On définit la fonction \(\lambda : [0,1] \mapsto \setR^n\) associée au segment \([u,v]\) par :
</p>

<p>
\[\lambda(s) = u + s \cdot (v - u)\]
</p>

<p>
pour tout \(s \in [0,1]\), ainsi que la fonction \(\varphi = f \circ \lambda\) qui vérifie :
</p>

<p>
\[\varphi(s) = (f \circ \lambda)(s) = f(u + s \cdot (v - u))\]
</p>

<p>
pour tout \(s \in [0,1]\). On pose :
</p>

<p>
\[h = v - u\]
</p>

<p>
On a :
</p>

<p>
\[\varphi(0) = f(u)\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\partial \varphi(s) = \sum_i \partial_i f(u + s \cdot h) \cdot h_i\]
</p>

<p>
ou, en utilisant la notation matricielle :
</p>

<p>
\[\partial \varphi(s) = \partial f(u + s \cdot h) \cdot h\]
</p>

<p>
On a la valeur particulière :
</p>

<p>
\[\partial \varphi(0) = \partial f(u) \cdot h\]
</p>

<p>
La dérivée seconde s'écrit :
</p>

<p>
\[\partial^2 \varphi(s) = \sum_{i,j} h_j \cdot \partial^2_{ji} f(u + s \cdot h) \cdot h_i\]
</p>

<p>
ou, en utilisant la notation matricielle :
</p>

<p>
\[\partial^2 \varphi(s) = h^\dual \cdot \partial^2 f(u + s \cdot h) \cdot h\]
</p>

<p>
Le développement du premier ordre de \(\varphi\) autour de \(0\) s'écrit donc :
</p>

<p>
\[\varphi(s) = f(u) + s \cdot \partial f(u) \cdot h + E_u^1(s,h)\]
</p>

<p>
avec :
</p>

<p>
\[E_u^1(s,h) = h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{(c - 0)^2}{2} =  h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{c^2}{2}\]
</p>

<p>
pour un certain \(c \in \intervalleouvert{0}{s}\). Mais comme :
</p>

<p>
\[\varphi(1) = f(u + h) = f(v)\]
</p>

<p>
on en déduit le développement de \(f\) :
</p>

<p>
\[f(v) = f(u) + \partial f(u) \cdot (v - u) + \mathcal{E}_u^1(h)\]
</p>

<p>
avec :
</p>

<p>
\[\mathcal{E}_u^1(h) = h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{c^2}{2}\]
</p>

<p>
pour un certain \(c \in \intervalleouvert{0}{1}\).
</p>
</div>
<div id="outline-container-org26487ea" class="outline-5">
<h5 id="org26487ea"><span class="section-number-5">1.8.1.1.</span> Borne</h5>
<div class="outline-text-5" id="text-1-8-1-1">
<p>
Soit :
</p>

<p>
\[M^2 = \max_{i,j} \norme{\partial^2_{ij} f}_\infty\]
</p>

<p>
On a :
</p>

<p>
\[\abs{\mathcal{E}_u^1(h)} \le \unsur{2} \cdot n^2 \cdot M^2 \cdot \norme{h}^2\]
</p>
</div>
</div>
</div>
<div id="outline-container-orgcda656a" class="outline-4">
<h4 id="orgcda656a"><span class="section-number-4">1.8.2.</span> Second ordre</h4>
<div class="outline-text-4" id="text-1-8-2">
<p>
Soit \(f \in \continue^3(\Omega,\setR)\). Avec les mêmes notations que précédemment, on a :
</p>

<p>
\[\partial^2 \varphi(0) = h^\dual \cdot \partial^2 f(u) \cdot h\]
</p>

<p>
La dérivée tierce de \(\varphi\) s'écrit :
</p>

<p>
\[\partial^3 \varphi(s) = \sum_{i,j,k} \partial^3_{kji} f(u + s \cdot h) \cdot h_i \cdot h_j \cdot h_k\]
</p>

<p>
ou, en utilisant la notation tensorielle :
</p>

<p>
\[\partial^3 \varphi(s) = \partial^3 f(u + s \cdot h) : h \otimes h \otimes h\]
</p>

<p>
Le développement  du second ordre de \(\varphi\) autour de \(0\) s'écrit :
</p>

<p>
\[\varphi(s) = f(u) + s \ \partial f(u) \cdot h + \frac{s^2}{2} \ h^\dual \cdot \partial^2 f(u) \cdot h + E_u^2(s,h)\]
</p>

<p>
avec :
</p>

<p>
\[E_u^2(s,h) = \partial^3 f(u + c \cdot h) : h \otimes h \otimes h \cdot \frac{c^3}{6}\]
</p>

<p>
pour un certain \(c \in \intervalleouvert{0}{s}\). Mais comme :
</p>

<p>
\[\varphi(1) = f(u + h) = f(v)\]
</p>

<p>
on en déduit le développement de \(f\) :
</p>

<p>
\[f(v) = f(u) + \partial f(u) \cdot h + h^\dual \cdot \partial^2 f(u) \cdot h + \mathcal{E}_u^2(h)\]
</p>

<p>
avec :
</p>

<p>
\[\mathcal{E}_u^2(h) = \partial^3 f(u + c \cdot h) : h \otimes h \otimes h \cdot \frac{c^3}{6}\]
</p>

<p>
pour un certain \(c \in \intervalleouvert{0}{1}\).
</p>
</div>
<div id="outline-container-org8140abd" class="outline-5">
<h5 id="org8140abd"><span class="section-number-5">1.8.2.1.</span> Borne</h5>
<div class="outline-text-5" id="text-1-8-2-1">
<p>
Soit :
</p>

<p>
\[M^3 = \max_{i,j,k} \norme{\partial^3_{ijk} f}_\infty\]
</p>

<p>
On a :
</p>

<p>
\[\abs{\mathcal{E}_u^2(h)} \le \unsur{6} \cdot n^3 \cdot M^3 \cdot \norme{h}^3\]
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org52becd8" class="outline-3">
<h3 id="org52becd8"><span class="section-number-3">1.9.</span> Notation</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Soit la fonction \(E : \Omega \subseteq \setR^m \mapsto \setR^n\), la fonction \(b : \setR \mapsto \setR\) et le vecteur \(h \in \Omega\). On note \(E \sim \petito{b(h)}\), ou on dit que \(E\) est en \(\petito{b(h)}\), pour signifier que :
</p>

<p>
\[\lim_{h \to 0} \frac{ \norme{E(h)} }{b(\norme{h})} = 0\]
</p>

<p>
On note \(E \sim \grando{b(h)}\), ou on dit que \(E\) est en \(\grando{b(h)}\), pour signifier qu'il existe \(M \in \setR\) tel que :
</p>

<p>
\[\norme{E(h)} \le M \cdot b(\norme{h})\]
</p>

<p>
pour tout \(h \in \Omega\).
</p>
</div>
<div id="outline-container-org30fce24" class="outline-4">
<h4 id="org30fce24"><span class="section-number-4">1.9.1.</span> Puissance</h4>
<div class="outline-text-4" id="text-1-9-1">
<p>
Une famille de fonction souvent employée est la puissance :
</p>

<p>
\[b_k : x \mapsto x^k\]
</p>

<p>
pour un certain \(k \in \setN\). On a alors \(\petito{h^k}\) si :
</p>

<p>
\[\lim_{h \to 0} \frac{ \norme{E(h)} }{\norme{h}^k} = 0\]
</p>

<p>
et \(\grando{h^k}\) si :
</p>

<p>
\[\norme{E(h)} \le M \cdot \norme{h}^k\]
</p>
</div>
</div>
<div id="outline-container-orge99fc8a" class="outline-4">
<h4 id="orge99fc8a"><span class="section-number-4">1.9.2.</span> Relation</h4>
<div class="outline-text-4" id="text-1-9-2">
<p>
Si \(E \sim \grando{h^k}\), on a :
</p>

<p>
\[0 \le \lim_{h \to 0} \frac{\norme{E(h)}}{\norme{h}^{k - 1}} \le \lim_{h \to 0} \frac{M \ \norme{h}^k}{\norme{h}^{k - 1}} = 0\]
</p>

<p>
d'où :
</p>

<p>
\[\lim_{h \to 0} \frac{\norme{E(h)}}{\norme{h}^{k - 1}} = 0\]
</p>

<p>
et \(E \sim \petito{h^{k - 1}}\).
</p>
</div>
</div>
<div id="outline-container-org099a971" class="outline-4">
<h4 id="org099a971"><span class="section-number-4">1.9.3.</span> Cas particulier</h4>
<div class="outline-text-4" id="text-1-9-3">
<p>
Le \(\grando{1}\) implique une erreur bornée en valeur absolue, le \(\petito{1}\) implique la continuité et le \(\petito{h}\) la différentiabilité.
</p>
</div>
</div>
<div id="outline-container-orgccc280a" class="outline-4">
<h4 id="orgccc280a"><span class="section-number-4">1.9.4.</span> Développement de Taylor</h4>
<div class="outline-text-4" id="text-1-9-4">
<p>
Pour toute fonction \(f \in \continue^{N + 1}(\Omega, \setR^n)\), l'erreur \(E_a^N(f)\) du développement de Taylor d'ordre \(N\) est en \(\grando{h^{N+1}}\).
</p>
</div>
</div>
</div>
<div id="outline-container-org725773e" class="outline-3">
<h3 id="org725773e"><span class="section-number-3">1.10.</span> Extrapolation de Richardson</h3>
<div class="outline-text-3" id="text-1-10">
<p>
Supposons qu'une fonction \(v\) nous donne une approximation de \(V\) respectant :
</p>

<p>
\[v(h) \approx V + C \cdot h^m + O(h^{m+1})\]
</p>

<p>
pour un certain \(C \in \setR\) et pour tout \(h \in [0,R] \subseteq \setR\). L'entier \(m\) est appelé l'ordre de l'approximation. Supposons que l'on dispose de deux estimations de \(V_1 = v(h)\) et \(V_2 = v(h/k)\). On a alors :
</p>

<div class="org-center">
<p>
\(
V<sub>1</sub> = v(h) = V + C &sdot; h<sup>m</sup> + O(h<sup>m+1</sup>) <br />
V<sub>2</sub> = v\left(h/k\right) = V + C &sdot; \left(\frac{h}{k}\right)<sup>m</sup>
</p>
<ul class="org-ul">
<li>O(h<sup>m+1</sup>)</li>
</ul>
<p>
\)
</p>
</div>

<p>
On se sert de la première équation pour obtenir une expression de \(C \cdot h^m\) :
</p>

<p>
\[C \cdot h^m = V_1 - V + O(h^{m+1})\]
</p>

<p>
Posons :
</p>

<p>
\[r = \unsur{k^m}\]
</p>

<p>
On a alors :
</p>

<p>
\[V_2 = V + r \cdot C \cdot h^m + O(h^{m+1}) = V + r \cdot (V_1 - V) + O(h^{m+1})\]
</p>

<p>
On en conclut que :
</p>

<p>
\[(1 - r) \cdot V = V_2 - r \cdot V_1 + O(h^{m+1})\]
</p>

<p>
Ce qui nous donne l'approximation :
</p>

<p>
\[V = \frac{V_2 - r \cdot V_1}{1 - r} + O(h^{m+1})\]
</p>

<p>
Cette approximation est plus précise, car l'erreur n'est plus en \(O(h^m)\) mais en \(O(h^{m + 1})\). On appelle cette technique l'extrapolation de Richardson.
</p>
</div>
<div id="outline-container-org1c29cce" class="outline-4">
<h4 id="org1c29cce"><span class="section-number-4">1.10.1.</span> Cas particulier</h4>
<div class="outline-text-4" id="text-1-10-1">
<p>
Un cas particulier intéressant est celui où l'approximation est d'ordre \(1\) et où \(k = 2\). On a alors :
</p>

<p>
\[V = 2 V_2 - V_1 + O(h^2) = V_2 + (V_2 - V_1) + O(h^2)\]
</p>

<p>
ce qui revient à faire l'approximation \(V - V_2 \approx V_2 - V_1\).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org22a929f" class="outline-2">
<h2 id="org22a929f"><span class="section-number-2">2.</span> Développements d'Hadamard</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents-2" role="doc-toc">
<ul>
<li><a href="#org389caf9">2.1. Dépendances</a></li>
<li><a href="#org912e800">2.2. Lemme de Hadamard</a></li>
<li><a href="#org575fdfb">2.3. Développement du second ordre</a></li>
<li><a href="#orge3a5f37">2.4. Développement du troisième ordre</a></li>
</ul>
</div>

<p>
\label{chap:fonda}
</p>
</div>
<div id="outline-container-org389caf9" class="outline-3">
<h3 id="org389caf9"><span class="section-number-3">2.1.</span> Dépendances</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:differ} : Les différentielles</li>
<li>Chapitre \ref{chap:integral} : Les intégrales</li>
</ul>
</div>
</div>
<div id="outline-container-org912e800" class="outline-3">
<h3 id="org912e800"><span class="section-number-3">2.2.</span> Lemme de Hadamard</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Soit la fonction \(f : \setR^m \to \setR^n\) et les vecteurs \(u,v \in \setR^m\). On définit la fonction \(\lambda : [0,1] \mapsto \setR^m\) associée au segment \([u,v] \subseteq \setR^m\) par :
</p>

<p>
\[\lambda(s) = u + s \cdot (v - u)\]
</p>

<p>
pour tout \(s \in [0,1]\). On a bien entendu \(\lambda(0) = u\) et \(\lambda(1) = v\). On définit également la fonction \(\varphi = f \circ \lambda\) qui vérifie :
</p>

<p>
\[\varphi(s) = (f \circ \lambda)(s) = f(u + s \cdot (v - u))\]
</p>

<p>
pour tout \(t \in [0,1]\). On voit que \(\varphi(0) = f(u)\) et \(\varphi(1) = f(v)\). Donc, en termes de composantes dans \(\setR^n\), on a :
</p>

<p>
\[f_i(v) - f_i(u) = \varphi_i(1) - \varphi_i(0) = \int_0^1 \OD{\varphi_i}{s}(s) \ ds\]
</p>

<p>
où \(i \in \{1,2,...,n\}\).
</p>

<p>
Voyons quelle est la forme de la dérivée :
</p>

\begin{align}
\OD{\varphi_i}{s}(s) &= \sum_j \partial_j f_i(u + s \cdot (v - u)) \cdot \partial \lambda_j(s) \\
&= \sum_j \partial_j f_i(u + s \cdot (v - u)) \cdot (v_j - u_j)
\end{align}

<p>
où \(j \in \{1,2,...,m\}\). Si nous définissons :
</p>

<p>
\[G_{ij}(u,v) = \int_0^1 \partial_j f_i(u + s \cdot (v - u)) \ ds\]
</p>

<p>
nous obtenons alors l'expression de la variation :
</p>

<p>
\[f_i(v) - f_i(u) = \sum_j G_{ij}(u,v) \cdot (v_j - u_j)\]
</p>

<p>
En termes matriciels :
</p>

<p>
$$G(u,v) = \big[G<sub>ij</sub>(u,v)\big]<sub>i,j</sub> = \left[ \int_0^1 \partial_j f_i(u + s \cdot (v - u)) \ ds \right]<sub>i,j</sub>
</p>

<p>
est donc l'intégrale de la Jacobienne :
</p>

<p>
\[G(u,v) = \int_0^1 \partial f(u + s \cdot (v - u)) \ ds\]
</p>

<p>
et :
</p>

<p>
\[f(v) - f(u) = G(u,v) \cdot (v - u)\]
</p>
</div>
</div>
<div id="outline-container-org575fdfb" class="outline-3">
<h3 id="org575fdfb"><span class="section-number-3">2.3.</span> Développement du second ordre</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Soit la fonction \(f \in \continue^2(\setR^n,\setR)\) et les vecteurs \(a,h \in \setR^n\). On définit la fonction \(\lambda : [0,1] \mapsto \setR^n\) associée au segment \([a, a + h]\) :
</p>

<p>
\[\lambda(s) = a + s \cdot h\]
</p>

<p>
pour tout \(s \in [0,1]\). Le lemme de Hadamard nous dit que :
</p>

<p>
\[f(a + h) - f(a) = \int_0^1 \partial f(a + s \cdot h) \cdot h \ ds\]
</p>

<p>
Par définition de la dérivée seconde, on a :
</p>

<p>
\[\partial_i f(a + s \cdot h) = \partial_i f(a) + \sum_j \partial_{ji}^2 f(a) \cdot h_j \cdot s + e_i(s \cdot h)\]
</p>

<p>
où l'erreur \(e\) vérifie :
</p>

<p>
\[\lim_{h \to 0} \frac{ \norme{e(h)} }{ \norme{h} } = 0\]
</p>

<p>
L'intégrale s'écrit alors :
</p>

<p>
\[f(a + h) - f(a) = \sum_i \int_0^1 \left[ \partial_i f(a) + \sum_j \partial_{ji}^2 f(a) \cdot h_j \cdot s + e_i(s \cdot h) \right]  \cdot h_i \ ds\]
</p>

<p>
La grandeur \(\partial_i f(a) \cdot h_i\) ne dépendant pas de \(s\), on a :
</p>

<p>
\[\int_0^1 \partial_i f(a) \cdot h_i \ ds = \partial_i f(a) \cdot h_i \cdot (1 - 0) = \partial_i f(a) \cdot h_i\]
</p>

<p>
D'un autre coté, comme \(s^2/2\) est une primitive de \(s\), on a :
</p>

<p>
\[\int_0^1 s \ ds = \unsur{2} \cdot (1^2 - 0^2) = \unsur{2}\]
</p>

<p>
et donc :
</p>

<p>
\[\int_0^1 \partial_{ji}^2 f(a) \cdot h_j \cdot h_i \cdot s \ ds = \unsur{2} \partial_{ji}^2 f(a) \cdot h_j \cdot h_i\]
</p>

<p>
Posons :
</p>

<p>
\[\mathcal{E}_2(h) = \sum_i \int_0^1 e_i(s \cdot h) \cdot h_i \ ds\]
</p>

<p>
On a alors :
</p>

<p>
\[f(a + h) - f(a) = \sum_i \partial_i f(a) \cdot h_i + \unsur{2} \sum_{i,j} h_j \cdot \partial_{ji}^2 f(a) \cdot h_i + \mathcal{E}_2(h)\]
</p>

<p>
En termes matriciels, cette expression fait intervenir la Jacobienne et la Hessienne :
</p>

<p>
\[f(a + h) - f(a) = \partial f(a) \cdot h + \unsur{2} \ h^\dual \cdot \partial^2 f(a) \cdot h + \mathcal{E}_2(h)\]
</p>
</div>
<div id="outline-container-org76da5b3" class="outline-4">
<h4 id="org76da5b3"><span class="section-number-4">2.3.1.</span> Comportement de l'erreur</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
Nous savons que, pour toute précision \(\epsilon \strictsuperieur 0\), nous pouvons trouver un \(\delta \strictsuperieur 0\) tel que :
</p>

<p>
\[\frac{\norme{e(h)}}{\norme{h}} \le \epsilon\]
</p>

<p>
pour tout \(h\) vérifiant \(\norme{h} \le \delta\). Comme \(\abs{e_i} \le \norme{e}\) et \(\abs{h_i} \le \norme{h}\), on a alors :
</p>

\begin{align}
\abs{\mathcal{E}_2(h)} &\le \sum_i \abs{\int_0^1 e_i(s \cdot h) \cdot h_i \ ds} \\
&\le n \cdot \epsilon \cdot \norme{h}^2
\end{align}

<p>
L'erreur décroît donc plus vite que \(\norme{h}^2\) :
</p>

<p>
\[\lim_{h \to 0} \frac{ \abs{\mathcal{E}_2(h)} }{ \norme{h}^2 } = 0\]
</p>
</div>
</div>
<div id="outline-container-orgb0162ed" class="outline-4">
<h4 id="orgb0162ed"><span class="section-number-4">2.3.2.</span> Dérivées ordinaires</h4>
<div class="outline-text-4" id="text-2-3-2">
<p>
Lorsque \(n = 1\), le développement est simplement :
</p>

<p>
\[f(a + h) = f(a) + \OD{f}{x}(a) \cdot h + \OOD{f}{x}(a) \cdot \frac{h^2}{2} + \mathcal{E}_2(h)\]
</p>

<p>
On constate qu'il est analogue au développement de Taylor d'ordre deux autour de \(a\).
</p>
</div>
</div>
</div>
<div id="outline-container-orge3a5f37" class="outline-3">
<h3 id="orge3a5f37"><span class="section-number-3">2.4.</span> Développement du troisième ordre</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Soit la fonction \(f \in \continue^3(\setR^n,\setR)\) et les vecteurs \(a,h \in \setR^n\). En évaluant le développement du second ordre de chaque \(\partial_i f\), on a :
</p>

<p>
\[\partial_i f(a + s \cdot h) = \partial_i f(a) + \sum_j \partial_{ji} f(a) \cdot h_j \cdot s + \sum_{j,k} h_k \cdot \partial_{kji}^3 f(a) \cdot h_j \cdot \frac{s^2}{2} + e_i(h)\]
</p>

<p>
où \(e \sim \petito{h^2}\). En intégrant, nous obtenons une estimation de la variation de \(f\) :
</p>

<p>
\[f(a + h) - f(a) = \sum_i \int_0^1 \partial_i f(a + s \cdot h) \cdot h_i \ ds\]
</p>

<p>
Posons :
</p>

\begin{align}
I_1(h) &= \sum_i \int_0^1 \partial_i f(a) \cdot h_i \ ds \\
I_2(h) &= \sum_{i,j} \int_0^1 h_j \cdot \partial_{ji} f(a) \cdot h_i \cdot s \ ds \\
I_3(h) &= \unsur{2} \sum_{i,j,k} \int_0^1 h_k \cdot \partial_{kji}^3 f(a) \cdot h_j \cdot h_i \cdot s^2 \ ds \\
\mathcal{E}_3(h) &= \sum_i \int_0^1 e_i(h) \cdot h_i \ ds
\end{align}

<p>
Comme \(s^3/3\) est une primitive de \(s^2\), on a :
</p>

<p>
\[\int_0^1 s^2 \ ds = \unsur{3} \cdot (1^3 - 0^3) = \unsur{3}\]
</p>

<p>
Les intégrales s'écrivent donc :
</p>

\begin{align}
I_1(h) &= \sum_i \partial_i f(a) \cdot h_i \\
I_2(h) &= \unsur{2} \sum_{i,j} h_i \cdot \partial_{ji} f(a) \cdot h_j \\
I_3(h) &= \unsur{6} \sum_{i,j,k} \partial_{kji}^3 f(a) \cdot h_i \cdot h_j \cdot h_k
\end{align}

<p>
et la variation de \(f\) est donnée par :
</p>

<p>
\[f(a + h) - f(a) = I_1(h) + I_2(h) + I_3(h) + \mathcal{E}_3(h)\]
</p>

<p>
En terme de notations tensorielles, on peut l'écrire symboliquement :
</p>

<p>
\[f(a + h) - f(a) = \partial f(a) \cdot h + \unsur{2} h^\dual \cdot \partial^2 f(a) \cdot h + \unsur{6} \contraction{\partial^3 f(a)}{3}{h \otimes h \otimes h}\]
</p>
</div>
<div id="outline-container-orgf4a4933" class="outline-4">
<h4 id="orgf4a4933"><span class="section-number-4">2.4.1.</span> Comportement de l'erreur</h4>
<div class="outline-text-4" id="text-2-4-1">
<p>
Nous savons que, pour toute précision \(\epsilon \strictsuperieur 0\), nous pouvons trouver un \(\delta \strictsuperieur 0\) tel que :
</p>

<p>
\[\frac{\norme{e(h)}}{\norme{h}^2} \le \epsilon\]
</p>

<p>
pour tout \(h\) vérifiant \(\norme{h} \le \delta\). Comme \(\abs{e_i(h)} \le \norme{e(h)}\) et \(\abs{h_i} \le \norme{h}\), on a :
</p>

\begin{align}
\abs{\mathcal{E}_3(h)} &\le \sum_i \abs{\int_0^1 e_i(h) \cdot h_i \ ds} \\
&\le n \cdot \epsilon \cdot \norme{h}^3
\end{align}

<p>
L'erreur \(\abs{\mathcal{E}_3(h)}\) est donc en \(\petito{h^3}\).
</p>
</div>
</div>
<div id="outline-container-orgde51493" class="outline-4">
<h4 id="orgde51493"><span class="section-number-4">2.4.2.</span> Dérivées ordinaires</h4>
<div class="outline-text-4" id="text-2-4-2">
<p>
Lorsque \(n = 1\), le développement est simplement :
</p>

<p>
\[f(a + h) = f(a) + \OD{f}{x}(a) \cdot h + \OOD{f}{x}(a) \cdot \frac{h^2}{2} + \NOD{f}{x}{3} \cdot \frac{h^3}{6} + \mathcal{E}_3(h)\]
</p>

<p>
On constate qu'il est analogue au développement de Taylor d'ordre trois autour de \(a\).
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-09-19 ven 09:20</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
