
#+STARTUP: showall

#+TITLE: Eclats de vers : Matemat 09 : Analyse
#+AUTHOR: chimay
#+EMAIL: or du val chez gé courriel commercial
#+LANGUAGE: fr
#+LINK_HOME: file:../index.html
#+LINK_UP: file:index.html
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../style/defaut.css" />

#+OPTIONS: H:6
#+OPTIONS: toc:nil

#+TAGS: noexport(n)

[[file:index.org][Index des Grimoires]]

#+INCLUDE: "../include/navigan-1.org"

#+TOC: headlines 1

#+INCLUDE: "../include/commandes-tex.org"

* Théorème de Rolle

#+TOC: headlines 1 local

\label{chap:intediff}


** Dépendances

  - Chapitre \ref{chap:differ} : Les différentielles
  - Chapitre \ref{chap:integral} : Les intégrales


** Extrema locaux

Soit $f : A \mapsto \setR$ avec $A \subseteq \setR^n$. Supposons que $f$ soit différentiable et atteigne un minimum local en $a \in \interieur A$. On a :

#+BEGIN_CENTER
\(
f(a + h) - f(a) = \differentielle{f}{a}(h) + E(h) \\
f(a - h) - f(a) = - \differentielle{f}{a}(h) + E(-h)
\)
#+END_CENTER

Fixons $\epsilon \strictsuperieur 0$. On peut trouver $\delta_1 \strictsuperieur 0$ tel que :

$$\abs{E(h)} \le \epsilon \cdot \abs{h}$$

pour tout $h \in \boule(0,\delta_1)$. On peut aussi trouver $\delta_2 \strictsuperieur 0$ tel que :

$$f(a) \le f(a + h)$$

pour tout $h \in \boule(0,\delta_2)$. Posons $\delta = \min \{ \delta_1,\delta_2 \}$ et choisissons $h \in \boule(0,\delta)$. On a également $-h \in \boule(0,\delta)$. Donc :

#+BEGIN_CENTER
\(
\differentielle{f}{a}(h) = f(a + h) - f(a) - E(h) \ge - E(h) \ge - \epsilon \cdot \norme{-h} \\
\differentielle{f}{a}(h) = f(a) - f(a - h) + E(-h) \le E(-h) \le \epsilon \cdot \norme{h}
\)
#+END_CENTER

On en conclut que :

$$\abs{\differentielle{f}{a}(h)} \le \epsilon \cdot \norme{h}$$

Posons $\gamma = \delta / 2$ et remarquons que l'ensemble de norme fixe $N = \{ h \in \setR^n : \norme{h} = \gamma \}$ est inclus dans $\boule(0,\delta)$. Les propriétés des applications linéaires nous disent que :

$$\norme{\differentielle{f}{a}} = \sup \left\{ \unsur{\gamma} \norme{\differentielle{f}{a}(h)} : h \in N \right\}$$

Or, la borne nous dit que :

$$\unsur{\gamma} \abs{\differentielle{f}{a}(h)} \le \epsilon$$

quel que soit $\epsilon \strictsuperieur 0$ et $h \in N$. Donc :

$$\norme{\differentielle{f}{a}} = 0$$

ce qui implique que :

$$\differentielle{f}{a} = 0$$

La différentielle s'annule donc en un minimum local. On montre de la même manière que la différentielle s'annule en un maximum local.


*** La Jacobienne

La Jacobienne étant la représentation matricielle de la différentielle, elle s'annule également aux extrema locaux.


** Théorème de Rolle

Soit $f \in \continue^1([a,b],\setR)$ avec $f(a) = f(b)$. Comme $f$ est continue, il existe $\lambda,\sigma \in [a,b]$ tels que :

#+BEGIN_CENTER
\(
f(\lambda) = \min f([a,b]) \\
f(\sigma) = \max f([a,b])
\)
#+END_CENTER


*** Configurations

Plusieurs cas peuvent se présenter :


  - $\lambda \strictinferieur f(a) = f(b) \strictinferieur \sigma$ : dans ce cas, la fonction atteint ses deux bornes à l'intérieur de l'intervalle :

$$\{\lambda,\sigma\} \subseteq \intervalleouvert{a}{b}$$

Comme les extrema sont aussi des extrema locaux, on a :

$$\partial f(\lambda) = \partial f(\sigma) = 0$$

  - $\lambda \strictinferieur f(a) = f(b) = \sigma$ : dans ce cas, la fonction atteint son minimum à l'intérieur de l'intervalle :

$$\lambda \in \intervalleouvert{a}{b}$$

et on a :

$$\partial f(\lambda) = 0$$

  - $\lambda = f(a) = f(b) \strictinferieur \sigma$ : dans ce cas, la fonction atteint son maximum à l'intérieur de l'intervalle :

$$\sigma \in \intervalleouvert{a}{b}$$

et on a :

$$\partial f(\sigma) = 0$$

  - $\lambda = f(a) = f(b) = \sigma$ : dans ce cas, on a :

$$\lambda \le f(x) \le \sigma = \lambda$$

pour tout $x \in [a,b]$, et donc :

$$f(x) = \lambda$$

La fonction $f$ est constante et $\partial f = 0$. On peut donc prendre n'importe quel $c \in \intervalleouvert{a}{b}$, on aura :

$$\partial f(c) = 0$$



*** Conclusion

Dans tous les cas, on a au moins un $c \in \intervalleouvert{a}{b}$ tel que :

$$\partial f(c) = 0$$


** Théorème des accroissements finis

Soit $f \in \continue^1([a,b],\setR)$ et la fonction $g$ associée définie par :

$$g(x) = f(x) - \frac{f(b) - f(a)}{b - a} \cdot (x - a)$$

pour tout $x \in [a,b]$. Comme $g(a) = g(b) = f(a)$, on peut trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$0 = \partial g(c) = \partial f(c) - \frac{f(b) - f(a)}{b - a}$$

On a donc :

$$\partial f(c) = \frac{f(b)-f(a)}{b-a}$$

On vient ainsi de démontrer le théorème des accroissements finis.


*** Dimension $n$

On peut généraliser ce théorème à une fonction $f \in \continue^1(\setR^m,\setR^n)$. Soit $u,v \in \setR^m$. On considére le segment $[u,v]$ et la fonction associée $\phi : [0,1] \mapsto \setR^m$ définie par :

$$\phi(t) = u + t \cdot (v - u)$$

pour tout $t \in [0,1]$. On pose alors :

$$g(t) = (f \circ \phi)(t) = f( u + t \cdot (v - u))$$

pour tout $t \in [0,1]$. En appliquant le résultat précédent aux composantes $g_i$ sur l'intervalle $[0,1]$, on obtient un $s \in \intervalleouvert{0}{1}$ tel que :

$$\partial g_i(s) = \frac{g_i(1) - g_i(0)}{1 - 0} = g_i(1) - g_i(0) = f_i(v) - f_i(u)$$

En appliquant la formule permettant d'évaluer la dérivée d'une composition de fonctions, on obtient :

$$\partial g_i(s) = \sum_j \partial_j f_i(u + s \cdot (v - u)) \cdot (v_j - u_j)$$

Utilisant la notation matricielle, on a donc :

$$f(v) - f(u) = \partial f(u + s \cdot (v - u)) \cdot (v - u)$$

Ce qui revient à dire qu'il existe un $w \in [u,v] \subseteq \setR^n$ tel que :

$$f(v) - f(u) = \partial f(w) \cdot (v - u)$$


** Théorème de Cauchy

Le théorème des accroissements finis nous donne un résultat sous la forme
symbolique :

$$\OD{f}{x} = \frac{\difference f}{\difference x}$$

Nous allons maintenant généraliser ce théorème, et obtenir le résultat :

$$\frac{df}{dg} = \frac{\difference f}{\difference g}$$

où $f,g \in \continue^1([a,b],\setR)$ et $a,b \in \setR$. Considérons à cette fin la
fonction $h$ définie par :

$$h(x) = [f(b) - f(a)] \cdot g(x) - f(x) \cdot [ g(b) - g(a) ]$$

On remarque que :

\begin{align}
h(a) &= f(b) \cdot g(a) - f(a) \cdot g(a) -  f(a)\cdot g(b) +  f(a)\cdot g(a) \\
&= f(b) \cdot g(a) - f(a) \cdot g(b) \\ \\
h(b) &= f(b) \cdot g(b) - f(a) \cdot g(b) -  f(b)\cdot g(b) +  f(b)\cdot g(a) \\
&= f(b) \cdot g(a) - f(a) \cdot g(b)
\end{align}

Donc :

$$h(a) = h(b)$$

Appliquant le théorème de Rolle à $h$, on peut donc trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$0 = \partial h(c) = [f(b) - f(a)] \cdot \partial g(c) - \partial f(c) \cdot [ g(b) - g(a) ]$$

On a donc :

$$\left[ f(b) - f(a) \right] \cdot \partial g(c) = \partial f(c) \cdot \left[ g(b) - g(a) \right]$$

Si $\partial f(c) \ne 0$ et $f(b) \ne f(a)$, on peut le mettre sous la forme :

$$\frac{\partial g(c)}{\partial f(c)} = \frac{g(b) - g(a)}{f(b) - f(a)}$$


** Théorème de l'Hospital

Soient $F,G$ deux fonctions continues sur $I=[\alpha,\beta]$ et dérivables
$I\setminus \{a\}$, avec $a \in \interieur\ I$. Supposons que les deux fonctions s'annulent en $a$ :

$$F(a) = G(a) = 0$$

Soit alors $h \ne 0$ tel que $b = a+h\in I\setminus \{a\}$. En appliquant le théorème de Cauchy à $F$ et $G$, on trouve un $t \in \intervalleouvert{0}{1}$ tel que :

$$[F(b) - F(a)] \cdot \partial G(a + t \cdot h) = [G(b) - G(a)] \cdot \partial F(a + t \cdot h)$$

Mais comme $F$ et $G$ s'annulent en $a$, on a :

$$F(b) \cdot \partial G(a + t \cdot h) = G(b) \cdot \partial F(a + t \cdot h)$$

Si de plus $\partial G$ ne s'annule pas sur $I$, on peut écrire :

$$\frac{ \partial F(a + t \cdot h) }{ \partial G(a + t \cdot h) } = \frac{F(b)}{F(a)}$$

On voit en faisant tendre $h$ vers $0$ que les limites, si elles existent, doivent être identiques. On a donc :

$$\lim_{x \to a} \frac{F(x)}{G(x)} =  \lim_{x \to a} \frac{\partial F(a)}{\partial G(a)}$$


** Uniformité

Nous allons à présent montrer que toute fonction continument différentiable sur un intervalle de la forme $[\alpha,\beta]$ y est uniformément différentiable.

Soit une fonction $f \in \continue^1([\alpha,\beta],\setR)$. Comme la dérivée $\partial f$ est continue sur $[\alpha,\beta]$, elle y est uniformément continue. Fixons $\epsilon \strictsuperieur 0$. On peut donc trouver un $\delta \strictsuperieur 0$ tel que :

$$\abs{\partial f(s) - \partial f(t)} \le \epsilon$$

pour tout $s,t \in [\alpha,\beta]$ vérifiant $\abs{s - t} \le \delta$. Si $s = t$, on a bien évidemment :

$$\abs{f(t) - f(t) - \partial f(t) \cdot (t - t)} = 0 \le \epsilon \cdot (t - t) = 0$$

Considérons à présent le cas $s \ne t$. Nous pouvons supposer sans perte de généralité que $s \strictinferieur t$. Le théorème des accroissements finis nous dit qu'on peut trouver un $\gamma \in ]s,t[$ tel que :

$$\partial f(\gamma) = \frac{f(t) - f(s)}{t - s}$$

On a donc :

$$\frac{f(t) - f(s)}{t - s} - \partial f(s) = \partial f(\gamma) - \partial f(s)$$

Mais comme $\abs{\gamma - s} \le \abs{t - s} \le \delta$, on a $\abs{\partial f(\gamma) - \partial f(s)} \le \epsilon$ et :

$$\abs{\frac{f(t) - f(s)}{t - s} - \partial f(s)} \le \epsilon$$

On a donc bien :

$$\abs{f(t) - f(s) - \partial f(s) \cdot (t - s)} \le \epsilon \cdot \abs{t - s}$$

pour tout $s,t \in [\alpha,\beta]$ vérifiant $\abs{s - t} \le \delta$.


*** Remarque

Le théorème {\em n'est pas} applicable aux autres types d'intervalles. Cela ne marche pas sur $]\alpha,\beta[$ par exemple.



* Théorème fondamental

#+TOC: headlines 1 local

\label{chap:fonda}


** Dépendances

  - Chapitre \ref{chap:differ} : Les différentielles
  - Chapitre \ref{chap:integral} : Les intégrales


** Dérivée de l'intégrale

\label{sec:derivee_integrale}

Soit une fonction $f \in \continue([\alpha,\beta],\setR)$, un réel $a \in [\alpha,\beta]$ et la fonction intégrale associée $I : [\alpha,\beta] \mapsto \setR$ définie par :

$$I(x) = \int_a^x f(s) \ ds$$

pour tout $x \in [\alpha,\beta]$. On constate que :

$$I(a) = \int_a^a f(s) \ ds = \int_{ \{a\} } f(s) \ ds$$

La mesure de Lebesgue du singleton $\{a\}$ étant nulle, l'intégrale s'annule et on a :

$$I(a) = 0$$

Nous allons chercher à évaluer la dérivée de la fonction intégrale $I$ en un point quelconque $b \in [\alpha,\beta]$.

Nous utilisons dans la suite la notation abrégée :

$$\int_x^y = \int_x^y f(s) \ ds$$

Par additivité, on a :

$$\int_a^{b + h} = \int_a^b + \int_b^{b + h}$$

c'est-à-dire :

$$I(b + h) = I(b) + \int_b^{b + h}$$

pour tout réel $h$ tel que $b + h \in [\alpha,\beta]$. Quelle est la valeur de l'intégrale sur $[b, b + h]$ ? Fixons $\epsilon \strictsuperieur 0$. Par continuité de $f$, on peut choisir $\delta > 0$ tel que :

$$\abs{f(b + s) - f(b)} \le \epsilon$$

pour tout $s$ vérifiant $\abs{s} \le \delta$. Cela n'est possible que si :

$$f(b) - \epsilon \le f(b + s) \le f(b) + \epsilon$$

On a donc :

#+BEGIN_CENTER
\(
\sup \Big\{ f(b + s) : \abs{s} \le \delta \Big\} \le f(b) + \epsilon \\
\inf \Big\{ f(b + s) : \abs{s} \le \delta \Big\} \ge f(b) - \epsilon
\)
#+END_CENTER

Si nous choisissons $h \in (0,\delta)$, l'intégrale peut donc être majorée et minorée par :

$$\int_b^{b + h} \le (f(b) + \epsilon) \cdot \mu_L([a, a + h]) = (f(b) + \epsilon) \cdot h$$

et :

$$\int_b^{b + h} \ge (f(b) - \epsilon) \cdot \mu_L([a, a + h]) = (f(b) - \epsilon) \cdot h$$

Nous disposons donc des inégalités :

$$(f(b) - \epsilon) \cdot h \le \int_b^{b + h} \le (f(b) + \epsilon) \cdot h$$

Autrement dit :

$$f(b) - \epsilon \le \unsur{h} \int_b^{b + h} \le f(b) + \epsilon$$

D'un autre coté, on a :

$$\unsur{h} \int_b^{b + h} f(s) \ ds = \frac{I(b + h) - I(b)}{h}$$

Passons à la limite $\delta \to 0$. On a alors $h \to 0$ et :

$$f(b) - \epsilon \le \lim_{h \to 0} \unsur{h} \int_b^{b + h} \le f(b) + \epsilon$$

Ces inégalités devant être valables pour tout $\epsilon \strictsuperieur 0$, on a forcément :

$$\lim_{h \to 0} \frac{I(b + h) - I(b)}{h} = f(b)$$

On en conclut que $I$ est dérivable et que :

$$\OD{I}{x}(b) = \lim_{h \to 0} \frac{I(b + h) - I(b)}{h} = f(b)$$

Autrement dit :

$$\OD{}{x} \int_a^x f(s) \ ds = f(x)$$


** Intégrale de la dérivée

\label{sec:integrale_derivee}

Soit $\alpha,\beta \in \setR$ avec $\alpha \le \beta$. Soit la fonction $F \in \continue^1([\alpha,\beta],\setR)$ et sa dérivée continue :

$$f = \partial F = \OD{F}{s}$$

Comme $F$ est continument différentiable sur $[\alpha,\beta]$, elle y est uniformément différentiable. De même, $f$ est continue sur $[\alpha,\beta]$. Elle y est donc uniformément continue. Nous allons tenter d'évaluer l'intégrale :

$$\int_a^b f(s) \ ds = \int_a^b \OD{F}{x}(s) \ ds$$

avec $a,b \in [\alpha,\beta]$ et $a \le b$.

Nous utilisons dans la suite la notation abrégée :

$$\int_x^y = \int_x^y f(s) \ ds$$


*** L'idée

L'idée intuitive est que :

$$\difference F = \sum_i \difference F_i = \sum_i \frac{ \difference F_i }{ \difference x_i } \cdot \difference x_i$$

En passant à la limite $\difference x_i \to 0$, on soupçonne alors le résultat suivant :

$$\difference F = \int_a^b \OD{F}{x} \ dx$$


*** La réalisation

Fixons $\epsilon \strictsuperieur 0$. Comme $f$ est uniformément continue, nous savons qu'il existe $\vartheta \strictsuperieur 0$ tel que :

$$\abs{f(x + h) - f(x)} \le \epsilon$$

pour tout $x,h$ vérifiant $x,x + h \in [\alpha,\beta]$ et $\abs{h} \le \vartheta$. On en déduit que :

#+BEGIN_CENTER
\(
\sup_{\xi \in [x - \vartheta , x + \vartheta]} f(\xi) \le f(x) + \epsilon \\
\inf_{\xi \in [x - \vartheta , x + \vartheta]} f(\xi) \ge f(x) - \epsilon
\)
#+END_CENTER

On a donc les bornes pour l'intégrale :

$$(f(x) - \epsilon) \cdot h \le \int_x^{x + h} \le (f(x) + \epsilon) \cdot h$$

Comme $F$ est uniformément différentiable, nous pouvons trouver $\varpi \strictsuperieur 0$ tel que :

$$\abs{F(x + h) - F(x) - f(x) \cdot h} \le \epsilon \cdot h$$

pour tout $x,h$ vérifiant $x,x + h \in [\alpha,\beta]$ et $\abs{h} \le \varpi$. On en déduit que :

#+BEGIN_CENTER
\(
F(x + h) - F(x) - f(x) \cdot h \le \epsilon \cdot h \\
f(x) \cdot h - (F(x + h) - F(x)) \le \epsilon \cdot h
\)
#+END_CENTER

En considérant ces deux inégalités par rapport au centre $f(x) \cdot h$, on obtient :

$$F(x + h) - F(x) - \epsilon \cdot h \le f(x) \cdot h \le F(x + h) - F(x) + \epsilon \cdot h$$

En soustrayant ou en ajoutant $\epsilon \cdot h$ à ces inégalités, on a :

\begin{align}
F(x + h) - F(x) - 2 \epsilon \cdot h &\le f(x) \cdot h - \epsilon \cdot h \le& F(x + h) - F(x) \\
F(x + h) - F(x) &\le f(x) \cdot h + \epsilon \cdot h \le& F(x + h) - F(x) + 2 \epsilon \cdot h
\end{align}

Si $\abs{h} \le \min \{ \vartheta , \varpi \}$, nous avons de nouvelles bornes pour l'intégrale :

$$F(x + h) - F(x) - 2 \epsilon \cdot h \le \int_x^{x + h} \le F(x + h) - F(x) + 2 \epsilon \cdot h$$

Choisissons à présent $n \in \setN$ tel que :

$$\abs{ \frac{b - a}{n} } \le \min \{ \vartheta , \varpi \}$$

Posons $h = (b - a)/n$ et définissons la série :

$$x_i = a + i \cdot h$$

On a alors $a = x_0 \le x_1 \le ... \le x_n = b$. Les propriétés des sommes nous disent que :

$$\sum_{i = 1}^n (F(x_i) - F(x_{i - 1})) = F(x_n) - F(x_0) = F(b) - F(a)$$

D'un autre coté, on a clairement :

$$\sum_{i = 1}^n \int_{ x_{i - 1} }^{x_i} = \int_a^b$$

Si nous appliquons les bornes précédentes avec $x = x_{i - 1}$, nous avons $x + h = x_i$ et :

$$F(x_i) - F(x_{i - 1}) - 2 \epsilon \cdot h \le \int_{ x_{i - 1} }^{x_i} \le F(x_i) - F(x_{i - 1}) + 2 \epsilon \cdot h$$

En sommant sur $i = 1,2,...,n$, nous obtenons par conséquent :

$$F(b) - F(a) - 2 \epsilon \cdot h \cdot n \le \int_a^b \le F(b) - F(a) + 2 \epsilon \cdot h \cdot n$$

Mais comme $h \cdot n = b - a$, cela devient :

$$F(b) - F(a) - 2 \epsilon \cdot (b - a) \le \int_a^b \le F(b) - F(a) + 2 \epsilon \cdot (b - a)$$

Ces bornes devant être satisfaites pour tout $\epsilon \strictsuperieur 0$, on en déduit que :

$$\int_a^b = F(b) - F(a)$$

On a donc finalement :

$$\int_a^b f(s) \ ds = \int_a^b \OD{F}{s}(s) \ ds = F(b) - F(a)$$


*** Primitive

Cette relation permet de calculer l'intégrale d'une fonction continue $f : t \mapsto f(t)$ lorsqu'on connaît une fonction $F$ vérifiant :

$$\OD{F}{t} = f$$

On appelle « primitive » de $f$ une telle fonction $F$.


*** Notation

On note aussi :

$$\difference F = \int dF$$


** Polynômes

On sait que :

$$\OD{}{t}\big(t^n\big) = n \cdot t^{n - 1}$$

Comme $n$ est constante, on peut le réécrire :

$$\OD{}{t}\left( \frac{t^n}{n} \right) = t^{n - 1}$$

ou, en posant $m = n - 1$ :

$$\OD{}{t}\left( \frac{t^{m + 1}}{m + 1} \right) = t^m$$

L'intégrale s'écrit donc :

$$\int_a^b t^m \ dt = \frac{ b^{m + 1} - a^{m + 1} }{m + 1}$$

On a en particulier :

$$\int_0^x t^m \ dt = \frac{ x^{m + 1} }{m + 1}$$


*** Exemples

$$\int_0^x t \ dt = \frac{ x^2 }{2}$$

$$\int_0^x t^2 \ dt = \frac{ x^3 }{3}$$


** Valeur moyenne


*** Accroissements finis

Soit des réels distincts $a,b$ vérifiant $a \strictinferieur b$, la fonction $f \in \continue([a,b],\setR)$ et la fonction $F : [a,b] \mapsto \setR$ définie par :

$$F(x) = \int_a^x f(t) \ dt$$

pour tout $x \in [a,b]$. Comme $F \in \continue^1([a,b],\setR)$, le théorème des accroissements finis nous dit qu'on peut trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$\partial F(c) = \frac{F(b) - F(a)}{b - a}$$

On sait que :

$$\partial F(c) = f(c)$$

On a aussi :

$$F(b) = \int_a^b f(t) \ dt$$

et :

$$F(a) = \int_a^a f(t) \ dt = \int_{ \{ a \} } f(t) \ dt$$

La mesure de Lebesgue du singleton $\{a\}$ étant nulle, l'intégrale s'annule et on a :

$$F(a) = 0$$

On a donc $F(b) - F(a) = F(b)$ et :

$$f(c) = \unsur{b - a} \int_a^b f(t) \ dt$$


*** Théorème de Cauchy

Soit des réels distincts $a,b$ vérifiant $a \strictinferieur b$, les fonctions $f,g \in \continue([a,b],\setR)$ et les fonction $F,G : [a,b] \mapsto \setR$ définies par :

\begin{align}
F(x) &= \int_a^x f(t) \ dt \\
G(x) &= \int_a^x g(t) \ dt
\end{align}

pour tout $x \in [a,b]$. Comme $F,G \in \continue^1([a,b],\setR)$, le théorème de Cauchy nous dit qu'on peut trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$\partial F(c) \cdot \big[G(b) - G(a)\big] = \big[F(b) - F(a)\big] \cdot \partial G(c)$$

On sait que :

#+BEGIN_CENTER
\(
\partial F(c) = f(c) \\
\partial G(c) = g(c)
\)
#+END_CENTER

On a aussi :

\begin{align}
F(b) &= \int_a^b f(t) \ dt \\
G(b) &= \int_a^b g(t) \ dt
\end{align}

et :

\begin{align}
F(a) &= \int_a^a f(t) \ dt = 0 \\
G(a) &= \int_a^a g(t) \ dt = 0
\end{align}

On en conclut que :

$$f(c) \ \int_a^b g(t) \ dt = g(c) \ \int_a^b f(t) \ dt$$

Si l'intégrale de $g$ et $g(c)$ sont non nuls, on peut mettre cette relation sous la forme :

$$\frac{f(c)}{g(c)} = \frac{ \int_a^b f(t) \ dt }{ \int_a^b g(t) \ dt }$$


** Intégration par parties

Soient $f,g \in \continue^1(\setR,\setR)$. On se rappelle que :

$$\partial (f \cdot g) = \partial f \cdot g + f \cdot \partial g$$

et comme on a :

$$\int_a^b \partial (f \cdot g) \ dx = f(b) \cdot g(b) - f(a) \cdot g(a)$$

on obtient la formule d'intégration par parties :

$$\int_a^b f(x) \cdot \partial g(x) \ dx = (f \cdot g)(b) - (f \cdot g)(a) - \int_a^b \partial f(x) \cdot g(x) \ dx$$


*** Stieltjes

Le résultat est également valable lorsqu'on utilise les mesures de Stieltjes associées à $f$ et $g$ :

$$\int_a^b f(x) \cdot dg(x) = \difference (f \cdot g) - \int_a^b g(x) \cdot df(x)$$


*** Dérivée constante

On considère le cas particulier où $\partial g = 1$. Une exemple de fonction $g$ vérifiant cette propriété est simplement $g = \identite$. On a donc $g(x) = x$ et :

$$\int_a^b f(x) \ dx = \int_a^b f(x) \cdot 1 \ dx = \int_a^b f(x) \cdot \partial g(x) \ dx$$

L'intégration par parties nous donne :

$$\int_a^b f(x) \ dx = f(b) \cdot b - f(a) \cdot a - \int_a^b \partial f(x) \cdot x \ dx$$


** Changement de variable

Considérons une fonction $f \in \continue(\setR,\setR)$ et un changement de variable $x = \varphi(s)$ où $\varphi \in \homeomorphisme^1(\setR,\setR)$. Soit la mesure de lebesgue $\mu([\alpha,\beta]) = \beta - \alpha$.


*** L'idée

$$\sum_i f_i \cdot \difference x_i = \sum_i f_i \cdot \frac{\difference x_i}{\difference s_i} \cdot \difference s_i$$

On devrait donc avoir par passage à la limite :

$$\int f \ dx = \int f \ \OD{x}{s} \ ds$$


*** La réalisation

On applique le même procédé qu'à la section \ref{sec:integrale_derivee}. Si $x$ est proche de $y$, on a :

$$\int_x^y \approx f(x) \cdot (y - x)$$

Posant $s = \varphi^{-1}(x)$ et $t = \varphi^{-1}(y)$, on a aussi :

$$y - x = \varphi(t) - \varphi(s) = \OD{\varphi}{s}(s) \cdot (t - s) + e(\abs{s - t})$$

où $e$ converge plus vite que $s - t$ vers $0$. On en conclut que :

$$\int_x^y \approx (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s) \cdot (t - s)$$

On remarque que le second membre est une approximation de l'intégrale de la fonction :

$$F(s) = (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s)$$

sur l'intervalle $[s,t] = [\varphi^{-1}(x),\varphi^{-1}(y)]$. Il ne nous reste plus qu'à sommer sur tous les petits intervalles $[x_{i - 1},x_i]$ et à passer à la limite $h = x_i - x_{i - 1} \to 0$ pour obtenir :

$$\int_a^b f(x) \ dx = \int_{\varphi^{-1}(a)}^{\varphi^{-1}(b)} (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s) \ ds$$


* Développements de Taylor

#+TOC: headlines 1 local

** Polynômes de Taylor

Considérons un polynôme $p : \setR \mapsto \setR$ de degré $n$ défini par :

$$p(x) = \sum_{i = 0}^n \gamma_i \cdot x^i$$

pour tout $x \in \setR$. Calculons ses dérivées :

\begin{align}
\partial p(x) &= \sum_{i = 1}^n \gamma_i \cdot i \cdot x^{i - 1} \\
\partial^2 p(x) &= \sum_{i = 2}^n \gamma_i \cdot i \cdot (i - 1) \cdot x^{i - 2} \\
\vdots \\
\partial^k p(x) &= \sum_{i = k}^n \gamma_i \cdot \frac{i !}{(i - k) !} \cdot x^{i - k} \\
\vdots \\
\partial^n p(x) &= n! \cdot \gamma_n
\end{align}

Lorsqu'on évalue ces dérivées en $0$, seuls les termes en $x^{k - k} = 1$ ne s'annulent pas. On obtient donc :

$$\partial^k p(0) = \frac{k !}{0 !} \cdot \gamma_k = k ! \cdot \gamma_k$$

ce qui nous donne l'expression des coefficients de $p$ en fonction de ses dérivées en $0$ :

$$\gamma_k = \unsur{k !} \cdot \partial^k p(0)$$

Le polynôme peut donc se réécrire :

$$p(x) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(0) \cdot x^i$$

Cette expression est appelée développement de Taylor de $p$ autour de $0$.


*** Généralisation

Soit $a \in \setR$. La fonction $r$ définie par :

$$r(t) = p(t + a) = \sum_{i = 0}^n \gamma_i \cdot (t + a)^i$$

pour tout $t \in \setR$ est clairement un polynôme de degré $n$. On a $r(0) = p(a)$ et plus généralement :

$$\partial^i r(0) = \partial^i p(a)$$

pout tout $i \ge 0$. Le développement de Taylor de $r$ autour de $0$ s'écrit :

$$r(t) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i r(0) \cdot t^i$$

ou encore :

$$r(t) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(a) \cdot t^i$$

En posant $x = t + a$, on a $t = x - a$ et :

$$p(x) = p(t + a) = r(t)$$

Le développement devient :

$$p(x) = \sum_{i = 0}^n \unsur{i !} \cdot \partial^i p(a) \cdot (x - a)^i$$

Cette expression est nommée développement de Taylor de $p$ autour de $a$.


** Opérateur de Taylor

Soit $\alpha, \beta \in \setR$ avec $\alpha \strictinferieur \beta$, une fonction $f \in \continue^N([\alpha,\beta],\setR)$ et $a \in [\alpha,\beta]$. Par analogie avec le développement de Taylor des polynômes, on définit l'opérateur de Taylor $T_a^N$ par :

$$T_a^N(f)(x) = \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(a) \cdot (x - a)^k$$

pour tout $x \in [\alpha,\beta]$.


*** Erreur

L'erreur $E_a^N$ de l'opérateur $T_a^N$ est donnée par :

$$E_a^N(f)(x) = f(x) - T_a^N(f)(x)$$

pour tout $x \in [\alpha,\beta]$.


*** Polynômes

Si $p$ est un polynôme de degré $N$, on a bien entendu $T_a^N(p) = p$ pour tout $a \in \setR$ et $E_a^N(p) = 0$.


** Forme intégrale


*** Premier ordre

Soit $\alpha, \beta \in \setR$ avec $\alpha \strictinferieur \beta$ et la fonction $f \in \continue^2([\alpha,\beta],\setR)$. Le théorème fondamental nous dit que :

$$\int_a^x \partial f(t) \ dt = f(x) - f(a)$$

pour tout $a,x \in [\alpha,\beta]$. Appliquant le même théorème à la dérivée $\partial f$, on a aussi :

$$\int_a^x \partial^2 f(t) \ dt = \partial f(x) - \partial f(a)$$


**** Intégration par parties

Soit $u = \partial f$ et $v = \identite$. on a :

$$\int_a^x u(x) \ \partial v(x) \ dx = \int_a^x \partial f(t) \cdot 1 \ dt = \int_a^x \partial f(t) \ dt$$

L'intégration par parties nous donne :

$$\int_a^x u(x) \ \partial v(x) \ dx = v(x) \ u(x) - v(a) \ u(a) - \int_a^x v(t) \ \partial u(t) \ dt$$

En tenant compte des définitions de $u$ et $v$, on obtient :

$$\int_a^x \partial f(t) \ dt = x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt$$


Appliquons le théorème fondamental au membre de gauche :

$$f(x) - f(a) = x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt$$

ou encore :

$$f(x) = f(a) + x \ \partial f(x) - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt$$

En multipliant la relation :

$$\partial f(x) - \partial f(a) = \int_a^x \partial^2 f(t) \ dt$$

par $x$, on arrive au résultat :

$$x \ \partial f(x) = x \ \partial f(a) + \int_a^x x \ \partial^2 f(t) \ dt$$

L'expression de $f(x)$ devient alors :

$$f(x) = f(a) + x \ \partial f(a) + \int_a^x x \ \partial^2 f(t) \ dt - a \ \partial f(a) - \int_a^x t \ \partial^2 f(t) \ dt$$

et finalement :

$$f(x) = f(a) + (x - a) \cdot \partial f(a) + \int_a^x (x - t) \cdot \partial^2 f(t) \ dt$$

Le membre de droite est appelé développement de Taylor du premier ordre de $f$ sous forme intégrale.


*** Second ordre

Soit $f \in \continue^3([\alpha,\beta],\setR)$. Comme $\continue^3 \subseteq \continue^2$, $f$ admet un développement de Taylor du premier ordre sous forme intégrale. Nous allons intégrer par parties le terme :

$$\int_a^x (x - t) \cdot \partial^2 f(t) \ dt$$

On sait que :

$$\OD{}{ŧ} \left[ \unsur{2} (x - t)^2 \right] = (x - t) \cdot (-1) = - (x - t)$$

Posons $u = \partial^2 f$ et :

$$v : t \mapsto \unsur{2} (x - t)^2$$

On a :

$$\int_a^x \partial v(t) \ u(t) \ dt = - \int_a^x (x - t) \ \partial^2 f(t) \ dt$$

et :

$$\int_a^x v(t) \ \partial u(t) \ dt = \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt$$

Enfin :

\begin{align}
\int_a^x \partial (v \cdot u)(t) \ dt &= \unsur{2} \ (x - x)^2 \ \partial^2 f(x) - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) \\
&= 0 - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) \\
&= - \unsur{2} \ (x - a)^2 \ \partial^2 f(a)
\end{align}

On en conclut que :

$$- \int_a^x (x - t) \ \partial^2 f(t) \ dt = - \unsur{2} \ (x - a)^2 \ \partial^2 f(a) - \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt$$

ou encore :

$$\int_a^x (x - t) \ \partial^2 f(t) \ dt = \unsur{2} \ (x - a)^2 \ \partial^2 f(a) + \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt$$

Le développement du premier ordre peut dont se réécrire :

$$f(x) = f(a) + (x - a) \ \partial f(a) + \unsur{2} \ (x - a)^2 \ \partial^2 f(a) + \unsur{2} \int_a^x (x - t)^2 \ \partial^3 f(t) \ dt$$

Le membre de droite est appelé développement du second ordre de $f$ sous forme intégrale.


*** Ordre $N$

Soit $f \in \continue^{N + 1}([\alpha,\beta],\setR)$. On montre en intégrant par parties que :

$$\int_a^x (x - t)^{k - 1} \ \partial^k f(t) \ dt = \unsur{k} \ (x - a)^k \ \partial^k f(a) + \unsur{k} \int_a^x (x - t)^k \ \partial^{k + 1} f(t) \ dt$$

pour tout $k \in \setZ[2,N]$. On en déduit par récurrence le développement de Taylor d'ordre $N$ de $f$ sous forme intégrale :

$$f(x) = \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(a) \cdot (x - a)^k + \unsur{N !} \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt$$


** Erreur

On a :

$$E_a^N(f)(x) = f(x) - T_a^N(f)(x) = \unsur{N !} \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt$$

En appliquant le théorème de Cauchy entre $a$ et $x$ aux fonctions $F,G$ définies par :

\begin{align}
F(z) &= \int_a^z (x - t)^N \ \partial^{N + 1} f(t) \ dt \\
G(z) &= \int_a^z (x - t)^N \ dt
\end{align}

pour tout $z \in [\alpha,\beta]$, on voit que l'on peut trouver un $c \in \intervalleouvert{a}{x}$ si $a \strictinferieur x$ ou un $c \in \intervalleouvert{x}{a}$ si $x \strictinferieur a$ tel que :

$$(x - c)^N \ F(x) = (x - c)^N \ \partial^{N + 1} f(c) \ G(x)$$

ou encore :

$$\partial^{N + 1} f(c) \ G(x) = F(x)$$

Comme :

\begin{align}
G(x) = \int_a^x (x - t)^N \ dt &= - \big[ (x - x)^{N + 1} - (x - a)^{N + 1} \big] / (N + 1) \\
&= - \big[ 0 - (x - a)^{N + 1} \big] / (N + 1) \\
&= (x - a)^{N + 1} / (N + 1)
\end{align}

on a :

$$\partial^{N + 1} f(c) \ \frac{ (x - a)^{N + 1} }{N + 1} = F(x) = \int_a^x (x - t)^N \ \partial^{N + 1} f(t) \ dt$$

On en déduit que :

$$E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{ (x - a)^{N + 1} }{(N + 1) !}$$


** Forme différentielle

Soit une fonction $f \in \continue^{N+1}([\alpha,\beta],\setR)$ et $a,x \in [\alpha,\beta]$. On définit la fonction $F : [\alpha,\beta] \mapsto \setR$ par :

\begin{align}
F(t) &= \sum_{k = 0}^N \unsur{k !} \cdot \partial^k f(t) \cdot (x - t)^k \\
&= f(t) + \partial f(t) \ (x - t) + \partial^2 f(t) \ \frac{(x - t)^2}{2} + ...
\end{align}

pour tout $t \in [\alpha,\beta]$. On a :

$$F(x) = f(x) + \partial f(x) \ (x - x) + \partial^2 f(x) \frac{(x - x)^2}{2} + ... = f(x) + 0 = f(x)$$

et :

$$F(a) = f(a) + \partial f(a) \ (x - a) + \partial^2 f(a) \frac{(x - a)^2}{2} + ... = T_a^N(f)(x)$$

La dérivée de $F$ s'écrit :

#+BEGIN_CENTER
\(
\partial F(t) = \partial f(t) + \big[ \partial f(t) \ (-1) + \partial^2 f(t) \ (x - t) \big] \\
+ \left[ - \partial^2 f(t) \ (x - t) + \partial^3 f(t) \ \frac{(x-t)^2}{2} \right] \\
... \\
+ \left[ - \partial^{N - 1} f(t) \ \frac{(x - t)^{N - 2}}{(N - 2) !} + \partial^N f(t) \ \frac{(x-t)^{N - 1}}{(N - 1) !} \right] \\
+ \left[ - \partial^N f(t) \ \frac{(x-t)^{N - 1}}{(N - 1) !} + \partial^{N + 1} f(t) \ \frac{(x-t)^N}{N !} \right]
\)
#+END_CENTER

On voit que tous les termes s'annulent sauf le dernier, et :

$$\partial F(t) = \partial^{N + 1} f(t) \ \frac{(x-t)^N}{N !}$$

Soit $G \in \continue^1([\alpha,\beta],\setR)$. On peut appliquer le théorème de Cauchy à $F$ et $G$ entre $a$ et $x$. On dispose alors d'un $c \in \intervalleouver{a}{x}$ si $a \strictinferieur x$ ou d'un $c \in \intervalleouvert{x}{a}$ si $x \strictinferieur a$ tel que :

$$\partial F(c) \ \big[G(x) - G(a)\big] = \big[F(x) - F(a)\big] \ \partial G(c)$$

On a :

$$F(x) - F(a) = f(x) - T_a^N(f)(x) = E_a^N(f)(x)$$

On en conclut que :

$$E_a^N(f)(x) \ \partial G(c) = \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ \big[G(x) - G(a)\big]$$


*** Forme de Lagrange

Soit le choix :

$$G : t \mapsto (x - t)^{N + 1}$$

on a :

$$G(x) = (x - x)^{N + 1} = 0$$

et :

$$G(a) = (x - a)^{N + 1}$$

La dérivée s'écrit :

$$\partial G(t) = - (N  + 1) \ (x - t)^N$$

La relation de Cauchy devient :

$$- E_a^N(f)(x) \ (N  + 1) \ (x - c)^N = - \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ (x - a)^{N + 1}$$

On a donc l'expression de l'erreur :

$$E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{(x - a)^{N + 1}}{(N + 1) !}$$


*** Forme de Cauchy

Soit le choix :

$$G : t \mapsto t - a$$

on a :

$$G(x) = x - a$$

et :

$$G(a) = a - a = 0$$

La dérivée s'écrit :

$$\partial G(t) = 1$$

La relation de Cauchy devient :

$$E_a^N(f)(x) = \partial^{N + 1} f(c) \ \frac{(x-c)^N}{N !} \ (x - a)$$


** Borne

Soit $f \in \continue^{N + 1}([\alpha,\beta],\setR)$. Comme $\partial^{N+1} f$ est continue, sa norme $\norme{.}_\infty$ sur $[\alpha,\beta]$ est finie et on a :

$$\abs{E_a^N(f)(x)} \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{x - a}^{N + 1} }{(N + 1) !}$$

On peut majorer cette expression en constatant que :

$$\abs{x - a} \le \abs{\beta - \alpha}$$

La borne de l'erreur devient alors :

$$\abs{E_a^N(f)(x)} \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}$$

Le membre de droite ne dépendant pas de $x$, on a :

$$\norme{E_a^N(f)}_\infty \le \norme{\partial^{N + 1} f}_\infty \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}$$


** Convergence

Soit $f \in \continue^\infty([\alpha,\beta],\setR)$. Si on peut trouver un $\sigma \in \setR$ tel que :

$$\norme{\partial^n f}_\infty \le \sigma$$

pour tout $n \in \setN$, on a :

$$\norme{E_a^N(f)}_\infty \le \sigma \ \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !}$$

On en conclut que :

$$0 \le \lim_{N \to \infty} \norme{E_a^N(f)}_\infty \le \sigma \ \lim_{N \to \infty} \frac{ \abs{\beta - \alpha}^{N + 1} }{(N + 1) !} = 0$$

L'erreur converge vers zéro quand $N$ tend vers l'infini :

$$\lim_{N \to \infty} \norme{E_a^N(f)}_\infty = 0$$


** Dimension $n$


*** Premier ordre

Soit $\Omega \subseteq \setR^n$, la fonction $f \in \continue^1(\Omega,\setR)$ et les vecteurs $u,v \in \setR^n$ tels que le segment $[u,v]$ est inclus dans $\Omega$. On définit la fonction $\lambda : [0,1] \mapsto \setR^n$ associée au segment $[u,v]$ par :

$$\lambda(s) = u + s \cdot (v - u)$$

pour tout $s \in [0,1]$, ainsi que la fonction $\varphi = f \circ \lambda$ qui vérifie :

$$\varphi(s) = (f \circ \lambda)(s) = f(u + s \cdot (v - u))$$

pour tout $s \in [0,1]$. On pose :

$$h = v - u$$

On a :

$$\varphi(0) = f(u)$$

La dérivée s'écrit :

$$\partial \varphi(s) = \sum_i \partial_i f(u + s \cdot h) \cdot h_i$$

ou, en utilisant la notation matricielle :

$$\partial \varphi(s) = \partial f(u + s \cdot h) \cdot h$$

On a la valeur particulière :

$$\partial \varphi(0) = \partial f(u) \cdot h$$

La dérivée seconde s'écrit :

$$\partial^2 \varphi(s) = \sum_{i,j} h_j \cdot \partial^2_{ji} f(u + s \cdot h) \cdot h_i$$

ou, en utilisant la notation matricielle :

$$\partial^2 \varphi(s) = h^\dual \cdot \partial^2 f(u + s \cdot h) \cdot h$$

Le développement du premier ordre de $\varphi$ autour de $0$ s'écrit donc :

$$\varphi(s) = f(u) + s \cdot \partial f(u) \cdot h + E_u^1(s,h)$$

avec :

$$E_u^1(s,h) = h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{(c - 0)^2}{2} =  h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{c^2}{2}$$

pour un certain $c \in \intervalleouvert{0}{s}$. Mais comme :

$$\varphi(1) = f(u + h) = f(v)$$

on en déduit le développement de $f$ :

$$f(v) = f(u) + \partial f(u) \cdot (v - u) + \mathcal{E}_u^1(h)$$

avec :

$$\mathcal{E}_u^1(h) = h^\dual \cdot \partial^2 f(u + c \cdot h) \cdot h \cdot \frac{c^2}{2}$$

pour un certain $c \in \intervalleouvert{0}{1}$.


**** Borne

Soit :

$$M^2 = \max_{i,j} \norme{\partial^2_{ij} f}_\infty$$

On a :

$$\abs{\mathcal{E}_u^1(h)} \le \unsur{2} \cdot n^2 \cdot M^2 \cdot \norme{h}^2$$


*** Second ordre

Soit $f \in \continue^3(\Omega,\setR)$. Avec les mêmes notations que précédemment, on a :

$$\partial^2 \varphi(0) = h^\dual \cdot \partial^2 f(u) \cdot h$$

La dérivée tierce de $\varphi$ s'écrit :

$$\partial^3 \varphi(s) = \sum_{i,j,k} \partial^3_{kji} f(u + s \cdot h) \cdot h_i \cdot h_j \cdot h_k$$

ou, en utilisant la notation tensorielle :

$$\partial^3 \varphi(s) = \partial^3 f(u + s \cdot h) : h \otimes h \otimes h$$

Le développement  du second ordre de $\varphi$ autour de $0$ s'écrit :

$$\varphi(s) = f(u) + s \ \partial f(u) \cdot h + \frac{s^2}{2} \ h^\dual \cdot \partial^2 f(u) \cdot h + E_u^2(s,h)$$

avec :

$$E_u^2(s,h) = \partial^3 f(u + c \cdot h) : h \otimes h \otimes h \cdot \frac{c^3}{6}$$

pour un certain $c \in \intervalleouvert{0}{s}$. Mais comme :

$$\varphi(1) = f(u + h) = f(v)$$

on en déduit le développement de $f$ :

$$f(v) = f(u) + \partial f(u) \cdot h + h^\dual \cdot \partial^2 f(u) \cdot h + \mathcal{E}_u^2(h)$$

avec :

$$\mathcal{E}_u^2(h) = \partial^3 f(u + c \cdot h) : h \otimes h \otimes h \cdot \frac{c^3}{6}$$

pour un certain $c \in \intervalleouvert{0}{1}$.


**** Borne

Soit :

$$M^3 = \max_{i,j,k} \norme{\partial^3_{ijk} f}_\infty$$

On a :

$$\abs{\mathcal{E}_u^2(h)} \le \unsur{6} \cdot n^3 \cdot M^3 \cdot \norme{h}^3$$


** Notation

Soit la fonction $E : \Omega \subseteq \setR^m \mapsto \setR^n$, la fonction $b : \setR \mapsto \setR$ et le vecteur $h \in \Omega$. On note $E \sim \petito{b(h)}$, ou on dit que $E$ est en $\petito{b(h)}$, pour signifier que :

$$\lim_{h \to 0} \frac{ \norme{E(h)} }{b(\norme{h})} = 0$$

On note $E \sim \grando{b(h)}$, ou on dit que $E$ est en $\grando{b(h)}$, pour signifier qu'il existe $M \in \setR$ tel que :

$$\norme{E(h)} \le M \cdot b(\norme{h})$$

pour tout $h \in \Omega$.


*** Puissance

Une famille de fonction souvent employée est la puissance :

$$b_k : x \mapsto x^k$$

pour un certain $k \in \setN$. On a alors $\petito{h^k}$ si :

$$\lim_{h \to 0} \frac{ \norme{E(h)} }{\norme{h}^k} = 0$$

et $\grando{h^k}$ si :

$$\norme{E(h)} \le M \cdot \norme{h}^k$$


*** Relation

Si $E \sim \grando{h^k}$, on a :

$$0 \le \lim_{h \to 0} \frac{\norme{E(h)}}{\norme{h}^{k - 1}} \le \lim_{h \to 0} \frac{M \ \norme{h}^k}{\norme{h}^{k - 1}} = 0$$

d'où :

$$\lim_{h \to 0} \frac{\norme{E(h)}}{\norme{h}^{k - 1}} = 0$$

et $E \sim \petito{h^{k - 1}}$.


*** Cas particulier

Le $\grando{1}$ implique une erreur bornée en valeur absolue, le $\petito{1}$ implique la continuité et le $\petito{h}$ la différentiabilité.


*** Développement de Taylor

Pour toute fonction $f \in \continue^{N + 1}(\Omega, \setR^n)$, l'erreur $E_a^N(f)$ du développement de Taylor d'ordre $N$ est en $\grando{h^{N+1}}$.


** Extrapolation de Richardson

Supposons qu'une fonction $v$ nous donne une approximation de $V$ respectant :

$$v(h) \approx V + C \cdot h^m + O(h^{m+1})$$

pour un certain $C \in \setR$ et pour tout $h \in [0,R] \subseteq \setR$. L'entier $m$ est appelé l'ordre de l'approximation. Supposons que l'on dispose de deux estimations de $V_1 = v(h)$ et $V_2 = v(h/k)$. On a alors :

#+BEGIN_CENTER
\(
V_1 = v(h) = V + C \cdot h^m + O(h^{m+1}) \\
V_2 = v\left(h/k\right) = V + C \cdot \left(\frac{h}{k}\right)^m
+ O(h^{m+1})
\)
#+END_CENTER

On se sert de la première équation pour obtenir une expression de $C \cdot h^m$ :

$$C \cdot h^m = V_1 - V + O(h^{m+1})$$

Posons :

$$r = \unsur{k^m}$$

On a alors :

$$V_2 = V + r \cdot C \cdot h^m + O(h^{m+1}) = V + r \cdot (V_1 - V) + O(h^{m+1})$$

On en conclut que :

$$(1 - r) \cdot V = V_2 - r \cdot V_1 + O(h^{m+1})$$

Ce qui nous donne l'approximation :

$$V = \frac{V_2 - r \cdot V_1}{1 - r} + O(h^{m+1})$$

Cette approximation est plus précise, car l'erreur n'est plus en $O(h^m)$ mais en $O(h^{m + 1})$. On appelle cette technique l'extrapolation de Richardson.


*** Cas particulier

Un cas particulier intéressant est celui où l'approximation est d'ordre $1$ et où $k = 2$. On a alors :

$$V = 2 V_2 - V_1 + O(h^2) = V_2 + (V_2 - V_1) + O(h^2)$$

ce qui revient à faire l'approximation $V - V_2 \approx V_2 - V_1$.


* Développements d'Hadamard

#+TOC: headlines 1 local

\label{chap:fonda}


** Dépendances

  - Chapitre \ref{chap:differ} : Les différentielles
  - Chapitre \ref{chap:integral} : Les intégrales


** Lemme de Hadamard

Soit la fonction $f : \setR^m \to \setR^n$ et les vecteurs $u,v \in \setR^m$. On définit la fonction $\lambda : [0,1] \mapsto \setR^m$ associée au segment $[u,v] \subseteq \setR^m$ par :

$$\lambda(s) = u + s \cdot (v - u)$$

pour tout $s \in [0,1]$. On a bien entendu $\lambda(0) = u$ et $\lambda(1) = v$. On définit également la fonction $\varphi = f \circ \lambda$ qui vérifie :

$$\varphi(s) = (f \circ \lambda)(s) = f(u + s \cdot (v - u))$$

pour tout $t \in [0,1]$. On voit que $\varphi(0) = f(u)$ et $\varphi(1) = f(v)$. Donc, en termes de composantes dans $\setR^n$, on a :

$$f_i(v) - f_i(u) = \varphi_i(1) - \varphi_i(0) = \int_0^1 \OD{\varphi_i}{s}(s) \ ds$$

où $i \in \{1,2,...,n\}$.

Voyons quelle est la forme de la dérivée :

\begin{align}
\OD{\varphi_i}{s}(s) &= \sum_j \partial_j f_i(u + s \cdot (v - u)) \cdot \partial \lambda_j(s) \\
&= \sum_j \partial_j f_i(u + s \cdot (v - u)) \cdot (v_j - u_j)
\end{align}

où $j \in \{1,2,...,m\}$. Si nous définissons :

$$G_{ij}(u,v) = \int_0^1 \partial_j f_i(u + s \cdot (v - u)) \ ds$$

nous obtenons alors l'expression de la variation :

$$f_i(v) - f_i(u) = \sum_j G_{ij}(u,v) \cdot (v_j - u_j)$$

En termes matriciels :

$$G(u,v) = \big[G_{ij}(u,v)\big]_{i,j} = \left[ \int_0^1 \partial_j f_i(u + s \cdot (v - u)) \ ds \right]_{i,j}

est donc l'intégrale de la Jacobienne :

$$G(u,v) = \int_0^1 \partial f(u + s \cdot (v - u)) \ ds$$

et :

$$f(v) - f(u) = G(u,v) \cdot (v - u)$$


** Développement du second ordre

Soit la fonction $f \in \continue^2(\setR^n,\setR)$ et les vecteurs $a,h \in \setR^n$. On définit la fonction $\lambda : [0,1] \mapsto \setR^n$ associée au segment $[a, a + h]$ :

$$\lambda(s) = a + s \cdot h$$

pour tout $s \in [0,1]$. Le lemme de Hadamard nous dit que :

$$f(a + h) - f(a) = \int_0^1 \partial f(a + s \cdot h) \cdot h \ ds$$

Par définition de la dérivée seconde, on a :

$$\partial_i f(a + s \cdot h) = \partial_i f(a) + \sum_j \partial_{ji}^2 f(a) \cdot h_j \cdot s + e_i(s \cdot h)$$

où l'erreur $e$ vérifie :

$$\lim_{h \to 0} \frac{ \norme{e(h)} }{ \norme{h} } = 0$$

L'intégrale s'écrit alors :

$$f(a + h) - f(a) = \sum_i \int_0^1 \left[ \partial_i f(a) + \sum_j \partial_{ji}^2 f(a) \cdot h_j \cdot s + e_i(s \cdot h) \right]  \cdot h_i \ ds$$

La grandeur $\partial_i f(a) \cdot h_i$ ne dépendant pas de $s$, on a :

$$\int_0^1 \partial_i f(a) \cdot h_i \ ds = \partial_i f(a) \cdot h_i \cdot (1 - 0) = \partial_i f(a) \cdot h_i$$

D'un autre coté, comme $s^2/2$ est une primitive de $s$, on a :

$$\int_0^1 s \ ds = \unsur{2} \cdot (1^2 - 0^2) = \unsur{2}$$

et donc :

$$\int_0^1 \partial_{ji}^2 f(a) \cdot h_j \cdot h_i \cdot s \ ds = \unsur{2} \partial_{ji}^2 f(a) \cdot h_j \cdot h_i$$

Posons :

$$\mathcal{E}_2(h) = \sum_i \int_0^1 e_i(s \cdot h) \cdot h_i \ ds$$

On a alors :

$$f(a + h) - f(a) = \sum_i \partial_i f(a) \cdot h_i + \unsur{2} \sum_{i,j} h_j \cdot \partial_{ji}^2 f(a) \cdot h_i + \mathcal{E}_2(h)$$

En termes matriciels, cette expression fait intervenir la Jacobienne et la Hessienne :

$$f(a + h) - f(a) = \partial f(a) \cdot h + \unsur{2} \ h^\dual \cdot \partial^2 f(a) \cdot h + \mathcal{E}_2(h)$$


*** Comportement de l'erreur

Nous savons que, pour toute précision $\epsilon \strictsuperieur 0$, nous pouvons trouver un $\delta \strictsuperieur 0$ tel que :

$$\frac{\norme{e(h)}}{\norme{h}} \le \epsilon$$

pour tout $h$ vérifiant $\norme{h} \le \delta$. Comme $\abs{e_i} \le \norme{e}$ et $\abs{h_i} \le \norme{h}$, on a alors :

\begin{align}
\abs{\mathcal{E}_2(h)} &\le \sum_i \abs{\int_0^1 e_i(s \cdot h) \cdot h_i \ ds} \\
&\le n \cdot \epsilon \cdot \norme{h}^2
\end{align}

L'erreur décroît donc plus vite que $\norme{h}^2$ :

$$\lim_{h \to 0} \frac{ \abs{\mathcal{E}_2(h)} }{ \norme{h}^2 } = 0$$


*** Dérivées ordinaires

Lorsque $n = 1$, le développement est simplement :

$$f(a + h) = f(a) + \OD{f}{x}(a) \cdot h + \OOD{f}{x}(a) \cdot \frac{h^2}{2} + \mathcal{E}_2(h)$$

On constate qu'il est analogue au développement de Taylor d'ordre deux autour de $a$.


** Développement du troisième ordre

Soit la fonction $f \in \continue^3(\setR^n,\setR)$ et les vecteurs $a,h \in \setR^n$. En évaluant le développement du second ordre de chaque $\partial_i f$, on a :

$$\partial_i f(a + s \cdot h) = \partial_i f(a) + \sum_j \partial_{ji} f(a) \cdot h_j \cdot s + \sum_{j,k} h_k \cdot \partial_{kji}^3 f(a) \cdot h_j \cdot \frac{s^2}{2} + e_i(h)$$

où $e \sim \petito{h^2}$. En intégrant, nous obtenons une estimation de la variation de $f$ :

$$f(a + h) - f(a) = \sum_i \int_0^1 \partial_i f(a + s \cdot h) \cdot h_i \ ds$$

Posons :

\begin{align}
I_1(h) &= \sum_i \int_0^1 \partial_i f(a) \cdot h_i \ ds \\
I_2(h) &= \sum_{i,j} \int_0^1 h_j \cdot \partial_{ji} f(a) \cdot h_i \cdot s \ ds \\
I_3(h) &= \unsur{2} \sum_{i,j,k} \int_0^1 h_k \cdot \partial_{kji}^3 f(a) \cdot h_j \cdot h_i \cdot s^2 \ ds \\
\mathcal{E}_3(h) &= \sum_i \int_0^1 e_i(h) \cdot h_i \ ds
\end{align}

Comme $s^3/3$ est une primitive de $s^2$, on a :

$$\int_0^1 s^2 \ ds = \unsur{3} \cdot (1^3 - 0^3) = \unsur{3}$$

Les intégrales s'écrivent donc :

\begin{align}
I_1(h) &= \sum_i \partial_i f(a) \cdot h_i \\
I_2(h) &= \unsur{2} \sum_{i,j} h_i \cdot \partial_{ji} f(a) \cdot h_j \\
I_3(h) &= \unsur{6} \sum_{i,j,k} \partial_{kji}^3 f(a) \cdot h_i \cdot h_j \cdot h_k
\end{align}

et la variation de $f$ est donnée par :

$$f(a + h) - f(a) = I_1(h) + I_2(h) + I_3(h) + \mathcal{E}_3(h)$$

En terme de notations tensorielles, on peut l'écrire symboliquement :

$$f(a + h) - f(a) = \partial f(a) \cdot h + \unsur{2} h^\dual \cdot \partial^2 f(a) \cdot h + \unsur{6} \contraction{\partial^3 f(a)}{3}{h \otimes h \otimes h}$$


*** Comportement de l'erreur

Nous savons que, pour toute précision $\epsilon \strictsuperieur 0$, nous pouvons trouver un $\delta \strictsuperieur 0$ tel que :

$$\frac{\norme{e(h)}}{\norme{h}^2} \le \epsilon$$

pour tout $h$ vérifiant $\norme{h} \le \delta$. Comme $\abs{e_i(h)} \le \norme{e(h)}$ et $\abs{h_i} \le \norme{h}$, on a :

\begin{align}
\abs{\mathcal{E}_3(h)} &\le \sum_i \abs{\int_0^1 e_i(h) \cdot h_i \ ds} \\
&\le n \cdot \epsilon \cdot \norme{h}^3
\end{align}

L'erreur $\abs{\mathcal{E}_3(h)}$ est donc en $\petito{h^3}$.


*** Dérivées ordinaires

Lorsque $n = 1$, le développement est simplement :

$$f(a + h) = f(a) + \OD{f}{x}(a) \cdot h + \OOD{f}{x}(a) \cdot \frac{h^2}{2} + \NOD{f}{x}{3} \cdot \frac{h^3}{6} + \mathcal{E}_3(h)$$

On constate qu'il est analogue au développement de Taylor d'ordre trois autour de $a$.


* Symétrie

#+TOC: headlines 1 local

Soit la fonction $f \in \continue^2(\setR^2,\setR)$. Posons $\partial_x = \partial_1$ et $\partial_y = \partial_2$. Nous allons tenter d'évaluer les dérivées secondes $\partial_{xy} = \partial_{12}$ et $\partial_{yx} = \partial_{21}$. On note :

\begin{align}
\varphi_{11} &= \varphi(x,y) \\
\varphi_{21} &= \varphi(x + h, y) \\
\varphi_{12} &= \varphi(x, y + h) \\
\varphi_{22} &= \varphi(x + h, y + h)
\end{align}

où $\varphi = f$ ou une de ses dérivées. Comme $\partial_{xy} = \partial_x \partial_y$ et $\partial_{yx} = \partial_y \partial_x$, on a par définition :

#+BEGIN_CENTER
\(
\Delta_{xy} = \partial_y f_{21} - \partial_y f_{11} = \partial_{xy} f_{11} \cdot h + o(h) \\
\Delta_{yx} = \partial_x f_{12} - \partial_x f_{11} = \partial_{yx} f_{11} \cdot h + o(h)
\)
#+END_CENTER

Multiplié par $h$, cela devient :

#+BEGIN_CENTER
\(
\Delta_{xy} \cdot h = \partial_{xy} f_{11} \cdot h^2 + o(h^2) \\
\Delta_{yx} \cdot h = \partial_{yx} f_{11} \cdot h^2 + o(h^2)
\)
#+END_CENTER

On dispose également des développements d'ordre deux :

#+BEGIN_CENTER
\(
f_{22} - f_{21} = \partial_y f_{21} \cdot h + \partial_{yy} f_{21} \cdot \frac{h^2}{2} + o(h^2) \\
f_{12} - f_{11} = \partial_y f_{11} \cdot h + \partial_{yy} f_{11} \cdot \frac{h^2}{2} + o(h^2) \\
f_{22} - f_{12} = \partial_x f_{12} \cdot h + \partial_{xx} f_{12} \cdot \frac{h^2}{2} + o(h^2) \\
f_{12} - f_{11} = \partial_x f_{11} \cdot h + \partial_{xx} f_{11} \cdot \frac{h^2}{2} + o(h^2)
\)
#+END_CENTER

On en conclut que :

#+BEGIN_CENTER
\(
\Delta_{xy} \cdot h = D + \Delta_{yy} + o(h^2) \\
\Delta_{yx} \cdot h = D + \Delta_{xx} + o(h^2)
\)
#+END_CENTER

où l'on a posé :

#+BEGIN_CENTER
\(
D = f_{22} - f_{21} - f_{12} + f_{11} \\
\Delta_{yy} = (\partial_{yy} f_{11} - \partial_{yy} f_{21}) \cdot h^2 \\
\Delta_{xx} = (\partial_{xx} f_{11} -  \partial_{xx} f_{12}) \cdot h^2
\)
#+END_CENTER

Par continuité de $\partial_{xx} f$ et de $\partial_{yy} f$, on a :

#+BEGIN_CENTER
\(
\lim_{h \to 0} \frac{\Delta_{yy}}{h^2} = \lim_{h \to 0} (\partial_{yy} f_{11} - \partial_{yy} f_{21}) = 0 \\
\lim_{h \to 0} \frac{\Delta_{xx}}{h^2} = \lim_{h \to 0} (\partial_{xx} f_{11} -  \partial_{xx} f_{12}) = 0
\)
#+END_CENTER

On en conclut que $\Delta_{xx}, \Delta_{yy} \sim o(h^2)$. Comme la somme de deux erreurs en $o(h^2)$ donne également une erreur en $o(h^2)$, on a :

#+BEGIN_CENTER
\(
\Delta_{xy} \cdot h = D + o(h^2) + o(h^2) = D + o(h^2) \\
\Delta_{yx} \cdot h = D + o(h^2) + o(h^2) = D + o(h^2)
\)
#+END_CENTER

et :

#+BEGIN_CENTER
\(
\partial_{xy} f_{11} \cdot h^2 = D + o(h^2) \\
\partial_{yx} f_{11} \cdot h^2 = D + o(h^2)
\)
#+END_CENTER

On en conclut que la différence $\partial_{xy} f_{11} - \partial_{yx} f_{11} \sim o(1)$ tend vers $0$ avec $h$, ce qui n'est possible que si :

$$\partial_{xy} f_{11} = \partial_{yx} f_{11}$$

Nous avons donc prouvé que :

$$\partial_{xy} f(x,y) = \partial_{yx} f(x,y)$$


*** Généralisation

On peut bien entendu généraliser à une fonction $f \in \continue^2(\setR^n,\setR)$. On a alors :

$$\partial_{ij} f = \partial_{ji} f$$

où $i,j \in \{1,2,...,n\}$. Si $H = \partial^2 f$, on écrit aussi ce résultat sous la forme :

$$H^\dual = H$$


** Dérivation par rapport à un paramètre

Nous allons a présent examiner ce qu'il se passe lorsque les bornes de l'intervalle d'intégration ($a,b : \setR \mapsto \setR$) et la fonction à intégrer ($f : \setR \times \setR \mapsto \setR$) varient par rapport à un paramètre. Soit la fonction $I : \setR \mapsto \setR$ définie par :

$$I(t) = \int_{a(t)}^{b(t)} f(s,t) \ ds$$

Pour une valeur donnée de $t$, posons :

$$\phi_t(s) = f(s,t)$$

L'intégrale de $\phi_t$ peut s'évaluer si nous connaissons une primitive $\psi_t$ telle que :

$$\OD{\psi_t}{s}(s) = \phi_t(s)$$

Mais cette expression consiste à évaluer la variation de $\psi$ lorsque $s$ varie, $t$ étant fixé. Cela revient donc à une dérivée partielle par rapport à $s$. Donc, si nous connaissons une fonction $F$ telle que :

$$\deriveepartielle{F}{s}(s,t) = f(s,t)$$

nous pouvons réécrire l'intégrale :

$$\int_{a(t)}^{b(t)} f(s,t) \ ds = F(b(t),t) - F(a(t),t)$$

Il ne nous reste plus alors qu'à évaluer la dérivée de $I$ par rapport à $t$ en utilisant la règle des compositions de fonctions :

$$\OD{I}{t}(t) = \deriveepartielle{F}{s}(b(t),t) \cdot \OD{b}{t}(t) + \deriveepartielle{F}{t}(b(t),t) - \deriveepartielle{F}{s}(a(t),t) \cdot \OD{b}{t}(t) - \deriveepartielle{F}{t}(a(t),t)$$

Si $F \in \continue^2(\setR^2,\setR)$, la symétrie des dérivées secondes nous permet d'écrire :

$$\deriveepartielle{F}{t} = \deriveepartielle{}{t} \left[ \deriveepartielle{f}{s} \right] = \deriveepartielle{}{s} \left[ \deriveepartielle{f}{t} \right]$$

La dérivée partielle de $F$ par rapport à $t$ est donc une primitive de la dérivée partielle de $f$ par rapport à $t$. On en déduit que :

$$\int_\alpha^\beta \deriveepartielle{f}{t}(s,t) \ ds = \deriveepartielle{F}{t}(\beta,t) - \deriveepartielle{F}{t}(\alpha,t)$$

pour tout $\alpha,\beta \in \setR$. Pour un $t$ fixé quelconque, on peut poser $\alpha = a(t)$ et $\beta = b(t)$. Il vient alors :

$$\OD{I}{t}(t) = \deriveepartielle{F}{s}(b(t),t) \cdot \OD{b}{t}(t) - \deriveepartielle{F}{s}(a(t),t) \cdot \OD{b}{t}(t) + \int_{a(t)}^{b(t)} \deriveepartielle{f}{t}(s,t) \ ds$$


** Différences finies

Soit une fonction $f : \setR^2 \mapsto \setR^m$ deux fois continument dérivable. Nous allons voir comment évaluer des approximations des dérivées premières et secondes de $f$. On note $\partial_x = \partial_1$ et $\partial_y = \partial_2$. On choisit les réels $x,y$ et la variation non nulle $h \in \setR$.


*** Dérivées premières

Soustrayons les développements d'ordre deux :

#+BEGIN_CENTER
\(
f(x + h,y) \approx f(x,y) + h \cdot \partial_x f(x,y) + \frac{h^2}{2} \cdot \partial^2 f(x,y) \\
f(x - h,y) \approx f(x,y) - h \cdot \partial_x f(x,y) + \frac{h^2}{2} \cdot \partial^2 f(x,y)
\)
#+END_CENTER

On obtient :

$$f(x + h,y) - f(x - h,y) \approx 2 h \cdot \partial_x f(x,y)$$

et donc :

$$\partial_x f(x,y) \approx \frac{f(x + h, y) - f(x - h, y)}{2 h}$$

L'erreur est en $o(h) = o(h^2)/h$. En procédant de même avec $y$, on obtient :

$$\partial_y f(x,y) \approx \frac{f(x, y + h) - f(x, y - h)}{2 h}$$


*** Dérivées secondes

On additionne cette fois les mêmes développements et on obtient :

$$f(x + h,y) + f(x - h,y) \approx 2 f(x,y) + \frac{h^2}{2} \cdot \partial^2 f(x,y) + o(h^2)$$

et donc :

$$\partial_{xx}^2 f(x,y) \approx \frac{f(x + h, y) - 2 f(x,y) + f(x - h, y)}{h^2}$$

L'erreur est en $o(1) = o(h^2)/h^2$, et donc aussi petite que l'on veut pourvu que $h \ne 0$ soit suffisamment petit. En procédant de même avec $y$, on obtient :

$$\partial_{yy}^2 f(x,y) \approx \frac{f(x, y + h) - 2 f(x,y) + f(x, y - h)}{h^2}$$

On vérifie également en évaluant les développements en $(x \pm h, y \pm h)$ que :

$$\partial_{xy}^2 f(x,y) \approx \frac{f(x + h, y + h) - f(x + h, y - h) - f(x - h, y + h) + f(x - h, y - h)}{h^2}$$

La dernière dérivée seconde s'évalue approximativement par $\partial_{yx}^2 f(x,y) = \partial_{xy}^2 f(x,y)$.


*** Généralisation

Nous allons voir comment généraliser ces résultats aux dérivées $\partial_{ij}$ d'une fonction $F : \setR^n \mapsto \setR^m$. Soit $u \in \setR^n$ et les vecteurs de la base canonique $\canonique_i \in \setR^n$. On définit les fonctions $f_{ij} : \setR^n \mapsto \setR^m$ par :

$$f_{ij}(x,y) = F(u + x \cdot \canonique_i + y \cdot \canonique_j)$$

On a clairement :

\begin{align}
\partial_i F(u) &= \partial_x f_{ij}(0,0) \\
\partial_{ii} F(u) &= \partial_{xx} f_{ij}(0,0) \\
\partial_{ij} F(u) &= \partial_{xy} f_{ij}(0,0) \\
\partial_{jj} F(u) &= \partial_{yy} f_{ij}(0,0)
\end{align}

Il suffit donc d'utiliser les méthodes d'approximations des dérivées de $f_{ij}$ pour approximer les dérivées de $F$.


* Distributions

#+TOC: headlines 1 local

\label{chap:distribu}


** Dépendances

  - Chapitre \ref{chap:relation} : Les fonctions
  - Chapitre \ref{chap:lineaire} : Les fonctions linéaires


** Formes et fonctions

On peut toujours associer une forme linéaire $\varphi$ à une fonction intégrable quelconque $\hat{\varphi}$ en définissant :

$$\forme{\varphi}{u} = \int_A u(x) \cdot \hat{\varphi}(x) \ dx$$

Inversément, on ne pourra pas toujours trouver une fonction $\hat{\varphi}$ correspondant à une forme linéaire $\varphi$ donnée. On définira malgré tout l'intégrale généralisée en notant :

$$\int_A u(x)  \cdot \varphi(x) \ dx = \forme{\varphi}{u}$$

où il ne faut pas perdre de vue que $\varphi$ n'est pas nécessairement une fonction.


** Formes et mesures

Soit $u : A \mapsto \setR$. A toute mesure $\mu$, on peut associer une forme linéaire $\hat{\mu}$ par :

$$\forme{ \hat{\mu} }{u} = \int_A u(x) \ d\mu(x)$$

Inversément, à toute forme linéaire $\hat{\mu}$, on peut associer une fonction
$\mu : \sousens(\setR) \mapsto \setR$ par :

$$\mu(A) = \forme{ \hat{\mu} }{\indicatrice_A}$$

Toutefois, rien ne garantit que la fonction $\mu$ ainsi définie est une mesure. En particulier, rien ne garantit qu'elle soit positive.


** Fonction et forme bilinéaire

A toute fonction $\hat{K} : A \times B \mapsto F$, on peut associer une forme bilinéaire $K$ par :

$$\biforme{u}{K}{v} = \int_{A \times B} u(x) \cdot K(x,y) \cdot v(y) \ d\mu(x) \ d\nu(y)$$

pour toutes fonctions $u,v : A \mapsto B$. Inversément, à toute forme bilinéaire $K$, on peut associer une intégrale généralisée en notant :

$$\int_{A \times B} u(x) \cdot K(x,y) \cdot v(y) \ d\mu(x) \ d\nu(y) = \biforme{u}{K}{v}$$


** Définition

Nous nous intéressons ici au cas où l'espace vectoriel $E$ est un ensemble de fonctions intégrables : $E = \mathcal{F} \subseteq \lebesgue^2(\setR,\setR)$. Les limites à l'infini doivent alors forcément s'annuler

$$\lim_{x \to +\infty} u(x) = \lim_{x \to -\infty} u(x) = 0$$

pour tout $u \in \mathcal{F}$.


** Delta de Dirac

La distribution $\dirac \in F^\dual$ de Dirac est définie par :

$$\forme{\dirac}{u} = u(0)$$

pour tout $u \in F$. Elle correspond bien sûr à l'intégrale :

$$\int_\setR \dirac(x) \cdot u(x) \ dx = u(0)$$

On remarque que :

$$\int_{A^2} \dirac(\xi - x) \cdot K(\xi,\eta) \cdot \dirac(\eta - y) \ d\mu(\xi) \ d\nu(\eta) = K(x,y)$$


** Dérivée

En intégrant par parties, on a :

#+BEGIN_CENTER
\(
\int_{\setR} \OD{u}{x}(x) \cdot v(x) \ dx =
\lim_{a \to +\infty} \left[ u(a) \cdot v(a) - u(-a) \cdot v(-a) \right]
- \int_{\setR} u(x) \cdot \OD{v}{x}(x) \ dx
\)
#+END_CENTER

mais comme les limites à l'infini s'annulent, cette expression se réduit à :

$$\int_{\setR} \OD{u}{x}(x) \cdot v(x) \ dx = - \int_{\setR} u(x) \cdot \OD{v}{x}(x) \ dx$$

Par extension, on définit la dérivée $\OD{u}{x}$ d'une distribution $u$ par :

$$\forme{\OD{u}{x}}{v} = - \forme{u}{\OD{v}{x}}$$

pour tout $v\in F$.


*** Échelon

Comme application, considérons la fonction échelon $e_+$ :

#+BEGIN_CENTER
\(
e_+(x) = \indicatrice_{[0,+\infty)} =
\begin{cases}
1 & \mbox{si  } t \ge 0 \\
0 & \mbox{si  } t < 0
\end{cases}
\)
#+END_CENTER

Pour tout $v\in F$, on a :

\begin{align}
\forme{\OD{e_+}{x}}{v} &= - \forme{e_+}{\OD{v}{x}} \\
&= - \int_0^{+\infty} \OD{v}{x}(x) dx
\end{align}

Appliquons à présent le théorème fondamental. Il vient :

$$\forme{\OD{e_+}{x}}{v} = - \left[\lim_{x \to +\infty} v(x) - v(0)\right] = v(0)$$

On en déduit que :

$$\OD{e_+}{x} = \dirac$$

au sens des distributions.


** Dilatation

Soit $d_a$ l'opérateur de dilatation :

$$d_a(u)(x) = u(a \cdot x)$$

où $a > 0$ est un réel strictement positif.

Le changement de variable $\xi = a \cdot x$ nous donne $d\xi = a \ dx$ et donc :

$$\int_{\setR} \hat{u}(a \ x) \ v(x) \ dx = \unsur{a} \int_{\setR} \hat{u}(\xi) \ v\left( \xi/a \right) \ d\xi$$

On définit donc l'extension de cet opérateur aux distributions par :

$$\forme{d_a(u)}{v} = \unsur{a} \forme{u}{d_{1/a}(v)}$$


** Réflexion

L'opérateur de réflexion $r$ se définit par :

$$r(u)(x) = u(-x)$$

Le changement de variable $\xi = -x$ nous donne $d\xi = -dx$ et donc :

\begin{align}
\int_{\setR} \hat{u}(-x) \ v(x) \ dx &= \lim_{a \to +\infty}\int_{-a}^a \hat{u}(-x) \ v(x) \ dx \\
&= \lim_{a \to +\infty} - \int_a^{-a} \hat{u}(\xi) \ v(-\xi) \ d\xi \\
&= \lim_{a \to +\infty} \int^{-a}_a \hat{u}(\xi) \ v(-\xi) \ d\xi
\end{align}

On définit donc l'extension de cet opérateur aux distributions par :

$$\forme{r(u)}{v} = \forme{u}{r(v)}$$


** Translation

L'opérateur de translation $t_a$ est défini par :

$$t_a(u)(x) = u(x - a)$$

Le changement de variable $\xi = x - a$ nous donne $d\xi = dx$ et donc :

$$\int_{\setR} \hat{u}(x-a) v(x) dx = \int_{\setR} \hat{u}(\xi) v(\xi+a) d\xi$$

On définit donc les extensions de cet opérateur aux distributions par :

$$\forme{t_a(u)}{v} = \forme{u}{t_{-a}(v)}$$


** Convolution

Les intégrales unidimensionnelles permettent de définir l'opérateur de convolution
$\convolution$. Soit deux fonctions $u, v : \setR \mapsto \setR$, leur convolution
est une fonction $u \convolution v : \setR \mapsto \setR$ définie par :

$$(u \convolution v)(t) = \int_{-\infty}^{+\infty} u(t-s) \ v(s) \ ds$$

pour tout $t \in \setR$.


*** Dirac

En utilisant les résultats ci-dessus, on arrive facilement à :

$$\int_{\setR} u(x) \ \dirac(x-a) \ dx = u(a)$$

Comme :

$$\int_{\setR} u(x) \ \dirac(-x) \ dx = \int_{\setR} u(-x) \ \dirac(x) \ dx = u(0)$$

on en déduit que $\dirac(-x) = \dirac(x)$ et :

$$\int_{\setR} \dirac(x-y) \ u(y)  \ dy = u(x)$$

c'est-à-dire :

$$\dirac \convolution u = u$$

La distribution de Dirac est neutre pour le produit de convolution.
On peut montrer que ce neutre est unique.


** Corrélation

Les intégrales unidimensionnelles permettent de définir l'opérateur de corrélation
$\correlation$. Soit deux fonctions $u, v : \setR \mapsto \setR$, leur corrélation
est une fonction $u \correlation v : \setR \mapsto \setR$ définie par :

$$(u \correlation v)(t) = \int_{-\infty}^{+\infty} u(s+t) \ v(s) \ ds$$

pour tout $t \in \setR$.


* Formes différentielles

#+TOC: headlines 1 local

\label{chap:formedif}


** Dépendances

  - Chapitre \ref{chap:differ} : Les différentielles
  - Chapitre \ref{chap:integral} : Les intégrales


** Intégrale d'un tenseur

Soit $(\canonique_1,\canonique_2,...,\canonique_n)$ la bace canonique de $\setR^n$ et la fonction tensorielle $T : A \mapsto \tenseur_m(\setR^n)$ qui, à chaque $x \in A$ associe un tenseur $T(x)$ de la forme :

$$T(x) = \sum_{i,j,...,p} t_{ij...p}(x) \cdot \canonique_i \otimes \canonique_j \otimes ... \otimes \canonique_p$$

L'intégrale de cette fonction est définie par :

$$\int_A T(x) \ d\mu(x) = \sum_{i,j,...,p} I_{ij...p} \cdot \canonique_i \otimes \canonique_j \otimes ... \otimes \canonique_p$$

où chaque coordonnée $I_{ij...p}$ est l'intégrale de la coordonnée correspondante de $T$ :

$$I_{ij...p} = \int_A t_{ij...p}(x) \ d\mu(x)$$


** Produit extérieur

Soit $d\mu = dx = dx_1 \ ... \ dx_n$ la mesure de Lebesgue sur $\setR^n$. On sait que $dx$ représente la mesure de l'élément de volume $[x_1,x_1 + dx_1] \times ... \times [x_n,x_n + dx_N]$. Etant donné que nous avons construit le produit extérieur pour représenter (au signe près) des mesures de surfaces et de volumes, il est tout à fait naturel de le faire intervenir dans une mesure de Lebesgue. Soit la base canonique $(e_1,e_2,...,e_n)$ de $\setR^n$ et les vecteurs :

$$\delta_i = dx_i \cdot e_i$$

où les $dx_i$ sont bien évidemment des scalaires. Si nous évaluons le produit extérieur des ces vecteurs, nous obtenons :

$$\delta_1 \wedge \delta_2 \wedge ... \wedge \delta_n = \sum_{i,j,...,k} \permutation_{ij...k} \cdot dx_1 \cdot \delta_{1i} \cdot dx_2 \cdot \delta_{2j} \hdots \cdot dx_n \cdot \delta_{nk}$$

Le seul terme ne s'annulant pas étant $\permutation_{1,2,...,n} = 1$, on a finalement :

$$\delta_1 \wedge \delta_2 \wedge ... \wedge \delta_n = dx_1 \cdot dx_2 \cdot ... \cdot dx_n = dx$$

Cette constatation nous amène à définir une mesure plus générale. Considérons à présent des vecteurs infinitésimaux $\upsilon_1,\upsilon_2,...,\upsilon_n \in \setR^n$, c'est à dire des vecteurs dont la norme tendra vers zéro dans l'intégrale. Afin de garantir la positivité de la mesure, nous définissons :

$$du = \abs{\upsilon_1 \wedge \upsilon_2 \wedge ... \wedge \upsilon_n}$$


** Tenseur différentiel

Il est même possible de définir des tenseurs différentiels $dU$ en choisissant $m \le n$ et en posant :

$$dU = \upsilon_1 \wedge \upsilon_2 \wedge ... \wedge \upsilon_m$$

Il est clair que $dU \in \tenseur_{n - m}(\setR^n)$. On nomme ce type de tenseur une forme différentielle.


** Paramétrisation

Soit $m,n \in \setN$ avec $m \le n$ et la fonction $\phi : U \subseteq \setR^m \mapsto \setR^n$, dérivable et inversible. Le but est de paramétrer $x$ sur $\phi(U)$ par la relation $x = \phi(u)$ pour tout $u \in U$. Nous utilisons la base canonique $(e_1,e_2,...,e_m)$ de $\setR^m$ et nous posons :

$$\delta_i = \phi(u + du_i \ e_i) - \phi(u) = \partial_i \phi(u) \ du_i$$

Sur $\phi(U)$, on utilise le tenseur différentiel :

$$dX = \delta_1 \wedge \delta_2 \wedge ... \wedge \delta_m$$

La linéarité du produit extérieur nous permet d'ecrire :

\begin{align}
dX &= \partial_1 \phi(u) \wedge \partial_2 \phi(u) \wedge ... \wedge \partial_m \phi(u) \ du_1 \ du_2 \ ... \ du_m \\
&= \partial_1 \phi(u) \wedge \partial_2 \phi(u) \wedge ... \wedge \partial_m \phi(u) \ du
\end{align}

On définit le tenseur $W \in \tenseur_{n - m}(\setR^n)$ associé à $dX$ par :

$$W(u) = \partial_1 \phi(u) \wedge \partial_2 \phi(u) \wedge ... \wedge \partial_m \phi(u)$$

Deux cas peuvent alors se présenter.


*** Fonction tensorielle

On peut évaluer l'intégrale d'une fonction tensorielle $f : \setR^n \mapsto \tenseur_p(\setR^n)$ en utilisant la contraction maximale avec $dX$. Comme on a l'équivalence $x \in \phi(U) \leftrightarrow u \in U$, on a alors :

$$\int_{\phi(U)} f(x) : dX = \int_U (f\circ\phi)(u) : W(u) \ du$$

Dans le cas particulier où $p = n - m$, on obtiendra un scalaire.


*** Fonction scalaire

On peut évaluer l'intégrale d'une fonction scalaire $f : \setR^n \mapsto \setR$ en utilisant la norme de $dX$. On a alors $dx = \norme{dX}$ et :

$$\int_{\phi(U)} f(x) dx = \int_U (f\circ\phi)(u) \cdot \norme{W(u)} \ du$$


*** Pavé

Un cas particulier important est celui où $U = [\alpha_1,\beta_1] \times .. \times [\alpha_m,\beta_m]$ pour certains $\alpha_i,\beta_i \in \setR$. On a alors :

$$\int_{\phi(U)} \sim \int_{\alpha_1}^{\beta_1} du_1 \int_{\alpha_2}^{\beta_2} du_2 \ ... \int_{\alpha_m}^{\beta_m} du_m$$


** Changement de variable

Nous considérons à présent le cas où $m = n$. Nous utilisons la base canonique $(e_1,e_2,...,e_n)$ de $\setR^n$ et nous posons de nouveau :

$$\delta_i = \phi(u + du_i \ e_i) - \phi(u) = \partial_i \phi(u) \ du_i$$

On utilise la mesure :

$$dx = \abs{\delta_1 \wedge \delta_2 \wedge ... \wedge \delta_n}$$

On a alors :

\begin{align}
dx &= \abs{\partial_1 \phi(u) \wedge \partial_2 \phi(u) \wedge ... \wedge \partial_n \phi(u) \ du} \\
&= \abs{\sum_{i,j,...,k} \permutation_{ij...k} \cdot \partial_1 \phi_i(u) \cdot \partial_2 \phi_j(u) \cdot \ \hdots \ \cdot \partial_n \phi_k(u)} \ du \\
&= \abs{\det \partial \phi(u)} \ du
\end{align}

On voit donc apparaître le déterminant de la Jacobienne de $\phi$. Comme on a l'équivalence $x \in A \leftrightarrow u \in \phi^{-1}(A)$, le changement de variable peut s'écrire :

$$\int_A f(x) \ dx = \int_{\phi^{-1}(A)} (f\circ\phi)(u) \cdot \abs{ \det \partial \phi(u) } \ du$$


*** Pavé

Un cas particulier important est celui où $\phi^{-1}(A) = [\alpha_1,\beta_1] \times .. \times [\alpha_n,\beta_n]$ pour certains $\alpha_i,\beta_i \in \setR$. On a alors :

$$\int_A \sim \int_{\alpha_1}^{\beta_1} du_1 \int_{\alpha_2}^{\beta_2} du_2 \ ... \int_{\alpha_n}^{\beta_n} du_n$$


** Intégrales de ligne vectorielles

Soit une fonction continue $\gamma : [a,b] \to \setR^n$ définissant la courbe $\Lambda = \gamma([a,b])$.  L'intégrale de ligne d'une fonction $f : \setR^n \mapsto \setR^n$ sur cette courbe est l'intégrale de la contraction d'ordre $1$ de $f$ avec $d\gamma$, qui revient ici au produit scalaire du vecteur $f(x) \in \Lambda$ par le vecteur $\partial \gamma(t)$. On a donc :

$$\int_\Lambda f\cdot d\Lambda = \int_a^b \scalaire{(f \circ \gamma)(t)}{\partial \gamma(t) } dt$$


** Intégrales de ligne scalaires

Dans le cas d'une fonction $g : \setR^n \mapsto \setR$, on utilise comme mesure la longueur $\norme{\partial \gamma(t)}$ de chaque petit segment $d\Lambda$. On a alors :

$$\int_\Lambda g \ d\Lambda = \int_a^b (g \circ \gamma)(t) \cdot \norme{\partial \gamma(t)} \ dt$$


** Contour fermé

Si $\gamma(a) = \gamma(b)$, on dit que le contour fermé, et on note en général :

$$\oint_\Lambda = \int_\Lambda$$


** Intégrales de surface vectorielles

Soit $f : \setR^n \mapsto \setR^n$, $\sigma : A \subseteq \setR^{n - 1} \mapsto \setR^n$ et la surface $\Theta = \sigma(A)$. On définit les vecteurs :

$$\delta_i = \deriveepartielle{\sigma}{u_i} du_i$$

pour $i = 1, ..., n - 1$. L'intégrale de surface est simplement la contraction d'ordre $1$ :

$$\int_\Theta f \cdot d\Theta = \int_A \scalaire{(f \circ \sigma)(u)}{ \delta_1 \wedge ... \wedge \delta_{n-1} }$$

qui nous donne un scalaire. Dans le cas particulier où $n = 3$ et où $A = [U_1,U_2] \times [V_1,V_2]$, on a :

$$\int_\Theta f \cdot d\Theta = \int_{U_1}^{U_2} du \ \int_{V_1}^{V_2} (f \circ \sigma)(u,v) \cdot \left( \deriveepartielle{\sigma}{u}(u,v) \wedge \deriveepartielle{\sigma}{v}(u,v) \right) \ dv$$


** Intégrales de surface scalaires

Soit $f : \setR^n \mapsto \setR^n$, $\sigma : A \subseteq \setR^{n - 1} \mapsto \setR^n$ et la surface $\Theta = \sigma(A)$. On définit les vecteurs :

$$\delta_i = \deriveepartielle{\sigma}{u_i} du_i$$

pour $i = 1, ..., n - 1$. Utilisant comme mesure la norme du produit extérieur des $\delta_i$, on obtient :

$$\int_\Theta f \ d\Theta = \int_A (f \circ \sigma)(u) \cdot \norme{ \delta_1 \wedge ... \wedge \delta_{n-1} }$$

Dans le cas particulier où $n = 3$ et où $A = [U_1,U_2] \times [V_1,V_2]$, on a :

$$\int_\Theta f \ d\Theta = \int_{U_1}^{U_2} du \ \int_{V_1}^{V_2} (f \circ \sigma)(u,v) \cdot \norme{ \deriveepartielle{\sigma}{u}(u,v) \wedge \deriveepartielle{\sigma}{v}(u,v) } \ dv$$


** Intégrale de flux

Soit $A \subseteq \setR^n$ et la fonction $a : \setR^n \to \setR$ telle que :

$$A = \{ x \in \setR^n : a(x) \le 0 \}$$

On s'arrange de plus pour avoir $a$ constante sur la frontière :

$$\partial A = \{ x \in \setR^n : a(x) = 0 \}$$

On introduit le vecteur normal :

$$n = \unsur{\norme{\deriveepartielle{a}{x}}} \cdot \deriveepartielle{a}{x}$$

L'intégrale du flux sortant de la fonction $f : \setR^n \to \setR^n$ est alors donnée par :

$$\int_{\partial A} \scalaire{f}{n} \ d\mu$$


** Différentielle

Soit une fonction $f : \setR^n \mapsto \setR$, les vecteurs infinitésimaux $\delta_1,...,\delta_{n - 1} \in \setR^n$ et la forme différentielle :

$$\omega = f \cdot \delta_1 \wedge \delta_2 \wedge ... \wedge \delta_{n-1}$$

Si $f$ est différentiable, on définit la différentielle de $\omega$ par :

$$d\omega = \sum_i \deriveepartielle{f}{x_i} \cdot \kappa_i \wedge \delta_1 \wedge \delta_2 \wedge ... \wedge \delta_{n-1}$$

où :

$$\kappa_i = dx_i \cdot e_i$$

On note aussi symboliquement :

$$d\omega = df \wedge dx_1 \wedge ... \wedge dx_{n-1}$$

On peut montrer sous certaines conditions que l'intégrale
sur la frontière de $A$ est alors donnée par :

$$\int_{\partial A} \omega = \int_A d\omega$$


** Théorème de Stokes

Soit $f,g : \setR^2 \mapsto \setR$ et les vecteurs infinitésimaux :

#+BEGIN_CENTER
\(
\delta x = e_1 \ dx \\
\delta y = e_2 \ dy
\)
#+END_CENTER

Considérons la forme différentielle :

$$\omega = f \delta x + g \delta y$$

Si les fonctions sont différentiables, on a alors :

$$d\omega = \deriveepartielle{f}{x} \delta x \wedge \delta x +  \deriveepartielle{f}{y} \delta y \wedge \delta x + \deriveepartielle{g}{x} \delta x \wedge \delta y +  \deriveepartielle{g}{y} \delta y \wedge \delta y$$

Mais comme :

#+BEGIN_CENTER
\(
\delta x \wedge \delta x = \delta y \wedge \delta y = 0 \\
\delta y \wedge \delta x = - \delta x \wedge \delta y
\)
#+END_CENTER

il vient :

$$d\omega =  \left( \deriveepartielle{g}{x} - \deriveepartielle{f}{y} \right) \delta x \wedge \delta y$$

En intégrant, on obtient alors :

$$\int_{\partial A} (f \ \delta x + g \ \delta y)  = \int_A \left( \deriveepartielle{g}{x} - \deriveepartielle{f}{y} \right) dx \wedge dy$$

Mais comme nous somme dans la base canonique, on a $\delta x \wedge \delta y = dx \ dy$ et :

$$\int_{\partial A} (f \ \delta x + g \ \delta y)  = \int_A \left( \deriveepartielle{g}{x} - \deriveepartielle{f}{y} \right) \ dx \ dy$$


* Géométrie différentielle

#+TOC: headlines 1 local

\label{chap:geometri}


** Dépendances

  - Chapitre \ref{chap:vecteur} : Les vecteurs
  - Chapitre \ref{chap:ps} : Les produits scalaires
  - Chapitre \ref{chap:tenseur} : Les tenseurs


** Indices covariants et contravariants

Les indices inférieurs (le $i$ des vecteurs $a_i^j$ par exemple) des
tenseurs sont appelés /indices covariants/.

Les indices supérieurs (le $j$ des vecteurs $a_i^j$ par exemple) des
tenseurs sont appelés /indices contravariants/.

Ne pas confondre ces /indices supérieurs/ contravariants , très
utilisés en calcul tensoriel, avec les puissances ! Dans le contexte
des tenseurs, une éventuelle puissance d'un scalaire $\theta_i^j$
serait notée au besoin par :

$$\big( \theta_j^i \big)^m = \theta_j^i \cdot ... \cdot \theta_j^i$$


** Coordonnées curvilignes

Soit l'espace vectoriel $E = \setR^n$ sur $\setR$. Les coordonnées curvilignes sont basées sur la notion de position $r$, exprimée comme une fonction de certains paramètres $x \in \setR^n$ que nous appelons « coordonnées » de $r$ :

$$r = \rho(x)$$

où $\rho : \setR^n \to \setR^n$. Nous envisageons également le cas du changement de variable. La position dépend alors d'un autre jeu de coordonnées $y \in \setR^n$ :

$$r = \sigma(y)$$

où $\sigma : \setR^n \to \setR^n$. Nous définissons les vecteurs fondamentaux $e_i$ et $e^i$ au moyen de ces fonctions :

#+BEGIN_CENTER
\(
e_i(x) = \deriveepartielle{\rho}{x^i}(x) \\
e^i(y) = \deriveepartielle{\sigma}{y_i}(y)
\)
#+END_CENTER

de telle sorte que :

$$dr = \sum_i e_i \ dx^i  = \sum_i e^i \ dy_i$$

Nous supposons que $(e_1, ..., e_n)$ et $(e^1, ..., e^n)$ sont des bases de $E$.


*** Courbe

Dans le cas où $x$ et $y$ ne dépendent que d'un paramètre $t \in \setR$, on a :

$$\OD{r}{t} = \sum_i e_i \ \OD{x^i}{t}  = \sum_i e^i \ \OD{y_i}{t}$$

On dit alors que la position $r$ décrit une courbe.


** Changement de variable

Si les fonctions $\rho$ et $\sigma$ sont inversibles, on a :

#+BEGIN_CENTER
\(
x = \rho^{-1}(r) = (\rho^{-1} \circ \sigma)(y) = \phi(y) \\
y = \sigma^{-1}(r) = (\sigma^{-1} \circ \rho)(x) = \psi(x)
\)
#+END_CENTER

où nous avons implicitement défini $\phi = \rho^{-1} \circ \sigma$ et $\psi = \sigma^{-1} \circ \rho$. Nous notons $\deriveepartielle{x^i}{y_j}$ et $\deriveepartielle{y_i}{x^j}$ les coordonnées des dérivées de $\phi$ et $\psi$ suivant les bases formées par les $e_i$ et les $e^i$ :

#+BEGIN_CENTER
\(
\deriveepartielle{\phi}{y_j} = \sum_i \deriveepartielle{x^i}{y_j} \ e_i \\
\deriveepartielle{\psi}{x^j} = \sum_i \deriveepartielle{y_i}{x^j} \ e^i
\)
#+END_CENTER

La composition des dérivées nous donne les relations :

#+BEGIN_CENTER
\(
e_i = \sum_j \deriveepartielle{r}{y_j} \ \deriveepartielle{y_j}{x^i} =  \sum_j \deriveepartielle{y_j}{x^i} \ e^j \\
e^i = \sum_j \deriveepartielle{r}{x^j} \ \deriveepartielle{x^j}{y_i} =  \sum_j \deriveepartielle{x^j}{y_i} \ e_j
\)
#+END_CENTER

qui nous permettent de relier les $e_i$ aux $e^j$ et inversément.


** Produit scalaire

Les produits intérieurs entre vecteurs de base se notent habituellement :

#+BEGIN_CENTER
\(
g_{ij} = \scalaire{e_i}{e_j} \\
g_i^j = \scalaire{e_i}{e^j} \\
g^{ij} = \scalaire{e^i}{e^j}
\)
#+END_CENTER

Il est clair d'après les propriétés de symétrie de ce produit que :

#+BEGIN_CENTER
\(
g_{ij} = g_{ji} \\
g^{ij} = g^{ji} \\
g_i^j = g_j^i
\)
#+END_CENTER

Le produit scalaire de deux vecteurs $a,b\in E$ définis par :

#+BEGIN_CENTER
\(
a = \sum_i a^i \ e_i = \sum_i a_i \ e^i \\
b = \sum_i b^i \ e_i = \sum_i b_i \ e^i
\)
#+END_CENTER

peut s'écrire indifféremment comme :

#+BEGIN_CENTER
\(
\scalaire{a}{b} = \sum_{i,j} g_{ij} \ a^i \ b^j \\
\scalaire{a}{b} = \sum_{i,j} g^{ij} \ a_i \ b_j \\
\scalaire{a}{b} = \sum_{i,j} g_j^i \ a_i \ b^j \\
\scalaire{a}{b} = \sum_{i,j} g_i^j \ a^i \ b_j
\)
#+END_CENTER

Et en particulier, la longeur $ds$ d'un changement de position $dr$ vérifie :

$$(ds)^2 = \scalaire{dr}{dr} = \sum_{i,j} g_{ij} \ dx^i \ dx^j = \sum_{i,j} g^{ij} \ dy_i \ dy_j$$

De plus, les relations entre les vecteurs $e_i$ et les vecteurs $e^i$ permettent
de déduire, en utilisant la linéarité du produit scalaire :

#+BEGIN_CENTER
\(
g_{ij} = \sum_k \deriveepartielle{y_k}{x^i} \ g_j^k = \sum_{k,l} \deriveepartielle{y_k}{x^i} \ \deriveepartielle{y_l}{x^j} \ g^{kl} \\
g^{ij} = \sum_k \deriveepartielle{x_k}{y^i} \ g_k^j = \sum_{k,l} \deriveepartielle{x^k}{y_i} \ \deriveepartielle{x^l}{y_j} \ g_{kl}
\)
#+END_CENTER


** Dérivées primales d'un vecteur

Nous allons à présent voir comment évolue un vecteur $a\in E$, que l'on note sous la forme :

$$a = \sum_i a^i \ e_i$$

où les coordonnées $a^i\in\setR$ tout comme les vecteurs de base $e_i$ dépendent des coordonnées
$x^i$. La règle de dérivation d'un produit nous donne :

$$da = \sum_i da^i \ e_i + \sum_k a^k \ de_k$$

La différentielle $da^i$ s'obtient directement :

$$da^i = \sum_j \deriveepartielle{a^i}{x^j} \ dx^j$$

On peut suivre la même règle avec $de_i$ :

$$de_k = \sum_j \deriveepartielle{e_k}{x^j} \ dx^j$$

Les symboles de Christoffel $\christoffel{i}{kj}$ sont définis comme
les coordonnées de $\deriveepartielle{e_k}{x^j}$ suivant la base $(e_1, ..., e_n)$ :

$$\deriveepartielle{e_k}{x^j} = \sum_i \christoffel{i}{kj} \ e_i$$

Notons que comme :

$$\deriveepartielle{e_k}{x^j} = \dfdxdy{r}{x^j}{x^k} = \dfdxdy{r}{x^k}{x^j} = \deriveepartielle{e_j}{x^k}$$

on a la symétrie :

$$\christoffel{i}{kj} = \christoffel{i}{jk}$$

On peut évaluer ces symboles si on connait par exemple les valeurs des :

\begin{align}
\scalaire{e^i}{ \deriveepartielle{e_k}{x^j} } &= \sum_m \christoffel{m}{kj} \ \scalaire{e^i}{e_m} \\
&= \sum_m \christoffel{m}{kj} \ g^i_m
\end{align}

On a alors, pour chaque choix de $k,j$ un système linéaire à résoudre. Il suffit d'inverser
la matrice $G = (g^i_m)_{i,m}$ pour obtenir les valeurs des symboles.

La dérivation d'un vecteur $a\in E$ s'écrit alors :

$$da = \sum_{i,j} e_i \ dx^j \ \left[ \deriveepartielle{a^i}{x^j} + \sum_k \christoffel{i}{kj} \ a^k  \right]$$

On définit les coordonnées :

$$\gradient_j a^i = \deriveepartielle{a^i}{x^j} + \sum_k \christoffel{i}{kj} \ a^k$$

Dans le cas où les coordonnées dépendent d'un paramètre $t\in\setR$, on a :

\begin{align}
\OD{a}{t} &= \sum_{i,j} e_i \ \OD{x^j}{t} \ \left[ \deriveepartielle{a^i}{x^j} + \sum_k \christoffel{i}{kj} \ a^k  \right] \\
&= \sum_{i} e_i \ \left[ \OD{a^i}{t} + \sum_{j,k} \christoffel{i}{kj} \ a^k \ \OD{x^j}{t} \right]
\end{align}


*** Dérivée seconde et géodésique

Considérons le cas :

$$a = \OD{r}{t} = \sum_i e_i \ \OD{x^i}{t}$$

Les coordonnées de $a$ sont clairement $a^i = \OD{x^i}{t}$ et la dérivée seconde :

$$\OOD{r}{t} = \OD{}{t}\OD{r}{t} = \OD{a}{t}$$

s'écrit :

$$\OOD{r}{t} = \sum_{i} e_i \ \left[ \OOD{x^i}{t} + \sum_{j,k} \christoffel{i}{kj} \ \OD{x^k}{t}\ \OD{x^j}{t} \right]$$

Les courbes $x^i = x^i(t)$ vérifiant $\OOD{r}{t} = 0$ sont appelées des géodésiques.


** Dérivées duales d'un vecteur

Nous allons recommencer le même processus, écrivant cette fois  $a\in E$ sous la forme :

$$a = \sum_i a_i \ e^i$$

Les coordonnées $a_i\in\setR$ tout comme les vecteurs de base $e^i$ dépendent des coordonnées
$y_i$. En suivant la même méthode que ci-dessus, on obtient :

$$da = \sum_{i,j} e^i \ dy_j \left[ \deriveepartielle{a_i}{y_j} + \sum_k \christoffel{kj}{i} \ a_k  \right]$$


où l'on a introduit de nouveaux symboles de Christoffel, définis par :

$$\deriveepartielle{e^k}{y_j} = \sum_i \christoffel{kj}{i} \ e^i$$

Ces nouveaux symboles présentent la symétrie :

$$\christoffel{kj}{i} = \christoffel{jk}{i}$$


** Dérivées d'un tenseur

On étend simplement la notion de dérivée aux tenseurs en appliquant
la formule :

$$d(a \otimes b) = da \otimes b + a \otimes db$$

où $a$ et $b$ sont deux tenseurs d'ordre quelconque.
Par exemple, pour le tenseur :

$$T = \sum_{i,j} T^i_j \ e_i \otimes e^j$$

on a :

$$dT = \sum_{i,j} \left[ dT^i_j \ e_i \otimes e^j + T^i_j \ de_i \otimes e^j + T^i_j \ e_i \otimes de^j \right]$$

qui devient, en introduisant les symboles de Christoffel :

$$dT = \sum_{i,j} e_i \otimes e^j \left[ dT^i_j + \sum_{k,m} \christoffel{i}{mk} \ T^m_j \ dx^k + \sum_{k,m} \christoffel{mk}{j} \ T^i_m \ dy_k \right]$$


** Produit scalaire et symboles de Christoffel

Lorsqu'on différentie les $g_{ij}$, on obtient :

\begin{align}
dg_{ij} &= \scalaire{de_i}{e_j} + \scalaire{e_i}{de_j} \\
&= \sum_{k,l} \christoffel{k}{il} \ g_{kj} \ dx^l + \sum_{k,l} \christoffel{k}{jl} \ g_{ik} \ dx^l
\end{align}

On en déduit que :

$$\deriveepartielle{g_{ij}}{x^l} = \sum_k \christoffel{k}{il} \ g_{kj} + \sum_k \christoffel{k}{jl} \ g_{ik}$$

Définissons :

$$\gamma_{ijl} = \sum_k \christoffel{k}{il} \ g_{kj}$$

Les propriétés de symétrie des symboles de Christoffel nous montrent que :

$$\gamma_{ijl} = \gamma_{ilj}$$

Et comme (changement de l'indice $l$ en $k$) :

$$\deriveepartielle{g_{ij}}{x^k} = \gamma_{ijk} + \gamma_{jik}$$

On en déduit :

\begin{align}
\deriveepartielle{g_{ij}}{x^k} + \deriveepartielle{g_{jk}}{x^i} - \deriveepartielle{g_{ki}}{x^j}
&= 2 \ \gamma_{jik} \\
&= 2 \sum_l \christoffel{l}{jk} \ g_{li}
\end{align}

AFAIRE : LA FIN DU CHAPITRE EST A DÉBROUILLONNER


** Bases biorthonormées


*** produit scalaire

Nous considérons tout au long de cette section le cas particulier où les bases
sont biorthonormées, c'est-à-dire :

$$g_i^j = \indicatrice_i^j$$

On déduit des relations liant les $g^{ij},g_{ij}$ aux $g_i^j$ que :

#+BEGIN_CENTER
\(
g_{ik} g^{kj} = \sum_{k,l,m} \deriveepartielle{y_l}{x^i}\deriveepartielle{x^m}{y_k} g_k^l g_m^j \\
g_{ik} g^{kj} = \sum_{k,l,m} \deriveepartielle{y_l}{x^i}\deriveepartielle{x^m}{y_k} \indicatrice_k^l \indicatrice_m^j \\
g_{ik} g^{kj} = \sum_{k} \deriveepartielle{y_k}{x^i}\deriveepartielle{x^j}{y_k} \\
g_{ik} g^{kj} = \deriveepartielle{x^i}{x^j} = \indicatrice_i^j
\)
#+END_CENTER

On aurait de même :

$$g^{ik} g_{kj} = \indicatrice_j^i$$


*** Coordonnées

Les coordonnées d'un tenseur de la forme :

$$T = \sum_{i,j,k,l} T_{i...j}^{k...l} e^i \otimes ... \otimes e^j \otimes e_k \otimes ... \otimes e_l$$

où il y a $m$ indices $i...j$ et $n$ indices $k...l$ s'obtiennent facilement
en utilisant la contraction double :

$$T_{i...j}^{k...l} = \dblecont{e_j \otimes ... \otimes e_i}{m}{T}{n}{e^l \otimes ... \otimes e^k}$$


** Dérivées des changements de variable

#+BEGIN_CENTER
\(
\deriveepartielle{x^i}{y_j} = \scalaire{e_i}{ \deriveepartielle{\phi}{y_j} } \\
\deriveepartielle{y_i}{x^j} = \scalaire{e^i}{ \deriveepartielle{\psi}{x^j} }
\)
#+END_CENTER


*** Christoffel

Tenant compte de cette identité, l'équation reliant les symboles de Christoffel
aux produits scalaires devient :

$$\christoffel{m}{jk} = \frac{1}{2}\sum_i g^{im}\left[\deriveepartielle{g_{ij}}{x^k} + \deriveepartielle{g_{jk}}{x^i} - \deriveepartielle{g_{ki}}{x^j}\right]$$


*** Dérivée d'un vecteur

La relation :

$$d\scalaire{e^i}{e_j} = d\indicatrice_i^j = 0$$

nous conduit à :

#+BEGIN_CENTER
\(
\scalaire{de^i}{e_j}+\scalaire{e^i}{de_j} = 0 \\
\sum_{k,l} \christoffel{ik}{l} \scalaire{e^l}{e_j} dy_k +
\sum_{k,l} \christoffel{l}{jk} \scalaire{e^i}{e_l} dx^k = 0 \\
\sum_k \christoffel{ik}{l} dy_k = - \sum_k \christoffel{l}{jk} dx^m
\)
#+END_CENTER

Par ailleurs :

$$da_i = \deriveepartielle{a_i}{y_j} dy_j = \deriveepartielle{a_i}{x^j} dx^j$$

On peut donc réexprimer la dérivée duale comme :

$$da = \sum_{i,j} e^i dx^j \left[ \deriveepartielle{a_i}{x^j} - \sum_k \christoffel{k}{ij} a_k \right]$$


*** Gradient

On peut également définir le gradient d'un vecteur par :

$$\gradient a = \sum_{i,j} \gradient_j a^i e_i \otimes e^j$$

de telle sorte que l'on ait :

$$da = \scalaire{\gradient a}{dr} = \gradient a \cdot dr$$



*** Dérivée d'un tenseur

$$dT = \sum_{i,j,k} e_i \otimes e^j dx^k \left[ \deriveepartielle{T^i_j}{x^k} + \sum_m \christoffel{i}{mk} T^m_j - \sum_m \christoffel{m}{jk} T^i_m \right]$$

On définit alors les coordonnées :

$$\gradient_k T^i_j = \deriveepartielle{T^i_j}{x^k} + \sum_m \christoffel{i}{mk} T^m_j - \sum_m \christoffel{m}{jk} T^i_m$$


*** Tenseur de courbure

Appliquons la formule de dérivation des coordonnées d'un tenseur dans le cas particulier où :

$$T^i_j = \gradient_j a^i$$

On a :

#+BEGIN_CENTER
\(
\deriveepartielle{T^i_j}{x^k} = \dfdxdy{a^i}{x^j}{x^k}
+ \sum_m \christoffel{i}{jm} \deriveepartielle{a^m}{x^k}
+ \sum_m \deriveepartielle{}{x^k}\christoffel{i}{jm} a^m \\ \\

\sum_l \christoffel{i}{kl} T^l_j =
\sum_l \christoffel{i}{kl} \deriveepartielle{a^i}{x^j} +
\sum_{l,m} \christoffel{i}{kl} \christoffel{l}{jm} a^m \\ \\

-\sum_l \christoffel{l}{jk} T^i_l =
-\sum_l \christoffel{l}{jk} \deriveepartielle{a^i}{x^l} -
\sum_{l,m} \christoffel{l}{jk} \christoffel{i}{lm} a^m
\)
#+END_CENTER

La somme de tous ces termes vaut $\gradient_k T^i_j = \gradient_k \gradient_j a^i$.
En interchangeant les indices $j$ et $k$, on obtient $\gradient_j \gradient_k a^i$.
On en déduit, en utilisant les propriétés de symétrie que :

$$\gradient_k \gradient_j a^i - \gradient_j \gradient_k a^i = \sum_m R^i_{m,kj} a^m$$

où les $R_{...}^{...}$ sont définis par :

$$R^i_{m,kj} = \deriveepartielle{}{x^k}\christoffel{i}{jm} - \deriveepartielle{}{x^j}\christoffel{i}{km} + \sum_l \christoffel{i}{kl}\christoffel{l}{jm} - \sum_l \christoffel{i}{jl}\christoffel{l}{km}$$

Ce sont les coordonnées du tenseur de courbure de Riemann-Christoffel.


* L'espace vectoriel des polynômes

#+TOC: headlines 1 local

\label{chap:vectpoly}


** Introduction

AFAIRE : ARRANGER LE CHAPITRE

Il est clair d'après la définition des polynômes que les espaces
$\mathcal{P}_n$ sont des espaces vectoriels pour l'ensemble des
scalaires $S=\setR$ et que :

$$\mathcal{P}_n = \ev{\mu_0,\mu_1,...,\mu_n}$$

Nous allons montrer que $(\mu_0,\mu_1,...,\mu_n)$ forme
une base de $\mathcal{P}_n$. Pour cela, il nous reste à prouver
l'indépendance linéaire des $\mu_i$ :

$$\sum_{i=0}^n a_i \mu_i = 0 \quad\Rightarrow\quad a_0 = a_1 = ... = a_n = 0$$

c'est-à-dire :

$$\sum_{i=0}^n a_i x^i = 0 \quad\forall x \in\setR \quad\Rightarrow\quad a_0 = a_1 = ... = a_n = 0$$

Nous allons le montrer par récurrence.

Comme $\mu_0=1$ on a évidemment :

$$a_0 1 = 0 \quad\Rightarrow\quad a_0 = 0$$

et la thèse est vraie pour $n=0$. Supposons à présent qu'elle
soit vraie pour $n-1$. Choisissons $p\in\mathcal{P}_n$ :

$$p(x) = \sum_{i=0}^n a_i x^i$$

et supposons que $p(x) = 0$ pour tout $x\in\setR$. Comme $p(0)=0$,
on a :

$$a_0 = 0$$

donc :

$$p(x) = \sum_{i=1}^n a_i x^i = x q(x) = 0$$

où l'on à définit $q\in\mathcal{P}_{n-1}$ par :

$$q(x) = \sum_{i=1}^n a_i x^{i-1}$$

Il est clair que, pour tout $x\ne 0$, $q(x) = 0$. Mais comme les polynômes
sont des fonctions continues, on a :

$$q(0) = \lim_{ \substack{ x \rightarrow 0 \\ x \ne 0 } } q(x) = 0$$

Donc $q$ s'annule également en $0$. On en conclut que $q(x)$ est
nul pour tout $x\in\setR$. Par l'hypothèse de récurrence, les
coefficients de ce polynôme sont tous nuls :

$$a_1 = a_2 = ... = a_n = 0$$

Rassemblant les résultats, il vient :

$$a_0 = a_1 = ... = a_n = 0$$

et $(\mu_0,\mu_1,...,\mu_n)$ forme bien une base de $\mathcal{P}_n$.


** Polynômes orthogonaux

Nous allons à présent voir comment construire des suites de polynômes
orthogonaux pour le produit scalaire :

$$\scalaire{p}{q} = \int_a^b p(x) q(x) d\mu(x)$$

ou, lorsque c'est possible :

$$\scalaire{p}{q} = \int_a^b p(x) q(x) w(x) dx$$


*** Récurrence

On pourrait bien entendu partir de la suite de la base canonique
de monômes $(1,x,x^2,...,x^n)$ et l'orthogonaliser en utilisant le
procédé de Gram-Schmidt, mais on peut arriver à un algorithme plus
rapide en utilisant les propriétés des polynômes. Soit $(\phi_n)_n$
une suite de polynômes orthonormés, où $\phi_i$ est de degré $i$.
On a donc :

$$\scalaire{\phi_m}{\phi_n} = \int_A \phi_m(x) \phi_n(x) d\mu(x) = \delta_{mn}$$

Supposons que $(\phi_0,...,\phi_n)$ forme une base de $\mathcal{P}_n$.
On peut vérifier que $(\phi_0,...,\phi_n,x\phi_n)$ forme une base de
$\mathcal{P}_{n+1}$. On peut donc représenter $\phi_{n+1}$ comme :

$$\phi_{n+1}(x) = a_n x\phi_n(x) + b_n \phi_n(x) + c_n \phi_{n-1}(x) + \sum_{i=0}^{n-2} d_i \phi_i(x)$$

Soit $i \in \{0, ..., n-2\}$. La condition d'orthogonalité de
$\phi_{n+1}$ avec $\phi_i$ s'écrit :

$$\scalaire{\phi_i}{\phi_{n+1}} = a_n \scalaire{\phi_i}{x\phi_n} + b_n \scalaire{\phi_i}{\phi_n} + c_n \scalaire{\phi_i}{\phi_{n-1}} + \sum_{j=0}^{n-2} d_j \scalaire{\phi_i}{\phi_j} = 0$$

L'orthogonalité implique que :

#+BEGIN_CENTER
\(
\scalaire{\phi_i}{\phi_n} = \scalaire{\phi_i}{\phi_{n-1}} = 0 \\
\scalaire{\phi_i}{\phi_j} = \delta_{ij}
\)
#+END_CENTER

On a aussi :

$$\scalaire{\phi_i}{x\phi_n} = \int_A x \phi_i(x) \phi_n(x) d\mu(x) = \scalaire{x\phi_i}{\phi_n}$$

Mais comme $\phi_i$ est de degré $i$, $x\phi_i$ est de degré $i+1$
et on peut l'exprimer comme :

$$x \phi_i = \sum_{j=0}^{i+1} \alpha_i \phi_j$$

Le produit scalaire devient alors :

$$\scalaire{\phi_i}{x\phi_n} = \sum_{j=0}^{i+1} \alpha_i \scalaire{\phi_j}{\phi_n} = 0$$

puisque $j \le i+1 < n$. On en conclut que :

$$\scalaire{\phi_i}{\phi_{n+1}} = \sum_{j=0}^{n-2} d_j \delta_{ij} = d_i = 0$$

Les conditions :

#+BEGIN_CENTER
\(
\scalaire{\phi_{n+1}}{\phi_n} = 0 \\
\scalaire{\phi_{n+1}}{\phi_{n-1}} = 0
\)
#+END_CENTER

impliquent respectivement que :

#+BEGIN_CENTER
\(
b_n = -a_n\scalaire{\phi_n}{x\phi_n} \\
c_n = -a_n\scalaire{\phi_{n-1}}{x\phi_n}
\)
#+END_CENTER

La condition de normalisation :

$$\scalaire{\phi_{n+1}}{\phi_{n+1}} = a_n \scalaire{x\phi_n}{\phi_{n+1}} = 1$$

nous donne alors la valeur de $a_n$ :

#+BEGIN_CENTER
\(
a_n^2 \scalaire{x\phi_n}{x\phi_n}} -
a_n^2 \scalaire{x\phi_n}{\phi_n}^2 -
a_n^2 \scalaire{x\phi_n}{\phi_{n-1}}^2 = 1 \\
a_n = \left[\scalaire{x\phi_n}{x\phi_n} -
\scalaire{x\phi_n}{\phi_n}^2 -
\scalaire{x\phi_n}{\phi_{n-1}}^2\right]^{-1/2}
\)
#+END_CENTER

On voit donc que le choix du produit scalaire détermine :

#+BEGIN_CENTER
\(
\phi_0 = \unsur{\sqrt{\scalaire{1}{1}}} \\
\phi_1 = a_1 (x - \scalaire{\phi_0}{x} \phi_0)
\)
#+END_CENTER

ainsi que toute la suite de polynômes.


*** Approximation

Soit une suite de polynômes orthonormaux $(\phi_0,...\phi_n)$
pour le produit scalaire :

$$\scalaire{u}{v} = \int_A u(x) v(x) d\mu(x)$$

Nous cherchons l'approximation de $u$ :

$$w(x) = \sum_{i=0}^n w_i \phi_i(x)$$

qui minimise l'erreur au sens intégral :

$$\scalaire{u-w}{u-w} = \int_A [u(x)-w(x)]^2 d\mu(x)$$

sur $\mathcal{P}_n$. Imposant que la dérivée par rapport aux $w_i$ soit nulle, on
obtient :

$$2 \int_A \phi_i(x) [u(x)-w(x)] d\mu(x) = 0$$

Mais comme :

$$w_i = \int_A \phi_i(x) w(x) d\mu(x)$$

on obtient :

$$w_i = \int_A \phi_i(x) u(x) d\mu(x) = \scalaire{\phi_i}{u}$$

Ce qui n'a rien d'étonnant au vu  des résultats du chapitre \ref{chap:vector}.
On peut vérifier facilement que la hessienne de l'erreur par rapport aux $w_i$
est bien positive. L'approximation ainsi définie :

#+BEGIN_CENTER
\(
w(x) = \sum_{i=0}^n \phi_i(x) \int_A \phi_i(y) u(y) d\mu(y) \\
w(x) = \sum_{i=0}^n \int_A \phi_i(x) \phi_i(y) u(y) d\mu(y)
\)
#+END_CENTER

minimise donc bien l'erreur sur l'ensemble des polynômes de degré $n$.


*** Intégration de Gauss

Soit une suite de polynômes orthonormaux $(\phi_0,...\phi_n)$
pour le produit scalaire :

$$\scalaire{u}{v} = \int_A u(x) v(x) d\mu(x)$$

Considérons la formule d'intégration :

$$I(f) = \sum_{i=0}^n w_i f(x_i)$$

supposée approximer l'intégrale :

$$\langle f \rangle = \scalaire{f}{1} = \int_A f(x) d\mu(x)$$

Fixons les points $x_0 < x_1 < ... < x_n$ et imposons que
la formule soit exacte pour $\phi_0,...,\phi_n$. On a :

$$\langle \phi_k \rangle = \sum_{i=0}^n w_i \phi_k(x_i)$$

où $k = 0,1,...,n$. Définissant les matrices et vecteurs :

#+BEGIN_CENTER
\(
\varphi = (\langle \phi_k \rangle)_k \\
W  = (w_i)_i \\
\Phi = \left(\phi_i(x_j)\right)_{i,j}
\)
#+END_CENTER

ces conditions se ramènent à :

$$\Phi W = \varphi$$

Si la matrice $\Phi(n+1,n+1)$ est inversible, on a alors :

$$W = \Phi^{-1} \varphi$$

La formule est alors valable pour tout polynôme de $\mathcal{P}_n$.
Notons que

$$\langle \phi_k \rangle = \unsur{\phi_0} \scalaire{\phi_k}{\phi_0}$$

s'annule pour tout $k\ne 0$. Si les racines de $\phi_{n+1}$ sont
toutes distinctes, on peut choisir les $x_i$ tels que :

$$\phi_{n+1}(x_i) = 0$$

On a alors :

$$\langle \phi_{n+1} \rangle = I(\phi_{n+1}) = 0$$

et la formule devient valable sur $\mathcal{P}_{n+1}$. Mieux,
considérons un polynôme $p$ de degré $n+m+1$ où $m \ge 0$ et sa
division euclidienne par $\phi_{n+1}$. On a :

$$p(x) = q(x) \phi_{n+1}(x) + r(x)$$

Comme $q$ est de degré $m$, on a :

$$q = \sum_{i=0}^m q_i \phi_i$$

Si $m \le n$, on a donc :

$$\langle q \phi_{n+1} \rangle = \sum_{i=0}^n q_i \scalaire{\phi_i}{\phi_{n+1}} = 0$$

et :

$$\langle p \rangle = \langle r \rangle = I(r)$$

puisque $r$ est de degré $n$ au plus. Comme $\phi_{n+1}$ s'annule en
les $x_i$, on a aussi ;

$$I(p) = I(r)$$

Rassemblant tout ces résultats, on obtient :

$$\int_A f(x) d\mu(x) = \sum_{i=0}^n w_i f(x_i)$$

pour tout polynôme $f\in\mathcal{P}_{2n+1}$. En pratique, on utilise
ces formules d'intégration pour des fonctions qui ne sont pas forcément
des polynômes.


** Legendre

Les polynômes de Legendre sont orthogonaux pour le produit scalaire :

$$\int_{-1}^1 P_n(x) P_m(x) dx = \frac{2}{2 n + 1} \delta_{mn}$$

Ils obéissent à la récurrence :

#+BEGIN_CENTER
\(
P_0(x) = 1 \\
P_1(x) = x \\
(n+1) P_{n+1}(x) = (2 n + 1) x P_n(x) - n P_{n-1}(x)
\)
#+END_CENTER


** Interpolation

Un problème d'interpolation consiste à trouver les coefficients :
$a_i\in\setR$ tels que la fonction :

$$u = \sum_{i=1}^n a_i u_i$$

où les $u_i$ sont des polynômes de degré $n$, vérifie :

$$\form{\phi_i}{u} = y_i$$

pour tout $i=1,2,...,n$, où les $\phi_i$ sont des formes linéaires de $\mathcal{P}_N^D$
et les $y_i$ des réels donnés.

On utilise couramment des bases biorthogonales :

$$\form{\phi_i}{u_j} = \delta_{ij}$$

et on a alors simplement :

$$a_i = \form{\phi_i}{u}$$

L'exemple le plus courant est :

#+BEGIN_CENTER
\(
\form{\phi_i}{u} = u(x_i) \\
y_i = f(x_i)
\)
#+END_CENTER

pour une certaine fonction $f$ à interpoler. Les conditions ci-dessus
se résument alors à l'égalité de $f$ et de $u$ en un nombre fini de points :

$$u(x_i) = f(x_i)$$

On rencontre parfois aussi le cas :

#+BEGIN_CENTER
\(
\form{\phi_i}{u} = \OD{u}{x}(x_i) \\
y_i = \OD{f}{x}(x_i)
\)
#+END_CENTER


*** Lagrange

Les polynômes de Lagrange $\Lambda_i$ sont biorthogonaux aux formes :

$$\form{\phi_i}{u} = u(x_i)$$

On a donc :

$$\form{\phi_j}{\Lambda_i} = \Lambda_i(x_j) = \delta_{ij}$$

Le polynôme $\Lambda_i$ doit donc s'annuler en tout les points $x_j$,
où $j \ne i$. On peut donc le factoriser comme :

$$\Lambda_i(x) = A_i \prod_{j \in E_i} (x-x_j) = A_i P_i(x)$$

où $E_i = \{ 1,2,...,n \} \setminus \{i\}$. Mais comme $\Lambda_i(x_i) = 1$, on a :

$$A_i = \unsur{P_i(x_i)}$$

et :

$$\Lambda_i(x) = \prod_{j \in E_i} \frac{(x-x_j)}{(x_i - x_j)}$$

Donc si on souhaite construire un polynôme :

$$w(x) = \sum_{i=1}^{n} u_i \Lambda_i(x)$$

qui interpole $u$ en les $x_i$ :

$$u(x_i) = w(x_i)$$

pour tout $i = 1,2,...,n$, il faut et il suffit de prendre :

$$u_i = \form{\phi_i}{u} = u(x_i)$$


*** Newton

L'interpolation de Newton utilise des polynômes construit récursivement à partir
des polynômes de degré inférieur. Soit $f$ la fonction à interpoler, $p_{i,j}$ le polynôme
de degré $j-i$ :

$$p_{ij}(x) = \sum_{j=0}^{j-i} a_k x^k$$

tels que :

$$p_{ij}(x_k) = f(x_k)$$

pour tous $k\in\{i,i+1,...,j\}$. On voit que si $i=j$, on a :

$$p_{ii} = f(x_i)$$

Pour $i < j$, on peut construire les $p_{i,j}$ par récurrence. On vérifie
que :

$$p_{ij}(x) = \frac{(x-x_i)p_{i+1,j}(x)-(x-x_j)p_{i,j-1}(x)}{x_j-x_i}$$

satisfait bien aux conditions d'interpolation ci-dessus.
