<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2019-04-12 ven 19:13 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 10 : Optimisation - 6</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="chimay" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Eclats de vers : Matemat 10 : Optimisation - 6</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="file:///home/david/racine/site/orgmode/index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents">
<h2>Table des matières</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgc35cc9a">1. Valeurs singulières</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\scalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-orgc35cc9a" class="outline-2">
<h2 id="orgc35cc9a"><span class="section-number-2">1</span> Valeurs singulières</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgdf8a683">1.1. Décomposition en valeurs singulières</a></li>
<li><a href="#orgacd5eaa">1.2. Représentation tensorielle</a></li>
<li><a href="#orgddab40f">1.3. Dualité</a></li>
<li><a href="#org00cb193">1.4. Inverse</a></li>
<li><a href="#org81cae4a">1.5. Pseudo-inverse</a></li>
<li><a href="#orga00e2f8">1.6. Représentation matricielle</a></li>
<li><a href="#org7817db4">1.7. Pseudo-inverse</a></li>
<li><a href="#org5b12269">1.8. Systèmes linéaires</a></li>
<li><a href="#org61247b0">1.9. Image et noyau</a></li>
<li><a href="#org973609c">1.10. Normes</a></li>
<li><a href="#org78cb842">1.11. Fonctions de matrices</a></li>
</ul>
</div>

<p>
\label{chap:vs}
</p>
</div>


<div id="outline-container-orgdf8a683" class="outline-3">
<h3 id="orgdf8a683"><span class="section-number-3">1.1</span> Décomposition en valeurs singulières</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Soit les espaces vectoriels \(E\) et \(F\) et une application linéaire \(A : E \mapsto F\) admettant un dual \(A^\dual : F \mapsto E\). Les applications \(A^\dual \circ A\) et \(A \circ A^\dual\) étant auto-adjointes, il y a fort à parier que leurs valeurs et vecteurs propres possèdent d'importantes propriétés.
</p>

<p>
Supposons que \(A^\dual \circ A\) admette les valeurs propres \(\lambda_i \in \corps\) triées par ordre décroissant ($&lambda;<sub>1</sub> &ge; &lambda;<sub>2</sub> &ge; &lambda;<sub>3</sub> &ge; &#x2026;$) et correspondant aux vecteurs propres \(v_i \in E\) formant une suite orthonormée. On a donc :
</p>

<p>
\[A^\dual \circ A(v_i) = \lambda_i \cdot v_i\]
</p>

<p>
On voit que les vecteurs \(z_i = A(v_i) \in F\) possèdent la propriété :
</p>

<p>
\[A^\dual(z_i) = A^\dual \circ A(v_i) = \lambda_i \cdot v_i\]
</p>

<p>
et :
</p>

<p>
\[A \circ A^\dual(z_i) = A(\lambda_i \cdot v_i) = \lambda_i \cdot A(v_i) = \lambda_i \cdot z_i\]
</p>

<p>
Les \(z_i\) sont donc vecteurs propres de \(A \circ A^\dual\) de valeurs propres \(\lambda_i\) identiques à celles de \(A^\dual \circ A\). On a l'orthogonalité :
</p>

<div class="org-center">
<p>
\(
\scalaire{z_i}{z_j} = \scalaire{A(v_i)}{A(v_j)} = \scalaire{v_i}{A^\dual \circ A(v_j)} = \lambda_j \cdot \scalaire{v_i}{v_j} = \lambda_i \cdot \indicatrice_{ij}
\)
</p>
</div>

<p>
On voit aussi que les valeurs propres sont positives :
</p>

<p>
\[\lambda_i = \scalaire{A(v_i)}{A(v_i)} \ge 0\]
</p>

<p>
Comme elles sont également triées par ordre décroissant, on a \(\lambda_1 \ge \lambda_2 \ge ... \ge \lambda_r \strictsuperieur 0\) pour un certain \(r \in \setN\), et \(\lambda_n = 0\) pour tout \(n \strictsuperieur r\). Dans la suite, nous nous restreignons aux valeurs propres non nulles. On peut alors poser :
</p>

<p>
\[\sigma_i = \sqrt{\lambda_i} \strictsuperieur 0\]
</p>

<p>
afin de normaliser les \(z_i\) :
</p>

<p>
\[u_i = \unsur{\sigma_i} \cdot z_i = \unsur{\sigma_i} \cdot A(v_i)\]
</p>

<p>
On a alors :
</p>

<p>
\[\scalaire{u_i}{u_j} = \scalaire{v_i}{v_j} = \indicatrice_{ij}\]
</p>

<p>
ainsi que :
</p>

<p>
\[A^\dual(u_i) = \frac{\lambda_i}{\sigma_i} \cdot v_i = \sigma_i \cdot v_i\]
</p>

<p>
Nous disposons donc des relations primales et duales :
</p>

<div class="org-center">
<p>
\(
A(v_i) = \sigma_i \cdot u_i \\
A^\dual(u_i) = \sigma_i \cdot v_i
\)
</p>
</div>

<p>
Pour tout \(x \in \combilin{v_1,...,v_r}\), on a :
</p>

<p>
\[x = \sum_{i = 1}^r \scalaire{v_i}{x} \cdot v_i\]
</p>

<p>
et :
</p>

\begin{eqnarray*}
A(x) &=& \sum_{i = 1}^r \scalaire{v_i}{x} \cdot A(v_i) \\
&=& \sum_{i = 1}^r \scalaire{v_i}{x} \cdot \sigma_i \cdot u_i
\end{eqnarray*}
</div>
</div>


<div id="outline-container-orgacd5eaa" class="outline-3">
<h3 id="orgacd5eaa"><span class="section-number-3">1.2</span> Représentation tensorielle</h3>
<div class="outline-text-3" id="text-1-2">
<p>
On conclut de ce qui précède que \(A\) peut être représentée sur \(\combilin{v_1,...,v_n}\) par le tenseur associé :
</p>

<p>
\[\mathcal{A} = \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i\]
</p>

<p>
de sorte que :
</p>

<p>
\[A(x) = \mathcal{A} \cdot x = \contraction{ \mathcal{A} }{1}{x} = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x}\]
</p>

<p>
On appelle une telle représentation une décomposition en valeurs singulières.
</p>
</div>
</div>


<div id="outline-container-orgddab40f" class="outline-3">
<h3 id="orgddab40f"><span class="section-number-3">1.3</span> Dualité</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Le tenseur dual est donc :
</p>

<p>
\[\mathcal{A}^\dual = \sum_{i = 1}^r \sigma_i \cdot v_i \otimes u_i\]
</p>
</div>


<div id="outline-container-org3810026" class="outline-4">
<h4 id="org3810026"><span class="section-number-4">1.3.1</span> Propriétés</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
On retrouve sans surprise les représentation de :
</p>

\begin{eqnarray*}
\mathcal{A}^\dual \cdot \mathcal{A} &=& \sum_{i,j = 1}^r \sigma_i \cdot \sigma_j \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes v_j \\
&=& \sum_{i = 1}^r \sigma_i^2 \cdot v_i \otimes v_i
\end{eqnarray*}

<p>
et de :
</p>

\begin{eqnarray*}
\mathcal{A} \cdot \mathcal{A}^\dual &=& \sum_{i,j = 1}^r \sigma_i \cdot \sigma_j \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes u_j \\
&=& \sum_{i = 1}^r \sigma_i^2 \cdot u_i \otimes u_i
\end{eqnarray*}

<p>
en fonction de leurs valeurs et vecteurs propres.
</p>
</div>
</div>
</div>


<div id="outline-container-org00cb193" class="outline-3">
<h3 id="org00cb193"><span class="section-number-3">1.4</span> Inverse</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Supposons que \((v_1,...,v_r)\) forme une base de \(E\) et que \((u_1,...u_r)\) forme une base de \(F\). Soit \(x \in E\) et \(y \in F\) tels que \(y = A(x) = \mathcal{A} \cdot x\). On a :
</p>

<p>
\[y = \sum_{i = 1}^r \scalaire{u_i}{y} \cdot u_i = \mathcal{A} \cdot x = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x}\]
</p>

<p>
On en déduit en comparant que \(\sigma_i \cdot \scalaire{v_i}{x} = \scalaire{u_i}{y}\), ce qui nous donne les produits scalaires correspondant aux coordonnées de \(x\) par rapport aux \(v_i\) :
</p>

<p>
\[\scalaire{v_i}{x} = \unsur{\sigma_i} \cdot \scalaire{u_i}{y}\]
</p>

<p>
On a donc :
</p>

<p>
\[x = \sum_i \scalaire{v_i}{x} \cdot v_i = \sum_i \unsur{\sigma_i} \cdot \scalaire{u_i}{y} \cdot v_i\]
</p>

<p>
Donc, si on pose :
</p>

<p>
\[\mathcal{A}^{-1} = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i\]
</p>

<p>
on a :
</p>

<p>
\[x = \mathcal{A}^{-1} \cdot y\]
</p>
</div>
</div>


<div id="outline-container-org81cae4a" class="outline-3">
<h3 id="org81cae4a"><span class="section-number-3">1.5</span> Pseudo-inverse</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Nous ne supposons à présent plus que les suites de vecteurs \((u_1,...,u_r)\) et \((v_1,...,v_r)\) forment des bases de \(E\) et \(F\), mais nous définissons malgré tout par analogie le tenseur pseudo-inverse de \(A\) par :
</p>

<p>
\[\mathcal{A}^\pinverse = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i\]
</p>

<p>
Le pseudo-inverse \(A^\pinverse\) de l'application linéaire correspondante \(A\) est donc défini par :
</p>

<p>
\[A^\pinverse(y) = \mathcal{A}^\pinverse \cdot y = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{y}\]
</p>
</div>


<div id="outline-container-orge1164dd" class="outline-4">
<h4 id="orge1164dd"><span class="section-number-4">1.5.1</span> Tenseurs de projections</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
On voit que :
</p>

\begin{eqnarray*}
\mathcal{A}^\pinverse \cdot \mathcal{A} &=& \sum_{i,j = 1}^r \unsur{\sigma_i} \cdot \sigma_j \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes v_j \\
&=& \sum_{i = 1}^r v_i \otimes v_i
\end{eqnarray*}

<p>
correspond au tenseur de projection sur \(\combilin{v_1,...,v_r}\). De même :
</p>

\begin{eqnarray*}
\mathcal{A} \cdot \mathcal{A}^\pinverse &=& \sum_{i,j = 1}^r \sigma_i \cdot \unsur{\sigma_j} \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes u_j \\
&=& \sum_{i = 1}^r u_i \otimes u_i
\end{eqnarray*}

<p>
correspond au tenseur de projection sur \(\combilin{u_1,...,u_r}\).
</p>
</div>
</div>


<div id="outline-container-orgd1ce824" class="outline-4">
<h4 id="orgd1ce824"><span class="section-number-4">1.5.2</span> Dualité</h4>
<div class="outline-text-4" id="text-1-5-2">
<p>
On a clairement :
</p>

<div class="org-center">
<p>
\(
(\mathcal{A} \cdot \mathcal{A}^\pinverse)^\dual = \mathcal{A} \cdot \mathcal{A}^\pinverse \\
(\mathcal{A}^\pinverse \cdot \mathcal{A})^\dual = \mathcal{A}^\pinverse \cdot \mathcal{A}
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org2031e77" class="outline-4">
<h4 id="org2031e77"><span class="section-number-4">1.5.3</span> Produits</h4>
<div class="outline-text-4" id="text-1-5-3">
<p>
On déduit des résultats ci-dessus que :
</p>

\begin{eqnarray*}
\mathcal{A} \cdot \mathcal{A}^\pinverse \cdot \mathcal{A} &=& \sum_{i,j = 1}^r \sigma_i \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes v_j \\
&=& \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i \\
&=& \mathcal{A}
\end{eqnarray*}

<p>
et :
</p>

\begin{eqnarray*}
\mathcal{A}^\pinverse \cdot \mathcal{A} \cdot \mathcal{A}^\pinverse &=& \sum_{i,j = 1}^r \unsur{\sigma_i} \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes u_j \\
&=& \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i \\
&=& \mathcal{A}^\pinverse
\end{eqnarray*}
</div>
</div>


<div id="outline-container-org69cae56" class="outline-4">
<h4 id="org69cae56"><span class="section-number-4">1.5.4</span> Orthogonalité</h4>
<div class="outline-text-4" id="text-1-5-4">
<p>
Soit le tenseur identité \(\tenseuridentite\). On déduit de ce qui précède les propriétés d'orthogonalité :
</p>

<div class="org-center">
<p>
\(
\mathcal{A} \cdot (\tenseuridentite - \mathcal{A}^\pinverse \cdot \mathcal{A}) = 0 \\
\mathcal{A}^\pinverse \cdot (\tenseuridentite - \mathcal{A} \cdot \mathcal{A}^\pinverse) = 0
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orga00e2f8" class="outline-3">
<h3 id="orga00e2f8"><span class="section-number-3">1.6</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Soit une matrice \(A \in \matrice(\corps,m,n)\) et \(p = \min \{ m , n \}\). L'algorithme de décomposition en valeurs singulières est très simple. On évalue :
</p>

<div class="org-center">
<p>
\(
(\Lambda_1, U) = \schur(A \cdot A^\dual) \\
(\Lambda_2, V) = \schur(A^\dual \cdot A)
\)
</p>
</div>

<p>
On a alors \(U,\Lambda_1 \in \matrice(\corps,n,n)\) et \(V,\Lambda_2 \in \matrice(\corps,m,m)\). Comme les matrices \(A^\dual \cdot A\) et \(A \cdot A^\dual\) sont hermitiennes et que leurs valeurs propres sont identiques, les matrices « triangulaires » obtenues sont en fait diagonales et :
</p>

<div class="org-center">
<p>
\(
\Lambda_1 = \diagonale_n(\lambda_1,...\lambda_p) \\
\Lambda_2 = \diagonale_m(\lambda_1,...\lambda_p)
\)
</p>
</div>

<p>
On pose alors \(\sigma_i = \sqrt{\lambda_i}\) pour \(i \in \{1,2,...,p\}\) et on a \(\sigma_1 \ge \sigma_2 \ge ... \ge \sigma_r \strictsuperieur 0\) et \(\sigma_{r + 1} = ... = \sigma_p = 0\). Les colonnes de \(U\) et de \(V\) sont les vecteurs propres correspondant :
</p>

<div class="org-center">
<p>
\(
u_i = \colonne_i U \\
v_i = \colonne_i V
\)
</p>
</div>

<p>
On a également \(U^{-1} = U^\dual\) et \(V^{-1} = V^\dual\). La décomposition en valeurs singulières de \(A\) s'écrit :
</p>

<p>
\[A = \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\]
</p>

<p>
Si nous posons :
</p>

<p>
\[S = \diagonale_{m,n}(\sigma_1,...,\sigma_r)\]
</p>

<p>
on peut réécrire la décomposition de \(A\) sous la forme :
</p>

<p>
\[A = U \cdot S \cdot V^\dual\]
</p>

<p>
On note alors :
</p>

<p>
\[(U,S,V) = \singuliere(A)\]
</p>
</div>
</div>


<div id="outline-container-org7817db4" class="outline-3">
<h3 id="org7817db4"><span class="section-number-3">1.7</span> Pseudo-inverse</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Le pseudo-inverse est donné par :
</p>

<p>
\[A^\pinverse = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot u_i^\dual\]
</p>

<p>
On a donc :
</p>

<p>
\[S^\pinverse = \diagonale_{n,m}\left(\unsur{\sigma_1},...,\unsur{\sigma_r}\right)\]
</p>

<p>
et :
</p>

<p>
\[A^\pinverse = V \cdot S^\pinverse \cdot U^\dual\]
</p>
</div>
</div>


<div id="outline-container-org5b12269" class="outline-3">
<h3 id="org5b12269"><span class="section-number-3">1.8</span> Systèmes linéaires</h3>
<div class="outline-text-3" id="text-1-8">
</div>
<div id="outline-container-orgd6c572f" class="outline-4">
<h4 id="orgd6c572f"><span class="section-number-4">1.8.1</span> Moindres carrés</h4>
<div class="outline-text-4" id="text-1-8-1">
<p>
Soit la matrice \(A \in \matrice(\corps,m,n)\), le vecteur matriciel \(b \in \corps^m\) et l'erreur produite par \(x \in \corps^n\) :
</p>

<p>
\[e(x) = b - A \cdot x\]
</p>

<p>
On dit aussi que \(e(x)\) est le résidu du système en \(x\). Nous allons tenter de minimiser :
</p>

<p>
\[\mathcal{E}(x) = e(x)^\dual \cdot e(x) = \norme{e(x)}^2\]
</p>

<p>
en utilisant la décomposition en valeurs singulières \(A = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\). Comme \((v_1,...,v_n)\), suite orthonormée et linéairement indépendante, forme une base de \(\corps^n\), on peut exprimer \(x\) en fonction de ses coordonnées dans cette base :
</p>

<p>
\[x = \sum_{i = 1}^n x_i \cdot v_i = \sum_{i = 1}^n \scalaire{v_i}{x} \cdot v_i\]
</p>

<p>
Comme \((u_1,...,u_m)\), suite orthonormée et linéairement indépendante, forme une base de \(\corps^m\), on peut exprimer \(b\) comme :
</p>

<p>
\[b = \sum_{i = 1}^m \scalaire{u_i}{b} \cdot u_i\]
</p>

<p>
On a également :
</p>

<p>
\[A \cdot x = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x} = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot x_i\]
</p>

<p>
On en conclut que l'erreur s'écrit :
</p>

<p>
\[e(x) = \sum_{i = 1}^r (\scalaire{u_i}{b} - \sigma_i \cdot x_i) \cdot u_i + \sum_{i = r + 1}^m \scalaire{u_i}{b} \cdot u_i\]
</p>

<p>
Posons :
</p>

<div class="org-center">
<p>
\(
e<sub>i</sub>(x) =
</p>
\begin{cases}
\scalaire{u_i}{b} - \sigma_i \cdot x_i & \text{ si } i \in \{1,...,r\} \\
\scalaire{u_i}{b} & \text{ si } i \in \{r + 1, ...,m\} \\
\end{cases}
<p>
\)
</p>
</div>

<p>
On a alors \(e(x) = \sum_{i = 1}^m e_i(x) \cdot u_i\) et :
</p>

<p>
\[\mathcal{E}(x) = \norme{e(x)}^2 = \sum_{i,j = 1}^m \conjaccent{e}_i(x) \cdot e_j(x) \cdot u_i^\dual \cdot u_j = \sum_{i = 1}^m \abs{e_i(x)}^2\]
</p>

<p>
On a donc :
</p>

<p>
\[\mathcal{E}(x) = \sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot x_i}^2 + \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2\]
</p>

<p>
Dans le cas où l'on travaille avec des réels, l'annulation de la dérivée par rapport aux \(x_i\) nous donne :
</p>

<p>
\[2 (\scalaire{u_i}{b} - \sigma_i \cdot x_i) = 0\]
</p>

<p>
lorsque \(i \in \{1,...,r\}\). Nous n'avons par contre aucune contrainte sur \(x_{r + 1},...,x_n\). Un choix satisfaisant les conditions ci-dessus est donc :
</p>

<div class="org-center">
<p>
\(
x<sub>i</sub> =
</p>
\begin{cases}
\scalaire{u_i}{b} / \sigma_i & \text{ si } i \in \{1,...,r\} \\
0 & \text{ si } i \in \{r + 1, ...,n\} \\
\end{cases}
<p>
\)
</p>
</div>

<p>
Notre \(x\) potentiellement optimal s'écrit donc :
</p>

<p>
\[x = \sum_{i = 1}^r \unsur{\sigma_i} \cdot \scalaire{u_i}{b} \cdot v_i\]
</p>

<p>
La somme ressemble à une expression faisant intervenir le pseudo-inverse. En effet, on a :
</p>

<p>
\[A^\pinverse \cdot b = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{b} = x\]
</p>

<p>
Considérons à présent le cas général complexe. On voit que pour le choix \(x = A^\pinverse \cdot b\) :
</p>

<p>
\[\mathcal{E}(x) = \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2\]
</p>

<p>
On en déduit la borne inférieure de l'erreur :
</p>

<p>
\[\mathcal{E}(z) = \sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot \scalaire{v_i}{z}}^2 + \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2 \ge \sum_{i = r + 1}^n \abs{\scalaire{u_i}{b}}^2 = \mathcal{E}(x)\]
</p>

<p>
pour tout \(z \in \setC^n\). Le choix \(x = A^\pinverse \cdot b\) minimise bien la norme de l'erreur sur \(\setC^n\) :
</p>

<p>
\[x = A^\pinverse \cdot b \in \arg\min_{z \in \setC^n} \mathcal{E}(z)\]
</p>

<p>
Les \(x_{r + 1},...,x_n\) étant des complexes arbitraires, nous allons montrer que l'ensemble optimal s'écrit :
</p>

<p>
\[\arg\min_{z \in \setC^n} \mathcal{E}(z) = \Gamma = \left\{ \left(A^\pinverse \cdot b + \sum_{i = r + 1}^n x_i \cdot v_i \right) : \ x_{r + 1},...,x_n \in \setC \right\}\]
</p>

<p>
En effet, on a \(\mathcal{E}(z) = \mathcal{E}(x)\) pour tout \(z \in \Gamma\). On voit aussi que tout choix de \(z \notin \Gamma\) provoque :
</p>

<p>
\[\sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot \scalaire{v_i}{z}}^2 \strictsuperieur 0\]
</p>

<p>
et donc \(\mathcal{E}(z) \strictsuperieur \mathcal{E}(x)\).
</p>
</div>
</div>


<div id="outline-container-org3150558" class="outline-4">
<h4 id="org3150558"><span class="section-number-4">1.8.2</span> Projection</h4>
<div class="outline-text-4" id="text-1-8-2">
<p>
On peut réécrire \(\Gamma\) sous la forme :
</p>

<p>
\[\Gamma = \{ A^\pinverse \cdot b \} + \combilin{v_{r + 1},...,v_n}\]
</p>

<p>
Soit la matrice de projection :
</p>

<p>
\[P = \sum_{i = r + 1}^n v_i \otimes v_i\]
</p>

<p>
On sait que \(P \cdot z \in \combilin{v_{r + 1},...,v_n}\) pour tout \(z \in \setC^n\) et que \(P \cdot y = y\) pour tout \(y \in \combilin{v_{r + 1},...,v_n}\). On en conclut que tout \(x \in \Gamma\) peut s'écrire sous la forme :
</p>

<p>
\[x = A^\pinverse \cdot b + P \cdot z\]
</p>

<p>
pour un certain \(z \in \corps^n\). La matrice de projection \(P\) est également la complémentaire de la projection sur \(\combilin{v_1,...,v_r}\). Or, on a a vu que \(A^\pinverse \cdot A\) est précisément cette matrice de projection. On retrouve donc fort logiquement :
</p>

<p>
\[I - A^\pinverse \cdot A = \sum_{i = 1}^n v_i \otimes v_i - \sum_{i = 1}^r v_i \otimes v_i = \sum_{i = r + 1}^n v_i \otimes v_i = P\]
</p>

<p>
On a donc en définitive des vecteurs optimaux de la forme :
</p>

<p>
\[x = A^\pinverse \cdot b + (I - A^\pinverse \cdot A) \cdot z\]
</p>
</div>
</div>


<div id="outline-container-org208d2d2" class="outline-4">
<h4 id="org208d2d2"><span class="section-number-4">1.8.3</span> Solutions</h4>
<div class="outline-text-4" id="text-1-8-3">
<p>
Soit l'espace des solutions :
</p>

<p>
\[S = \{ x \in \setC^n : A \cdot x = b \} = \{ x \in \setC^n : \mathcal{E}(x) = 0 \}\]
</p>

<p>
Si \(\scalaire{u_{r + 1}}{b} = ... = \scalaire{u_m}{b} = 0\), le minimum de l'erreur est nul et \(\mathcal{E}(x) = 0\) pour tout \(x \in \Gamma\). On en conclut que \(x \in S\), d'où \(\Gamma \subseteq S\). D'un autre coté, tout \(z \in S\) minimise \(\mathcal{E}(z) = 0\). On a donc également \(S \subseteq \Gamma\) et finalement \(\Gamma = S\).
</p>

<p>
Inversément, si \(S \ne \emptyset\), on conclut que \(\scalaire{u_{r + 1}}{b} = ... = \scalaire{u_m}{b} = 0\).
</p>
</div>
</div>


<div id="outline-container-org6b870ce" class="outline-4">
<h4 id="org6b870ce"><span class="section-number-4">1.8.4</span> Norme contrainte</h4>
<div class="outline-text-4" id="text-1-8-4">
<p>
Supposons que \(S \ne \emptyset\). Soit \(x \in \Gamma = S\), que l'on écrit sous la forme :
</p>

\begin{eqnarray*}
x &=& A^\pinverse \cdot b + \sum_{i = r + 1}^n x_i \cdot v_i \\
&=& \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{b} + \sum_{i = r + 1}^n x_i \cdot v_i \\
\end{eqnarray*}

<p>
Par orthonormalité des \(v_i\), on a :
</p>

<p>
\[\norme{x}^2 = x^\dual \cdot x = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot \abs{\scalaire{u_i}{b}}^2 + \sum_{i = r + 1}^n \abs{x_i}^2\]
</p>

<p>
On voit que :
</p>

<p>
\[\norme{x}^2 \ge \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot \abs{\scalaire{u_i}{b}}^2 = \norme{A^\pinverse \cdot b}^2\]
</p>

<p>
On en conclut que le choix \(x = A^\pinverse \cdot b\) minimise la norme de \(x\) sur \(S\) :
</p>

<p>
\[A^\pinverse \cdot b \in \arg\min_{z \in S} \norme{z}^2\]
</p>
</div>
</div>


<div id="outline-container-orge8fe975" class="outline-4">
<h4 id="orge8fe975"><span class="section-number-4">1.8.5</span> Lien avec les résultats précédents</h4>
<div class="outline-text-4" id="text-1-8-5">
<ul class="org-ul">
<li>On a montré précédemment en dérivant les expressions matricielles que le choix :</li>
</ul>

<p>
\[x = (A^\dual \cdot A)^{-1} \cdot A^\dual \cdot b\]
</p>

<p>
minimise également l'erreur \(\mathcal{E}\) sur \(\setR^n\) lorsque l'inverse de \(A^\dual \cdot A\) existe. Si tel est le cas, on a :
</p>

<p>
\[(A^\dual \cdot A)^{-1} = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot v_i \otimes v_i\]
</p>

<p>
et :
</p>

\begin{eqnarray*}
(A^\dual \cdot A)^{-1} \cdot A^\dual &=& \sum_{i,j = 1}^r \frac{\sigma_j}{\sigma_i^2} \cdot \scalaire{v_i}{v_j} \cdot v_i \otimes u_j \\
&=& \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i = A^\pinverse
\end{eqnarray*}

<ul class="org-ul">
<li>On a vu aussi en utilisant les multiplicateurs de lagrange que le choix :</li>
</ul>

<p>
\[x = A^\dual \cdot (A \cdot A^\dual)^{-1} \cdot b\]
</p>

<p>
minimise également la norme de \(x\) sur \(S\) lorsque l'inverse de \(A \cdot A^\dual\) existe. Si tel est le cas, on a :
</p>

<p>
\[(A \cdot A^\dual)^{-1} = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot u_i \otimes u_i\]
</p>

<p>
et :
</p>

\begin{eqnarray*}
A^\dual \cdot (A \cdot A^\dual)^{-1} &=& \sum_{i,j = 1}^r \frac{\sigma_i}{\sigma_j^2} \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes u_j \\
&=& \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i = A^\pinverse
\end{eqnarray*}
</div>
</div>
</div>


<div id="outline-container-org61247b0" class="outline-3">
<h3 id="org61247b0"><span class="section-number-3">1.9</span> Image et noyau</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Tout vecteur \(b = A \cdot x = \sum_{i = 1}^r \sigma_i \cdot \scalaire{v_i}{x} \cdot u_i\) est exprimé comme une combinaison linéaire des \((u_1,...,u_r)\). On en conclut que \(\image A \subseteq \combilin{u_1,...,u_r}\). Réciproquement, si \(b \in \combilin{u_1,...,u_r}\), on a \(\scalaire{u_{r + 1}}{b} = \scalaire{u_m}{b} = 0\) et l'espace des solutions \(\{ x \in \setC^n : A \cdot x = b\}\) n'est pas vide. On en conclut que \(\combilin{u_1,...,u_r} \subseteq \image A\). D'où finalement :
</p>

<p>
\[\image A = \combilin{u_1,...,u_r}\]
</p>

<p>
Tout vecteur \(z \in \combilin{v_{r + 1},...,v_n}\) vérifie \(\scalaire{v_1}{z} = ... = \scalaire{v_r}{z} = 0\). On en déduit que \(A \cdot z = \sum_{i = 1}^r \sigma_i \cdot 0 \cdot u_i = 0\) et que \(\combilin{v_{r + 1},...,v_n} \subseteq \noyau A\). Réciproquement, si \(z \in \noyau A\), on a \(\sum_{i = 1}^r \sigma_i \cdot \scalaire{v_i}{z} \cdot u_i = 0\) ce qui implique \(\scalaire{v_1}{z} = ... = \scalaire{v_r}{z} = 0\). On en conclut que \(\noyau A \subseteq \combilin{v_{r + 1},...,v_n}\). D'où finalement :
</p>

<p>
\[\noyau A = \combilin{v_{r + 1},...,v_n}\]
</p>
</div>
</div>


<div id="outline-container-org973609c" class="outline-3">
<h3 id="org973609c"><span class="section-number-3">1.10</span> Normes</h3>
<div class="outline-text-3" id="text-1-10">
<p>
La décomposition en valeurs singulières permet d'évaluer facilement
la norme usuelle des applications linéaires :
</p>

<p>
\[\norme{A}_\lineaire = \sup_{x \ne 0} \frac{\norme{A \cdot x}}{\norme{x}} = \max \{\sigma_1,...,\sigma_r\}\]
</p>

<p>
ainsi que la norme de Frobénius :
</p>

<p>
\[\norme{A}_F = \sqrt{A^\dual : A} = \sqrt{\sum_{i = 1}^r \sigma_i^2}\]
</p>
</div>
</div>


<div id="outline-container-org78cb842" class="outline-3">
<h3 id="org78cb842"><span class="section-number-3">1.11</span> Fonctions de matrices</h3>
<div class="outline-text-3" id="text-1-11">
<p>
La décomposition en valeurs singulières permet d'étendre la définition
d'une fonction \(f : \setR \mapsto \setR\). Soit la décomposition de \(A\) :
</p>

<p>
\[A = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\]
</p>

<p>
On définit alors :
</p>

<p>
\[f(A) = \sum_{i = 1}^r f(\sigma_i) \cdot u_i \cdot v_i^\dual\]
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2019-04-12 ven 19:13</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
