<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2019-10-01 mar 12:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 10 : Optimisation - 8</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="chimay" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Eclats de vers : Matemat 10 : Optimisation - 8</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents">
<h2>Table des matières</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org8aefeaa">1. Théorie spectrale</a></li>
<li><a href="#org4b0ec91">2. Calcul variationnel</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-org8aefeaa" class="outline-2">
<h2 id="org8aefeaa"><span class="section-number-2">1</span> Théorie spectrale</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents">
<ul>
<li><a href="#org851f052">1.1. Progression géométrique</a></li>
<li><a href="#org41be811">1.2. Convergence</a></li>
<li><a href="#org885ef7b">1.3. Exponentielle</a></li>
</ul>
</div>

<p>
\label{spectral}
</p>
</div>


<div id="outline-container-org851f052" class="outline-3">
<h3 id="org851f052"><span class="section-number-3">1.1</span> Progression géométrique</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Soit un espace de Hilbert \(H\) et une application linéaire \(A : H \mapsto H\). On voit que :
</p>

\begin{align}
\sum_{k = 0}^n A^k &= \identite + A + A^2 + ... + A^n \\
A \circ \sum_{k = 0}^n A^k &= A + A^2 + A^3 + ... + A^{n + 1}
\end{align}

<p>
En soustrayant ces deux équations, on obtient :
</p>

<p>
\[(\identite - A) \circ \sum_{k = 0}^n A^k = \identite - A^{n + 1}\]
</p>

<p>
On montre de même que :
</p>

<p>
\[\left[ \sum_{k = 0}^n A^k \right] \circ (\identite - A) = \identite - A^{n + 1}\]
</p>
</div>


<div id="outline-container-org180eeb9" class="outline-4">
<h4 id="org180eeb9"><span class="section-number-4">1.1.1</span> Infinie</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
Si \(\norme{A} \strictinferieur 1\), on a \(\norme{A^n} \le \norme{A}^n \to 0\) lorsque \(n \to \infty\) et donc \(A^n \to 0\). On en déduit que :
</p>

<p>
\[(\identite - A) \circ \sum_{k = 0}^{+\infty} A^k = \lim_{n \to \infty} (\identite - A^{n + 1}) = \identite\]
</p>

<p>
On a aussi :
</p>

<p>
\[\left[ \sum_{k = 0}^{+\infty} A^k \right] \circ (\identite - A) = \identite\]
</p>

<p>
On en déduit que :
</p>

<p>
\[(\identite - A)^{-1} = \sum_{k = 0}^{+\infty} A^k\]
</p>
</div>
</div>
</div>


<div id="outline-container-org41be811" class="outline-3">
<h3 id="org41be811"><span class="section-number-3">1.2</span> Convergence</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Soit une application linéaire continue \(A : H \mapsto H\). Choisissons \(\lambda \in \setC\) tel que \(\norme{A} \strictinferieur \abs{\lambda}\). On a :
</p>

<p>
\[\norme{A^k} \le \norme{A}^k \strictinferieur \abs{\lambda}^k\]
</p>

<p>
Posons \(r = \norme{A} / \abs{\lambda} \strictinferieur 1\) et divisons par le module de \(\lambda\) puissance \(k\) :
</p>

<p>
\[\frac{ \norme{A^k} }{ \abs{\lambda}^k } \le \frac{ \norme{A}^k }{ \abs{\lambda}^k } = r^k \strictinferieur 1\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\sum_{k = 0}^n \frac{ \norme{A^k} }{ \abs{\lambda}^k } \le \sum_{k = 0}^n r^k = \frac{1 - r^k}{1 - r} \le \unsur{1 - r}\]
</p>

<p>
La suite des :
</p>

<p>
\[S_n = \sum_{k = 0}^n \frac{ \norme{A^k} }{ \abs{\lambda}^k }\]
</p>

<p>
étant croissante et bornée, elle converge vers son supremum :
</p>

<p>
\[S = \sum_{k = 0}^{+\infty} \frac{ \norme{A^k} }{ \abs{\lambda}^k } = \lim_{n \to \infty} S_n = \sup_{n \in \setN} S_n\]
</p>

<p>
Soit \(x \in H\) et la suite définie par \(u_0 = x\) et :
</p>

<p>
\[u_n = \sum_{k = 0}^n \unsur{\lambda^k} \cdot A^k(x)\]
</p>

<p>
Pour tout \(m,n \in \setN\) avec \(m \ge n\), on a :
</p>

<p>
\[\norme{u_m - u_n} = \norme{\sum_{k = n + 1}^m \unsur{\lambda^k} \cdot A^k(x)} \le \sum_{k = n + 1}^m \frac{ \norme{A^k(x)} }{ \abs{\lambda}^k }\]
</p>

<p>
Majorons par la norme de \(A^k\), puis la norme de \(A\) puissance \(k\) :
</p>

<p>
\[\norme{u_m - u_n} \le \left[ \sum_{k = n + 1}^m \frac{ \norme{A^k} }{ \abs{\lambda}^k } \right] \cdot \norme{x} \le \left[ \sum_{k = n + 1}^m \frac{ \norme{A}^k }{ \abs{\lambda}^k } \right] \cdot \norme{x}\]
</p>

<p>
et effectuons le changement de variable \(i = k - (n + 1)\). Il vient :
</p>

<p>
\[\norme{u_m - u_n} \le \frac{ \norme{A}^{n + 1} }{ \abs{\lambda}^{n + 1} } \left[ \sum_{i = 0}^{m - n - 1} \frac{ \norme{A}^i }{ \abs{\lambda}^i } \right] \cdot \norme{x} = r^{n + 1} \cdot S_{m - n - 1} \cdot \norme{x}\]
</p>

<p>
Mais comme \(S_{m - n - 1} \le S\), on a finalement :
</p>

<p>
\[\norme{u_m - u_n} \le r^{n + 1} \cdot S \cdot \norme{x}\]
</p>

<p>
qui converge vers \(0\) lorsque \(n \to \infty\). La suite des \(u_n\) est donc de Cauchy et converge vers un certain \(L(x) \in H\), ce qui définit l'application \(L : H \mapsto H\), que l'on note :
</p>

<p>
\[L = \sum_{k = 0}^{+\infty} \unsur{\lambda^k} \cdot A^k\]
</p>
</div>


<div id="outline-container-org7eff583" class="outline-4">
<h4 id="org7eff583"><span class="section-number-4">1.2.1</span> Continuité</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
Cette application est de norme finie et donc continue car pour tout \(n \in \setN\) :
</p>

<p>
\[\norme{u_n} \le \left[ \sum_{k = 0}^n \frac{ \norme{A}^k }{ \abs{\lambda}^k } \right] \cdot \norme{x} = \frac{ 1 - r^{n + 1} }{1 - r} \cdot \norme{x} \le \frac{\norme{x}}{1 - r}\]
</p>

<p>
On a donc :
</p>

<p>
\[\norme{L(x)} = \lim_{n \to \infty} \norme{u_n} \le \frac{\norme{x}}{1 - r}\]
</p>

<p>
d'où :
</p>

<p>
\[\norme{L} \le \unsur{1 - r}\]
</p>
</div>
</div>


<div id="outline-container-org0e62449" class="outline-4">
<h4 id="org0e62449"><span class="section-number-4">1.2.2</span> Inverse</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
Comme l'application \(B = A / \lambda\) vérifie \(\norme{B} \strictinferieur 1\), on a :
</p>

<div class="org-center">
<p>
\(
(\lambda \cdot \identite - A) \circ (\unsur{\lambda} \cdot L) = (\identite - \unsur{\lambda} \cdot A) \circ L = \identite \\
(\unsur{\lambda} \cdot L) \circ (\lambda \cdot \identite - A) = L \circ (\identite - \unsur{\lambda} \cdot A) = \identite
\)
</p>
</div>

<p>
et donc :
</p>

<p>
\[(\lambda \cdot \identite - A)^{-1} = \unsur{\lambda} \cdot L\]
</p>
</div>
</div>
</div>


<div id="outline-container-org885ef7b" class="outline-3">
<h3 id="org885ef7b"><span class="section-number-3">1.3</span> Exponentielle</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Soit une application linéaire continue \(A : H \mapsto H\). Sous réserve de convergence, on définit l'opérateur \(\exp(A)\) associé par :
</p>

<p>
\[\exp(A) = \sum_{k = 0}^{+\infty} \unsur{k !} \cdot A^k\]
</p>

<p>
On a donc :
</p>

<p>
\[\exp(A)(u) = \sum_{k = 0}^{+\infty} \unsur{k !} \cdot A^k(u)\]
</p>

<p>
pour tout \(u \in H\).
</p>
</div>
</div>
</div>


<div id="outline-container-org4b0ec91" class="outline-2">
<h2 id="org4b0ec91"><span class="section-number-2">2</span> Calcul variationnel</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents">
<ul>
<li><a href="#org61d04c5">2.1. Méthode des variations</a></li>
<li><a href="#org601882f">2.2. Discrétisation</a></li>
<li><a href="#org9e39a7f">2.3. Moindres carrés</a></li>
<li><a href="#orgbc2f76a">2.4. Lax-Milgram</a></li>
<li><a href="#orgf394855">2.5. Valeurs propres</a></li>
</ul>
</div>

<p>
\label{chap:varia}
</p>
</div>


<div id="outline-container-org61d04c5" class="outline-3">
<h3 id="org61d04c5"><span class="section-number-3">2.1</span> Méthode des variations</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Soit l'espace fonctionnel \(\mathcal{F}\) et la forme \(I : \mathcal{F} \mapsto \setR\). Un problème variationnel consiste à chercher une fonction \(u\) qui minimise \(I\) sur \(\mathcal{F}\) :
</p>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v\in\mathcal{F}\). L'astuce consiste à transformer ce problème en considérant la famille de fonctions \(\{ J_w : w \in \mathcal{F} \}\) définies par :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). Comme \(\mathcal{F}\) est un espace vectoriel, \(u + \epsilon \cdot w \in \mathcal{F}\). On en déduit que :
</p>

<p>
\[J_w(0) = I(u) \le J_w(\epsilon)\]
</p>

<p>
Si les fonctions \(J_w\) sont dérivables, les propriétés des extrema des fonctions \(\setR \mapsto \setR\) nous disent que :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = 0\]
</p>

<p>
pour toute variation \(w \in \mathcal{F}\). Si la dérivée seconde existe, on doit également avoir :
</p>

<p>
\[\OOD{J_w}{\epsilon}(0) \ge 0\]
</p>

<p>
Ces équations nous permettent de caractériser la solution \(u\) de notre problème variationnel.
</p>
</div>
</div>


<div id="outline-container-org601882f" class="outline-3">
<h3 id="org601882f"><span class="section-number-3">2.2</span> Discrétisation</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Une technique couramment employée pour résoudre les problèmes variationnels
est de choisir une suite de fonctions \(\varphi_i \in \mathcal{F}\) linéairement indépendantes et de minimiser sur l'espace vectoriel \(\mathcal{F}_n = \combilin{\varphi_1,\varphi_2,...,\varphi_n} \subseteq \mathcal{F}\). On espère que la solution obtenue sera proche de la solution exacte. Ce sera par exemple le cas si on a schématiquement :
</p>

<p>
\[\lim_{n \to \infty} \adh \mathcal{F}_n = \mathcal{F}\]
</p>

<p>
au sens de la distance \(\distance\) définie sur \(\mathcal{F}\). Pour toute précision \(\epsilon > 0\), on pourra alors trouver un \(n \in \setN\) assez grand et un \(u_n\in \mathcal{F}_n\) tels que :
</p>

<p>
\[\distance(u_n,u) \le \epsilon\]
</p>
</div>
</div>


<div id="outline-container-org9e39a7f" class="outline-3">
<h3 id="org9e39a7f"><span class="section-number-3">2.3</span> Moindres carrés</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Soit \(f : A \mapsto \setR\) et le sous-ensemble \(\mathcal{F} \subseteq \fonction(A,\setR)\). On cherche la fonction \(u \in \mathcal{F}\) qui se rapproche le plus possible de \(f\) au sens intégral des moindres carrés. On cherche donc le \(u\) qui minimise la fonctionnelle :
</p>

<p>
\[I(u) = \int_A \Big[ u(x) - f(x) \Big]^2 dx\]
</p>

<p>
Afin de résoudre ce problème, on pose :
</p>

<p>
\[J_v(\epsilon) = I(u + \epsilon \cdot v) = \int_A \Big[ u(x) + \epsilon \cdot v(x) - f(x) \Big]^2 dx\]
</p>

<p>
pour tout \(\epsilon \in \setR\) et \(v \in \mathcal{F}\). La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \int_A 2 \big[ u(x) + \epsilon \cdot v(x) - f(x) \big] \cdot v(x) \ dx\]
</p>

<p>
Comme elle doit s'annuler en \(\epsilon = 0\), on a :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = 2 \int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
donc :
</p>

<p>
\[\int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
pour tout \(v \in F\).
</p>
</div>


<div id="outline-container-orga656011" class="outline-4">
<h4 id="orga656011"><span class="section-number-4">2.3.1</span> Discrétisation</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
On résout approximativement ce problème en posant :
</p>

<p>
\[u_n(x) = \sum_{i = 1}^n U_i \cdot \varphi_i(x)\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont des fonctions connues et où les \(U_i\) sont des réels à déterminer. Comme on désire que \(u_n \approx u\), on impose :
</p>

<p>
\[\int_A (u_n(x) - f(x)) \cdot \varphi_i(x) \ dx = 0\]
</p>

<p>
On a alors :
</p>

<p>
\[\int_A \varphi_i \sum_j U_j \cdot \varphi_j \ dx = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
ou :
</p>

<p>
\[\sum_j \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right] \cdot U_j = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
Définissons les matrices \(A \in \matrice(\setR,n,n)\), \(B \in \matrice(\setR,n,1)\) et \(U \in \matrice(\setR,n,1)\) :
</p>

\begin{align}
A &= \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right]_{i,j} \\
B &= \left[ \int_A \varphi_i \cdot f \ dx \right]_i \\
U &= \left[ U_i \right]_i
\end{align}

<p>
Le problème peut alors s'exprimer sous forme matricielle :
</p>

<p>
\[A \cdot U = B\]
</p>

<p>
Si la matrice \(A\) est inversible, la solution est donnée par :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
et nous en déduisons notre approximation \(u_n = \sum_i U_i \cdot \varphi_i\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgbc2f76a" class="outline-3">
<h3 id="orgbc2f76a"><span class="section-number-3">2.4</span> Lax-Milgram</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Soit un espace fonctionnel de Hilbert \(\mathcal{F}\). Nous considérons une forme bilinéaire \(a : \mathcal{F} \times \mathcal{F} \mapsto \setR\), de norme finie, coercive et symétrique :
</p>

<p>
\[\biforme{u}{a}{v} = \biforme{v}{a}{u}\]
</p>

<p>
pour tout \(u,v \in F\). Nous considérons également une forme linéaire continue \(b : \mathcal{F} \mapsto \setR\) et nous définissons la fonctionnelle \(I : \mathcal{F} \mapsto \setR\) par :
</p>

<p>
\[I(v) = \unsur{2} \biforme{v}{a}{v} - \forme{b}{v}\]
</p>


<ul class="org-ul">
<li>Supposons que \(I\) atteigne un minimum global en \(u\). On a alors :</li>
</ul>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v \in F\). Choisissons un quelconque \(w \in \mathcal{F}\) et posons :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon \in \setR\). Tenant compte des propriétés de \(a\) et \(b\), on obtient :
</p>

<p>
\[J_w(\epsilon) = \unsur{2} \biforme{u}{a}{u} + \epsilon \cdot \biforme{u}{a}{w} + \frac{\epsilon^2}{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \epsilon \cdot \forme{b}{w}\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \biforme{u}{a}{w} + \epsilon \cdot \biforme{w}{a}{w} - \forme{b}{w}\]
</p>

<p>
La condition extrémale sur \(u\) nous dit que \(J_w(0) \le J_w(\epsilon)\) pour tout \(\epsilon \in \setR\). On doit donc avoir :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = \biforme{u}{a}{w} - \forme{b}{w} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Le théorème de Lax-Milgram nous dit qu'il existe un unique \(u \in  \mathcal{F}\) vérifiant cette condition.
</p>

<ul class="org-ul">
<li>Supposons à présent que \(u \in \mathcal{F}\) soit l'unique élément de \(\mathcal{F}\) vérifiant :</li>
</ul>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Choisissons \(v \in \mathcal{F}\) et posons \(w = v - u\). Comme \(\biforme{u}{a}{w} = \forme{b}{w}\), on a :
</p>

\begin{align}
I(v) &= I(u + w) \\
&= \unsur{2} \biforme{u}{a}{u} + \biforme{u}{a}{w} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \forme{b}{w} \\
&= \unsur{2} \biforme{u}{a}{u} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} \\
&= I(u) + \unsur{2} \biforme{w}{a}{w} \ge I(u)
\end{align}

<p>
On a donc :
</p>

<p>
\[u = \arg\min_{ v \in \mathcal{F} } I(v)\]
</p>
</div>


<div id="outline-container-org5e60ea0" class="outline-4">
<h4 id="org5e60ea0"><span class="section-number-4">2.4.1</span> Orthogonalité</h4>
<div class="outline-text-4" id="text-2-4-1">
<p>
Soit le sous-espace vectoriel \(\mathcal{G} \subseteq \mathcal{F}\) et :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } I(z)\]
</p>

<p>
On a alors :
</p>

<p>
\[\biforme{v}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{G}\).
</p>

<p>
Supposons que \(u \in \mathcal{F}\) minimise \(I\) sur \(\mathcal{F}\) et posons \(e = v - u\). On a :
</p>

<p>
\[\biforme{e}{a}{w} = \biforme{v}{a}{w} - \biforme{u}{a}{w} = \forme{b}{w} - \forme{b}{w} = 0\]
</p>

<p>
Cette propriété est similaire aux propriétés d'orthogonalité vue dans les projections. On est tenté d'en déduire que le \(v\) en question minimise la « norme » de l'écart \(e\) au sens de \(a\). Soit \(z \in \mathcal{G}\) et \(\delta = z - v\). On a \(z - u = z - v + v - u = \delta + e\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + 2 \biforme{e}{a}{\delta} + \biforme{e}{a}{e}\]
</p>

<p>
Mais comme \(\delta \in \mathcal{G}\), on a \(\biforme{e}{a}{\delta} = 0\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + \biforme{e}{a}{e} \ge \biforme{e}{a}{e}\]
</p>

<p>
ce qui prouve que :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } \biforme{z - u}{a}{z - u}\]
</p>
</div>
</div>


<div id="outline-container-org08f8b77" class="outline-4">
<h4 id="org08f8b77"><span class="section-number-4">2.4.2</span> Borne inférieure</h4>
<div class="outline-text-4" id="text-2-4-2">
<p>
Comme \(a\) est coercive, on peut trouver un réel \(\varrho \strictsuperieur 0\) tel que :
</p>

<p>
\[a(u,u) \ge \varrho \cdot \norme{u}^2\]
</p>

<p>
pour tout \(u \in \mathcal{F}\). On sait aussi que :
</p>

<p>
\[\norme{b} = \sup \{ \abs{b(u)} : u \in \mathcal{F}, \ \norme{u} = 1 \} \strictinferieur +\infty\]
</p>

<p>
Posons :
</p>

<p>
\[K(\epsilon) = I(\epsilon \cdot v) = \frac{\epsilon^2}{2} \cdot \biforme{v}{a}{v} - \epsilon \cdot \forme{b}{v}\]
</p>

<p>
et cherchons la valeur de \(\epsilon = \gamma\) qui minimise cette fonction. On trouve :
</p>

<p>
\[\OD{K}{\epsilon}(\gamma) = \gamma \cdot \biforme{v}{a}{v} - \forme{b}{v} = 0\]
</p>

<p>
Donc :
</p>

<p>
\[\gamma = \frac{ \forme{b}{v} }{ \biforme{v}{a}{v} }\]
</p>

<p>
et :
</p>

<p>
\[K(\gamma) = \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } - \frac{ \forme{b}{v}^2 }{ \biforme{v}{a}{v} } = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
On en déduit que :
</p>

<p>
\[I(v) = K(1) \ge K(\gamma) = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
Mais comme :
</p>

<div class="org-center">
<p>
\(
\forme{b}{v}^2 \le \norme{b}^2 \cdot \norme{v}^2 \\
\biforme{v}{a}{v} \ge \varrho \cdot \norme{v}^2
\)
</p>
</div>

<p>
on a :
</p>

<p>
\[\frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } \le \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
et :
</p>

<p>
\[I(v) \ge - \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
Ce résultat étant valable pour tout \(v \in \mathcal{F}\), on a la borne inférieure :
</p>

<p>
\[\inf_{ v \in \mathcal{F} } I(v) \ge - \frac{\norme{b}^2}{2\varrho}\]
</p>
</div>
</div>


<div id="outline-container-org38288bb" class="outline-4">
<h4 id="org38288bb"><span class="section-number-4">2.4.3</span> Discrétisation</h4>
<div class="outline-text-4" id="text-2-4-3">
<p>
Afin de trouver une approximation \(u_n \approx u\), on pose :
</p>

<p>
\[u_n = \sum_{i = 1}^n U_i \cdot \varphi_i\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont connues et où les \(U_i\) sont des réels à déterminer. La linéarité de \(a\) et \(b\) nous permet de développer :
</p>

<p>
\[I(u_n) = \unsur{2} \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j - \sum_{i=1}^n \forme{b}{\varphi_i} U_i\]
</p>

<p>
Si nous définissons les matrices :
</p>

\begin{align}
A &= \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \\
B &= \left[ \forme{b}{\varphi_i} \right]_i \\
U &= \left[ U_i \right]_i
\end{align}

<p>
on peut réécrire \(I(u_n)\) sous forme matricielle :
</p>

<p>
\[I(u_n) = J(U) = \unsur{2} U^\dual \cdot A \cdot U - U^\dual \cdot B\]
</p>

<p>
La condition \(\partial J(U) = 0\) nous amène à :
</p>

<p>
\[A \cdot U - B = 0\]
</p>

<p>
Si la matrice \(A\) est inversible, on en déduit :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
ce qui nous donne \(U\) et donc \(u_n\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgf394855" class="outline-3">
<h3 id="orgf394855"><span class="section-number-3">2.5</span> Valeurs propres</h3>
<div class="outline-text-3" id="text-2-5">
<p>
Soit un espace vectoriel \(E\) et les formes bilinéaires \(a,b : E \times E \mapsto \setR\). Nous supposons que \(a,b\) sont symétriques et définies positives. Nous allons tenter de minimiser la fonctionnelle :
</p>

<p>
\[I(v) = \biforme{v}{a}{v}\]
</p>

<p>
sur l'ensemble :
</p>

<p>
\[\Omega = \{ v \in E : \biforme{v}{b}{v} = 1 \}\]
</p>

<p>
L'espace \(\Omega\) n'est malheureusement pas un sous-espace vectoriel. Par exemple, si \(u\) appartient à \(\Omega\), on a :
</p>

<p>
\[\biforme{2 u}{b}{2 u} = 4 \biforme{u}{b}{u} = 4 \ne 1\]
</p>

<p>
Donc \(2 u \notin \Omega\). Par conséquent, nous ne pouvons pas utiliser les techniques de projection sur un espace vectoriel pour résoudre ce problème. Nous allons donc employer les techniques de minimisation sous contraintes. Définissons le lagrangien :
</p>

<p>
\[\lagrangien(v,y) = \biforme{v}{a}{v} + y \cdot (1 - \biforme{v}{b}{v})\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). La fonction \(u\) minimisant \(I\) sur \(\Omega\) peut dès lors s'obtenir via le point de selle \((u,\lambda)\) :
</p>

<p>
\[\lagrangien(u,y) \le \lagrangien(u,\lambda) \le \lagrangien(v,\lambda)\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). Nous allons évaluer le minimum sur \(v\) en utilisant la méthode des variations. Soit \(w \in E\) et \(\epsilon \in \setR\). On pose :
</p>

\begin{align}
J_v(\epsilon) &= \lagrangien(u + \epsilon \cdot w, \lambda) \\
&= \biforme{u + \epsilon \cdot w}{a}{u + \epsilon \cdot w} + \lambda \cdot [ 1 - \biforme{u + \epsilon \cdot w}{b}{u + \epsilon \cdot w} ]
\end{align}

<p>
Utilisant les propriétés de \(a,b\) et la contrainte \(\biforme{u}{b}{u} = 1\), il vient :
</p>

<div class="org-center">
<p>
\(
J_v(\epsilon) = \biforme{u}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{u} + \epsilon^2 \cdot \biforme{w}{a}{w} \\
\qquad - \lambda \cdot [ 2 \epsilon \cdot \biforme{w}{b}{u} + \epsilon^2 \cdot \biforme{w}{b}{w} ]
\)
</p>
</div>

<p>
Les propriétés du point de selle en \((u,\lambda)\) nous garantissent que :
</p>

<p>
\[J_v(0) \le J_v(\epsilon)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). La dérivée :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = 2 \biforme{w}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{w} - 2 \lambda \cdot [ \biforme{w}{b}{u} + \epsilon \cdot \biforme{w}{b}{w} ]\]
</p>

<p>
doit donc s'annuler en \(\epsilon = 0\) :
</p>

<p>
\[\OD{J_v^\lambda}{\epsilon}(0) = 2 \biforme{w}{a}{u} - 2 \lambda \cdot \biforme{w}{b}{u} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{w}{a}{u} = \lambda \cdot \biforme{w}{b}{u}\]
</p>

<p>
pour tout \(w \in E\). On dit alors que \(\lambda\) est valeur propre de \(a,b\) correspondant à la fonction propre \(u\).
</p>
</div>


<div id="outline-container-orgc5cb25d" class="outline-4">
<h4 id="orgc5cb25d"><span class="section-number-4">2.5.1</span> Propriétés extrémales</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
Si nous choisissons \(w = u\), nous obtenons :
</p>

<p>
\[\biforme{u}{a}{u} = \lambda \cdot \biforme{u}{b}{u} = \lambda\]
</p>

<p>
La valeur propre est donc la valeur minimale de \(I\) sur \(\Omega\) :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \min_{v \in \Omega} \biforme{v}{a}{v}\]
</p>
</div>
</div>


<div id="outline-container-org8a6f34b" class="outline-4">
<h4 id="org8a6f34b"><span class="section-number-4">2.5.2</span> Rapport de Rayleigh</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
Supposons que \(b\) soit strictement définie positive. Posons \(x = \alpha \cdot u\), pour un certain \(\alpha \in \setR\) non nul. On a \(\biforme{x}{a}{x} = \alpha^2 \cdot \biforme{u}{a}{u}\) et \(\biforme{x}{b}{x} = \alpha^2 \cdot \biforme{u}{b}{u} = \alpha^2\). Donc :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \frac{ \biforme{x}{a}{x} }{ \biforme{x}{b}{x} }\]
</p>

<p>
Considérons la même expression pour un quelconque \(z \in E\) non nul :
</p>

<p>
\[R(z) = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} }\]
</p>

<p>
On dit que \(R(z)\) est le rapport de Rayleigh de \(z\). Soit \(v = z / \sqrt{ \biforme{z}{b}{z} }\). On a :
</p>

<p>
\[\biforme{v}{a}{v} = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} } = R(z)\]
</p>

<p>
et :
</p>

<p>
\[\biforme{v}{b}{v} = \frac{ \biforme{z}{b}{z} }{ \biforme{z}{b}{z} } = 1\]
</p>

<p>
ce qui prouve que \(v \in \Omega\). On a donc :
</p>

<p>
\[\lambda = R(x) \le \biforme{v}{a}{v} = R(z)\]
</p>

<p>
On en conclut que \(x\) minimise le rapport de Rayleigh sur \(E_0 = E \setminus \{0\}\) :
</p>

<p>
\[\lambda = R(x) = \arg\min_{z \in E_0} R(z) = \arg\min_{z \ne 0} R(z)\]
</p>

<p>
Comme \(\Omega \subseteq F\), on en conclut que la réciproque est vraie : si \(x\) minimise \(R\) sur \(E_0\), le vecteur \(x/\sqrt{ \biforme{x}{b}{x} }\) minimise la fonctionnelle \(I\) sur \(\Omega\). Les deux problèmes de minimisation sont donc équivalents.
</p>
</div>
</div>


<div id="outline-container-org3068e7f" class="outline-4">
<h4 id="org3068e7f"><span class="section-number-4">2.5.3</span> Suite de vecteurs propres</h4>
<div class="outline-text-4" id="text-2-5-3">
<p>
On peut en fait définir une suite de vecteurs et de valeurs propres. Soit \(\Omega_1 = \Omega\) et \(e_1 = u\). On pose récursivement :
</p>

<p>
\[\Omega_{n + 1} = \{ v \in \Omega : \biforme{v}{b}{e_1} = ... = \biforme{v}{b}{e_n} = 0 \}\]
</p>

<p>
et :
</p>

<p>
\[e_{n + 1} \in \arg\min_{ v \in \Omega_{n + 1} } \biforme{v}{a}{v}\]
</p>

<p>
On aura alors bien sûr \(\Omega_{n + 1} \subseteq \Omega_n \subseteq ... \Omega_1\). Les propriétés extrémales des valeurs propres nous montrent que \(\lambda_{n + 1} \ge \lambda_n \ge ... \ge \lambda_1\).
</p>
</div>
</div>


<div id="outline-container-orga31009f" class="outline-4">
<h4 id="orga31009f"><span class="section-number-4">2.5.4</span> Discrétisation</h4>
<div class="outline-text-4" id="text-2-5-4">
<p>
On pose :
</p>

<p>
\[u_n = \sum_{i=1}^n U_i \cdot \varphi_i\]
</p>

<p>
On a alors :
</p>

<div class="org-center">
<p>
\(
\biforme{u_n}{a}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j \\
\biforme{u_n}{b}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{b}{\varphi_j} \cdot U_j
\)
</p>
</div>

<p>
Avec les matrices :
</p>

<div class="org-center">
<p>
\(
A = \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \\
B = \left[ \biforme{\varphi_i}{b}{\varphi_j} \right]_{i,j}
\)
</p>
</div>

<p>
le lagrangien peut s'écrire :
</p>

<p>
\[\lagrangien(u_n,y) = U^\dual \cdot A \cdot U + y \cdot \left[ 1 - U^\dual \cdot B \cdot U \right]\]
</p>

<p>
Les conditions :
</p>

<div class="org-center">
<p>
\(
\partial_v \lagrangien(u_n,\lambda) = 2 A \cdot U - 2 \lambda \cdot B \cdot U = 0 \\
\partial_y \lagrangien(u_n,\lambda) = 1 - U^\dual \cdot B \cdot U = 0
\)
</p>
</div>

<p>
nous amènent au problème :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot B \cdot U \\
U^\dual \cdot B \cdot U = 1
\)
</p>
</div>

<p>
à résoudre en \(U\). Notons que si on choisit les \(\varphi_i\) « orthonormées » dans le sens du pseudo-produit scalaire introduit par \(b\), on a :
</p>

<p>
\[\biforme{\varphi_i}{b}{\varphi_j} = \delta_{ij}\]
</p>

<p>
et \(B = I\). On peut par exemple construire une telle suite de \(\varphi_i\) en utilisant la méthode de Gram-Schmidt. Le problème se simplifie alors en :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot U \\
U^\dual \cdot U = 1
\)
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2019-10-01 mar 12:32</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
