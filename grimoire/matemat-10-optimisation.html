<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2019-05-07 mar 08:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 10 : Optimisation</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="chimay" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Eclats de vers : Matemat 10 : Optimisation</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="file:///home/david/racine/site/orgmode/index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents">
<h2>Table des matières</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgd1addbc">1. Optimisation libre</a></li>
<li><a href="#org8677323">2. Projections</a></li>
<li><a href="#org800acdf">3. Algorithmes d'optimisation libre</a></li>
<li><a href="#org8b570dd">4. Solveurs itératifs</a></li>
<li><a href="#org4241d26">5. Optimisation sous contrainte</a></li>
<li><a href="#org90cd6c2">6. Valeurs propres</a></li>
<li><a href="#org575af2c">7. Valeurs singulières</a></li>
<li><a href="#orgbff7a3b">8. Espaces de Hilbert</a></li>
<li><a href="#org6212f90">9. Théorie spectrale</a></li>
<li><a href="#orgdbdcf00">10. Calcul variationnel</a></li>
<li><a href="#org1693bbb">11. Algorithmes d'optimisation contrainte</a></li>
<li><a href="#org2639068">12. Réseaux de neurones</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-orgd1addbc" class="outline-2">
<h2 id="orgd1addbc"><span class="section-number-2">1</span> Optimisation libre</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents">
<ul>
<li><a href="#org879c1bf">1.1. Minimum</a></li>
<li><a href="#org5a01a47">1.2. Maximum</a></li>
<li><a href="#org2b6aaa2">1.3. Equivalence</a></li>
<li><a href="#org83b766e">1.4. Dérivées ordinaires</a></li>
<li><a href="#org0284601">1.5. Point de selle</a></li>
<li><a href="#org2238e9d">1.6. Convexité</a></li>
<li><a href="#org6a6411a">1.7. Convexité stricte</a></li>
<li><a href="#org85f2c0e">1.8. Concavité</a></li>
<li><a href="#org30c93ac">1.9. Concavité stricte</a></li>
<li><a href="#orged4a7fb">1.10. Equation du second degré</a></li>
<li><a href="#orgf6f02aa">1.11. Moindres-carrés</a></li>
</ul>
</div>

<p>
\label{chap:optimisationlibre}
</p>
</div>


<div id="outline-container-org879c1bf" class="outline-3">
<h3 id="org879c1bf"><span class="section-number-3">1.1</span> Minimum</h3>
<div class="outline-text-3" id="text-1-1">
\begin{theoreme}

Soit $\varphi \in \continue^2(\setR^n,\setR)$. Supposons que que $a \in \setR^n$ annule la Jacobienne (on parlera ici plutôt de gradient) :

$$\partial \varphi(a) = 0$$

Supposons également que la Hessienne en $a$ soit définie positive, c'est-à-dire que :

$$\Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta \ge 0$$

pour tout $\Delta \in \setR^n$ qui vérifie $\Delta \ne 0$. Si ces conditions sont remplies, nous nous proposons de montrer que $\varphi$ atteint un minimum local en $a$. On peut donc trouver $\delta \strictsuperieur 0$ tel que :

$$\varphi(a) \le \varphi(a + \Delta)$$

pour tout $\Delta \in \setR^n$ vérifiant $\norme{\Delta} \le \delta$. A l'inverse, si $\varphi$ atteint un minimum local en $a$, les conditions sur le gradient et la Hessienne seront remplies.
\end{theoreme}

<ul class="org-ul">
<li>Supposons que les conditions sur le gradient et la hessienne soit remplies. Le développement d'ordre deux :</li>
</ul>

<p>
\[\varphi(a + \Delta) = \varphi(a) + \partial \varphi(a) \cdot \Delta + \unsur{2} \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta + E(\Delta)\]
</p>

<p>
où \(E \sim \petito{\Delta^2}\) devient alors simplement :
</p>

<p>
\[\varphi(a + \Delta) = \varphi(a) + \unsur{2} \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta + E(\Delta)\]
</p>

<p>
Choisissons \(h \in \setR^n\). Pour un \(\lambda \in \setR\) quelconque, posons \(\Delta = \lambda \cdot h\). On a alors :
</p>

<p>
\[\varphi(a + \Delta) = \varphi(a) + \frac{\lambda^2}{2} \cdot h^\dual \cdot \partial^2 \varphi(a) \cdot h + E(\lambda \cdot h)\]
</p>

<p>
Mais comme la Hessienne est définie positive et que \(E\) converge plus vite que \(\norme{\Delta}^2 = \lambda^2 \cdot \norme{h}^2\) vers \(0\), il suffit de choisir \(\lambda \strictsuperieur 0\) assez petit pour avoir :
</p>

<p>
\[\abs{E(\lambda \cdot h)} \le \frac{\lambda^2}{2} \cdot h^\dual \cdot \partial^2 \varphi(a) \cdot h\]
</p>

<p>
on a alors :
</p>

<p>
\[\unsur{2} \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta + E(\Delta) \ge \unsur{2} \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta - \abs{E(\Delta)} \ge 0\]
</p>

<p>
et :
</p>

<p>
\[\varphi(a + \Delta) = \varphi(a) + \unsur{2} \cdot \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta + E(\Delta) \ge \varphi(a)\]
</p>

<p>
Nous avons donc bien un minimum local de \(\varphi\) en \(a\).
</p>

<ul class="org-ul">
<li>Inversément, si \(\varphi\) atteint un minimum local en \(a\), nous avons vu que la différentielle s'annulait. La jacobienne s'annule donc aussi et le développement d'ordre deux devient :</li>
</ul>

<p>
\[\varphi(a + \Delta) = \varphi(a) + \unsur{2} \Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta + E(\Delta) \ge \varphi(a)\]
</p>

<p>
La condition de minimum local nous dit donc que :
</p>

<p>
\[\Delta^\dual \cdot \partial^2 f(a) \cdot \Delta + E(\Delta) \ge 0\]
</p>

<p>
Choisissons à nouveau \(h \in \setR^n\) et posons \(\Delta = \lambda \cdot h\) pour un  \(\lambda \in \setR\) quelconque. On a alors :
</p>

<p>
\[\frac{\lambda^2}{2} \cdot h^\dual \cdot \partial^2 f(a) \cdot h + E(\lambda \cdot h) \ge 0\]
</p>

<p>
Divisant par \(\lambda^2\), on obtient :
</p>

<p>
\[\unsur{2} \cdot h^\dual \cdot \partial^2 f(a) \cdot h + \frac{E(\lambda \cdot h)}{\lambda^2 \cdot \norme{h}^2} \cdot \norme{h}^2 \ge 0\]
</p>

<p>
Si on fait tendre \(\lambda \strictsuperieur 0\) vers \(0\), on arrive à la relation :
</p>

<p>
\[\unsur{2} \cdot h^\dual \cdot \partial^2 f(a) \cdot h \ge 0\]
</p>

<p>
Comme ce résultat est valable quel que soit \(h \in \setR^n\), on en conclut que la Hessienne est définie positive.
</p>
</div>
</div>



<div id="outline-container-org5a01a47" class="outline-3">
<h3 id="org5a01a47"><span class="section-number-3">1.2</span> Maximum</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Un raisonnement analogue nous montre que :
</p>

\begin{theoreme}

Soit $\varphi \in \continue^2(\setR^n,\setR)$. Supposons que que $a \in \setR^n$ annule la Jacobienne (on parlera ici plutôt de gradient) :

$$\partial \varphi(a) = 0$$

Supposons également que la Hessienne en $a$ soit définie négative, c'est-à-dire que :

$$\Delta^\dual \cdot \partial^2 \varphi(a) \cdot \Delta \le 0$$

pour tout $\Delta \in \setR^n$ qui vérifie $\Delta \ne 0$. Si ces conditions sont remplies, $\varphi$ atteint un maximum local en $a$. On peut donc trouver $\delta \strictsuperieur 0$ tel que :

$$\varphi(a) \ge \varphi(a + \Delta)$$

pour tout $\Delta \in \setR^n$ vérifiant $\norme{\Delta} \le \delta$. A l'inverse, si $\varphi$ atteint un maximum local en $a$, les conditions sur le gradient et la Hessienne seront remplies.
\end{theoreme}
</div>
</div>


<div id="outline-container-org2b6aaa2" class="outline-3">
<h3 id="org2b6aaa2"><span class="section-number-3">1.3</span> Equivalence</h3>
<div class="outline-text-3" id="text-1-3">
<p>
En pratique, on peut toujours se ramener à un problème de minimisation.
En effet, maximiser une fonction revient à minimiser son opposé :
</p>

<p>
\[\arg\max_{x \in A} \varphi(x) = \arg\min_{x \in A} (-\varphi(x))\]
</p>

<p>
Nous nous restreindrons donc dans la suite aux problèmes de minimisation.
</p>
</div>
</div>


<div id="outline-container-org83b766e" class="outline-3">
<h3 id="org83b766e"><span class="section-number-3">1.4</span> Dérivées ordinaires</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Pour des fonctions \(f: \setR \mapsto \setR\), les conditions
se simplifient en :
</p>

<div class="org-center">
<p>
\(
\OD{f}{t}(a) = 0 \\
\OOD{f}{t}(a) \ge 0
\)
</p>
</div>

<p>
pour un minimum et en :
</p>

<div class="org-center">
<p>
\(
\OD{f}{t}(a) = 0 \\
\OOD{f}{t}(a) \le 0
\)
</p>
</div>

<p>
pour un maximum.
</p>
</div>
</div>


<div id="outline-container-org0284601" class="outline-3">
<h3 id="org0284601"><span class="section-number-3">1.5</span> Point de selle</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Soit une fonction \(\lagrangien : \setR^n \times \setR^m \mapsto \setR\). Un point de selle \((\gamma,\lambda) \in \setR^n \times \setR^m\) est un couple d'élément qui minimise \(\lagrangien(x,y)\) par rapport à \(x\) et qui la maximise par rapport à \(y\). On aura alors :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>
</div>
</div>


<div id="outline-container-org2238e9d" class="outline-3">
<h3 id="org2238e9d"><span class="section-number-3">1.6</span> Convexité</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Soit l'ensemble :
</p>

<p>
\[L = \{ (s,t) \in \setR^2 : (s,t) \ge 0 \text{ et } s + t = 1 \}\]
</p>

<p>
Une fonction \(\varphi : \setR^n \mapsto \setR)\) est dite convexe si pour tout \(u, v \in \setR^n\) et \((s,t) \in L\), on a :
</p>

<p>
\[\varphi(s \cdot u + t \cdot v) \le s \cdot \varphi(u) + t \cdot \varphi(v)\]
</p>
</div>


<div id="outline-container-orgb5a591a" class="outline-4">
<h4 id="orgb5a591a"><span class="section-number-4">1.6.1</span> Formulation équivalente</h4>
<div class="outline-text-4" id="text-1-6-1">
<p>
En substituant \(s = 1 - t\), on obtient :
</p>

<p>
\[\varphi(u + t \cdot (v - u)) \le \varphi(u) + t \cdot (\varphi(v) - \varphi(u))\]
</p>

<p>
ou :
</p>

<p>
\[\varphi(u + t \cdot (v - u)) - \varphi(u) \le t \cdot (\varphi(v) - \varphi(u))\]
</p>
</div>
</div>


<div id="outline-container-orgb90f972" class="outline-4">
<h4 id="orgb90f972"><span class="section-number-4">1.6.2</span> Différentielle</h4>
<div class="outline-text-4" id="text-1-6-2">
<p>
Si \(\varphi\) est différentiable, on peut écrire par définition :
</p>

<p>
\[\differentielle{\varphi}{u}(t \cdot (v - u)) + \petito{t \cdot (v - u)} \le t \cdot (\varphi(v) - \varphi(u))\]
</p>

<p>
On peut bien entendu faire sortir le \(t\) par linéarité :
</p>

<p>
\[t \cdot \differentielle{\varphi}{u}(v - u) + \petito{t \cdot (v - u)} \le t \cdot (\varphi(v) - \varphi(u))\]
</p>

<p>
Il ne nous reste plus qu'à diviser par \(t\) et à faire tendre \(t \to 0\) pour annuler le terme d'erreur. On a alors la borne supérieure :
</p>

<p>
\[\differentielle{\varphi}{u}(v - u) \le \varphi(v) - \varphi(u)\]
</p>

<p>
En termes matriciels, cela se réécrit :
</p>

<p>
\[\partial \varphi(u) \cdot (v - u) \le \varphi(v) - \varphi(u)\]
</p>
</div>
</div>


<div id="outline-container-org2e52e21" class="outline-4">
<h4 id="org2e52e21"><span class="section-number-4">1.6.3</span> Hessienne</h4>
<div class="outline-text-4" id="text-1-6-3">
<p>
Supposons à présent que la fonction convexe \(\varphi : \setR^n \mapsto \setR\) soit deux fois continûment différentiable. Soit \(u,v \in \setR^n\). Posons \(\Delta = v - u\). On considère le développement d'ordre deux :
</p>

<p>
\[\varphi(v) = \varphi(u) + \partial \varphi(u) \cdot \Delta + \unsur{2} \cdot \Delta^\dual \cdot \partial^2 \varphi(u) \cdot \Delta + \petito{\Delta^2}\]
</p>

<p>
La borne supérieure de la différentielle nous dit que :
</p>

<p>
\[\partial \varphi(u) \cdot \Delta \le \varphi(v) - \varphi(u)\]
</p>

<p>
On a donc :
</p>

<p>
\[\unsur{2} \cdot \Delta^\dual \cdot \partial^2 \varphi(u) \cdot \Delta + \petito{\Delta^2} = \varphi(v) - \varphi(u) - \partial \varphi(u) \cdot \Delta \ge 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\Delta^\dual \cdot \partial^2 \varphi(u) \cdot \Delta + \petito{\Delta^2} \ge 0\]
</p>

<p>
Choisissons \(\delta \in \setR^n\) et \(t \in \setR\). Considérons le cas où \(v = u + t \cdot \delta\). On a alors \(\Delta = t \cdot \delta\) et :
</p>

<p>
\[t^2 \cdot \delta^\dual \cdot \partial^2 \varphi(u) \cdot \delta + \petito{t^2 \cdot \delta^2} \ge 0\]
</p>

<p>
Il suffit alors de diviser par \(t^2\) et de faire tendre \(t \to 0\) pour obtenir :
</p>

<p>
\[\delta^\dual \cdot \partial^2 \varphi(u) \cdot \delta \ge 0\]
</p>

<p>
Comme ce doit être valable pour tout \(\delta \in \setR^n\), la Hessienne est définie positive en tout \(u \in \setR^n\).
</p>
</div>
</div>


<div id="outline-container-orgcd8c34d" class="outline-4">
<h4 id="orgcd8c34d"><span class="section-number-4">1.6.4</span> Globalité</h4>
<div class="outline-text-4" id="text-1-6-4">
<p>
Considérons le minimum global :
</p>

<p>
\[\lambda \in \arg\min_{x \in \setR^n} \varphi(x)\]
</p>

<p>
Supposons à présent que \(\varphi\) atteigne un minimum local en \(\gamma\). On sait que \(\varphi(\lambda) \le \varphi(\gamma)\) par définition de \(\lambda\). Mais comme \(\partial \varphi(\gamma) = 0\), on a aussi :
</p>

<p>
\[0 = \partial \varphi(\gamma) \cdot (\lambda - \gamma) \le \varphi(\lambda) - \varphi(\gamma)\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\varphi(\gamma) \le \varphi(\lambda)\]
</p>

<p>
donc \(\varphi(\gamma) = \varphi(\lambda)\) est également un minimum global.
</p>

<p>
Attention toutefois, cela ne prouve aucunement que le point minimisant \(\varphi\) est unique.
</p>
</div>
</div>


<div id="outline-container-org427f23b" class="outline-4">
<h4 id="org427f23b"><span class="section-number-4">1.6.5</span> Corollaire</h4>
<div class="outline-text-4" id="text-1-6-5">
<p>
Un corollaire important de ces résultats est que si \(\varphi\) est convexe et deux fois différentiable et que l'on trouve un point \(x\) tel que \(\partial \varphi(x) = 0\), ce point minimise localement \(\varphi\) car la Hessienne est définie positive. Le réel \(\varphi(x)\) est donc également le minimum global de \(\varphi\).
</p>
</div>
</div>
</div>


<div id="outline-container-org6a6411a" class="outline-3">
<h3 id="org6a6411a"><span class="section-number-3">1.7</span> Convexité stricte</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Une fonction \(\varphi : \setR^n \mapsto \setR)\) est dite strictement convexe si pour tout \(u, v \in \setR^n\) tels que \(u \ne v\) et tout \((s,t) \in L \setminus \{ (1,0),(0,1) \}\), on a :
</p>

<p>
\[\varphi(s \cdot u + t \cdot v) \strictinferieur s \cdot \varphi(u) + t \cdot \varphi(v)\]
</p>
</div>


<div id="outline-container-org0bc3442" class="outline-4">
<h4 id="org0bc3442"><span class="section-number-4">1.7.1</span> Minima</h4>
<div class="outline-text-4" id="text-1-7-1">
<p>
Supposons qu'il existe deux \(u,v \in \setR^n\) distincts (\(u \ne v\)) tels que \(\varphi(u) = \varphi(v)\) soit le minimum global de \(\varphi\). On a alors :
</p>

\begin{align}
\varphi(s \cdot u + t \cdot v) &\strictinferieur& s \cdot \varphi(u) + t \cdot \varphi(v) \\
&\strictinferieur& (s + t) \cdot \varphi(u) = \varphi(u)
\end{align}

<p>
ce qui n'est pas possible puisque \(\varphi(u)\) est minimum global. Il existe donc au plus un seul \(u \in \setR^n\) minimisant globalement \(\varphi\) :
</p>

<p>
\[u = \arg\min_{x \in \setR^n} \varphi(x)\]
</p>
</div>
</div>
</div>


<div id="outline-container-org85f2c0e" class="outline-3">
<h3 id="org85f2c0e"><span class="section-number-3">1.8</span> Concavité</h3>
<div class="outline-text-3" id="text-1-8">
<p>
Une fonction \(\psi : \setR^n \mapsto \setR\) est dite concave si pour tout \(u, v \in \setR^n\) et \((s,t) \in L\), on a :
</p>

<p>
\[\psi(s \cdot u + t \cdot v) \ge s \cdot \psi(u) + t \cdot \psi(v)\]
</p>

<p>
On voit que si \(\psi\) est concave, \(\varphi = -\psi\) est convexe. L'équivalence max-min nous montre alors que tout maximum local de \(\psi\) est également un maximum global.
</p>
</div>
</div>


<div id="outline-container-org30c93ac" class="outline-3">
<h3 id="org30c93ac"><span class="section-number-3">1.9</span> Concavité stricte</h3>
<div class="outline-text-3" id="text-1-9">
<p>
Une fonction \(\psi : \setR^n \mapsto \setR\) est dite strictement concave si pour tout \(u, v \in \setR^n\) tels que \(u \ne v\) et tout \((s,t) \in L \setminus \{ (1,0),(0,1) \}\), on a :
</p>

<p>
\[\psi(s \cdot u + t \cdot v) \strictsuperieur s \cdot \psi(u) + t \cdot \psi(v)\]
</p>

<p>
On voit que si \(\psi\) est strictement concave, \(\varphi = -\psi\) est strictement convexe. L'équivalence max-min nous montre alors qu'il existe au plus un seul élément de \(\setR^n\) maximisant globalement \(\psi\).
</p>
</div>
</div>


<div id="outline-container-orged4a7fb" class="outline-3">
<h3 id="orged4a7fb"><span class="section-number-3">1.10</span> Equation du second degré</h3>
<div class="outline-text-3" id="text-1-10">
<p>
Soit \(a,b,c \in \setR\) avec \(a \ne 0\). Soit le polynôme du second degré, ou polynôme de degré \(2\) défini par :
</p>

<p>
\[p(x) = a \cdot x^2 + b \cdot x + c\]
</p>

<p>
pour tout \(x \in \setR\). Nous allons chercher un éventuel extrema \(\gamma\) de ce polynôme. La dérivée première s'écrit :
</p>

<p>
\[\OD{p}{x}(x) = 2 \cdot a \cdot x + b\]
</p>

<p>
La condition :
</p>

<p>
\[\OD{p}{x}(\gamma) = 2 \cdot a \cdot \gamma + b = 0\]
</p>

<p>
nous donne :
</p>

<p>
\[\gamma = -\frac{b}{2a}\]
</p>

<p>
La dérivée seconde est donnée par :
</p>

<p>
\[\OOD{p}{x}(x) = 2 \cdot a\]
</p>

<p>
Si \(a \strictsuperieur 0\), la dérivée seconde est toujours positive et \(\gamma\) minimise localement \(p\). On vérifie que \(p\) est strictement convexe, et on en déduit que \(\gamma\) est l'unique réel qui minimise globalement \(p\).
</p>

<p>
Par contre, si \(a \strictinferieur 0\), la dérivée seconde est toujours négative et \(\gamma\) maximise localement \(p\). On vérifie que \(p\) est strictement concave, et on en déduit que \(\gamma\) est l'unique réel qui maximise globalement \(p\).
</p>
</div>


<div id="outline-container-org180c4bd" class="outline-4">
<h4 id="org180c4bd"><span class="section-number-4">1.10.1</span> Racines</h4>
<div class="outline-text-4" id="text-1-10-1">
<p>
Intéressons-nous à présent à l'écart par rapport à \(\gamma\) :
</p>

<p>
\[\delta = x - \gamma = x + \frac{b}{2 a}\]
</p>

<p>
On a donc :
</p>

<p>
\[x = \gamma + \delta = - \frac{b}{2a} + \delta\]
</p>

<p>
et :
</p>

<p>
\[x^2 = (\gamma + \delta)^2 = \delta^2 - \frac{\delta \cdot b}{a} + \frac{b^2}{4 \cdot a^2}\]
</p>

<p>
En injectant ces relations dans la définition du polynôme, on obtient :
</p>

\begin{align}
p(\gamma + \delta) &= a \cdot \delta^2 - b \cdot \delta + \frac{b^2}{4 \cdot a} + b \cdot \delta - \frac{b^2}{2 \cdot a} + c \\
&= a \cdot \delta^2 - \frac{b^2}{4 \cdot a} + c
\end{align}

<p>
Cette expression nous permet d'obtenir les racines d'un polynôme du second degré. La condition :
</p>

<p>
\[p(\delta + \gamma) = 0\]
</p>

<p>
nous donne :
</p>

<p>
\[\delta^2 = \frac{b^2 - 4 \cdot a \cdot c}{4 \cdot a^2}\]
</p>

<p>
équation qui admet deux solution \(\delta_+, \delta_-\) :
</p>

<div class="org-center">
<p>
\(
\delta_+ = \frac{\sqrt{ b^2 - 4 \cdot a \cdot c }}{2 \cdot a} \\
\delta_- = - \frac{\sqrt{ b^2 - 4 \cdot a \cdot c }}{2 \cdot a}
\)
</p>
</div>

<p>
Nous avons donc deux racines \(x_+,x_-\) :
</p>

<div class="org-center">
<p>
\(
x_+ = \frac{-b + \sqrt{b^2 - 4 \cdot a \cdot c}}{2 \cdot a} \\ \\
x_- = \frac{-b - \sqrt{b^2 - 4 \cdot a \cdot c}}{2 \cdot a}
\)
</p>
</div>

<p>
telles que \(p(x_+) = p(x_-) = 0\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgf6f02aa" class="outline-3">
<h3 id="orgf6f02aa"><span class="section-number-3">1.11</span> Moindres-carrés</h3>
<div class="outline-text-3" id="text-1-11">
<p>
Soit la matrice \(A \in \matrice(\setR,m,n)\) et le vecteur matriciel \(b \in \matrice(\setR,m,1)\). On aimerait trouver le \(\xi \in \matrice(\setR^n,n,1)\) qui minimise la norme de l'erreur \(e\) définie par :
</p>

<p>
\[e(x) = A \cdot x - b\]
</p>

<p>
pour tout \(x \in \matrice(\setR^n,n,1)\). Comme la fonction \(\norme{x} \mapsto \norme{x}^2\) est strictement croissante sur \(\norme{x} \in \setR^+\), cela revient à minimiser :
</p>

<p>
\[\mathcal{E}(x) = \norme{x}^2 = e(x)^\dual \cdot e(x) = (A \cdot x - b)^\dual \cdot (A \cdot x - b)\]
</p>

<p>
En développant, on obtient :
</p>

<p>
\[\mathcal{E}(x) = x^\dual \cdot A^\dual \cdot A \cdot x - x^\dual \cdot A^\dual \cdot b - b^\dual \cdot A \cdot x + b^\dual \cdot b\]
</p>

<p>
Comme \((A^\dual \cdot A)^\dual = A^\dual \cdot A\) et \(x^\dual \cdot A^\dual \cdot b = b^\dual \cdot A^\dual \cdot x\), l'annulation de la dérivée nous donne :
</p>

<p>
\[\partial \mathcal{E}(\xi) = 2 A^\dual \cdot A \cdot \xi - 2 A^\dual \cdot b = 0\]
</p>

<p>
d'où l'on tire directement :
</p>

<p>
\[A^\dual \cdot A \cdot \xi = A^\dual \cdot b\]
</p>

<p>
Si \(A^\dual \cdot A\) est inversible, on en déduit que :
</p>

<p>
\[\xi = \left(A^\dual \cdot A\right)^{-1} \cdot A^\dual \cdot b\]
</p>
</div>


<div id="outline-container-org0b13057" class="outline-4">
<h4 id="org0b13057"><span class="section-number-4">1.11.1</span> Orthogonalité</h4>
<div class="outline-text-4" id="text-1-11-1">
<p>
Considérons la partition en colonne \(A = [c_1 \ ... \ c_n]\). On a alors :
</p>

<div class="org-center">
<p>
\(
A^\dual =
</p>
\begin{Matrix}{c}
c_1^\dual \\ \vdots \\ c_n^\dual
\end{Matrix}
<p>
\)
</p>
</div>

<p>
La propriété :
</p>

<p>
\[A^\dual \cdot (A \cdot \xi - b) = A^\dual \cdot A \cdot \xi - A^\dual \cdot b = 0\]
</p>

<p>
nous dit donc que les colonnes de \(A\) sont orthogonales au vecteur \(r = A \cdot \xi - b\) :
</p>

<p>
\[\scalaire{c_i}{r} = c_i^\dual \cdot r = \ligne_i [ A^\dual \cdot (A \cdot \xi - b) ] = 0\]
</p>
</div>
</div>


<div id="outline-container-orge093ee3" class="outline-4">
<h4 id="orge093ee3"><span class="section-number-4">1.11.2</span> Approximation de fonctions</h4>
<div class="outline-text-4" id="text-1-11-2">
<p>
On désire obtenir une approximation \(w\) d'une fonction \(u\) dont on connaît les valeurs aux points \(x_1,...,x_m\) en minimisant l'erreur :
</p>

<p>
\[\sum_{i=1}^{m} ( u(x_i) - w(x_i) )^2\]
</p>

<p>
On choisit alors les fonctions \(\varphi_1(x),...,\varphi_n(x)\), où \(n \le m\) et on pose :
</p>

<p>
\[w(x) = \sum_{i=1}^m a_i \cdot \varphi_i(x)\]
</p>

<p>
En utilisant les matrices :
</p>

\begin{align}
A &= [\varphi_j(x_i)]_{i,j} \\
a &= [a_1 \ a_2 \ ... \ a_m]^T \\
b &= [u(x_1) \ u(x_2) \ ... \ u(x_n)]^T
\end{align}

<p>
on peut réécrire le problème de minimisation comme suit :
</p>

<p>
\[a = \arg\min_z (A \cdot z - b)^\dual \cdot (A \cdot z - b)\]
</p>

<p>
La solution est donc :
</p>

<p>
\[a = (A^\dual \cdot A)^{-1} \cdot A^\dual \cdot b\]
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org8677323" class="outline-2">
<h2 id="org8677323"><span class="section-number-2">2</span> Projections</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents">
<ul>
<li><a href="#org94634aa">2.1. Minimisation de l'écart</a></li>
<li><a href="#org980c8ba">2.2. Théorème de Pythagore</a></li>
<li><a href="#orgeef2a44">2.3. Carré de la distance</a></li>
<li><a href="#org01ed34b">2.4. Cauchy-Schwartz</a></li>
<li><a href="#org305d373">2.5. Propriétés extrémales</a></li>
<li><a href="#orgd26a298">2.6. Sous-espace vectoriel</a></li>
<li><a href="#org227e6fe">2.7. Tenseur de projection</a></li>
<li><a href="#orge329f75">2.8. Gram-Schmidt</a></li>
<li><a href="#orgdc3e894">2.9. Représentation matricielle</a></li>
<li><a href="#org01b2fdb">2.10. Factorisation</a></li>
<li><a href="#org999d2bb">2.11. Vecteurs $A$-orthogonaux</a></li>
</ul>
</div>

<p>
\label{chap:project}
</p>
</div>


<div id="outline-container-org94634aa" class="outline-3">
<h3 id="org94634aa"><span class="section-number-3">2.1</span> Minimisation de l'écart</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Soit un espace vectoriel \(E\) sur \(\setR\) et des vecteurs \(x,y \in E\), où \(x \ne 0\). La projection de \(y\) sur \(x\) est le vecteur :
</p>

<p>
\[p \in \combilin{x} = \{ \gamma \cdot x : \gamma \in \setR \}\]
</p>

<p>
qui minimise sur \(\combilin{x}\) la norme usuelle \(\norme{e} = \sqrt{ \scalaire{e}{e} }\) de l'écart \(e\) séparant \(y\) de \(p\). Afin de trouver le \(\lambda \in \setR\) minimisant cet écart, on utilise la fonction \(\mathcal{E} : \setR \mapsto \setR\) définie par :
</p>

<p>
\[\mathcal{E}(\gamma) = \scalaire{y - \gamma \cdot x}{y - \gamma \cdot x} = \scalaire{y}{y} - 2 \cdot \gamma \cdot \scalaire{x}{y} + \gamma^2 \cdot \scalaire{x}{x}\]
</p>

<p>
pour tout \(\gamma \in \setR\). Nous imposons l'annulation de la dérivée en un certain \(\gamma = \lambda\) qui minimise potentiellement l'écart :
</p>

<p>
\[\partial \mathcal{E}(\lambda) = - 2 \cdot \scalaire{x}{y} + 2 \cdot \lambda \cdot \scalaire{x}{x} = 0\]
</p>

<p>
ce qui nous donne :
</p>

<p>
\[\lambda = \frac{\scalaire{x}{y}}{\scalaire{x}{x}}\]
</p>
</div>


<div id="outline-container-orgfca67b0" class="outline-4">
<h4 id="orgfca67b0"><span class="section-number-4">2.1.1</span> Produit scalaire complexe</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
Nous nous plaçons à présent dans le cas plus général où \(E\) est un espace vectoriel sur \(\setC\). Le \(\lambda\) défini plus haut devient donc un complexe. Nous allons déterminer s'il minimise la fonction \(\mathcal{E} : \setC \mapsto \setR\) définie par :
</p>

<p>
\[\mathcal{E}(\gamma) = \norme{y - \gamma \cdot x}^2\]
</p>

<p>
pour tout \(\gamma \in \setC\). Considérons le vecteur d'écart :
</p>

<p>
\[e = y - \lambda \cdot x\]
</p>

<p>
On voit qu'il vérifie la propriété :
</p>

<p>
\[\scalaire{x}{e} = \scalaire{x}{y} - \lambda \cdot \scalaire{x}{x} = 0\]
</p>

<p>
On a donc aussi :
</p>

<p>
\[\scalaire{e}{x} = \conjugue \scalaire{x}{e} = 0\]
</p>

<p>
On dit que le vecteur d'écart est orthogonal à \(x\). Soit l'écart \(\delta = \gamma - \lambda\). On a alors \(\gamma = \lambda + \delta\) et :
</p>

<p>
\[y - \gamma \cdot x = y - \lambda \cdot x - \delta \cdot x = e - \delta \cdot x\]
</p>

<p>
En utilisant les propriétés du produit scalaire, on en déduit :
</p>

\begin{align}
\mathcal{E}(\gamma) &= \scalaire{e - \delta \cdot x}{e - \delta \cdot x} \\
&= \scalaire{e}{e} - \delta \cdot \scalaire{e}{x} - \conjaccent{\delta} \cdot \scalaire{x}{e} + \abs{\delta}^2 \cdot \scalaire{x}{x} \\
&= \scalaire{e}{e} + \abs{\delta}^2 \cdot \scalaire{x}{x}
\end{align}

<p>
Comme \(\abs{\delta}^2 \cdot \scalaire{x}{x}\) est un réel \(\ge 0\), on a finalement :
</p>

<p>
\[\mathcal{E}(\gamma) \ge \scalaire{e}{e} = \mathcal{E}(\lambda)\]
</p>

<p>
Notre paramètre \(\lambda\) ainsi défini minimise donc bien \(\mathcal{E}\) sur \(\setC\). De plus, si \(\delta \ne 0\) on a \(\abs{\delta}^2 \strictsuperieur 0\) et
\(\mathcal{E}(\gamma) \strictsuperieur \scalaire{e}{e}\), ce qui prouve que :
</p>

<p>
\[\lambda = \arg\min_{\gamma \in \setC} \mathcal{E}(\gamma)\]
</p>

<p>
est l'unique complexe à minimiser \(\mathcal{E}\). La racine carrée étant une fonction monotone strictement croissante sur \(\setR\), la norme \(\norme{e} = \sqrt{\mathcal{E}(\lambda)}\) est donc également minimisée et la projection s'écrit :
</p>

<p>
\[p = \lambda \cdot x = \frac{ \scalaire{x}{y} }{ \scalaire{x}{x} } \cdot x\]
</p>
</div>
</div>
</div>


<div id="outline-container-org980c8ba" class="outline-3">
<h3 id="org980c8ba"><span class="section-number-3">2.2</span> Théorème de Pythagore</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Calculons à présent la norme de \(y\) en partant de la relation :
</p>

<p>
\[y = p + e\]
</p>

<p>
On déduit de la propriété d'orthogonalité que :
</p>

<p>
\[\scalaire{p}{e} = \lambda \cdot \scalaire{x}{e} = 0\]
</p>

<p>
On peut donc appliquer le théorème de pythagore, qui nous dit que :
</p>

<p>
\[\norme{y}^2 = \norme{p + e}^2 = \norme{p}^2 + \norme{e}^2\]
</p>
</div>
</div>


<div id="outline-container-orgeef2a44" class="outline-3">
<h3 id="orgeef2a44"><span class="section-number-3">2.3</span> Carré de la distance</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Si :
</p>

<p>
\[D = \min_{\gamma \in \setC} \norme{y - \gamma \cdot x}\]
</p>

<p>
on a donc :
</p>

<p>
\[D^2 = \norme{y - \lambda \cdot x}^2 = \norme{e}^2 = \norme{y}^2 - \norme{p}^2\]
</p>

<p>
et finalement :
</p>

<p>
\[D^2 = \norme{y}^2 - \abs{\lambda}^2 \cdot \norme{x}^2\]
</p>
</div>
</div>


<div id="outline-container-org01ed34b" class="outline-3">
<h3 id="org01ed34b"><span class="section-number-3">2.4</span> Cauchy-Schwartz</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Par positivité du produit scalaire, on a bien évidemment :
</p>

<p>
\[\norme{e}^2 = \scalaire{e}{e} \ge 0\]
</p>

<p>
Le théorème de Pythagore implique donc que :
</p>

<p>
\[\scalaire{p}{p} = \norme{p}^2 \le \norme{y}^2 = \scalaire{y}{y}\]
</p>

<p>
En substituant \(p = \lambda \cdot x\), on obtient :
</p>

<p>
\[\conjaccent \lambda \cdot \lambda \cdot \scalaire{x}{x} \le \scalaire{y}{y}\]
</p>

<p>
Mais comme :
</p>

<p>
\[\conjaccent{\lambda} = \conjugue \frac{ \scalaire{x}{y} }{ \scalaire{x}{x} } = \frac{ \scalaire{y}{x} }{ \scalaire{x}{x} }\]
</p>

<p>
on a :
</p>

<p>
\[\frac{ \scalaire{y}{x} }{ \scalaire{x}{x} } \cdot \frac{ \scalaire{x}{y} }{ \scalaire{x}{x} } \cdot \scalaire{x}{x} \le \scalaire{y}{y}\]
</p>

<p>
En simplifiant et en multipliant par la norme carrée de \(x\), on a finalement :
</p>

<p>
\[\scalaire{y}{x} \cdot \scalaire{x}{y} \le \scalaire{x}{x} \cdot \scalaire{y}{y}\]
</p>

<p>
relation dont la racine nous donne l'inégalité de Cauchy-Schwartz :
</p>

<p>
\[\abs{ \scalaire{x}{y} } \le \norme{x} \cdot \norme{y}\]
</p>
</div>
</div>


<div id="outline-container-org305d373" class="outline-3">
<h3 id="org305d373"><span class="section-number-3">2.5</span> Propriétés extrémales</h3>
<div class="outline-text-3" id="text-2-5">
<p>
L'égalité :
</p>

<p>
\[\norme{p}^2 = \norme{y}^2\]
</p>

<p>
n'est atteinte que lorsque \(\norme{e}^2 = 0\), c'est-à-dire \(e = 0\) et \(y = \lambda \cdot x\) pour un certain \(\lambda \in \setC\). Ce constat nous amène aux problèmes d'optimisations suivants. Soit un vecteur \(c \ne 0\) fixé et :
</p>

<p>
\[d = \norme{c} = \sqrt{ \scalaire{c}{c} }\]
</p>

<p>
On cherche à maximiser ou à minimiser :
</p>

<p>
\[\varphi(x) = \scalaire{c}{x}\]
</p>

<p>
sur l'ensemble \(B = \boule(0,r) = \{ x : \norme{x} \le r \}\). L'inégalité de Cauchy-Schwartz nous dit que :
</p>

<p>
\[- d \cdot r \le - \norme{c} \cdot \norme{x} \le \scalaire{c}{x} \le \norme{c} \cdot \norme{x} \le d \cdot r\]
</p>

<p>
Nous allons chercher nos solutions sous la forme \(x = \alpha \cdot c\), pour un certain \(\alpha \in \setC\). On a alors :
</p>

<p>
\[\norme{\alpha \cdot c} = \abs{\alpha} \cdot \norme{c} = \abs{\alpha} \cdot d \le r\]
</p>

<p>
et donc \(\abs{\alpha} \le r / d\). Si on choisit \(\alpha = r / d\), on a :
</p>

<p>
\[\scalaire{c}{x} = \frac{r}{d} \cdot \scalaire{c}{c} = \frac{r}{d} \cdot d^2 = d \cdot r\]
</p>

<p>
La borne supérieure est atteinte. La fonction \(\varphi\) est donc maximisée :
</p>

<p>
\[\eta = \frac{r}{d} \cdot c \in \arg\max_{x \in B} \scalaire{c}{x}\]
</p>

<p>
Si on choisit \(\alpha = - r / d\), on a :
</p>

<p>
\[\scalaire{c}{x} = - \frac{r}{d} \cdot \scalaire{c}{c} = - d \cdot r\]
</p>

<p>
La borne inférieure est atteinte. La fonction \(\varphi\) est donc minimisée :
</p>

<p>
\[\theta = - \frac{r}{d} \cdot c \in \arg\min_{x \in B} \scalaire{c}{x}\]
</p>
</div>
</div>


<div id="outline-container-orgd26a298" class="outline-3">
<h3 id="orgd26a298"><span class="section-number-3">2.6</span> Sous-espace vectoriel</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Soit l'espace vectoriel \(E\) sur \(\setR\) et un sous-espace vectoriel \(U \subseteq E\) possédant une base orthonormée \((u_1,...,u_n)\). La projection d'un vecteur quelconque \(z \in E\) sur \(U\) est le vecteur \(p \in U\) qui minimise la norme de l'écart entre \(z\) et \(p\). On cherche donc le \(\lambda = (\lambda_1,...,\lambda_n) \in \setR^n\) qui minimise la fonction \(\mathcal{E} : \setR^n \mapsto \setR\) définie par :
</p>

<p>
\[\mathcal{E}(\gamma) = \norme{z - \sum_{i = 1}^n \gamma_i \cdot u_i}^2\]
</p>

<p>
pour tout \(\gamma = (\gamma_1,...,\gamma_n) \in \setR^n\). En utilisant \(\scalaire{u_i}{u_j} = \indicatrice_{ij}\), on obtient :
</p>

\begin{align}
\mathcal{E}(\gamma) &= \scalaire{z}{z} - 2 \sum_i \gamma_i \cdot \scalaire{u_i}{z} + \sum_{i,j} \gamma_i \cdot \gamma_j \cdot \scalaire{u_i}{u_j} \\
&= \scalaire{z}{z} - 2 \sum_i \gamma_i \cdot \scalaire{u_i}{z} + \sum_i \gamma_i^2
\end{align}

<p>
Imposant \(\partial_k \mathcal{E}(\lambda_1,...,\lambda_n) = 0\), on obtient les \(n\) équations :
</p>

<p>
\[-2 \lambda_k \cdot \scalaire{u_k}{z} + 2 \lambda_k = 0\]
</p>

<p>
On en déduit que le choix :
</p>

<p>
\[\lambda = (\lambda_1,...,\lambda_n) = (\scalaire{u_1}{z},...,\scalaire{u_n}{z})\]
</p>

<p>
minimise potentiellement \(\mathcal{E}\). Notre projection potentielle de \(z\) sur \(U\) est donc donnée par :
</p>

<p>
\[p = \sum_i \scalaire{u_i}{z} \cdot u_i\]
</p>
</div>


<div id="outline-container-orgbddb9a4" class="outline-4">
<h4 id="orgbddb9a4"><span class="section-number-4">2.6.1</span> Produit scalaire complexe</h4>
<div class="outline-text-4" id="text-2-6-1">
<p>
Nous nous plaçons à présent dans le cas plus général où \(E\) est un espace vectoriel sur \(\setC\). Le \(\lambda\) défini plus haut devient donc un élément de \(\setC^n\). Nous allons déterminer s'il minimise la fonction \(\mathcal{E} : \setC^n \mapsto \setR\) définie par :
</p>

<p>
\[\mathcal{E}(\gamma) = \norme{z - \sum_{i = 1}^n \gamma_i \cdot u_i}^2\]
</p>

<p>
pour tout \(\gamma = (\gamma_1,...,\gamma_n) \in \setC^n\). Choisissons \(x \in U\). On a alors :
</p>

<p>
\[x = \sum_i x_i \cdot u_i\]
</p>

<p>
où \(x_i = \scalaire{u_i}{z}\). Considérons le vecteur d'écart :
</p>

<p>
\[e = z - p\]
</p>

<p>
On a alors :
</p>

\begin{align}
\scalaire{x}{e} &= \sum_i \conjaccent{x_i} \cdot \scalaire{u_i}{z - p} \\
&= \sum_i \conjaccent{x_i} \cdot \scalaire{u_i}{z} - \sum_{i,j} \conjaccent{x_i} \cdot \scalaire{u_i}{u_j} \cdot \lambda_j \\
&= \sum_i \scalaire{x}{u_i} \cdot \scalaire{u_i}{z} - \sum_i \scalaire{x}{u_i} \cdot \scalaire{u_i}{z} = 0
\end{align}

<p>
Le vecteur d'écart est donc orthogonal à tous les \(x \in U\). On a également :
</p>

<p>
\[\scalaire{e}{x} = \conjugue \scalaire{x}{e} = 0\]
</p>

<p>
Soit l'écart \(\delta = \gamma - \lambda\). On a alors \(\gamma = \lambda + \delta\). Posons :
</p>

<div class="org-center">
<p>
\(
g = \sum_i \gamma_i \cdot u_i \\
p = \sum_i \lambda_i \cdot u_i \\
\Delta = \sum_i \delta_i \cdot u_i
\)
</p>
</div>

<p>
On a alors \(z - g = z - p - \Delta = e - \Delta\) et :
</p>

\begin{align}
\mathcal{E}(\gamma) &= \scalaire{e - \Delta}{e - \Delta} \\
&= \scalaire{e}{e} - \scalaire{e}{\Delta} - \scalaire{\Delta}{e} + \scalaire{\Delta}{\Delta}
\end{align}

<p>
Comme \(\Delta \in U\), ses produits scalaires avec \(e\) s'annulent par orthogonalité et on a finalement :
</p>

<p>
\[\mathcal{E}(\gamma) = \scalaire{e}{e} + \scalaire{\Delta}{\Delta} \ge \scalaire{e}{e} = \mathcal{E}(\lambda)\]
</p>

<p>
Les scalaires \(\lambda_k\) minimisent donc bien la norme de l'écart sur \(U\).
</p>
</div>
</div>


<div id="outline-container-org8e9c08b" class="outline-4">
<h4 id="org8e9c08b"><span class="section-number-4">2.6.2</span> Théorème de Pythagore</h4>
<div class="outline-text-4" id="text-2-6-2">
<p>
On a \(z = p + e\). Comme \(p\) est un vecteur de \(U\), on a \(\scalaire{p}{e} = \scalaire{e}{p} = 0\). Le théorème de Pythagore est donc applicable :
</p>

<p>
\[\norme{z}^2 = \norme{p}^2 + \norme{e}^2\]
</p>
</div>
</div>


<div id="outline-container-org450388d" class="outline-4">
<h4 id="org450388d"><span class="section-number-4">2.6.3</span> Carré de la distance</h4>
<div class="outline-text-4" id="text-2-6-3">
<p>
Soit :
</p>

<p>
\[D = \min \{ \norme{z - v} : v \in U \}\]
</p>

<p>
Par orthonormalité, on a :
</p>

<p>
\[\norme{p}^2 = \sum_{i,j} \conjugue(\scalaire{u_i}{z}) \cdot \scalaire{u_j}{z} \cdot \scalaire{u_i}{u_j} = \sum_i \abs{\scalaire{u_i}{z}}^2\]
</p>

<p>
et donc :
</p>

<p>
\[D^2 = \norme{z}^2 - \norme{p}^2 = \norme{z}^2 - \sum_i \abs{\scalaire{u_i}{z}}^2\]
</p>
</div>
</div>
</div>


<div id="outline-container-org227e6fe" class="outline-3">
<h3 id="org227e6fe"><span class="section-number-3">2.7</span> Tenseur de projection</h3>
<div class="outline-text-3" id="text-2-7">
<p>
On peut réécrire la projection de \(z\) sur \(U\) sous la forme :
</p>

<p>
\[p = \sum_i u_i \cdot \scalaire{u_i}{z}\]
</p>

<p>
Cette expression ressemble à la contraction d'ordre \(1\) d'un tenseur d'ordre \(2\). Effectivement, si on pose :
</p>

<p>
\[\mathcal{P} = \sum_i u_i \otimes u_i\]
</p>

<p>
on a alors :
</p>

<p>
\[p = \mathcal{P} \cdot z = \contraction{\mathcal{P} }{1}{z}\]
</p>
</div>


<div id="outline-container-orgd17f042" class="outline-4">
<h4 id="orgd17f042"><span class="section-number-4">2.7.1</span> Identité locale</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
Pour tout \(y \in U\), on a :
</p>

<p>
\[y = \sum_i \scalaire{u_i}{y} \cdot u_i\]
</p>

<p>
et :
</p>

<p>
\[\mathcal{P} \cdot y = \sum_i u_i \cdot \scalaire{u_i}{y}\]
</p>

<p>
Ces deux expressions étant identiques, on a \(\mathcal{P} \cdot y = y\). Le tenseur de projection correspond donc localement (sur \(U\)) au tenseur identité.
</p>
</div>
</div>


<div id="outline-container-orgdee3e5f" class="outline-4">
<h4 id="orgdee3e5f"><span class="section-number-4">2.7.2</span> Invariance</h4>
<div class="outline-text-4" id="text-2-7-2">
<p>
Pour tout \(z \in E\), on a \(y = \mathcal{P} \cdot z \in U\). On en conclut que :
</p>

<p>
\[\mathcal{P} \cdot z = y = \mathcal{P} \cdot y = \mathcal{P} \cdot (\mathcal{P} \cdot z)\]
</p>

<p>
Donc \(\mathcal{P} = \mathcal{P} \cdot \mathcal{P}\).
</p>
</div>
</div>


<div id="outline-container-orgceee748" class="outline-4">
<h4 id="orgceee748"><span class="section-number-4">2.7.3</span> Complémentaire</h4>
<div class="outline-text-4" id="text-2-7-3">
<p>
Soit \((u_1,...,u_n)\) une base orthonormée de \(E\). On voit que le tenseur identité :
</p>

<p>
\[\tenseuridentite = \sum_{i = 1}^n u_i \otimes u_i\]
</p>

<p>
est le tenseur de projection de \(E\) dans lui-même. On considère le tenseur de projection sur \(\combilin{u_1,...,u_m}\), où \(m \le n\) :
</p>

<p>
\[\mathcal{P} = \sum_{i = 1}^m u_i \otimes u_i\]
</p>

<p>
Le tenseur complémentaire est défini par :
</p>

<p>
\[\mathcal{Q} = \tenseuridentite - \mathcal{P} = \sum_{i = 1}^n u_i \otimes u_i - \sum_{i = 1}^m u_i \otimes u_i = \sum_{i = m + 1}^n u_i \otimes u_i\]
</p>

<p>
Il s'agit donc d'un tenseur de projection sur l'espace complémentaire \(\combilin{u_{m + 1},...,u_n}\). Il est lié à l'écart de projection car \(e = z - p = \mathcal{Q} \cdot z\). On remarque l'orthogonalité :
</p>

<p>
\[\mathcal{Q} \cdot \mathcal{P} = (\tenseuridentite - \mathcal{P}) \cdot \mathcal{P} = \mathcal{P} - \mathcal{P} \cdot \mathcal{P} = 0\]
</p>

<p>
De même :
</p>

<p>
\[\mathcal{P} \cdot \mathcal{Q} = \mathcal{P} \cdot \mathcal{P} - \mathcal{P} = 0\]
</p>

<p>
On a aussi sans surprise :
</p>

<p>
\[\mathcal{Q} \cdot \mathcal{Q} = \mathcal{Q} - \mathcal{Q} \cdot \mathcal{P} =  \mathcal{Q}\]
</p>
</div>
</div>
</div>


<div id="outline-container-orge329f75" class="outline-3">
<h3 id="orge329f75"><span class="section-number-3">2.8</span> Gram-Schmidt</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Nous allons construire une suite de vecteurs orthonormaux \((u_1,u_2,...u_n)\) à partir d'une suite \((a_1,a_2,...,a_n)\) de vecteurs linéairement indépendants de \(E\). L'indépendance linéaire nous garantit que \(a_1 \ne 0\). On peut donc normaliser pour obtenir le premier vecteur de la série :
</p>

<p>
\[u_1 = \frac{a_1}{ \norme{a_1} }\]
</p>

<p>
On a alors :
</p>

<p>
\[\scalaire{u_1}{u_1} = \frac{ \scalaire{a_1}{a_1} }{ \norme{a_1}^2 } = \frac{ \scalaire{a_1}{a_1} }{ \scalaire{a_1}{a_1} } = 1\]
</p>

<p>
Nous projetons \(a_2\) sur \(u_1\) en utilisant le tenseur \(\mathcal{P}_1 = u_1 \otimes u_1\) et nous évaluons l'écart :
</p>

<p>
\[e_2 = (\tenseuridentite - \mathcal{P}_1) \cdot a_2 = a_2 - u_1 \cdot \scalaire{u_1}{a_2}\]
</p>

<p>
Les propriétés d'orthogonalité de l'écart nous assurent alors que \(\scalaire{u_1}{e_2} = 0\). L'indépendance linéaire nous garantit que \(e_2 \ne 0\). On peut donc normaliser en utilisant \(u_2 = e_2 / \norme{e_2}\). On a alors clairement \(\scalaire{u_2}{u_2} = 1\) et \(\scalaire{u_1}{u_2} = 0\).
</p>

<p>
Supposons à présent avoir trouvé la suite orthonormée \((u_1,u_2,...,u_k)\), où \(k \le n - 1\). Nous projetons \(a_{k + 1}\) sur l'espace vectoriel \(U_k = \combilin{u_1,u_2,...,u_k}\) en utilisant le tenseur :
</p>

<p>
\[\mathcal{P}_k = \sum_{i = 1}^k u_i \otimes u_i\]
</p>

<p>
et nous évaluons l'écart :
</p>

<p>
\[e_{k + 1} = (\tenseuridentite - \mathcal{P}_k) \cdot a_{k + 1} = a_{k + 1} - \sum_{i = 1}^k u_i \cdot \scalaire{u_i}{a_{k + 1} }\]
</p>

<p>
Les propriétés d'orthogonalité de l'écart nous assurent alors que \(\scalaire{u_j}{e_{k + 1} } = 0\) pour tout \(j \in \{1,2,...,k\}\). L'indépendance linéaire nous garantit que \(e_{k + 1} \ne 0\). On peut donc normaliser en utilisant :
</p>

<p>
\[u_{k + 1} = \frac{e_{k + 1} }{ \norme{ e_{k + 1} } }\]
</p>

<p>
On a alors clairement \(\scalaire{u_j }{u_{k + 1} } = \indicatrice_{j, k + 1}\).
</p>

<p>
Nous disposons donc à la fin du processus d'une suite de vecteurs \((u_1,u_2,...,u_n)\) orthonormée :
</p>

<p>
\[\scalaire{u_i}{u_j} = \indicatrice_{ij}\]
</p>

<p>
Ce procédé est appelé processus d'orthogonalisation de Gram-Schmidt.
</p>
</div>


<div id="outline-container-orgceecd6f" class="outline-4">
<h4 id="orgceecd6f"><span class="section-number-4">2.8.1</span> Remarque</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
Dans le cas où l'indépendance linéaire n'est pas garantie, il est toujours possible d'adapter l'algorithme en enlevant dynamiquement de la liste des \(a_k\) les vecteurs donnant un écart de projection nul. On se retrouve alors à la fin du processus avec une suite orthonormée \((u_1,...,u_m)\), où \(m \le n\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgdc3e894" class="outline-3">
<h3 id="orgdc3e894"><span class="section-number-3">2.9</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-2-9">
<p>
Soient \(u_1,u_2,...,u_m \in \matrice(\corps,n,1)\) des vecteurs matriciels orthonormés pour le produit scalaire usuel :
</p>

<p>
\[u_i^\dual \cdot u_j = \indicatrice_{ij}\]
</p>

<p>
La matrice de projection associée au tenseur de projection sur \(U = \combilin{u_1,...,u_m}\) s'écrit :
</p>

<p>
\[P = \sum_{k = 1}^m u_k \otimes u_k = \sum_{k = 1}^m u_k \cdot u_k^\dual\]
</p>

<p>
Il s'agit donc d'une matrice de taille \((n,n)\). Elle permet de projeter tout vecteur matriciel \(z \in \matrice(\corps,n,1)\) sur \(U\) :
</p>

<p>
\[P \cdot z = \sum_{k = 1}^m u_k \cdot u_k^\dual \cdot z = \sum_{k = 1}^m u_k \cdot \scalaire{u_k}{z}\]
</p>
</div>
</div>


<div id="outline-container-org01b2fdb" class="outline-3">
<h3 id="org01b2fdb"><span class="section-number-3">2.10</span> Factorisation</h3>
<div class="outline-text-3" id="text-2-10">
<p>
En terme de composantes, si \(u_k = ( u_{kj} )_j\) et si \(P = ( p_{ij} )_{i,j}\), on a :
</p>

<p>
\[p_{ij} = \sum_{k = 1}^m u_{ki} \cdot \conjaccent{u}_{kj}\]
</p>

<p>
expression qui ressemble furieusement à un produit matriciel. Soit la matrice \(U\) de taille \((n,m)\) rassemblant les \(m\) vecteurs \(u_k\) :
</p>

<p>
\[U = [u_1 \ u_2 \ \hdots \ u_m]\]
</p>

<p>
On a alors :
</p>

\begin{align}
\composante_{ik} U &= u_{ki} \\
\composante_{kj} U^\dual &= \conjugue \composante_{jk} U = \conjaccent{u}_{kj}
\end{align}

<p>
Le produit ci-dessus peut donc s'écrire :
</p>

<p>
\[p_{ij} = \sum_{k = 1}^m b_{ik} \cdot c_{kj}\]
</p>

<p>
où \(b_{ik} = \composante_{ik} U\) et \(c_{kj} = \composante_{kj} U^\dual\). On a donc finalement :
</p>

<p>
\[P = U \cdot U^\dual\]
</p>
</div>


<div id="outline-container-org880333f" class="outline-4">
<h4 id="org880333f"><span class="section-number-4">2.10.1</span> Propriétés</h4>
<div class="outline-text-4" id="text-2-10-1">
<p>
Comme les \(u_k\) sont orthonormaux, on a :
</p>

<p>
\[\composante_{ij} (U^\dual \cdot U) = u_i^\dual \cdot u_j = \scalaire{u_i}{u_j} = \indicatrice_{ij}\]
</p>

<p>
On a donc \(U^\dual \cdot U = I\), la matrice identité de taille \((m,m)\). On a également, comme attendu :
</p>

<p>
\[P^2 = U \cdot U^\dual \cdot U \cdot U^\dual = U \cdot I \cdot U^\dual = U \cdot U^\dual = P\]
</p>

<p>
Si on pose \(Q = I - P\), on a aussi :
</p>

<p>
\[P \cdot Q = Q \cdot P = P - P^2 = 0\]
</p>
</div>
</div>


<div id="outline-container-orge1de710" class="outline-4">
<h4 id="orge1de710"><span class="section-number-4">2.10.2</span> Cas particulier</h4>
<div class="outline-text-4" id="text-2-10-2">
<p>
Les \(m\) vecteurs \(u_i\) étant linéairement indépendants dans \(\corps^n\) qui est de dimension \(n\), on doit forcément avoir \(m \le n\). Dans le cas où \(m = n\), on a de plus \(U^\dual = U^{-1}\) et :
</p>

<p>
\[\sum_{i = 1}^n u_i \otimes u_i = P = U \cdot U^{-1} = I\]
</p>
</div>
</div>
</div>


<div id="outline-container-org999d2bb" class="outline-3">
<h3 id="org999d2bb"><span class="section-number-3">2.11</span> Vecteurs $A$-orthogonaux</h3>
<div class="outline-text-3" id="text-2-11">
<p>
Soit une matrice de produit scalaire \(A \in \matrice(\corps,n,n)\). On peut utiliser le procédé de Gram-Schmidt pour construire une base de vecteurs orthogonaux pour le produit scalaire :
</p>

<p>
\[\scalaire{x}{y} = x^\dual \cdot A \cdot y\]
</p>

<p>
On part d'une suite \((a_1,a_2,...,a_n)\) de vecteurs matriciels linéairement indépendants de \(\corps^n\) (typiquement la base canonique). On commence par normaliser \(a_1\) :
</p>

<p>
\[u_1 = \frac{a_1}{ \sqrt{a_1^\dual \cdot A \cdot a_1} }\]
</p>

<p>
et on construit étape après étape la suite des \(u_i\). Supposons être arrivé à la suite \((u_1,u_2,...,u_k)\) vérifiant \(\scalaire{u_i}{u_j} = u_i^\dual \cdot A \cdot u_j = \indicatrice_{ij}\), où \(k \le n - 1\). Nous projetons \(a_{k + 1}\) sur l'espace vectoriel \(\combilin{u_1,u_2,...,u_k}\) et nous évaluons l'écart :
</p>

\begin{align}
e_{k + 1} &= a_{k + 1} - \sum_{i = 1}^k u_i \cdot \scalaire{u_i}{ a_{k + 1} } \\
&= a_{k + 1} - \sum_{i = 1}^k u_i \cdot u_i^\dual \cdot A \cdot a_{k + 1}
\end{align}

<p>
Ensuite, nous normalisons le résultat :
</p>

<p>
\[u_{k + 1} = \frac{e_{k + 1} }{ \sqrt{e_{k + 1}^\dual \cdot A \cdot e_{k + 1} } }\]
</p>

<p>
Nous disposons donc à la fin du processus d'une suite de vecteurs \((u_1,u_2,...,u_n)\) orthonormée :
</p>

<p>
\[\scalaire{u_i}{u_j} = u_i^\dual \cdot A \cdot u_j = \indicatrice_{ij}\]
</p>

<p>
On dit que la suite des \(u_i\) est $A$-orthonormée. Si on définit la famille de matrices :
</p>

<p>
\[U_m = [u_1 \ u_2 \ ... \ u_m]\]
</p>

<p>
pour tout \(m \le n\), on peut réecrire l'orthogonalité comme suit :
</p>

<p>
\[U_m^\dual \cdot A \cdot U_m = I_m\]
</p>

<p>
On note aussi \(U = U_n\).
</p>
</div>


<div id="outline-container-org15258b3" class="outline-4">
<h4 id="org15258b3"><span class="section-number-4">2.11.1</span> Complément orthogonal</h4>
<div class="outline-text-4" id="text-2-11-1">
<p>
Si les vecteurs orthonormaux \((u_1,...,u_p)\), où \(p \le n\), sont donnés, on peut simplement commencer le processus à \(k = p\) pour complèter la suite de vecteurs jusqu'à \(k = n\). On obtient alors la suite orthonormée \((u_1,...,u_p,u_{p + 1},...,u_n)\). On dit que \((u_{p + 1},...,u_n)\) est le complément orthogonal de \((u_1,...,u_p)\).
</p>
</div>
</div>


<div id="outline-container-orgda74be0" class="outline-4">
<h4 id="orgda74be0"><span class="section-number-4">2.11.2</span> Orthogonalité usuelle</h4>
<div class="outline-text-4" id="text-2-11-2">
<p>
Dans le cas où l'on choisit \(A = I\), cette méthode offre un moyen d'obtenir (ou de compléter) une suite de vecteurs \(u_i\) tels que \(u_i^\dual \cdot u_j = \indicatrice_{ij}\) et des matrices \(U_m\) correspondantes telles que \(U_m^\dual \cdot U_m = I_m\). Comme \(U = U_n\) est carrée, on a de plus :
</p>

<p>
\[U^{-1} = U^\dual\]
</p>
</div>
</div>


<div id="outline-container-org5c112a3" class="outline-4">
<h4 id="org5c112a3"><span class="section-number-4">2.11.3</span> Systèmes linéaires</h4>
<div class="outline-text-4" id="text-2-11-3">
<p>
Lorsqu'on dispose de \(n\) vecteurs $A$-orthonormés, il est facile de résoudre le système linéaire \(A \cdot x = y\). Les \(u_i\) forment alors une base de \(\corps^n\) et on peut trouver des scalaires \(x_i \in \corps\) tels que :
</p>

<p>
\[x = \sum_{i = 1}^n x_i \cdot u_i\]
</p>

<p>
En prenant le produit scalaire de \(x\) avec \(u_k\), on obtient :
</p>

<p>
\[u_k^\dual \cdot A \cdot x = \sum_{i = 1}^n (u_k^\dual \cdot A \cdot u_i) \cdot x_i = x_k\]
</p>

<p>
On voit donc apparaître une expression analogue à celle d'une projection usuelle :
</p>

<p>
\[x = \sum_{i = 1}^n u_i \cdot (u_i^\dual \cdot A \cdot x) = \sum_{i = 1}^n u_i \cdot u_i^\dual \cdot y\]
</p>

<p>
Attention, analogue n'est pas identique, les \(u_i\) ne sont en général pas orthonormés pour le produit scalaire usuel.
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org800acdf" class="outline-2">
<h2 id="org800acdf"><span class="section-number-2">3</span> Algorithmes d'optimisation libre</h2>
<div class="outline-text-2" id="text-3">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgfbea4f4">3.1. Introduction</a></li>
<li><a href="#org8b9dd3c">3.2. Minimum dans une direction</a></li>
<li><a href="#org28abfd8">3.3. Méthode de la plus grande descente</a></li>
<li><a href="#org4cb3525">3.4. Newton</a></li>
<li><a href="#org0f7cde7">3.5. Gradients conjugués</a></li>
<li><a href="#org5bcf9c6">3.6. Moindres carrés</a></li>
<li><a href="#org010c857">3.7. Levenberg-Marquardt</a></li>
</ul>
</div>

<p>
\label{chap:algoptim}
</p>
</div>


<div id="outline-container-orgfbea4f4" class="outline-3">
<h3 id="orgfbea4f4"><span class="section-number-3">3.1</span> Introduction</h3>
<div class="outline-text-3" id="text-3-1">
<p>
Nous allons présenter des algorithmes permettant de résoudre approximativement des problèmes de minimisation d'une fonction \(\varphi\) sur \(\setR^n\). Ces algorithmes partent d'un point initial \(x_0 \in \Omega\) et itèrent schématiquement comme suit :
</p>

<p>
\[x_{k + 1} = I(x_k) = x_k + p_k\]
</p>

<p>
pour un certain \(p_k \in \setR^n\). On espère bien entendu que la suite converge et que :
</p>

<p>
\[x_N \approx \lim_{k \to \infty} x_k = \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
pour \(N\) assez grand. Nous adoptons les notations :
</p>

<p>
\[J = (\partial \varphi)^\dual\]
</p>

<p>
pour le gradient, de taille \((n,1)\), et :
</p>

<p>
\[H = \partial^2 \varphi\]
</p>

<p>
pour la hessienne, de taille \((n,n)\). On note également :
</p>

<p>
\[\Phi_k = \Phi(x_k)\]
</p>

<p>
pour toute fonction \(\Phi\) (par exemple, \(\Phi \in \{\varphi,J,H\}\)).
</p>
</div>
</div>


<div id="outline-container-org8b9dd3c" class="outline-3">
<h3 id="org8b9dd3c"><span class="section-number-3">3.2</span> Minimum dans une direction</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Soit l'itération :
</p>

<p>
\[x_{k+1} = x_k - \alpha_k \cdot p_k\]
</p>

<p>
où \(\alpha_k \in \setR\) et \(p_k \in \setR^n\). On choisit généralement le paramètre \(\alpha_k\) de façon à minimiser le développement d'ordre deux :
</p>

<p>
\[\varphi_{k + 1} \approx \varphi_k - \alpha_k \cdot J_k^\dual \cdot p_k + \frac{\alpha_k^2}{2} \cdot p_k^\dual \cdot H_k \cdot p_k\]
</p>

<p>
En imposant l'annulation de la dérivée de ce développement par rapport à \(\alpha_k\), on en déduit que :
</p>

<p>
\[- J_k^\dual \cdot p_k + \alpha_k \cdot p_k^\dual \cdot H_k \cdot p_k = 0\]
</p>

<p>
La valeur optimale de \(\alpha_k\) s'écrit :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot p_k}{p_k^\dual \cdot H_k \cdot p_k}\]
</p>
</div>
</div>


<div id="outline-container-org28abfd8" class="outline-3">
<h3 id="org28abfd8"><span class="section-number-3">3.3</span> Méthode de la plus grande descente</h3>
<div class="outline-text-3" id="text-3-3">
<p>
La méthode de la plus grande pente consiste à partir à chaque itération
du point \(x^{(k)}\) et à suivre la direction \(\delta_k\) où \(\varphi\)
descend le plus rapidement dans le voisinage immédiat. En première approximation, si :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot \delta_k\]
</p>

<p>
pour un certain \(\alpha_k \in \setR\), on a :
</p>

<p>
\[\varphi_{k+1} \approx \varphi_k + \alpha_k \cdot J_k^\dual \cdot \delta_k\]
</p>

<p>
Nous choisissons le vecteur \(\delta_k\) qui minimise \(J_k^\dual \cdot \delta_k = \scalaire{J_k}{\delta_k}\) sur \(\boule(0,\norme{J_k})\), c'est-à-dire :
</p>

<p>
\[\delta_k = - J_k\]
</p>

<p>
On a alors :
</p>

<p>
\[x_{k + 1} = x_k - \alpha_k \cdot J_k\]
</p>

<p>
La valeur optimale de \(\alpha_k\) s'écrit donc :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot J_k}{J_k^\dual \cdot H_k \cdot J_k}\]
</p>
</div>
</div>


<div id="outline-container-org4cb3525" class="outline-3">
<h3 id="org4cb3525"><span class="section-number-3">3.4</span> Newton</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Il s'agit ici d'optimiser le pas \(s_k\) :
</p>

<p>
\[x_{k + 1} = x_k + s_k\]
</p>

<p>
pour minimiser le développement :
</p>

<p>
\[\varphi_{k+1} \approx \varphi_k + J_k^\dual \cdot s_k + \unsur{2} \cdot s_k^\dual \cdot H_k \cdot s_k\]
</p>

<p>
Mais comme \(H = H^\dual\), l'annulation du gradient par rappord à \(s_k\) nous donne :
</p>

<p>
\[J_k + H_k \cdot s_k \approx 0\]
</p>

<p>
On en déduit la valeur optimale :
</p>

<p>
\[s_k = - H_k^{-1} \cdot J_k\]
</p>
</div>
</div>


<div id="outline-container-org0f7cde7" class="outline-3">
<h3 id="org0f7cde7"><span class="section-number-3">3.5</span> Gradients conjugués</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Soit l'itération :
</p>

<p>
\[x_{k + 1} = x_k - \alpha_k \cdot p_k\]
</p>

<p>
où \(\alpha_k \in \setR\) et \(p_k \in \setR^n\). On a comme d'habitude :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot p_k}{p_k^\dual \cdot H_k \cdot p_k}\]
</p>

<p>
Lorsque \(k = 0\), on prend le gradient comme direction :
</p>

<p>
\[p_0 = J_0\]
</p>

<p>
Pour \(k \ge 1\), on choisit \(p_k\) comme combinaison linéaire du gradient \(J_k\) et du pas précédent \(p_{k - 1}\) :
</p>

<p>
\[p_k = J_k - \beta_k \cdot p_{k-1}\]
</p>

<p>
où \(\beta_k \in \setR\). L'idée des gradients conjugué est de construire une suite de \(p_k\) orthogonaux entre-eux afin de minimiser la fonction dans toutes les directions. Au bout de \(n\) itérations, on espère avoir construit une base de \(\setR^n\) et être très proche du minimum global. En fait, nous n'allons pas vérifier que toutes les directions sont orthogonales, mais seulement que deux directions successives le sont. On demande donc l'orthogonalité au sens du produit scalaire défini par \(H\) :
</p>

<p>
\[p_k^\dual \cdot H_k \cdot p_{k - 1} = J_k^\dual \cdot H_k \cdot p_{k - 1} - \beta_k \cdot p_{k - 1}^\dual \cdot H_k \cdot p_{k - 1} = 0\]
</p>

<p>
On en déduit la valeur de \(\beta_k\) :
</p>

<p>
\[\beta_k = \frac{J_k^\dual \cdot H_k \cdot p_{k - 1}}{p_{k - 1}^\dual \cdot H_k \cdot p_{k - 1}}\]
</p>

<p>
Nous allons à présent obtenir une valeur approximative de \(\beta_k\) en fonction des variations du gradient. Le développement d'ordre un de \(J\) s'écrit :
</p>

<p>
\[J_k - J_{k - 1} \approx H_k \cdot (x_k - x_{k - 1}) = - \alpha_k \cdot H_k \cdot p_{k - 1}\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\beta_k \approx \frac{J_k^\dual \cdot (J_k - J_{k - 1})}{p_{k - 1}^\dual \cdot (J_k - J_{k - 1})}\]
</p>
</div>
</div>


<div id="outline-container-org5bcf9c6" class="outline-3">
<h3 id="org5bcf9c6"><span class="section-number-3">3.6</span> Moindres carrés</h3>
<div class="outline-text-3" id="text-3-6">
<p>
Soit la fonction \(f : \setR^n \mapsto \setR^m\). On cherce à minimiser la fonction \(\varphi = f^\dual \cdot f / 2\). Le problème de minimisation s'écrit alors :
</p>

<p>
\[\arg\min_x \unsur{2} f(x)^\dual \cdot f(x)\]
</p>

<p>
Dans ce cas, si on définit :
</p>

<p>
\[D = \partial f\]
</p>

<p>
le gradient s'écrit :
</p>

<p>
\[J = D^\dual \cdot f\]
</p>

<p>
Si on suppose que les dérivées secondes de \(f\) sont négligeables par rapport
aux dérivées premières, on a :
</p>

<p>
\[H \approx D^\dual \cdot D\]
</p>

<p>
La méthode de Newton devient dans ce cas :
</p>

<p>
\[x_{k+1} = x_k + s_k\]
</p>

<p>
avec :
</p>

<p>
\[s_k = -[D_k^\dual \cdot D_k]^{-1} \cdot D_k^\dual \cdot f_k\]
</p>
</div>


<div id="outline-container-org3930332" class="outline-4">
<h4 id="org3930332"><span class="section-number-4">3.6.1</span> Zéros</h4>
<div class="outline-text-4" id="text-3-6-1">
<p>
Si \(S = \noyau f \ne \emptyset\), soit \(\gamma \in S\). On a alors :
</p>

<p>
\[0 \le \min \unsur{2} f(x)^\dual \cdot f(x) \le  \unsur{2} f(\gamma)^\dual \cdot f(\gamma) = 0\]
</p>

<p>
On en déduit que tout \(x \in \setR^n\) minimisant \(\varphi\) vérifiera \(f(x) = 0\). La méthode de minimisation nous fournit donc une approximation d'un tel \(x\).
</p>
</div>
</div>
</div>


<div id="outline-container-org010c857" class="outline-3">
<h3 id="org010c857"><span class="section-number-3">3.7</span> Levenberg-Marquardt</h3>
<div class="outline-text-3" id="text-3-7">
<p>
C'est une variante de la méthode des moindres carrés, utile dans les cas où
\(D_k^\dual \cdot D_k\) est numériquement proche d'une matrice non inversible. On
ajoute alors la matrice identité multipliée par un scalaire \(\lambda\)
sur la diagonale :
</p>

<p>
\[s_k = -[D_k^\dual \cdot D_k+ \lambda_k \cdot I]^{-1} \cdot D_k^\dual \cdot f_k\]
</p>
</div>
</div>
</div>


<div id="outline-container-org8b570dd" class="outline-2">
<h2 id="org8b570dd"><span class="section-number-2">4</span> Solveurs itératifs</h2>
<div class="outline-text-2" id="text-4">
<div id="text-table-of-contents">
<ul>
<li><a href="#orge1321fb">4.1. Dépendances</a></li>
<li><a href="#org49e1eaf">4.2. Méthodes itératives</a></li>
<li><a href="#org95f1f58">4.3. Résolution par minimisation</a></li>
<li><a href="#orgb432359">4.4. Espaces de Krylov</a></li>
<li><a href="#orged7f231">4.5. Méthode de projection</a></li>
<li><a href="#org752378a">4.6. Minimisation du résidu</a></li>
<li><a href="#orgf0d0318">4.7. Gradients biconjugués</a></li>
</ul>
</div>

<p>
\label{chap:solveur}
</p>
</div>


<div id="outline-container-orge1321fb" class="outline-3">
<h3 id="orge1321fb"><span class="section-number-3">4.1</span> Dépendances</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:matrice} : Les matrices</li>
</ul>
</div>
</div>


<div id="outline-container-org49e1eaf" class="outline-3">
<h3 id="org49e1eaf"><span class="section-number-3">4.2</span> Méthodes itératives</h3>
<div class="outline-text-3" id="text-4-2">
<p>
Il s'agit de résoudre itérativement (et approximativement) en \(x\) un système linéaire \(A \cdot x = b\), où \(A\) est une matrice et \(b\) un vecteur. L'itération générique s'écrit :
</p>

<p>
\[x_{k + 1} = I(x_k)\]
</p>

<p>
et on espère que la suite des \(x_k \in \setR^n\) converge vers la solution. On initialise en général les algorithmes avec \(x_0 = 0\).
</p>
</div>
</div>


<div id="outline-container-org95f1f58" class="outline-3">
<h3 id="org95f1f58"><span class="section-number-3">4.3</span> Résolution par minimisation</h3>
<div class="outline-text-3" id="text-4-3">
<p>
Soit une matrice \(H\) de taille \((n,n)\) hermitienne (\(H = H^\dual\)) et définie positive :
</p>

<p>
\[x^\dual \cdot H \cdot x \ge 0\]
</p>

<p>
pour tout \(x \in \setR^n\). Considérons la fonction définie par :
</p>

<p>
\[\varphi(x) = \unsur{2} x^\dual \cdot H \cdot x - x^\dual \cdot b\]
</p>

<p>
Si un certain \(x\) minimise \(\varphi\) sur \(\setR^n\), on doit avoir :
</p>

<p>
\[\partial \varphi(x) = H \cdot x - b = 0\]
</p>

<p>
ce qui revient à résoudre le système linéaire :
</p>

<p>
\[H \cdot x = b\]
</p>

<p>
Comme \(\partial^2 \varphi = H\) est définie positive, résoudre le système \(H \cdot x = b\) en \(x\) revient donc à minimiser \(\varphi\) sur \(\setR^n\). On peut obtenir une approximation de la solution en utilisant la méthode de la plus grande descente, le gradient étant donné par :
</p>

<p>
\[J = (\partial \varphi)^\dual = H \cdot x - b\]
</p>

<p>
On a donc des itérations \(k\) de la forme :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot (b - H \cdot x)\]
</p>

<p>
pour un \(\alpha_k \in \setR\) bien choisi. On peut aussi utiliser un autre algorithme, comme les gradients conjugués par exemple.
</p>
</div>


<div id="outline-container-org5357d05" class="outline-4">
<h4 id="org5357d05"><span class="section-number-4">4.3.1</span> Résidu</h4>
<div class="outline-text-4" id="text-4-3-1">
<p>
On remarque que la direction de la descente est donné par le résidu :
</p>

<p>
\[-J =  b - H \cdot x\]
</p>
</div>
</div>


<div id="outline-container-orgafd3b0f" class="outline-4">
<h4 id="orgafd3b0f"><span class="section-number-4">4.3.2</span> Newton</h4>
<div class="outline-text-4" id="text-4-3-2">
<p>
On pourrait bien entendu résoudre par la méthode de Newton, mais cela reviendrait alors à inverser la matrice \(H\) directement, ce que l'on cherche précisément à éviter ici.
</p>
</div>
</div>


<div id="outline-container-org4c51848" class="outline-4">
<h4 id="org4c51848"><span class="section-number-4">4.3.3</span> Généralisation</h4>
<div class="outline-text-4" id="text-4-3-3">
<p>
Soit la matrice \(A\) de taille \((N,n)\), où \(N \ge n\), et \(y \in \setR^N\). Considérons le système général :
</p>

<p>
\[A \cdot x = y\]
</p>

<p>
à résoudre en \(x \in \setR^n\). Si on multiplie à gauche par \(A^\dual\), on obtient :
</p>

<p>
\[A^\dual \cdot A \cdot x = A^\dual \cdot y\]
</p>

<p>
Posons :
</p>

<div class="org-center">
<p>
\(
H = A^\dual \cdot A \\
b = A^\dual \cdot y
\)
</p>
</div>

<p>
On est donc amenés à résoudre le système :
</p>

<p>
\[H \cdot x = b\]
</p>

<p>
où \(H\) est clairement hermitienne et définie positive puisque :
</p>

<p>
\[x^\dual \cdot (A^\dual \cdot A) \cdot x = (A \cdot x)^\dual \cdot (A \cdot x) \ge 0\]
</p>

<p>
Cette technique présente deux avantages. Premièrement, si \(H\) est inversible, la solution :
</p>

<p>
\[x = H^{-1} \cdot b = (A^\dual \cdot A)^{-1} \cdot A^\dual \cdot y\]
</p>

<p>
minimise la norme \(\norme{A \cdot x - y}\) même si la solution de \(A \cdot x = y\) n'existe pas. Il est même possible d'utiliser cette méthode avec des matrices \(A\) strictement hautes. Ensuite, les propriétés de \(H\) nous disent qu'une solution du système minimise la fonction \(\varphi\) associée. Il est donc possible de se ramener au problème de minimisation :
</p>

<p>
\[x \in \arg\min_{z \in \setR^n} \left[ \unsur{2} z^\dual \cdot A^\dual \cdot A \cdot z - z^\dual \cdot A^\dual \cdot y \right]\]
</p>

<p>
que l'on peut de nouveau résoudre itérativement en utilisant par exemple la méthode de la plus grande descente ou les gradients conjugués.
</p>
</div>
</div>
</div>


<div id="outline-container-orgb432359" class="outline-3">
<h3 id="orgb432359"><span class="section-number-3">4.4</span> Espaces de Krylov</h3>
<div class="outline-text-3" id="text-4-4">
<p>
Les espaces de Krylov sont des espaces de vecteurs engendrés par les puissances de la matrice \(A\) appliquées à un vecteur initial \(u\) :
</p>

<p>
\[\krylov_m(A,u) = \combilin{ u, A \cdot u, A^2 \cdot u, ..., A^{m - 1} \cdot u }\]
</p>

<p>
On a donc des éléments \(x \in \krylov_m(A,u)\) de la forme :
</p>

<p>
\[x = \left[ \sum_{i = 0}^{m - 1} \alpha_i \cdot A^i \right] \cdot u\]
</p>

<p>
pour certains \(\alpha_i \in \corps\). Il s'agit donc de polynômes matriciels appliquées à \(u\).
</p>
</div>
</div>


<div id="outline-container-orged7f231" class="outline-3">
<h3 id="orged7f231"><span class="section-number-3">4.5</span> Méthode de projection</h3>
<div class="outline-text-3" id="text-4-5">
<p>
Soit la matrice \(A\) de taille \((n,n)\), le vecteur \(b \in \setR^n\) et le système \(A \cdot x = b\) à résoudre en \(x \in \setR^n\). On choisit \(m \le n\) beaucoup plus petit que \(n\) et les vecteurs \((v_1,...,v_m)\) de \(\setR^n\). Nous allons tenter de minimiser l'erreur en \(x_{k + 1}\) produite par l'itération générique suivante :
</p>

<p>
\[x_{k + 1} = x_k + \sum_{i = 1}^m v_i \cdot y_i\]
</p>

<p>
où les \(y_i \in \setR\). Posons :
</p>

\begin{align}
V &= [v_1 \ ... \ v_m] \\
y &= [y_1 \ ... \ y_m]^\dual
\end{align}

<p>
On peut réécrire l'itération sous la forme :
</p>

<p>
\[x_{k + 1} = x_k + V \cdot y\]
</p>

<p>
Nous avons vu en résolvant les moindres carrés qu'une condition nécessaire de minimisation était d'imposer l'orthogonalité entre \((A \cdot x - b)\) et les colonnes de \(A\). Nous imposant ici une variante :
</p>

<p>
\[w_i^\dual \cdot (b - A \cdot x_{k + 1}) = 0\]
</p>

<p>
pour certains \(w_1,...,w_m \in \setR^n\). En posant :
</p>

<p>
\[W = [w_1 \ ... \ w_m]\]
</p>

<p>
cette condition peut s'écrire :
</p>

<p>
\[W^\dual \cdot (b - A \cdot x_{k + 1}) = 0\]
</p>

<p>
Posons :
</p>

<p>
\[r_k = b - A \cdot x_k\]
</p>

<p>
On a alors :
</p>

<p>
\[b - A \cdot x_{k + 1} = b - A \cdot x_k - A \cdot V \cdot y = r_k - A \cdot V \cdot y\]
</p>

<p>
La condition d'orthogonalité devient :
</p>

<p>
\[W^\dual \cdot (r_k - A \cdot V \cdot y) = W^\dual \cdot r_k - W^\dual \cdot A \cdot V \cdot y = 0\]
</p>

<p>
Si la matrice \(W^\dual \cdot A \cdot V\) est inversible, on a :
</p>

<p>
\[y = (W^\dual \cdot A \cdot V)^{-1} \cdot W^\dual \cdot r_k\]
</p>

<p>
Comme \(V\) et \(W\) sont de taille \((n,m)\), la matrice \(W^\dual \cdot A \cdot V\) est de taille \((m,m)\), donc beaucoup plus petite que \(A\). Le système correspondant est donc beaucoup plus facile à résoudre.
</p>
</div>


<div id="outline-container-org8ddcfbc" class="outline-4">
<h4 id="org8ddcfbc"><span class="section-number-4">4.5.1</span> Orthonormés</h4>
<div class="outline-text-4" id="text-4-5-1">
<p>
Si On choisit \(V = W\) et si les vecteurs \(v_i = w_i\) sont $A$-orthonormés, on a simplement :
</p>

<p>
\[\composante_{ij} W^\dual \cdot A \cdot V = w_i^\dual \cdot A \cdot v_j = v_i^\dual \cdot A \cdot v_j = \indicatrice_{ij}\]
</p>

<p>
et :
</p>

<p>
\[(W^\dual \cdot A \cdot V)^{-1} = W^\dual \cdot A \cdot V = I\]
</p>
</div>
</div>


<div id="outline-container-org265fd1a" class="outline-4">
<h4 id="org265fd1a"><span class="section-number-4">4.5.2</span> Krylov</h4>
<div class="outline-text-4" id="text-4-5-2">
<p>
On peut par exemple choisir des vecteurs de base de \(\krylov_m(A,r_k)\) pour former les colonnes des matrices \(V\) et \(W\). On peut aussi utiliser aussi des vecteurs de base de \(\krylov_m(A^\dual,r_k)\).
</p>
</div>
</div>
</div>


<div id="outline-container-org752378a" class="outline-3">
<h3 id="org752378a"><span class="section-number-3">4.6</span> Minimisation du résidu</h3>
<div class="outline-text-3" id="text-4-6">
<p>
On tente de minimiser la norme quadratique du résidu :
</p>

<p>
\[\mathcal{E}(y) = (r_k - A \cdot V \cdot y)^\dual \cdot (r_k - A \cdot V \cdot y)\]
</p>

<p>
La condition d'annulation de la dérivée par rapport à \(y\) nous donne la valeur optimale :
</p>

<p>
\[y = (V^\dual \cdot A^\dual \cdot A \cdot V)^{-1} \cdot (V^\dual \cdot A^\dual \cdot r_k)\]
</p>
</div>
</div>


<div id="outline-container-orgf0d0318" class="outline-3">
<h3 id="orgf0d0318"><span class="section-number-3">4.7</span> Gradients biconjugués</h3>
<div class="outline-text-3" id="text-4-7">
<p>
Soit la matrice \(A\) de taille \((n,n)\) et les vecteurs \(b,c \in \corps^n\). Les gradients biconjugués permettent d'obtenir simultanément les deux solutions \(x,y \in \corps^n\) telles que :
</p>

<div class="org-center">
<p>
\(
A \cdot x = b \quad \text{ (système primal)} \\
A^\dual \cdot y = c \quad \text{ (système dual)}
\)
</p>
</div>

<p>
Soit \((x_k,y_k)\) l'estimation de \((x,y)\) obtenues à l'itération \(k\) et les résidus :
</p>

<div class="org-center">
<p>
\(
r_k = b - A \cdot x_k \\
s_k = c - A^\dual \cdot y_k
\)
</p>
</div>

<p>
L'algorithme est initialisé par \(x_0 = y_0 = 0\). On a alors \(r_0 = b\) et \(s_0 = c\). L'itération est donnée par :
</p>

<div class="org-center">
<p>
\(
x_{k + 1} = x_k + \alpha_k \cdot p_k \\
y_{k + 1} = y_k + \gamma_k \cdot q_k
\)
</p>
</div>

<p>
où \(p_k,q_k \in \corps^n\) et \(\alpha_k,\gamma_k \in \corps\). Par analogie avec la plus grande descente, les premiers pas s'écrivent \(p_0 = r_0\) et \(q_0 = s_0\). On adapte ensuite à chaque itération les \(p_k, q_k\) par :
</p>

<div class="org-center">
<p>
\(
p_{k + 1} = r_{k + 1} + \beta_k \cdot p_k \\
q_{k + 1} = s_{k + 1} + \delta_k \cdot q_k
\)
</p>
</div>

<p>
où \(\beta_k,\delta_k \in \corps\). On impose l'orthogonalité des résidus ainsi que l'$A$-orthogonalité
des pas successifs :
</p>

<p>
\[s_k^\dual \cdot r_{k + 1} = r_k^\dual \cdot s_{k + 1} = q_k^\dual \cdot A \cdot p_{k + 1} = p_k^\dual \cdot A^\dual \cdot q_{k + 1} = 0\]
</p>

<p>
On voit que :
</p>

\begin{align}
r_{k + 1} &= b - A \cdot x_{k + 1} \\
&= b - A \cdot x_k - \alpha_k\cdot A\cdot p_k \\
&= r_k - \alpha_k \cdot A \cdot p_k \\
s_{k + 1} &= c - A^\dual \cdot y_{k + 1} \\
&= c - A^\dual \cdot y_k - \gamma_k \cdot A^\dual \cdot q_k \\
&= s_k - \gamma_k \cdot A^\dual \cdot q_k
\end{align}

<p>
Les conditions d'orthogonalité nous donnent donc les valeurs des coefficients
</p>

\begin{align}
\alpha_k = \frac{s_k^\dual \cdot r_k}{s_k^\dual \cdot A \cdot p_k} \ \ && \ \
\gamma_k = \frac{r_k^\dual \cdot s_k}{r_k^\dual \cdot A^\dual \cdot q_k} \\ \\
\beta_k = - \frac{ q_k^\dual \cdot A \cdot r_{k + 1} }{q_k^\dual \cdot A \cdot p_k} \ \ && \ \
\delta_k = - \frac{ p_k^\dual \cdot A^\dual \cdot s_{k + 1} }{p_k^\dual \cdot A^\dual \cdot  q_k}
\end{align}
</div>


<div id="outline-container-orgdbc7ead" class="outline-4">
<h4 id="orgdbc7ead"><span class="section-number-4">4.7.1</span> Simplification des coefficients</h4>
<div class="outline-text-4" id="text-4-7-1">
<p>
Il existe un procédé plus rapide pour évaluer les coefficients. En prenant le dual des relations entre les résidus successifs, on obtient \((s_k - s_{k + 1})^\dual = \conjaccent{\gamma_k} \cdot q_k^\dual \cdot A\). Donc :
</p>

<p>
\[q_k^\dual \cdot A \cdot r_{k + 1} = \unsur{\conjaccent{\gamma_k}} \cdot (s_k - s_{k + 1})^\dual \cdot r_{k + 1} = - \unsur{\conjaccent{\gamma_k}} \cdot s_{k + 1}^\dual \cdot r_{k + 1}\]
</p>

<p>
et :
</p>

\begin{align}
q_k^\dual \cdot A \cdot p_k &= q_k^\dual \cdot A \cdot r_k - \beta_k \cdot q_k^\dual \cdot A \cdot p_{k - 1} = q_k^\dual \cdot A \cdot r_k \\
&=  \unsur{\conjaccent{\gamma_k}} \cdot (s_k - s_{k + 1})^\dual \cdot r_k = \unsur{\conjaccent{\gamma_k}} \cdot s_k^\dual \cdot r_k
\end{align}

<p>
On en conclut que :
</p>

<p>
\[\beta_k = \frac{ s_{k + 1}^\dual \cdot r_{k + 1} }{ s_k^\dual \cdot r_k }\]
</p>

<p>
D'un autre coté, \((r_k - r_{k + 1})^\dual = \conjaccent{\alpha_k} \cdot p_k^\dual \cdot A^\dual\). On obtient en suivant un raisonnement analogue :
</p>

<p>
\[\delta_k = \frac{ r_{k + 1}^\dual \cdot s_{k + 1} }{ r_k^\dual \cdot s_k }\]
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org4241d26" class="outline-2">
<h2 id="org4241d26"><span class="section-number-2">5</span> Optimisation sous contrainte</h2>
<div class="outline-text-2" id="text-5">
<div id="text-table-of-contents">
<ul>
<li><a href="#orge66c8f9">5.1. Introduction</a></li>
<li><a href="#org0ebfee8">5.2. Problème de minimisation sous contrainte</a></li>
<li><a href="#org0b05718">5.3. Convexité</a></li>
<li><a href="#org73e29e4">5.4. Frontière</a></li>
<li><a href="#org850b49f">5.5. Pénalité</a></li>
<li><a href="#org70c9902">5.6. Lagrangien</a></li>
<li><a href="#orgd58e445">5.7. Conditions de Kuhn-Tucker</a></li>
<li><a href="#org48178d0">5.8. Point de selle</a></li>
<li><a href="#org70b2d81">5.9. Solution</a></li>
<li><a href="#org1eb577e">5.10. Problème de maximisation sous contrainte</a></li>
<li><a href="#org46f6695">5.11. Contraintes d'égalité</a></li>
<li><a href="#org24f11b7">5.12. Récapitulation</a></li>
<li><a href="#orgc3bed77">5.13. Découplage</a></li>
<li><a href="#org92cca7d">5.14. Dualité en optimisation linéaire</a></li>
<li><a href="#org4e5263a">5.15. Minimisation de la norme sous contraintes linéaires</a></li>
</ul>
</div>

<p>
\label{chap:lagrange}
</p>
</div>


<div id="outline-container-orge66c8f9" class="outline-3">
<h3 id="orge66c8f9"><span class="section-number-3">5.1</span> Introduction</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Ce chapitre traite de la résolution numérique de problèmes d'optimisation sous contraintes, ainsi que de leurs fondements théoriques. Les applications de ces méthodes sont nombreuses : maximisation du profit sous contrainte de ne pas dépasser un certain budget, maximiser la solidité d'une structure sans dépasser un certain poids, &#x2026;
</p>
</div>
</div>


<div id="outline-container-org0ebfee8" class="outline-3">
<h3 id="org0ebfee8"><span class="section-number-3">5.2</span> Problème de minimisation sous contrainte</h3>
<div class="outline-text-3" id="text-5-2">
<p>
Soit les fonctions convexes et et deux fois continument différentiables \(\omega_1,\omega_2,...,\omega_m : \setR^n \mapsto \setR\) et la fonction \(\omega : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\omega(x) = (\omega_1(x), \omega_2(x), ..., \omega_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Omega = \{ x \in \setR^n : \omega(x) \le 0 \}\]
</p>

<p>
Par définition de l'ordre partiel sur \(\setR^m\), tout \(x \in \Omega\) doit donc vérifier les \(m\) contraintes :
</p>

\begin{align}
\omega_1(x) &\le 0 \\
\omega_2(x) &\le 0 \\
\dots & & \\
\omega_m(x) &\le 0
\end{align}

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Omega\) qui minimise la fonction convexe et et deux fois continument différentiable \(\varphi : \setR^n \mapsto \setR\) sur \(\Omega\) :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
Nous avons donc un problème de minimisation à \(n\) paramètres :
</p>

<p>
\[x = (x_1,...,x_n)\]
</p>

<p>
et \(m\) contraintes correspondant aux \(\omega_i\). On dit que \(\varphi\) est la fonction objectif et \(\omega\) la fonction contraignante.
</p>
</div>


<div id="outline-container-orgd4cddc0" class="outline-4">
<h4 id="orgd4cddc0"><span class="section-number-4">5.2.1</span> Lien avec la minimisation libre</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
Il est important de se rendre compte que si \(\xi\) est la solution de :
</p>

<p>
\[\partial \varphi(\xi) = 0\]
</p>

<p>
on sait que :
</p>

<p>
\[\xi \in \arg\min_{x \in \setR^n} \varphi(x)\]
</p>

<p>
mais rien ne nous dit que \(\xi\) respecte les contraintes exigées ! On ne peut donc pas dans le cas général appliquer la technique classique de la minimisation libre pour résoudre des problèmes de minimisation contraints.
</p>
</div>
</div>
</div>


<div id="outline-container-org0b05718" class="outline-3">
<h3 id="org0b05718"><span class="section-number-3">5.3</span> Convexité</h3>
<div class="outline-text-3" id="text-5-3">
<p>
Soit \(u,v \in \Omega\) et \(s,t \in \setR\) tels que \(s,t \ge 0\) et \(s + t = 1\). On a alors par convexité des \(\omega_i\) :
</p>

<p>
\[\omega(s \cdot u + t \cdot v) \le s \cdot \omega(u) + t \cdot \omega(v) \le 0\]
</p>

<p>
On en conclut que \(w = s \cdot u + t \cdot v \in \Omega\). On a donc \(\convexe(\Omega) = \Omega\). L'ensemble \(\Omega\) est convexe.
</p>
</div>
</div>


<div id="outline-container-org73e29e4" class="outline-3">
<h3 id="org73e29e4"><span class="section-number-3">5.4</span> Frontière</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Soit \(x \in \frontiere \Omega\). Comme \(x \in \adh \Omega\), on a \(\distance(x,\Omega) = 0\). On peut donc construire une suite \(u_n \in \Omega\) convergeant vers \(x\). La continuité des \(\omega_i\) et la définition de \(\Omega\) nous disent que :
</p>

<p>
\[\omega_i(x) = \lim_{n \to \infty} \omega_i(u_n) \le \limsup_{n \to \infty} \omega_i(u_n) \le 0\]
</p>

<p>
pour tout \(i \in \{1,...,m\}\). Comme \(x \notin \interieur \Omega\), on a aussi \(\distance(x,\setR^n \setminus \Omega) = 0\) et on peut construire une suite \(v_n \in \setR^n \setminus \Omega\) convergeant vers \(x\). On peut alors trouver un \(i \in \{1,...,m\}\) tel que :
</p>

<p>
\[\omega_i(x) = \lim_{n \to \infty} \omega_i(v_n) \ge \liminf_{n \to \infty} \omega_i(v_n) \ge 0\]
</p>

<p>
Ces deux inégalités nous disent que, pour tout \(x \in \frontiere \Omega\), il existe un \(i\) tel que \(\omega_i(x) = 0\).
</p>
</div>
</div>


<div id="outline-container-org850b49f" class="outline-3">
<h3 id="org850b49f"><span class="section-number-3">5.5</span> Pénalité</h3>
<div class="outline-text-3" id="text-5-5">
<p>
L'idée est de laisser l'objectif inchangé sur \(\Omega\) mais de l'augmenter suffisamment en dehors pour que le minimum sur \(\Omega\) soit également le minimum global. On utilise une fonction \(p\) convexe et différentiable vérifiant :
</p>

\begin{align}
p(x) &= 0 \text{ pour tout } x \in \Omega \\
p(x) &\strictsuperieur& 0 \text{ pour tout } x \in \setR^n \setminus \Omega
\end{align}

<p>
et on construit donc un nouvel objectif \(\psi\) par :
</p>

<p>
\[\psi(x) = \varphi(x) + p(x)\]
</p>

<p>
On dit alors que \(p(x)\) est un terme de pénalité. On a :
</p>

<p>
\[\min_{x \in \Omega} \psi(x) = \min_{x \in \Omega} \varphi(x) = \varphi(\gamma)\]
</p>

<p>
Choisissons :
</p>

<p>
\[\chi \in \arg\min_{x \in \setR^n \setminus \Omega} \psi(x)\]
</p>

<p>
Si \(p\) est assez élevée en dehors de \(\Omega\) pour avoir \(\psi(\chi) \ge \varphi(\gamma)\), on a :
</p>

<p>
\[\min_{x \in \setR^n} \psi(x) = \min \{ \psi(\chi) , \varphi(\gamma) \} = \varphi(\gamma)\]
</p>

<p>
Si de plus \(\psi(\chi) \strictsuperieur \varphi(\gamma)\), aucun minimum global ne pourra être en dehors de \(\Omega\) (sinon il serait minimisé par \(\varphi(\gamma)\)). On aura donc :
</p>

<p>
\[\arg\min_{x \in \setR^n} \psi(x) \subseteq \Omega\]
</p>

<p>
et il suffit de choisir :
</p>

<p>
\[\gamma \in \arg\min_{x \in \setR^n} \psi(x)\]
</p>

<p>
pour obtenir une solution à notre problème. De par les propriétés des fonctions convexes, \(\gamma\) sera une solution de \(\partial \psi(\gamma) = 0\).
</p>
</div>
</div>


<div id="outline-container-org70c9902" class="outline-3">
<h3 id="org70c9902"><span class="section-number-3">5.6</span> Lagrangien</h3>
<div class="outline-text-3" id="text-5-6">
<p>
Par définition de \(\Omega\), on peut trouver au moins un \(\omega_i(x) \strictsuperieur 0\) pour tout \(x \notin \Omega\). Il est donc possible de s'en servir pour former un terme de pénalité. Comme chaque \(\omega_i\) est convexe, \(y_i \cdot \omega_i\) le sera aussi pour tout \(y_i \in \setR\) tel que \(y_i \ge 0\) (si \(y_i\) était strictement négatif, on aurait \(y_i \cdot \omega_i\) concave). Posons :
</p>

<p>
\[\mathcal{P} = \{ y \in \setR^m : y \ge 0 \}\]
</p>

<p>
L'objectif modifié s'écrit alors :
</p>

<p>
\[\lagrangien(x,y) = \varphi(x) + \sum_{i = 1}^m y_i \cdot \omega_i(x)\]
</p>

<p>
pour tout \(x \in \setR^n\) et tout \(y = (y_1,...,y_m) \in \mathcal{P}\). On dit que les \(y_i\) sont les multiplicateurs de Lagrange et que \(\lagrangien\) est le lagrangien associé au problème de minimisation. Utilisant la notation du produit scalaire entre vecteurs matriciels, on le note sous la forme schématique :
</p>

<p>
\[\lagrangien(x,y) = \varphi(x) + y^\dual \cdot \omega(x)\]
</p>
</div>
</div>


<div id="outline-container-orgd58e445" class="outline-3">
<h3 id="orgd58e445"><span class="section-number-3">5.7</span> Conditions de Kuhn-Tucker</h3>
<div class="outline-text-3" id="text-5-7">
<p>
Nous allons à présent essayer de caractériser un choix \(y = \lambda\) tel que \(\gamma\) minimise globalement \(\lagrangien(x,\lambda)\) :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \min_{x \in \setR^n} \lagrangien(x,\lambda)\]
</p>

<p>
Puisqu'il s'agit d'un problème de minimisation libre, on sait que la dérivée doit s'annuler en \(\gamma\) :
</p>

<p>
\[\deriveepartielle{\lagrangien}{x}(\gamma,\lambda) = \partial \varphi(\gamma) + \lambda^\dual \cdot \partial \omega(\gamma) = 0\]
</p>

<p>
En terme de composantes, on a donc :
</p>

<p>
\[\partial \varphi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \omega_i(\gamma) = 0\]
</p>

<p>
D'un autre coté, \(\gamma\) doit appartenir à \(\Omega\), où le terme de pénalité doit également s'annuler :
</p>

<p>
\[\lambda^\dual \cdot \omega(\gamma) = 0\]
</p>

<p>
On a donc :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \varphi(\gamma) + \lambda^\dual \cdot \omega(\gamma) = \varphi(\gamma) + 0 = \varphi(\gamma)\]
</p>

<p>
En terme de composantes, la condition d'annulation du terme de pénalité s'écrit :
</p>

<p>
\[\sum_i \lambda_i \cdot \omega_i(\gamma) = 0\]
</p>

<p>
Mais comme \(\lambda_i \ge 0\) et \(\omega_i(\gamma) \le 0\), on en déduit que \(\lambda_i \cdot \omega_i(\gamma) \le 0\). Que se passerait-il si on pouvait trouver un \(k\) tel que \(\lambda_k \cdot \omega_k(\gamma) \strictinferieur 0\) ? On aurait :
</p>

<p>
\[\sum_i \lambda_i \cdot \omega_i(\gamma) \le \lambda_k \cdot \omega_k(\gamma) \strictinferieur 0\]
</p>

<p>
ce qui est incompatible avec la condition d'annulation du terme de pénalité. On a donc :
</p>

<p>
\[\lambda_i^\dual \cdot \omega_i(\gamma) = 0\]
</p>

<p>
pour tout \(i \in \{1,2,...,m\}\). Les conditions :
</p>

<div class="org-center">
<p>
\(
\partial \varphi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \omega_i(\gamma) = 0 \\ \\
\lambda_i^\dual \cdot \omega_i(\gamma) = 0 \\ \\
\omega(\gamma) \le 0
\)
</p>
</div>

<p>
sont appellées conditions de Kuhn-Tucker.
</p>
</div>
</div>


<div id="outline-container-org48178d0" class="outline-3">
<h3 id="org48178d0"><span class="section-number-3">5.8</span> Point de selle</h3>
<div class="outline-text-3" id="text-5-8">
<p>
Supposons que \((\gamma,\lambda) \in \Omega \times \mathcal{P}\) vérifie les conditions de Kuhn-Tucker. Choisissons \(x \in \setR^n\) et \(y \in \mathcal{P}\). L'annulation du gradient (\(\partial_x \lagrangien(\gamma,\lambda) = 0\)) et la convexité du lagrangien par rapport à la variable \(x\) nous assurent que :
</p>

<p>
\[\lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
D'un autre coté, on a \(\lambda^\dual \cdot \omega(\gamma) = 0\) et \(\lagrangien(\gamma,\lambda) = \varphi(\gamma)\). On sait aussi que \(y \ge 0\) et que \(\omega(\gamma) \le 0\). Donc \(y^\dual \cdot \omega(\gamma) \le 0\) et :
</p>

<p>
\[\lagrangien(\gamma,y) = \varphi(\gamma) + y^\dual \cdot \omega(\gamma) \le \varphi(\gamma) = \lagrangien(\gamma,\lambda)\]
</p>

<p>
On voit que \(\lambda\) maximise le lagrangien par rapport à la variable \(y\). Ces deux propriétés extrémales nous montrent que \((\gamma,\lambda)\) est un point de selle :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>
</div>


<div id="outline-container-org223296e" class="outline-4">
<h4 id="org223296e"><span class="section-number-4">5.8.1</span> Réciproque</h4>
<div class="outline-text-4" id="text-5-8-1">
<p>
Nous venons de voir que les conditions de Kuhn-Tucker remplies sur \(\Omega \times \mathcal{P}\) nous offraient un point de selle sur \(\setR^n \times \mathcal{P}\). Nous allons voir que la réciproque est également vraie. Supposons que \((\gamma,\lambda) \in \setR^n \times \mathcal{P}\) soit un point de selle du lagrangien :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,y) \in \setR^n \times \mathcal{P}\). On a :
</p>

<p>
\[\lagrangien(\gamma,y) - \lagrangien(\gamma,\lambda) = (y - \lambda)^\dual \cdot \omega(\gamma) \le 0\]
</p>

<p>
relation qui doit être valable pour tout \(y \ge 0\). Fixons \(i \in \{1,2,...,m\}\) et choisissons :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \\
0 & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
on en déduit que \((y - \lambda)^\dual \cdot \omega(\gamma) = -\lambda_i \cdot \omega_i(\gamma) \le 0\), c'est-à-dire :
</p>

<p>
\[\lambda_i \cdot \omega_i(\gamma) \ge 0\]
</p>

<p>
Considérons à présent le choix :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \\
2 \lambda_i & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
On en déduit alors que :
</p>

<p>
\[(y - \lambda)^\dual \cdot \omega(\gamma) = \lambda_i \cdot \omega_i(\gamma) \le 0\]
</p>

<p>
On conclut de ces deux inégalités que :
</p>

<p>
\[\lambda_i \cdot \omega_i(\gamma) = 0\]
</p>

<p>
Enfin, si nous prenons :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \\
\lambda_i + 1 & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
on voit que :
</p>

<p>
\[(y - \lambda)^\dual \cdot \omega(\gamma) = 1 \cdot \omega_i(\gamma) = \omega_i(\gamma) \le 0\]
</p>

<p>
ce qui nous montre que \(\gamma \in \Omega\).
</p>

<p>
De plus, comme :
</p>

<p>
\[\gamma \in \arg\min_{x \in \setR^n} \lagrangien(x,\lambda)\]
</p>

<p>
les propriétés des fonctions dérivables nous imposent que \(\partial_x \lagrangien(\gamma,\lambda) = 0\).
</p>
</div>
</div>
</div>


<div id="outline-container-org70b2d81" class="outline-3">
<h3 id="org70b2d81"><span class="section-number-3">5.9</span> Solution</h3>
<div class="outline-text-3" id="text-5-9">
<p>
Supposons que \((\gamma,\lambda)\) soit un point de selle du lagrangien. Choisissons \(x \in \Omega\). On a \(\omega(x) \le 0\) et \(\lambda^\dual \cdot \omega(x) \le 0\). On en déduit que :
</p>

<p>
\[\lagrangien(x,\lambda) = \varphi(x) + \lambda^\dual \cdot \omega(x) \le \varphi(x)\]
</p>

<p>
On a donc bien :
</p>

<p>
\[\varphi(\gamma) = \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda) \le \varphi(x)\]
</p>

<p>
ce qui prouve que \(\gamma\) minimise \(\varphi\) sur \(\Omega\). La solution du problème de point de selle du lagrangien contient donc la solution de notre problème de minimisation sous contrainte.
</p>
</div>


<div id="outline-container-org1e57e93" class="outline-4">
<h4 id="org1e57e93"><span class="section-number-4">5.9.1</span> Généralisation</h4>
<div class="outline-text-4" id="text-5-9-1">
<p>
Remarquons que nous n'avons pas utilisé la convexité de \(\varphi\) ou de \(\omega\) pour démontrer que \(\gamma\) est bien la solution de notre problème. On peut donc appliquer la technique du point de selle du lagrangien à une classe de fonctions beaucoup plus générale.
</p>

<p>
Attention, si \(\varphi\) et/ou \(\omega\) ne sont plus supposées convexes, le point de selle impliquera toujours les conditions de Kuhn-Tucker mais l'inverse ne sera plus vrai. En pratique, on essaiera malgré tout de trouver une solution aux conditions de Kuhn-Tucker, et on déterminera a posteriori :
</p>

<ul class="org-ul">
<li>si le minimum trouvé est bien un minimum local (test de la Hessienne définie positive au \(\gamma\) obtenu)</li>
<li>si ce minimum local est aussi un minimum sur \(\Omega\)</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org1eb577e" class="outline-3">
<h3 id="org1eb577e"><span class="section-number-3">5.10</span> Problème de maximisation sous contrainte</h3>
<div class="outline-text-3" id="text-5-10">
<p>
Soit les fonctions {\em concaves} et deux fois continument différentiables \(\vartheta_1,\vartheta_2,...,\vartheta_m : \setR^n \mapsto \setR\) et la fonction \(\vartheta : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\vartheta(x) = (\vartheta_1(x), \vartheta_2(x), ..., \vartheta_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Theta = \{ x \in \setR^n : \vartheta(x) \ge 0 \}\]
</p>

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Theta\) qui maximise la fonction concave et et deux fois continument différentiable \(\psi : \setR^n \mapsto \setR\) sur \(\Theta\) :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \psi(x)\]
</p>

<p>
On note que ce problème est équivalent au suivant :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} (-\psi(x))\]
</p>

<p>
où :
</p>

<p>
\[\Omega = \{ x \in \setR^n : -\vartheta(x) \le 0 \}\]
</p>
</div>


<div id="outline-container-org50af9bf" class="outline-4">
<h4 id="org50af9bf"><span class="section-number-4">5.10.1</span> Lagrangien</h4>
<div class="outline-text-4" id="text-5-10-1">
<p>
On sait que maximiser \(\psi\) revient à minimiser \(-\psi\). Comme \(-\psi\) et \(-\vartheta\) sont convexes, on peut utiliser le lagrangien défini par :
</p>

<p>
\[\lagrangien_{\min}(x,y) = \Big[-\psi(x)\Big] + y^\dual \cdot \Big[-\vartheta(x)\Big] =  -\psi(x) - y^\dual \cdot \vartheta(x)\]
</p>

<p>
pour tout \((x,y) \in \setR^n \times \mathcal{P}\). La solution \((\gamma,\lambda)\) vérifie alors :
</p>

<p>
\[\lagrangien_{\min}(\gamma,y) \le \lagrangien_{\min}(\gamma,\lambda) \le \lagrangien_{\min}(x,\lambda)\]
</p>

<p>
On voit que la fonction opposée :
</p>

<p>
\[\lagrangien_{\max}(x,y) = - \lagrangien_{\min}(x,y) = \psi(x) + y^\dual \cdot \vartheta(x)\]
</p>

<p>
vérifie les conditions du point de selle inversées :
</p>

<p>
\[\lagrangien_{\max}(x,\lambda) \le \lagrangien_{\max}(\gamma,\lambda) \le \lagrangien_{\max}(\gamma,y)\]
</p>

<p>
Il s'agit du lagrangien natif du problème de maximisation. Il est maximisé par rapport à \(x\) et minimisé par rapport aux multiplicateurs de Lagrange.
</p>
</div>
</div>


<div id="outline-container-org21ba5e4" class="outline-4">
<h4 id="org21ba5e4"><span class="section-number-4">5.10.2</span> Kuhn-Tucker</h4>
<div class="outline-text-4" id="text-5-10-2">
<p>
Les conditions de Kuhn-Tucker associées à \(\lagrangien_{\min}\) s'écrivent :
</p>

<div class="org-center">
<p>
\(
</p>
<ul class="org-ul">
<li>&part; &psi;(&gamma;) - &sum;<sub>i = 1</sub><sup>m</sup> &lambda;<sub>i</sub> &sdot; &part; &thetasym;<sub>i</sub>(&gamma;) = 0 \\ <br /></li>
<li>&lambda;<sub>i</sub>^\dual &sdot; &thetasym;<sub>i</sub>(&gamma;) = 0 \\ <br /></li>
<li>&thetasym;(&gamma;) &le; 0</li>
</ul>
<p>
\)
</p>
</div>

<p>
Elles sont équivalentes aux conditions analogues associées à \(\lagrangien_{\max}\) :
</p>

<div class="org-center">
<p>
\(
\partial \psi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \vartheta_i(\gamma) = 0 \\ \\
\lambda_i^\dual \cdot \vartheta_i(\gamma) = 0 \\ \\
\vartheta(\gamma) \ge 0
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org46f6695" class="outline-3">
<h3 id="org46f6695"><span class="section-number-3">5.11</span> Contraintes d'égalité</h3>
<div class="outline-text-3" id="text-5-11">
<p>
Soit les fonctions deux fois continument différentiables \(\varrho_1,\varrho_2,...,\varrho_m : \setR^n \mapsto \setR\) et la fonction \(\varrho : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\varrho(x) = (\varrho_1(x), \varrho_2(x), ..., \varrho_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Phi = \{ x \in \setR^n : \varrho(x) = 0 \}\]
</p>

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Phi\) qui minimise la fonction deux fois continument différentiable \(\varphi : \setR^n \mapsto \setR\) sur \(\Phi\) :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Phi} \varphi(x)\]
</p>
</div>


<div id="outline-container-orga31b085" class="outline-4">
<h4 id="orga31b085"><span class="section-number-4">5.11.1</span> Lagrangien</h4>
<div class="outline-text-4" id="text-5-11-1">
<p>
On peut réécrire l'ensemble \(\Phi\) sous la forme :
</p>

<p>
\[\Phi = \{ x \in \setR^n : \varrho(x) \le 0, \ \varrho(x) \ge 0 \}\]
</p>

<p>
On introduit donc deux séries de multiplicateurs et le lagrangien défini par :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \varrho(x) + z^\dual \cdot (-\varrho(x))\]
</p>

<p>
pour tout \((x,y,z) \in \setR^n \times \mathcal{P} \times \mathcal{P}\). On constate qu'il ne dépend que de \(x\) et de \(y - z\) :
</p>

<p>
\[L(x,y,z) = \varphi(x) + (y - z)^\dual \cdot \varrho(x)\]
</p>

<p>
On voit que \(u = y - z\) est libre d'aller où il veut dans \(\setR^m\). On pose :
</p>

<p>
\[\lagrangien(x,u) = \varphi(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,u) \in \setR^n \times \setR^m\).
</p>
</div>
</div>


<div id="outline-container-org8fe0fdf" class="outline-4">
<h4 id="org8fe0fdf"><span class="section-number-4">5.11.2</span> Kuhn-Tucker</h4>
<div class="outline-text-4" id="text-5-11-2">
<p>
Comme on veut que \(\gamma\) minimise \(\lagrangien\) par rapport à la variable \(x\) sur \(\setR^n\), on impose \(\partial_x \lagrangien(\gamma,\lambda) = 0\). On doit avoir aussi \(\varrho(x) = 0\). Mais comme \(\partial_u \lagrangien(x,u) = \varrho(x)\), on se retrouve finalement avec les conditions nécessaires de Kuhn-Tucker :
</p>

<div class="org-center">
<p>
\(
\partial_x \lagrangien(\gamma,\lambda) = 0 \\ \\
\partial_u \lagrangien(\gamma,\lambda) = 0
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org2d54050" class="outline-4">
<h4 id="org2d54050"><span class="section-number-4">5.11.3</span> Point de selle</h4>
<div class="outline-text-4" id="text-5-11-3">
<p>
Nous allons montrer que tout point de selle est solution du problème de minimisation. Soit \((\gamma,\lambda)\) tel que :
</p>

<p>
\[\lagrangien(\gamma,u) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,u) \in \setR^n \times \setR^m\). On en déduit que :
</p>

<p>
\[\lagrangien(\gamma,u) - \lagrangien(\gamma,\lambda) \le 0\]
</p>

<p>
pour tout \(u \in \setR^m\), c'est-à-dire :
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) \le 0\]
</p>

<p>
Considérons la base canonique \((\canonique_1,...,\canonique_m)\) de \(\setR^m\). Si on prend \(u = \lambda + \canonique_i\), on obtient la condition
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) = \varrho_i(\gamma) \le 0\]
</p>

<p>
Mais comme \(u\) n'est pas forcément positif, on peut aussi prendre \(u = \lambda - \canonique_i\). On obtient alors la condition :
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) = -\varrho_i(\gamma) \le 0\]
</p>

<p>
On déduit de ces deux inégalités que \(\varrho(\gamma) = 0\), c'est à dire \(\gamma \in \Phi\).
</p>

<p>
A présent, soit \(x \in \Phi\). Comme \(\varrho(\gamma) = \varrho(x) = 0\), on a :
</p>

<p>
\[\varphi(\gamma) = \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda) = \varphi(x)\]
</p>

<p>
Le \(\gamma\) issu du point de selle est donc bien la solution de notre problème de minimisation contraint.
</p>
</div>
</div>
</div>


<div id="outline-container-org24f11b7" class="outline-3">
<h3 id="org24f11b7"><span class="section-number-3">5.12</span> Récapitulation</h3>
<div class="outline-text-3" id="text-5-12">
<p>
Considérons l'ensemble :
</p>

<p>
\[\Omega = \{ x \in \setR^n : \omega(x) \le 0, \ \vartheta(x) \ge 0, \ \varrho(x) = 0 \}\]
</p>
</div>


<div id="outline-container-org6d24f8e" class="outline-4">
<h4 id="org6d24f8e"><span class="section-number-4">5.12.1</span> Minimisation</h4>
<div class="outline-text-4" id="text-5-12-1">
<p>
Si on veut minimiser \(\varphi\) sur \(\Omega\), on utilisera le lagrangien défini par :
</p>

<p>
\[\lagrangien(x,y,z,u) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot \vartheta(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,y,z,u)\) tels que \(y,z \ge 0\). Le point de selle \((\gamma,\lambda,\mu,\nu)\) vérifiera :
</p>

<p>
\[\lagrangien(\gamma,y,z,u) \le \lagrangien(\gamma,\lambda,\mu,\nu) \le \lagrangien(x,\lambda,\mu,\nu)\]
</p>

<p>
Les conditions de Kuhn-Tucker s'écriront :
</p>

<div class="org-center">
<p>
\(
\partial \varphi(\gamma) + \sum_i \left[ \lambda_i \cdot \partial \omega_i(x) - \mu_i \cdot \partial \vartheta_i(x) + \nu_i \cdot \partial \varrho_i(x) \right] = 0 \\ \\
\lambda_i \cdot \omega_i(x) = 0 \\ \\
\mu_i \cdot \vartheta_i(x) = 0 \\ \\
\omega_i(x) \le 0 \\ \\
\vartheta_i(x) \ge 0 \\ \\
\varrho_i(x) = 0
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org965f5e6" class="outline-4">
<h4 id="org965f5e6"><span class="section-number-4">5.12.2</span> Maximisation</h4>
<div class="outline-text-4" id="text-5-12-2">
<p>
Si on veut maximiser \(\psi\) sur \(\Omega\), on utilisera le lagrangien défini par :
</p>

<p>
\[\lagrangien(x,y,z,u) = \psi(x) - y^\dual \cdot \omega(x) + z^\dual \cdot \vartheta(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,y,z,u)\) tels que \(y,z \ge 0\). Le point de selle \((\gamma,\lambda,\mu,\nu)\) vérifiera :
</p>

<p>
\[\lagrangien(x,\lambda,\mu,\nu) \le \lagrangien(\gamma,\lambda,\mu,\nu) \le \lagrangien(\gamma,y,z,u)\]
</p>

<p>
Les conditions de Kuhn-Tucker s'écriront :
</p>

<div class="org-center">
<p>
\(
\partial \psi(\gamma) + \sum_i \left[ -\lambda_i \cdot \partial \omega_i(x) + \mu_i \cdot \partial \vartheta_i(x) + \nu_i \cdot \partial \varrho_i(x) \right] = 0 \\ \\
\lambda_i \cdot \omega_i(x) = 0 \\ \\
\mu_i \cdot \vartheta_i(x) = 0 \\ \\
\omega_i(x) \le 0 \\ \\
\vartheta_i(x) \ge 0 \\ \\
\varrho_i(x) = 0
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org5f64e51" class="outline-4">
<h4 id="org5f64e51"><span class="section-number-4">5.12.3</span> Equivalence</h4>
<div class="outline-text-4" id="text-5-12-3">
<p>
On exprime parfois ces problèmes en utilisant des contraintes équivalentes. Si on pose \(s = - \omega(x)\), on a \(s \ge 0\). De même, on pose \(t = \vartheta(x) \ge 0\). On définit alors \(\Gamma\) comme l'ensemble des \((x,s,t)\) vérifiant les conditions :
</p>

\begin{align}
s,t &\ge 0 \\
s + \omega(x) &= 0 \\
t - \vartheta(x) &= 0 \\
\varrho(x) &= 0
\end{align}

<p>
Et on minimise \(\varphi(x)\) (ou on maximise \(\psi(x)\)) sur les \((x,s,t) \in \Gamma\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgc3bed77" class="outline-3">
<h3 id="orgc3bed77"><span class="section-number-3">5.13</span> Découplage</h3>
<div class="outline-text-3" id="text-5-13">
</div>
<div id="outline-container-orgd0f41b9" class="outline-4">
<h4 id="orgd0f41b9"><span class="section-number-4">5.13.1</span> Minimisation</h4>
<div class="outline-text-4" id="text-5-13-1">
<p>
Soit le problème de minimisation :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
où :
</p>

<p>
\[\Omega^+ = \{ x \in \corps^n : \omega(x) \le 0, \ x \ge 0 \}\]
</p>

<p>
La condition \(x \ge 0\) est équivalente à \(-x \le 0\). On définit le lagrangien :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot x\]
</p>

<p>
La solution de notre problème vérifie les conditions du point de selle :
</p>

<p>
\[L(\gamma,y,z) \le L(\gamma,\lambda,\mu) \le L(x,\lambda,\mu)\]
</p>

<p>
pour tout \(x \in \setR^n\) et \(y,z \ge 0\). Si \(x \ge 0\), on a :
</p>

<p>
\[-z^\dual \cdot x \le 0\]
</p>

<p>
par positivité de \(z\). On a alors :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot x \le \varphi(x) + y^\dual \cdot \omega(x) = L(x,y,0)\]
</p>

<p>
On en conclut qu'un choix permettant de maximiser \(L\) par rapport à son troisième argument est \(\mu = 0\). Introduisons le lagrangien modifié :
</p>

<p>
\[\lagrangien(x,y) = L(x,y,0) = \varphi(x) + y^\dual \cdot \omega(x)\]
</p>

<p>
Le problème du point de selle est équivalent à trouver \((\gamma,\lambda) \ge 0\) tel que :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,y) \ge 0\). La différence est qu'on ne fait plus apparaître explicitement la contrainte de positivité de \(x\) dans le lagrangien.
</p>
</div>
</div>


<div id="outline-container-org6bfc14e" class="outline-4">
<h4 id="org6bfc14e"><span class="section-number-4">5.13.2</span> Maximisation</h4>
<div class="outline-text-4" id="text-5-13-2">
<p>
Soit le problème de minimisation :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \psi(x)\]
</p>

<p>
où :
</p>

<p>
\[\Theta = \{ x \in \corps^n : \vartheta(x) \ge 0, \ x \ge 0 \}\]
</p>

<p>
On pose le lagrangien :
</p>

<p>
\[L(x,y,z) = \psi(x) + y^\dual \cdot \omega(x) + z^\dual \cdot x\]
</p>

<p>
La solution de notre problème vérifie les conditions du point de selle inversé :
</p>

<p>
\[L(x,\lambda,\mu) \le L(\gamma,\lambda,\mu) \le L(\gamma,y,z)\]
</p>

<p>
pour tout \(x \in \setR^n\) et \(y,z \ge 0\). Si \(x \ge 0\), on a :
</p>

<p>
\[z^\dual \cdot x \ge 0\]
</p>

<p>
par positivité de \(z\). On a alors :
</p>

<p>
\[L(x,y,z) \ge L(x,y,0)\]
</p>

<p>
On en conclut qu'un choix permettant de minimiser \(L\) par rapport à son troisième argument est \(\mu = 0\). Introduisons le lagrangien modifié :
</p>

<p>
\[\lagrangien(x,y) = L(x,y,0) = \psi(x) + y^\dual \cdot \vartheta(x)\]
</p>

<p>
Le problème du point de selle est équivalent à trouver \((\gamma,\lambda) \ge 0\) tel que :
</p>

<p>
\[\lagrangien(x,\lambda) \le \lagrangien(\gamma,\lambda) \le \lagrangien(\gamma,y)\]
</p>

<p>
pour tout \((x,y) \ge 0\).
</p>
</div>
</div>
</div>


<div id="outline-container-org92cca7d" class="outline-3">
<h3 id="org92cca7d"><span class="section-number-3">5.14</span> Dualité en optimisation linéaire</h3>
<div class="outline-text-3" id="text-5-14">
</div>
<div id="outline-container-org6485263" class="outline-4">
<h4 id="org6485263"><span class="section-number-4">5.14.1</span> Problème primal</h4>
<div class="outline-text-4" id="text-5-14-1">
<p>
Soit une matrice réelle \(A\) de taille \((m,n)\), l'ensemble :
</p>

<p>
\[\Theta = \{ x \in \setR^n : A \cdot x \le b, \ x \ge 0 \}\]
</p>

<p>
et le vecteur \(c \in \setR^n\). Nous nous intéressons au problème de maximisation linéaire sous contrainte :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \big[ c^\dual \cdot x \big]\]
</p>
</div>
</div>


<div id="outline-container-org71ec573" class="outline-4">
<h4 id="org71ec573"><span class="section-number-4">5.14.2</span> Lagrangien</h4>
<div class="outline-text-4" id="text-5-14-2">
<p>
La contrainte \(A \cdot x \le b\) est équivalente à :
</p>

<p>
\[b - A \cdot x \ge 0\]
</p>

<p>
On introduit donc le lagrangien :
</p>

\begin{align}
\lagrangien(x,y) &= c^\dual \cdot x + y^\dual \cdot (b - A \cdot x) \\
&= c^\dual \cdot x + y^\dual \cdot b - y^\dual \cdot A \cdot x
\end{align}

<p>
défini pour tout \((x,y) \ge 0\).
</p>
</div>
</div>


<div id="outline-container-org61e2a5a" class="outline-4">
<h4 id="org61e2a5a"><span class="section-number-4">5.14.3</span> Dualité</h4>
<div class="outline-text-4" id="text-5-14-3">
<p>
Comme on travaille dans les réels, on a par symétrie du produit scalaire :
</p>

\begin{align}
c^\dual \cdot x &= x^\dual \cdot c \\
y^\dual \cdot b &= b^\dual \cdot y \\
y^\dual \cdot A \cdot x &= (A \cdot x)^\dual \cdot y = x^\dual \cdot A^\dual \cdot y
\end{align}

<p>
Le lagrangien du problème primal peut donc se réécrire :
</p>

\begin{align}
\lagrangien(x,y) &= x^\dual \cdot c + b^\dual \cdot y - x^\dual \cdot A^\dual \cdot y \\
&= b^\dual \cdot y + x^\dual \cdot (c - A^\dual \cdot y)
\end{align}

<p>
On voit que la fonction duale définie par :
</p>

<p>
\[\lagrangien^\dual(y,x) = \lagrangien(x,y) = b^\dual \cdot y + x^\dual \cdot (c - A^\dual \cdot y)\]
</p>

<p>
pour tout \((y,x) \ge 0\) peut également être considérée comme un lagrangien formé à partir de l'objectif \(y \mapsto b^\dual \cdot y\) et d'une des deux contraintes suivantes :
</p>

<div class="org-center">
<p>
\(
?
</p>
\begin{cases}
c - A^\dual \cdot y \le 0 \\
c - A^\dual \cdot y \ge 0
\end{cases}
<p>
\)
</p>
</div>

<p>
Résoudre le problème primal revient à trouver un point \((\gamma,\lambda) \ge 0\) vérifiant :
</p>

<p>
\[\lagrangien(x,\lambda) \le \lagrangien(\gamma,\lambda) \le \lagrangien(\gamma,y)\]
</p>

<p>
pour tout \(x,y \ge 0\). En utilisant la définition de \(\lagrangien^\dual\), ces conditions se réécrivent :
</p>

<p>
\[\lagrangien^\dual(\lambda,x) \le \lagrangien^\dual(\lambda,\gamma) \le \lagrangien^\dual(y,\gamma)\]
</p>

<p>
Le couple \((\lambda,\gamma)\) est donc solution d'un problème de minimisation en \(y\). Dans un problème de minimisation, les contraintes associées aux multiplicateurs de lagrange doivent être négatives. On a donc \(c - A^\dual \cdot y \le 0\), autrement dit :
</p>

<p>
\[A^\dual \cdot y \ge c\]
</p>

<p>
Le problème primal est donc équivalent au problème dual suivant.
</p>
</div>
</div>


<div id="outline-container-org054eadc" class="outline-4">
<h4 id="org054eadc"><span class="section-number-4">5.14.4</span> Problème dual</h4>
<div class="outline-text-4" id="text-5-14-4">
<p>
Trouver :
</p>

<p>
\[\lambda \in \arg\min_{y \in \Omega} (b^\dual \cdot y)\]
</p>

<p>
où :
</p>

<p>
\[\Omega = \{ y \in \setR^m : A^\dual \cdot y \ge c, \ y \ge 0 \}\]
</p>
</div>
</div>


<div id="outline-container-org7669e2c" class="outline-4">
<h4 id="org7669e2c"><span class="section-number-4">5.14.5</span> Valeurs extrémales</h4>
<div class="outline-text-4" id="text-5-14-5">
<p>
Les conditions de Khun-Tucker des problèmes primal et dual impliquent :
</p>

<div class="org-center">
<p>
\(
\lambda^\dual \cdot (b - A \cdot \gamma) = 0 \\ \\
\gamma^\dual \cdot (c - A^\dual \cdot \lambda) = 0
\)
</p>
</div>

<p>
Les valeurs des lagrangiens aux points de selle s'écrivent donc :
</p>

<div class="org-center">
<p>
\(
\lagrangien(\gamma,\lambda) = c^\dual \cdot \gamma + \lambda^\dual \cdot (b - A \cdot \gamma) = c^\dual \cdot \gamma \\ \\
\lagrangien^\dual(\lambda,\gamma) = b^\dual \cdot \lambda + \gamma^\dual \cdot (c - A^\dual \cdot \lambda) = b^\dual \cdot \lambda
\)
</p>
</div>

<p>
La définition du lagrangien dual implique que :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \lagrangien^\dual(\lambda,\gamma)\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[c^\dual \cdot \gamma = b^\dual \cdot \lambda\]
</p>

<p>
Le maximum de \(x \mapsto c^\dual \cdot x\) sur \(\Theta\) est donc égal au minimum de \(y \mapsto b^\dual \cdot y\) sur \(\Omega\). Dans la suite, on note :
</p>

<p>
\[V = \max_{x \in \Theta} (c^\dual \cdot x) = \min_{y \in \Omega} (b^\dual \cdot y)\]
</p>
</div>
</div>


<div id="outline-container-orga0419e5" class="outline-4">
<h4 id="orga0419e5"><span class="section-number-4">5.14.6</span> Bornes</h4>
<div class="outline-text-4" id="text-5-14-6">
<p>
Par définition des maxima et minima, on a :
</p>

<p>
\[c^\dual \cdot x \le V \le b^\dual \cdot y\]
</p>

<p>
pour tout \(x \in \Theta\) et \(y \in \Omega\). Si les deux valeurs \(c^\dual \cdot x\) et \(b^\dual \cdot y\) sont proches, les éléments \(x\) et \(y\) sont presque optimaux.
</p>
</div>
</div>


<div id="outline-container-org11ee946" class="outline-4">
<h4 id="org11ee946"><span class="section-number-4">5.14.7</span> Attention</h4>
<div class="outline-text-4" id="text-5-14-7">
<p>
Ne pas confondre la notion de dualité \(\max - \min\) avec la dualité au sens des applications linéaires.
</p>
</div>
</div>
</div>


<div id="outline-container-org4e5263a" class="outline-3">
<h3 id="org4e5263a"><span class="section-number-3">5.15</span> Minimisation de la norme sous contraintes linéaires</h3>
<div class="outline-text-3" id="text-5-15">
<p>
Soit la matrice \(A \in \matrice(\setR,m,n)\), le vecteur colonne \(b \in \matrice(\setR,m,1)\) et l'ensemble :
</p>

<p>
\[\Phi = \{ x \in \matrice(\setR,n,1) : A \cdot x = b \}\]
</p>

<p>
On veut trouver le \(\gamma \in \Phi\) qui minimise la norme usuelle \(\norme{x} = \sqrt{x^\dual \cdot x}\) sur \(\Phi\). Comme la fonction $\norme{x} \mapsto \norme{x}<sup>2</sup> /2 $ est une fonction monotone strictement croissante sur \(\norme{x} \in \setR^+\), cela revient à minimiser :
</p>

<p>
\[\gamma = \arg\min_{x \in \Phi} \left( \unsur{2} \cdot x^\dual \cdot x \right)\]
</p>

<p>
Afin de résoudre ce problème, on introduit le lagrangien :
</p>

<p>
\[\lagrangien(x,u) = \unsur{2} \cdot x^\dual \cdot x + u^\dual \cdot (b - A \cdot x)\]
</p>

<p>
On impose les conditions de Kuhn-Tucker :
</p>

<div class="org-center">
<p>
\(
\partial_x \lagrangien(\gamma,\lambda) = \gamma - A^\dual \cdot \lambda = 0 \\ \\
\partial_u \lagrangien(\gamma,\lambda) = b - A \cdot \gamma = 0
\)
</p>
</div>

<p>
On en déduit que \(\gamma = A^\dual \cdot \lambda\) et que :
</p>

<p>
\[A \cdot A^\dual \cdot \lambda = b\]
</p>

<p>
Si \(A \cdot A^\dual\) est inversible, on a donc :
</p>

<p>
\[\lambda = \left( A \cdot A^\dual \right)^{-1} \cdot b\]
</p>

<p>
et :
</p>

<p>
\[\gamma = A^\dual \cdot \left( A \cdot A^\dual \right)^{-1} \cdot b\]
</p>
</div>
</div>
</div>


<div id="outline-container-org90cd6c2" class="outline-2">
<h2 id="org90cd6c2"><span class="section-number-2">6</span> Valeurs propres</h2>
<div class="outline-text-2" id="text-6">
<div id="text-table-of-contents">
<ul>
<li><a href="#org55bd9ea">6.1. Minimisation d'une forme quadratique avec norme contrainte</a></li>
<li><a href="#org76ff8e2">6.2. Application linéaire</a></li>
<li><a href="#org9ca6c0f">6.3. Opérateurs auto-adjoints</a></li>
<li><a href="#org78c08ae">6.4. Représentation tensorielle</a></li>
<li><a href="#org88ee280">6.5. Inverse</a></li>
<li><a href="#orgc1e8c0d">6.6. Représentation matricielle</a></li>
<li><a href="#org12a12c5">6.7. Invariance</a></li>
<li><a href="#org770c796">6.8. Matrices triangulaires</a></li>
<li><a href="#orga76fa0b">6.9. Forme de Schur</a></li>
<li><a href="#org57a6bc5">6.10. Algorithme \(Q R\)</a></li>
<li><a href="#org24589c9">6.11. Matrices hermitiennes</a></li>
<li><a href="#org7d3db26">6.12. Théorème de Courant-Fisher</a></li>
</ul>
</div>

<p>
\label{chap:vp}
</p>
</div>


<div id="outline-container-org55bd9ea" class="outline-3">
<h3 id="org55bd9ea"><span class="section-number-3">6.1</span> Minimisation d'une forme quadratique avec norme contrainte</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Soit un réel \(R \ne 0\), la matrice \(H \in \matrice(\setR,m,n)\) hermitienne et définie positive, et l'ensemble :
</p>

<p>
\[\Omega = \{ x \in \corps^n : \norme{x} = \sqrt{x^\dual \cdot x} = R \}\]
</p>

<p>
On peut reformuler \(\Omega\) de manière équivalente par :
</p>

<p>
\[\Omega = \{ x \in \corps^n : x^\dual \cdot x = R^2 \}\]
</p>

<p>
Soit l'objectif \(\varphi : \corps^n \mapsto \corps\) défini par :
</p>

<p>
\[\varphi(x) = x^\dual \cdot H \cdot x\]
</p>

<p>
pour tout \(x \in \corps^n\). On veut trouver le \(x \in \Omega\) qui minimise \(\varphi\) sur \(\Omega\). Définissons le lagrangien :
</p>

<p>
\[\lagrangien(x,\lambda) = x^\dual \cdot H \cdot x + \lambda \cdot (R^2 - x^\dual \cdot x)\]
</p>

<p>
où \(\lambda \in \setR\). On impose les conditions de Kuhn-Tucker :
</p>

<div class="org-center">
<p>
\(
\partial_x \lagrangien(x,\lambda) = 2 H \cdot x - 2 \lambda \cdot x = 0 \\
\partial_\lambda \lagrangien(x,\lambda) = R^2 - x^\dual \cdot x = 0
\)
</p>
</div>

<p>
Toute solution optimale \(x \in \Omega\) vérifie donc l'équation :
</p>

<p>
\[H \cdot x = \lambda \cdot x\]
</p>

<p>
pour un certain \(\lambda \in \setR\). Nous allons généraliser cette propriété aux applications linéaires.
</p>
</div>


<div id="outline-container-orgb69ea73" class="outline-4">
<h4 id="orgb69ea73"><span class="section-number-4">6.1.1</span> Norme unité</h4>
<div class="outline-text-4" id="text-6-1-1">
<p>
Un cas particulier souvent utilisé est celui où \(R = 1\).
</p>
</div>
</div>
</div>


<div id="outline-container-org76ff8e2" class="outline-3">
<h3 id="org76ff8e2"><span class="section-number-3">6.2</span> Application linéaire</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Soit l'espace vectoriel \(E\) sur \(\corps\) et une application linéaire \(A : E \mapsto E\). Si le couple \((u,\lambda) \in (E \setminus \{0\}) \times \corps\) vérifie :
</p>

<p>
\[A(u) = \lambda \cdot u\]
</p>

<p>
On dit que \(u\) est vecteur propre de \(A\) correspondant à la valeur propre \(\lambda\).
</p>
</div>


<div id="outline-container-org509e142" class="outline-4">
<h4 id="org509e142"><span class="section-number-4">6.2.1</span> Rapport de Rayleigh</h4>
<div class="outline-text-4" id="text-6-2-1">
<p>
En prenant le produit scalaire de \(u\) avec la relation \(A(u) = \lambda \cdot u\), on obtient :
</p>

<p>
\[\scalaire{u}{A(u)} = \lambda \cdot \scalaire{u}{u}\]
</p>

<p>
d'où l'on tire :
</p>

<p>
\[\lambda  = \frac{ \scalaire{u}{A(u)} }{ \scalaire{u}{u} }\]
</p>

<p>
Une telle expression est appelée rapport de Rayleigh. Par extension, on définit :
</p>

<p>
\[R(v)  = \frac{ \scalaire{v}{A(v)} }{ \scalaire{v}{v} }\]
</p>

<p>
pou tout vecteur non nul \(v \in E\).
</p>
</div>
</div>


<div id="outline-container-orgd091eec" class="outline-4">
<h4 id="orgd091eec"><span class="section-number-4">6.2.2</span> Définie positive</h4>
<div class="outline-text-4" id="text-6-2-2">
<p>
Si \(A\) est définie positive, toute valeur propre \(\lambda = R(u) \ge 0\) est un réel positif.
</p>
</div>
</div>


<div id="outline-container-org546b03b" class="outline-4">
<h4 id="org546b03b"><span class="section-number-4">6.2.3</span> Formulation équivalente</h4>
<div class="outline-text-4" id="text-6-2-3">
<p>
On voit qu'il est équivalent de chercher un scalaire \(\lambda\) et un vecteur \(u \ne 0\) tel que :
</p>

<p>
\[(A - \lambda \cdot \identite)(u) = A(u) - \lambda \cdot u = 0\]
</p>
</div>
</div>
</div>


<div id="outline-container-org9ca6c0f" class="outline-3">
<h3 id="org9ca6c0f"><span class="section-number-3">6.3</span> Opérateurs auto-adjoints</h3>
<div class="outline-text-3" id="text-6-3">
<p>
Si l'application linéaire \(A\) est auto-adjointe (\(A^\dual = A\)), ses valeurs et vecteurs propres possèdent d'importantes propriétés. Soit \(u \in E\) et \(\lambda \in \setC\) tels que \(A(u) = \lambda \cdot u\) et \(\scalaire{u}{u} = 1\). On a alors :
</p>

<p>
\[\lambda  = \scalaire{u}{A(u)} = \scalaire{A(u)}{u} = \conjugue \scalaire{u}{A(u)} = \bar{\lambda}\]
</p>

<p>
La valeur propre doit donc être réelle.
</p>
</div>


<div id="outline-container-orgb2de652" class="outline-4">
<h4 id="orgb2de652"><span class="section-number-4">6.3.1</span> Orthonormalité</h4>
<div class="outline-text-4" id="text-6-3-1">
<p>
Soit la suite de vecteurs propres \(u_i \in \Omega\) et de valeurs propres \(\lambda_i \in \setR\). On a :
</p>

<p>
\[\scalaire{u_i}{A(u_j)} = \lambda_j \cdot \scalaire{u_i}{u_j}\]
</p>

<p>
ainsi que :
</p>

<p>
\[\scalaire{u_i}{A(u_j)} = \scalaire{A(u_i)}{u_j} = \lambda_i \cdot \scalaire{u_i}{u_j}\]
</p>

<p>
En soustrayant ces deux équations, on obtient :
</p>

<p>
\[(\lambda_j - \lambda_i) \cdot \scalaire{u_i}{u_j} = 0\]
</p>

<p>
Le produit scalaire doit s'annuler lorsque les valeurs propres diffèrent.
Si toutes les valeurs propres sont distinctes, les vecteurs propres forment une suite orthonormée :
</p>

<p>
\[\scalaire{u_i}{u_j} = \indicatrice_{ij}\]
</p>
</div>
</div>


<div id="outline-container-org9258ae5" class="outline-4">
<h4 id="org9258ae5"><span class="section-number-4">6.3.2</span> Orthogonalité par rapport à l'application linéaire</h4>
<div class="outline-text-4" id="text-6-3-2">
<p>
Si les vecteurs propres \(u_i \in \Omega\) sont orthonormés, on a :
</p>

<p>
\[\scalaire{u_i}{A(u_j)} = \lambda_j \cdot \scalaire{u_i}{u_j} = \lambda_j \cdot \indicatrice_{ij}\]
</p>
</div>
</div>
</div>


<div id="outline-container-org78c08ae" class="outline-3">
<h3 id="org78c08ae"><span class="section-number-3">6.4</span> Représentation tensorielle</h3>
<div class="outline-text-3" id="text-6-4">
<p>
Supposons que la suite de vecteurs propres \((u_1,...,u_n)\) soit orthonormée. Pour tout \(x \in \combilin{u_1,...,u_n}\), on a alors :
</p>

<p>
\[x = \sum_i \scalaire{u_i}{x} \cdot u_i\]
</p>

<p>
et :
</p>

\begin{align}
A(x) &= \sum_i \scalaire{u_i}{x} \cdot A(u_i) \\
&= \sum_i \lambda_i \cdot \scalaire{u_i}{x} \cdot u_i
\end{align}

<p>
On peut donc représenter \(A\) sur \(\combilin{u_1,...,u_n}\) par le tenseur associé :
</p>

<p>
\[\mathcal{A} = \sum_i \lambda_i \cdot u_i \otimes u_i\]
</p>

<p>
de sorte que :
</p>

<p>
\[A(x) = \mathcal{A} \cdot x = \contraction{ \mathcal{A} }{1}{x}\]
</p>
</div>
</div>


<div id="outline-container-org88ee280" class="outline-3">
<h3 id="org88ee280"><span class="section-number-3">6.5</span> Inverse</h3>
<div class="outline-text-3" id="text-6-5">
<p>
Supposons que les vecteurs propres \(u_i\) forment une base orthonormée de \(E\), et que les valeurs propres correspondantes \(\lambda_i\) soient non nulles. Si \(x,y \in E\) sont tels que \(A(x) = \mathcal{A} \cdot x = y\), on a :
</p>

<p>
\[y = \sum_i \scalaire{u_i}{y} \cdot u_i = \mathcal{A} \cdot x = \sum_i \lambda_i \cdot u_i \cdot \scalaire{u_i}{x}\]
</p>

<p>
On en déduit en comparant les coefficients de chaque vecteur \(u_i\) que \(\lambda_i \cdot \scalaire{u_i}{x} = \scalaire{u_i}{y}\), d'où :
</p>

<p>
\[\scalaire{u_i}{x} = \unsur{\lambda_i} \cdot \scalaire{u_i}{y}\]
</p>

<p>
Mais ces produits scalaires sont les coordonnées de \(x\) par rapport aux \(u_i\) :
</p>

<p>
\[x = \sum_i \scalaire{u_i}{x} \cdot u_i = \sum_i \unsur{\lambda_i} \cdot \scalaire{u_i}{y} \cdot u_i\]
</p>

<p>
Donc, si on pose :
</p>

<p>
\[\mathcal{A}^{-1} = \sum_i \unsur{\lambda_i} \cdot u_i \otimes u_i\]
</p>

<p>
on a :
</p>

<p>
\[x = \mathcal{A}^{-1} \cdot y\]
</p>
</div>
</div>


<div id="outline-container-orgc1e8c0d" class="outline-3">
<h3 id="orgc1e8c0d"><span class="section-number-3">6.6</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-6-6">
<p>
On dit que \(\lambda \in \corps\) est la valeur propre de la matrice \(A \in \matrice(\corps,n,n)\) correspondant au vecteur propre non nul \(u \in \corps^n\) si ils sont valeurs et vecteurs propres de l'application linéaire sous-jacente :
</p>

<p>
\[A \cdot u = \lambda \cdot u\]
</p>
</div>


<div id="outline-container-org8c14183" class="outline-4">
<h4 id="org8c14183"><span class="section-number-4">6.6.1</span> Formulation équivalente</h4>
<div class="outline-text-4" id="text-6-6-1">
<p>
On voit qu'il est équivalent de chercher un scalaire \(\lambda\) et un vecteur \(u \ne 0\) tel que :
</p>

<p>
\[(A - \lambda \cdot I) \cdot u = 0\]
</p>
</div>
</div>


<div id="outline-container-orgf24c0ab" class="outline-4">
<h4 id="orgf24c0ab"><span class="section-number-4">6.6.2</span> Rapport de Rayleigh</h4>
<div class="outline-text-4" id="text-6-6-2">
<p>
On peut évaluer \(\lambda\) à partir de \(u\) en multipliant l'équation ci-dessus à gauche par \(u^\dual\). On obtient alors :
</p>

<p>
\[u^\dual \cdot A \cdot u = \lambda \cdot u^\dual \cdot u\]
</p>

<p>
et le rapport de Rayleigh en \(u\) s'en suit :
</p>

<p>
\[\lambda = \frac{u^\dual \cdot A \cdot u}{u^\dual \cdot u} = R(u)\]
</p>
</div>
</div>
</div>


<div id="outline-container-org12a12c5" class="outline-3">
<h3 id="org12a12c5"><span class="section-number-3">6.7</span> Invariance</h3>
<div class="outline-text-3" id="text-6-7">
<p>
Soit la valeur propre \(\lambda\) de \(A\) et le vecteur propre correspondant \(u \ne 0\). On a :
</p>

<p>
\[A \cdot u = \lambda \cdot u\]
</p>

<p>
Multiplions cette équation à gauche par une matrice inversible \(Q\) :
</p>

<p>
\[Q \cdot A \cdot u = \lambda \cdot Q \cdot u\]
</p>

<p>
Posons à présent \(v = Q \cdot u\). On a alors \(u = Q^{-1} \cdot v\) et :
</p>

<p>
\[Q \cdot A \cdot Q^{-1} \cdot v = \lambda \cdot v\]
</p>

<p>
On constate aussi que \(v \ne 0\), car sinon :
</p>

<p>
\[0 \ne u = Q^{-1} \cdot v = Q^{-1} \cdot 0 = 0\]
</p>

<p>
ce qui est impossible. On en conclut que \(\lambda\) est aussi une valeur propre de la matrice :
</p>

<p>
\[B = Q \cdot A \cdot Q^{-1}\]
</p>

<p>
On dit que les valeurs propres sont des invariants sous transformation linéaire réversible.
</p>
</div>
</div>


<div id="outline-container-org770c796" class="outline-3">
<h3 id="org770c796"><span class="section-number-3">6.8</span> Matrices triangulaires</h3>
<div class="outline-text-3" id="text-6-8">
<p>
Nous allons démontrer par récurrence sur la taille \(n\) d'une matrice triangulaire supérieure \(T\) que les composantes diagonales sont des valeurs propres de \(T\).
</p>

<ul class="org-ul">
<li>Si \(n = 1\), soit les uniques composantes \(\lambda = \composante_{11}(T)\) et \(\mu = \composante_1(u)\). On a :</li>
</ul>

<p>
\[T \cdot u = [\lambda] \cdot [\mu] = \lambda \cdot [1] \cdot [\mu] = \lambda \cdot u\]
</p>

<p>
ce qui montre que la composante diagonale \(\lambda\) est une valeur propre de \(T\).
</p>

<ul class="org-ul">
<li>Supposons que le résultat soit vrai pour \(n - 1\). Partitionnons à part la dernière ligne et la dernière colonne d'une matrice \(T \in \matrice(\corps,n,n)\) :</li>
</ul>

<div class="org-center">
<p>
\(
T =
</p>
\begin{Matrix}{cc}
T^{(n-1)} & z \\
0 & \lambda_n
\end{Matrix}
<p>
\)
</p>
</div>

<p>
Donc, \(T^{(n-1)}\) est une matrice triangulaire de la forme :
</p>

<div class="org-center">
<p>
\(
T<sup>(n-1)</sup> =
</p>
\begin{Matrix}{ccc}
\lambda_1 & \hdots & \hdots \\
0 & \ddots & \hdots \\
0 & 0 & \lambda_{n-1} \\
\end{Matrix}
<p>
\)
</p>
</div>

<p>
où les composantes diagonales \(\lambda_1,...,\lambda_{n-1}\) vérifient :
</p>

<p>
\[T^{(n-1)} \cdot u_i^{(n-1)} = \lambda_i \cdot u_i^{(n-1)}\]
</p>

<p>
pour certains vecteurs propres \(u_i^{(n-1)} \ne 0\). Nous allons chercher les vecteurs propres \(u \in \corps^n\) de \(T\) sous la forme :
</p>

<div class="org-center">
<p>
\(
u =
</p>
\begin{Matrix}{c}
v \\ \mu
\end{Matrix}
<p>
\)
</p>
</div>

<p>
où \(v \in \corps^{n - 1}\) et \(\mu \in \setC\). Si on choisit \(v = u_i^{(n-1)}\) pour \(i \in \{1,2,...,n-1\}\) et \(\mu = 0\), on a :
</p>

\begin{align}
T \cdot u &=
\begin{Matrix}{cc}
T^{(n-1)} & z \\
0 & \lambda_n
\end{Matrix}
\cdot
\begin{Matrix}{c}
u_i^{(n-1)} \\ 0
\end{Matrix} \\
&=
\begin{Matrix}{c}
T^{(n-1)} \cdot u_i^{(n-1)} \\
0
\end{Matrix}
=
\begin{Matrix}{c}
\lambda_i \cdot u_i^{(n-1)} \\ 0
\end{Matrix} \\
&= \lambda_i \cdot
\begin{Matrix}{c}
u_i \\ 0
\end{Matrix}
= \lambda_i \cdot u
\end{align}

<p>
Les valeurs propres de \(T^{(n-1)}\) sont donc également valeurs propres de \(T\). Il nous reste à examiner le cas de \(\lambda_n\). Posons :
</p>

<div class="org-center">
<p>
\(
A =
</p>
\begin{Matrix}{cccc}
\lambda_1 - \lambda_n & \hdots & \hdots & \hdots \\
0 & \ddots & \hdots & \hdots \\
0 & 0 & \lambda_{n-1} - \lambda_n & \hdots
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On doit donc trouver un vecteur \(u \in \corps^n\) non nul tel que :
</p>

<div class="org-center">
<p>
\(
(T - &lambda;<sub>n</sub> &sdot; I) &sdot; u =
</p>
\begin{Matrix}{c}
A \\ 0
\end{Matrix}
<p>
&sdot; u =
</p>
\begin{Matrix}{c}
A \cdot u \\ 0
\end{Matrix}
<p>
= 0
\)
</p>
</div>

<p>
Il suffit donc que \(u \ne 0\) vérifie \(A \cdot u = 0\). Mais comme \(A\) est de taille \((n - 1, n)\), le rang \(r\) vérifie \(r \le n - 1 \strictinferieur n\). Le système admet donc une infinité de solutions non nulles et \(\lambda_n\) est également une valeur propre de \(T\).
</p>
</div>
</div>



<div id="outline-container-orga76fa0b" class="outline-3">
<h3 id="orga76fa0b"><span class="section-number-3">6.9</span> Forme de Schur</h3>
<div class="outline-text-3" id="text-6-9">
<p>
Soit une matrice carrée \(A\) de taille \((n,n)\). On choisit la valeur propre \(\lambda_1\) la plus grande de \(A\) et on évaluer un vecteur propre non nul correspondant \(u_1\) en résolvant le système :
</p>

<p>
\[(A - \lambda_1 \cdot I) \cdot u_1 = 0\]
</p>

<p>
On construit alors le complément orthogonal \((u_2, ..., u_n)\) tel que \((u_1,...,u_n)\) forme une suite orthonormée. On a donc \(u_j^\dual \cdot u_i = \indicatrice_{ij}\). Soit la matrice \(U\) de taille \((n,n)\) définie par :
</p>

<p>
\[U_1 = [u_1 \ u_2 \ ... \ u_n]\]
</p>

<p>
On a bien sur \(U_1^{-1} = U_1^\dual\) et :
</p>

\begin{align}
A \cdot U_1 &=
\begin{Matrix}{cccc}
A \cdot u_1 & A \cdot u_2 & \hdots & A \cdot u_n
\end{Matrix} \\
&=
\begin{Matrix}{cccc}
\lambda_1 \cdot u_1 & A \cdot u_2 & \hdots & A \cdot u_n
\end{Matrix}
\end{align}

<p>
En multipliant à gauche par la duale, on obtient :
</p>

\begin{align}
U_1^\dual \cdot A \cdot U_1 &=
\begin{Matrix}{cccc}
(\lambda_1 \cdot u_1^\dual \cdot u_1) & (u_1^\dual \cdot A \cdot u_2) & \hdots & (u_1^\dual \cdot A \cdot u_n) \\
(\lambda_1 \cdot u_2^\dual \cdot u_1) & (u_2^\dual \cdot A \cdot u_2) & \hdots & (u_2^\dual \cdot A \cdot u_n) \\
\vdots & \vdots & \vdots & \vdots \\
(\lambda_1 \cdot u_n^\dual \cdot u_1) & (u_n^\dual \cdot A \cdot u_2) & \hdots & (u_n^\dual \cdot A \cdot u_n)
\end{Matrix} \\
&=
\begin{Matrix}{cccc}
\lambda_1 & (u_1^\dual \cdot A \cdot u_2) & \hdots & (u_1^\dual \cdot A \cdot u_n) \\
0 & (u_2^\dual \cdot A \cdot u_2) & \hdots & (u_2^\dual \cdot A \cdot u_n) \\
\vdots & \vdots & \vdots & \vdots \\
0 & (u_n^\dual \cdot A \cdot u_2) & \hdots & (u_n^\dual \cdot A \cdot u_n)
\end{Matrix} \\
\end{align}

<p>
ou, plus schématiquement :
</p>

<div class="org-center">
<p>
\(
U<sub>1</sub>^\dual &sdot; A &sdot; U<sub>1</sub> =
</p>
\begin{Matrix}{cc}
\lambda_1 &  \hdots \\ 0 & A^{(n - 1)}
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On peut réitérer le même raisonnement en utilisant la plus grande valeur propre de \(A^{(n - 1)}\) et une matrice unitaire correspondante \(U^{(n - 1)}\). Posons :
</p>

<div class="org-center">
<p>
\(
U<sub>2</sub> =
</p>
\begin{Matrix}{cc}
1 & 0 \\
0 & U^{(n - 1)}
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On obtient :
</p>

<div class="org-center">
<p>
\(
U<sub>2</sub>^\dual &sdot; U<sub>1</sub>^\dual &sdot; A &sdot; U<sub>1</sub> &sdot; U<sub>2</sub> =
</p>
\begin{Matrix}{ccc}
\lambda_1 & \hdots & \hdots \\
0 & \lambda_2 & \hdots \\
0 & 0 & A^{(n - 2)}
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On continue ainsi, en utilisant à l'étape \(k + 1\) la plus grande valeur propre de \(A^{(n - k)}\) et :
</p>

<div class="org-center">
<p>
\(
U<sub>k + 1</sub> =
</p>
\begin{Matrix}{cc}
I_k & 0 \\
0 & U^{(n-k)}
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On s'arrête évidemment lorsque \(k + 1 = n\). Posons :
</p>

<p>
\[U = U_1 \cdot ... \cdot U_n\]
</p>

<p>
On obtient à la fin du processus une matrice triangulaire :
</p>

<div class="org-center">
<p>
\(
U^\dual &sdot; A &sdot; U = T =
</p>
\begin{Matrix}{ccc}
\lambda_1 & \hdots & \hdots \\
0 & \ddots & \hdots \\
0 & 0 & \lambda_n
\end{Matrix}
<p>
\)
</p>
</div>

<p>
Comme :
</p>

<p>
\[U^{-1} = U_n^\dual \cdot ... \cdot U_1^\dual = U^\dual\]
</p>

<p>
on obtient, en multipliant la relation précédente à gauche par \(U\) et à droite par \(U^\dual\) la décomposition :
</p>

<p>
\[A = U \cdot T \cdot U^\dual\]
</p>

<p>
On appelle cette décomposition la forme de Schur et on la note :
</p>

<p>
\[(T,U) = \schur(A)\]
</p>
</div>


<div id="outline-container-orgec2efaa" class="outline-4">
<h4 id="orgec2efaa"><span class="section-number-4">6.9.1</span> Valeurs propres</h4>
<div class="outline-text-4" id="text-6-9-1">
<p>
La matrice \(T\) étant triangulaire supérieure, ses éléments diagonaux sont des valeurs propres de \(T\). Par invariance sous transformation, on voit aussi que les valeurs propres de :
</p>

<p>
\[A = U \cdot T \cdot U^\dual = U \cdot T \cdot U^{-1}\]
</p>

<p>
sont égales aux valeurs propres de \(T\). La décomposition de Schur d'une matrice \(A\) nous permet donc de connaître les valeurs propres en examinant la matrice triangulaire obtenue.
</p>
</div>
</div>


<div id="outline-container-orgd9ad7b3" class="outline-4">
<h4 id="orgd9ad7b3"><span class="section-number-4">6.9.2</span> Ordre</h4>
<div class="outline-text-4" id="text-6-9-2">
<p>
Nous allons montrer par récurrence sur la taille de \(A\) que les valeurs propres sont triées par ordre décroissant. Si \(n = 1\), il n'y a rien à montrer. Supposons à présent que le résultat soit vrai pour \(n - 1\). Soit :
</p>

<p>
\[(R,V) = \schur(A^{(n - 1)})\]
</p>

<p>
Par l'hypothèse de récurrence, \(R\) contient sur sa diagonale les valeurs propres de \(A^{(n - 1)}\) triées par ordre décroissant :
</p>

<p>
\[\lambda_2 \ge \lambda_3 \ge ...\]
</p>

<p>
Mais on a aussi :
</p>

<div class="org-center">
<p>
\(
</p>
\begin{Matrix}{cc}
1 & 0 \\
0 & V^\dual
\end{Matrix}
<p>
&sdot; U<sub>1</sub>^\dual &sdot; A &sdot; U<sub>1</sub> &sdot;
</p>
\begin{Matrix}{cc}
1 & 0 \\
0 & V
\end{Matrix}
<p>
=
</p>
\begin{Matrix}{cc}
\lambda_1 & \hdots \\
0 & R
\end{Matrix}
<p>
\)
</p>
</div>

<p>
Les valeurs propres de \(A^{(n - 1)}\) sont donc également les valeurs propres de \(A\). Par construction de l'algorithme, \(\lambda_1\) est la plus grande valeur propre et on a \(\lambda_1 \ge \max\{\lambda_2,...,\lambda_n\}\). On en conclut finalement que :
</p>

<p>
\[\lambda_1 \ge \lambda_2 \ge \lambda_3 \ge ...\]
</p>
</div>
</div>
</div>


<div id="outline-container-org57a6bc5" class="outline-3">
<h3 id="org57a6bc5"><span class="section-number-3">6.10</span> Algorithme \(Q R\)</h3>
<div class="outline-text-3" id="text-6-10">
<p>
Le but est d'évaluer les valeurs propres d'une matrice \(A\). Pour cela, on tente d'obtenir une approximation de la forme de Schur. Il s'agit d'un algorithme itératif qui part de :
</p>

<p>
\[A_0 = A\]
</p>

<p>
A chaque itération \(k\), on décompose la matrice \(A_k\) obtenue à l'itération précédente en utilisant l'algorithme de Householder :
</p>

<p>
\[(Q_k, R_k) = \householder(A_k)\]
</p>

<p>
On a alors \(A_k = Q_k \cdot R_k\), avec \(Q_k^\dual = Q_k^{-1}\). On construit ensuite une nouvelle matrice \(A_{k+1}\) par :
</p>

<p>
\[A_{k + 1} = Q_k^\dual \cdot A_k \cdot Q_k = Q_k^\dual \cdot Q_k \cdot R_k \cdot Q_k = R_k \cdot Q_k\]
</p>

<p>
Au bout de \(p\) itérations, la matrice \(A_p\) produite par l'algorithme vérifie :
</p>

<p>
\[A_p = Q_p^\dual \cdot ... \cdot Q_0^\dual \cdot A \cdot Q_0 \cdot ... \cdot Q_p\]
</p>

<p>
En inversant cette relation, on obtient :
</p>

<p>
\[A = Q_0 \cdot ... \cdot Q_p \cdot A_p \cdot Q_p^\dual \cdot ... \cdot Q_0^\dual\]
</p>

<p>
En injectant l'identité \(A_p \cdot Q_p^\dual = R_p\), on arrive à :
</p>

<p>
\[A = Q_0 \cdot ... Q_p \cdot R_p \cdot Q_{p - 1}^\dual \cdot ... \cdot Q_0^\dual\]
</p>

<p>
Si les suites :
</p>

<p>
\[\mathcal{U}_p = Q_0 \cdot ... Q_p\]
</p>

<p>
et \(R_p\) convergent :
</p>

<div class="org-center">
<p>
\(
\lim_{p \to \infty} \mathcal{U}_p = U \\
\lim_{p \to \infty} R_p = R
\)
</p>
</div>

<p>
on a bien évidemment :
</p>

<p>
\[\lim_{p \to \infty} \mathcal{U}_{p - 1}^\dual = U^\dual\]
</p>

<p>
On en déduit la forme approximative :
</p>

<p>
\[A = U \cdot R \cdot U^\dual \approx \mathcal{U}_N \cdot R_N \cdot \mathcal{U}_N^\dual\]
</p>

<p>
pour \(N\) suffisamment grand. Par invariance sous transformation réversible, les estimations des valeurs propres de \(A\) sont sur la diagonale de la matrice triangulaire supérieure \(R_N \approx R\). On peut se servir de ces estimations pour appliquer l'algorithme de Schur et construire une matrice triangulaire où les valeurs propres sont triées par ordre décroissant sur la diagonale.
</p>
</div>
</div>


<div id="outline-container-org24589c9" class="outline-3">
<h3 id="org24589c9"><span class="section-number-3">6.11</span> Matrices hermitiennes</h3>
<div class="outline-text-3" id="text-6-11">
<p>
Si \(A\) est hermitienne (\(A = A^\dual)\), la forme de Schur \((T,U) = \schur(A)\) implique que :
</p>

<p>
\[A = U \cdot T \cdot U^\dual = A^\dual = U \cdot T^\dual \cdot U^\dual\]
</p>

<p>
On en déduit en multipliant à gauche par \(U^\dual\) et à droite par \(U\) que \(T = T^\dual\). Mais comme \(T\) est triangulaire supérieure, on a \(t_{ij} = \composante_{ij}(T) = 0\) si \(i \strictsuperieur j\). De l'autre coté de la diagonale, on a \(t_{ji} = \conjaccent{t}_{ij} = 0\). On en conclut que les seuls éléments potentiellement non nuls doivent se trouver sur la diagonale (\(i = j\)). La matrice \(T\) se réduit donc à une matrice diagonale formée à partir des valeurs propres \(\lambda_i\) (non nécessairement distinctes) de \(A\) :
</p>

<p>
\[T = \Lambda  = \diagonale_n(\lambda_1,...,\lambda_n)\]
</p>

<p>
En multipliant \(A = U \cdot \Lambda \cdot U^\dual\) à droite par \(U\), on a :
</p>

<p>
\[A \cdot U = \Lambda \cdot U\]
</p>

<p>
Donc, si \(u_i = \colonne_i U\), on a :
</p>

<p>
\[A \cdot u_i = \lambda_i \cdot u_i\]
</p>

<p>
Les vecteurs propres sont donc donnés par les colonnes de \(U\). Comme \(U^\dual \cdot U = I\), on a la propriété d'orthonormalité :
</p>

<p>
\[u_i^\dual \cdot u_j = \indicatrice_{ij}\]
</p>
</div>
</div>


<div id="outline-container-org7d3db26" class="outline-3">
<h3 id="org7d3db26"><span class="section-number-3">6.12</span> Théorème de Courant-Fisher</h3>
<div class="outline-text-3" id="text-6-12">
<p>
Soit une matrice hermitienne \(A\) et sa forme de Schur :
</p>

<p>
\[A = U \cdot \Lambda \cdot U^\dual\]
</p>

<p>
Nous posons :
</p>

\begin{align}
\lambda_i &= \composante_{ii} \Lambda \\
u_i &= \colonne_i U
\end{align}

<p>
pour les valeurs propres et vecteurs propres correspondants. Les valeurs propres étant triées par ordre décroissant, on a :
</p>

<p>
\[\lambda_1 \ge \lambda_2 \ge \lambda_3 \ge ...\]
</p>

<p>
On considère le rapport de Rayleigh défini par :
</p>

<p>
\[R(x) = \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>

<p>
pour tout \(x \in \setC^n \setminus \{0\}\). Choisissons un tel \(x\). Comme les \(u_i\) forment une base orthonormée, on a :
</p>

<p>
\[x = \sum_{i = 1}^n a_i \cdot u_i\]
</p>

<p>
où \(a_i = \scalaire{u_i}{x}\) par orthonormalité. Le rapport s'écrit alors :
</p>

\begin{align}
R(x) &= \frac{ \sum_{i,j = 1}^n \conjaccent{a}_i \cdot a_j \cdot u_i^\dual \cdot A \cdot u_j }{ \sum_{i,j = 1}^n \conjaccent{a}_i \cdot a_j \cdot u_i^\dual \cdot u_j} \\ \\
&= \frac{ \sum_{i = 1}^n \abs{a_i}^2 \cdot \lambda_i }{ \sum_{j = 1}^n \abs{a_j}^2 }
\end{align}

<p>
Posons :
</p>

<p>
\[w_i = \frac{\abs{a_i}^2}{\sum_{j = 1}^n \abs{a_j}^2}\]
</p>

<p>
Il est clair que les \(w_i\) sont des réels positifs et que :
</p>

<p>
\[\sum_{i = 1}^n w_i = \frac{\sum_{i = 1}^n \abs{a_i}^2}{\sum_{j = 1}^n \abs{a_j}^2} = 1\]
</p>

<p>
On a alors :
</p>

<p>
\[R(x) = \sum_{i = 1}^n w_i \cdot \lambda_i\]
</p>
</div>


<div id="outline-container-orge572ab6" class="outline-4">
<h4 id="orge572ab6"><span class="section-number-4">6.12.1</span> Propriétés extrémales</h4>
<div class="outline-text-4" id="text-6-12-1">
<p>
Nous allons analyser les extrema du rapport de Rayleigh sur les ensembles :
</p>

\begin{align}
\mathcal{P}_m &= \combilin{u_1,u_2,...,u_m} \setminus \{0\} \\
\mathcal{Q}_m &= \mathcal{P}_{m - 1}^\orthogonal \setminus \{0\}
\end{align}

<ul class="org-ul">
<li>Si \(x \in \mathcal{P}_m\), les seules coordonnées non nulles sont \(a_1,...,a_m\). Il en va donc de même des \(w_i\) et :</li>
</ul>

<p>
\[R(x) = \sum_{i = 1}^m w_i \cdot \lambda_i\]
</p>

<p>
On voit aussi que :
</p>

\begin{align}
1 = \sum_{i = 1}^n w_i &= \sum_{i = 1}^m w_i + \sum_{i = m + 1}^n w_i \\
&= \sum_{i = 1}^m w_i + 0 \\
&= \sum_{i = 1}^m w_i
\end{align}

<p>
Les valeurs propres étant ordonnées par ordre décroissant, on a donc :
</p>

<p>
\[R(x) \ge \lambda_m \sum_{i = 1}^m w_i = \lambda_m\]
</p>

<p>
Cette borne inférieure est atteinte en \(u_m \in \mathcal{P}_m\) :
</p>

<p>
\[R(u_m) = \lambda_m\]
</p>

<p>
On en conclut que \(\lambda_m\) est le minimum de \(R\) sur l'espace \(\mathcal{P}_m\) :
</p>

<p>
\[\lambda_m = \min_{x \in \mathcal{P}_m} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>

<p>
et que \(u_m\) est solution du problème de minimisation :
</p>

<p>
\[u_m \in \arg\min_{x \in \mathcal{P}_m} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>

<ul class="org-ul">
<li>Si \(x \in \mathcal{Q}_m\), on doit avoir \(\scalaire{z}{x} = 0\) pour tout \(z \in \mathcal{P}_{m - 1}\), et en particulier :</li>
</ul>

<p>
\[a_k = \scalaire{u_k}{x} = 0\]
</p>

<p>
pour tout \(k \in \{1, ..., m - 1\}\). Les \(m - 1\) premières coordonnées sont nulles. Les \(m - 1\) premiers \(w_i\) le sont donc aussi et :
</p>

<p>
\[R(x) = \sum_{i = m}^n w_i \cdot \lambda_i\]
</p>

<p>
La somme des \(w_i\) se simplifie alors en :
</p>

<p>
\[\sum_{i = m}^n w_i = 1\]
</p>

<p>
Les valeurs propres étant ordonnées par ordre décroissant, on a donc :
</p>

<p>
\[R(x) \le \lambda_m \sum_{i = m}^n w_i = \lambda_m\]
</p>

<p>
Cette borne supérieure est atteinte en \(u_m \in \mathcal{Q}_m\) :
</p>

<p>
\[R(u_m) = \lambda_m\]
</p>

<p>
On en conclut que \(\lambda_m\) est le maximum de \(R\) sur l'espace \(\mathcal{Q}_m\) :
</p>

<p>
\[\lambda_m = \max_{x \in \mathcal{Q}_m} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>

<p>
et que \(u_m\) est solution du problème de maximisation :
</p>

<p>
\[u_m \in \arg\max_{x \in \mathcal{Q}_m} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>
</div>
</div>



<div id="outline-container-org2509579" class="outline-4">
<h4 id="org2509579"><span class="section-number-4">6.12.2</span> Minimax</h4>
<div class="outline-text-4" id="text-6-12-2">
<p>
Soit \(m \in \setN\) et la collection d'espaces vectoriels de dimension \(m\) générés par des bases orthonormées :
</p>

<p>
\[\mathcal{D}_m = \{ \combilin{v_1,...,v_m} : v_i \in \setC^n, \ \scalaire{v_i}{v_j} = \delta_{ij} \text{ pour tout } i,j \in \{1,...,m\} \}\]
</p>

<p>
On définit des collections associées par :
</p>

\begin{align}
\mathcal{V}_m &= \{ X \setminus \{0\} : X \in \mathcal{D}_m \} \\
\mathcal{W}_m &= \{ X^\orthogonal \setminus \{0\} : X \in \mathcal{D}_{m - 1} \}
\end{align}

<ul class="org-ul">
<li>Soit \(X \in \mathcal{V}_m\) et la suite \((v_1,...,v_m)\) formant une base orthonormée de \(X\). Il est équivalent d'imposer la contrainte \(x \in X \cap \mathcal{Q}_m\), ou d'imposer simultanément que \(x \ne 0\) s'écrive :</li>
</ul>

<p>
\[x = \sum_{j = 1}^m a_j \cdot v_j\]
</p>

<p>
et que \(x\) soit orthogonal à \(u_1,...,u_{m - 1}\) :
</p>

<p>
\[\scalaire{u_i}{x} = \sum_{j = 1}^m \scalaire{u_i}{v_j} \cdot a_j = 0\]
</p>

<p>
pour tout \(i \in \{1,...,m - 1\}\). Soit la matrice \(C \in \matrice(\setC, m - 1, m)\) de composantes :
</p>

<p>
\[\composante_{ij} C = \scalaire{u_i}{v_j}\]
</p>

<p>
et le vecteur \(a = [a_1 \ ... \ a_m]^\dual\). On doit alors avoir \(C \cdot a = 0\). Cette matrice étant strictement longue, il existe une infinité de solution dans l'espace :
</p>

<p>
\[S = \{ a \in \setC^m : C \cdot a = 0 \}\]
</p>

<p>
On peut donc choisir \(a \ne 0\) dans \(S\) correspondant à un \(x \ne 0\) appartenant à \(X \cap \mathcal{Q}_m\). On a alors :
</p>

<p>
\[\min_{z \in X} R(z) \le R(x) \le \max_{z \in \mathcal{Q}_m} R(z) = \lambda_m\]
</p>

<p>
L'espace \(X\) produit donc un minimum inférieur ou égal à \(\lambda_m\). Le cas particulier \(X = \mathcal{P}_m \in \mathcal{V}_m\) atteignant la borne, on en déduit que :
</p>

<p>
\[\lambda_m = \max_{X \in \mathcal{V}_m} \min_{x \in X} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>

<ul class="org-ul">
<li>Soit \(Y \in \mathcal{W}_m\). On peut alors trouver un \(X \in \mathcal{D}_{m - 1}\) tel que \(Y = X^\orthogonal \setminus \{0\}\). Soit la suite \((v_1,...,v_{m - 1})\) formant une base orthonormée de \(X\). Il est équivalent d'imposer la contrainte \(x \in Y \cap \mathcal{P}_m\), ou d'imposer simultanément que \(x \ne 0\) s'écrive :</li>
</ul>

<p>
\[x = \sum_{j = 1}^m a_j \cdot u_j\]
</p>

<p>
et que \(x\) soit orthogonal à \(v_1,...,v_{m - 1}\) :
</p>

<p>
\[\scalaire{v_i}{x} = \sum_{j = 1}^m \scalaire{v_i}{u_j} \cdot a_j = 0\]
</p>

<p>
pour tout \(i \in \{1,...,m - 1\}\). Soit la matrice \(C \in \matrice(\setC, m - 1, m)\) de composantes :
</p>

<p>
\[\composante_{ij} C = \scalaire{v_i}{u_j}\]
</p>

<p>
et le vecteur \(a = [a_1 \ ... \ a_m]^\dual\). On doit alors avoir \(C \cdot a = 0\). Cette matrice étant strictement longue, il existe une infinité de solution dans l'espace :
</p>

<p>
\[S = \{ a \in \setC^m : C \cdot a = 0 \}\]
</p>

<p>
On peut donc choisir \(a \ne 0\) dans \(S\) correspondant à un \(x \ne 0\) appartenant à \(Y \cap \mathcal{P}_m\). On a alors :
</p>

<p>
\[\lambda_m = \min_{z \in \mathcal{P}_m} R(z) \le R(x) \le \max_{z \in Y} R(z)\]
</p>

<p>
L'espace \(Y\) produit donc un maximum supérieur ou égal à \(\lambda_m\). Le cas particulier \(Y = \mathcal{Q}_m \in \mathcal{V}_m\) atteignant la borne, on en déduit que :
</p>

<p>
\[\lambda_m = \min_{Y \in \mathcal{W}_m} \max_{x \in Y} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>
</div>
</div>



<div id="outline-container-orga330af0" class="outline-4">
<h4 id="orga330af0"><span class="section-number-4">6.12.3</span> Remarque</h4>
<div class="outline-text-4" id="text-6-12-3">
<p>
Si les valeurs propres étaient ordonnées par ordre croissant :
</p>

<p>
\[\lambda_1 \le \lambda_2 \le \lambda_3 \le ...\]
</p>

<p>
on aurait bien entendu :
</p>

<p>
\[\lambda_m = \min_{X \in \mathcal{V}_m} \max_{x \in X} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x} = \max_{Y \in \mathcal{W}_m} \min_{x \in Y} \frac{x^\dual \cdot A \cdot x}{x^\dual \cdot x}\]
</p>
</div>
</div>


<div id="outline-container-orgb934be6" class="outline-4">
<h4 id="orgb934be6"><span class="section-number-4">6.12.4</span> Résolution numérique</h4>
<div class="outline-text-4" id="text-6-12-4">
<p>
Les propriétés extrémales nous offrent un moyen d'obtenir numériquement des approximations des valeurs et vecteurs propres d'une matrice hermitienne.
</p>
</div>


<div id="outline-container-orgdba50d2" class="outline-5">
<h5 id="orgdba50d2"><span class="section-number-5">6.12.4.1</span> Valeur propre maximale</h5>
<div class="outline-text-5" id="text-6-12-4-1">
<p>
Nous allons nous servir d'un algorithme d'optimisation pour obtenir le maximum \(\lambda_1\) de \(R\) sur \(\mathcal{Q}_1 = \setR^n\). A titre d'exemple, nous choisissons « la plus grande montée », qui n'est rien d'autre que l'opposé de la plus grande descente. On part d'un vecteur \(x \ne 0\) et on considère l'itération \(k\) :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot \delta_k\]
</p>

<p>
où \(\alpha_k \in \setR\) et \(\delta_k \in \setR^n\). Soit \(J_k = (\partial R(x_k))^\dual\) et le développement :
</p>

<p>
\[R(x_{k + 1}) \approx R(x_k) + \alpha_k \cdot J_k^\dual \cdot \delta_k\]
</p>

<p>
On a vu que pour maximiser \(J_k^\dual \cdot \delta_k = \scalaire{J_k}{\delta_k}\) sur \(\boule(0,\norme{J_k})\), il suffit de choisir \(\delta_k = J_k\). On pose donc :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot J_k\]
</p>

<p>
Si \(H_k = \partial^2 R(x_k)\), la valeur optimale de \(\alpha_k\) s'écrit :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot J_k}{J_k^\dual \cdot H_k \cdot J_k}\]
</p>

<p>
On peut aussi utiliser un autre algorithme de minimisation libre pour construire une suite \(x_k\) dont on espère que \(\lim_{k \to \infty} x_k = u_1\) et \(\lim_{k \to \infty} R(x_k) = \lambda_1\).
</p>
</div>
</div>


<div id="outline-container-org293b9ea" class="outline-5">
<h5 id="org293b9ea"><span class="section-number-5">6.12.4.2</span> Autres valeurs propres</h5>
<div class="outline-text-5" id="text-6-12-4-2">
<p>
Supposons que l'on ait déjà obtenu une bonne approximation de \((\lambda_1,...,\lambda_{m - 1})\) et de \((u_1,...,u_{m - 1})\). Si on veut que \(x \in \mathcal{Q}_m\), il faut et il suffit d'imposer que :
</p>

<p>
\[\scalaire{u_1}{x} = ... = \scalaire{u_{m - 1}}{x} = 0\]
</p>

<p>
On est donc amenés à construire le complémentaire orthogonal \((v_m,...,v_n)\) de \((u_1,...,u_{m - 1})\) et à poser :
</p>

<p>
\[V = [v_m \ v_{m + 1} \ ... \ v_n]\]
</p>

<p>
On a alors \(\combilin{v_m,...,v_n} = \mathcal{Q}_m\). Pour tout \(x \in \mathcal{Q}_m\), on peut donc trouver \(z = [z_m \ ... \ z_n]^\dual \in \setR^{n - m + 1}\) tel que :
</p>

<p>
\[x = \sum_{i = m}^n z_i \cdot v_i = V \cdot z\]
</p>

<p>
On pose donc :
</p>

<p>
\[\varrho(z) = R(V \cdot z) = \frac{z^\dual \cdot V^\dual \cdot A \cdot V \cdot z}{z^\dual \cdot V^\dual \cdot V \cdot z}\]
</p>

<p>
Par orthonormalité, on a \(V^\dual \cdot V = I\). On est donc finalement amené à maximiser :
</p>

<p>
\[\varrho(z) = \frac{z^\dual \cdot V^\dual \cdot A \cdot V \cdot z}{z^\dual \cdot z}\]
</p>

<p>
sur \(\setR^{n - m + 1}\). Pour cela, on part de \(z_0 \ne 0\) et on itère :
</p>

<p>
\[z_{k + 1} = z_k + \alpha_k \cdot \partial \varrho(z_k)\]
</p>

<p>
où :
</p>

<p>
\[\alpha_k = \frac{\partial \varrho(z_k)^\dual \cdot \partial \varrho(z_k)}{\partial \varrho(z_k)^\dual \cdot \partial^2 \varrho(z_k) \cdot \partial \varrho(z_k)}\]
</p>
</div>
</div>
</div>
</div>
</div>


<div id="outline-container-org575af2c" class="outline-2">
<h2 id="org575af2c"><span class="section-number-2">7</span> Valeurs singulières</h2>
<div class="outline-text-2" id="text-7">
<div id="text-table-of-contents">
<ul>
<li><a href="#org5d415d9">7.1. Décomposition en valeurs singulières</a></li>
<li><a href="#org12b4d12">7.2. Représentation tensorielle</a></li>
<li><a href="#org776b7b5">7.3. Dualité</a></li>
<li><a href="#org99b31da">7.4. Inverse</a></li>
<li><a href="#org1f5e459">7.5. Pseudo-inverse</a></li>
<li><a href="#org0e7b46a">7.6. Représentation matricielle</a></li>
<li><a href="#orgb5c7e7f">7.7. Pseudo-inverse</a></li>
<li><a href="#orgb9d4b4e">7.8. Systèmes linéaires</a></li>
<li><a href="#orgeb38925">7.9. Image et noyau</a></li>
<li><a href="#orgeb27a58">7.10. Normes</a></li>
<li><a href="#org9739a11">7.11. Fonctions de matrices</a></li>
</ul>
</div>

<p>
\label{chap:vs}
</p>
</div>


<div id="outline-container-org5d415d9" class="outline-3">
<h3 id="org5d415d9"><span class="section-number-3">7.1</span> Décomposition en valeurs singulières</h3>
<div class="outline-text-3" id="text-7-1">
<p>
Soit les espaces vectoriels \(E\) et \(F\) et une application linéaire \(A : E \mapsto F\) admettant un dual \(A^\dual : F \mapsto E\). Les applications \(A^\dual \circ A\) et \(A \circ A^\dual\) étant auto-adjointes, il y a fort à parier que leurs valeurs et vecteurs propres possèdent d'importantes propriétés.
</p>

<p>
Supposons que \(A^\dual \circ A\) admette les valeurs propres \(\lambda_i \in \corps\) triées par ordre décroissant ($&lambda;<sub>1</sub> &ge; &lambda;<sub>2</sub> &ge; &lambda;<sub>3</sub> &ge; &#x2026;$) et correspondant aux vecteurs propres \(v_i \in E\) formant une suite orthonormée. On a donc :
</p>

<p>
\[A^\dual \circ A(v_i) = \lambda_i \cdot v_i\]
</p>

<p>
On voit que les vecteurs \(z_i = A(v_i) \in F\) possèdent la propriété :
</p>

<p>
\[A^\dual(z_i) = A^\dual \circ A(v_i) = \lambda_i \cdot v_i\]
</p>

<p>
et :
</p>

<p>
\[A \circ A^\dual(z_i) = A(\lambda_i \cdot v_i) = \lambda_i \cdot A(v_i) = \lambda_i \cdot z_i\]
</p>

<p>
Les \(z_i\) sont donc vecteurs propres de \(A \circ A^\dual\) de valeurs propres \(\lambda_i\) identiques à celles de \(A^\dual \circ A\). On a l'orthogonalité :
</p>

<div class="org-center">
<p>
\(
\scalaire{z_i}{z_j} = \scalaire{A(v_i)}{A(v_j)} = \scalaire{v_i}{A^\dual \circ A(v_j)} = \lambda_j \cdot \scalaire{v_i}{v_j} = \lambda_i \cdot \indicatrice_{ij}
\)
</p>
</div>

<p>
On voit aussi que les valeurs propres sont positives :
</p>

<p>
\[\lambda_i = \scalaire{A(v_i)}{A(v_i)} \ge 0\]
</p>

<p>
Comme elles sont également triées par ordre décroissant, on a \(\lambda_1 \ge \lambda_2 \ge ... \ge \lambda_r \strictsuperieur 0\) pour un certain \(r \in \setN\), et \(\lambda_n = 0\) pour tout \(n \strictsuperieur r\). Dans la suite, nous nous restreignons aux valeurs propres non nulles. On peut alors poser :
</p>

<p>
\[\sigma_i = \sqrt{\lambda_i} \strictsuperieur 0\]
</p>

<p>
afin de normaliser les \(z_i\) :
</p>

<p>
\[u_i = \unsur{\sigma_i} \cdot z_i = \unsur{\sigma_i} \cdot A(v_i)\]
</p>

<p>
On a alors :
</p>

<p>
\[\scalaire{u_i}{u_j} = \scalaire{v_i}{v_j} = \indicatrice_{ij}\]
</p>

<p>
ainsi que :
</p>

<p>
\[A^\dual(u_i) = \frac{\lambda_i}{\sigma_i} \cdot v_i = \sigma_i \cdot v_i\]
</p>

<p>
Nous disposons donc des relations primales et duales :
</p>

<div class="org-center">
<p>
\(
A(v_i) = \sigma_i \cdot u_i \\
A^\dual(u_i) = \sigma_i \cdot v_i
\)
</p>
</div>

<p>
Pour tout \(x \in \combilin{v_1,...,v_r}\), on a :
</p>

<p>
\[x = \sum_{i = 1}^r \scalaire{v_i}{x} \cdot v_i\]
</p>

<p>
et :
</p>

\begin{align}
A(x) &= \sum_{i = 1}^r \scalaire{v_i}{x} \cdot A(v_i) \\
&= \sum_{i = 1}^r \scalaire{v_i}{x} \cdot \sigma_i \cdot u_i
\end{align}
</div>
</div>


<div id="outline-container-org12b4d12" class="outline-3">
<h3 id="org12b4d12"><span class="section-number-3">7.2</span> Représentation tensorielle</h3>
<div class="outline-text-3" id="text-7-2">
<p>
On conclut de ce qui précède que \(A\) peut être représentée sur \(\combilin{v_1,...,v_n}\) par le tenseur associé :
</p>

<p>
\[\mathcal{A} = \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i\]
</p>

<p>
de sorte que :
</p>

<p>
\[A(x) = \mathcal{A} \cdot x = \contraction{ \mathcal{A} }{1}{x} = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x}\]
</p>

<p>
On appelle une telle représentation une décomposition en valeurs singulières.
</p>
</div>
</div>


<div id="outline-container-org776b7b5" class="outline-3">
<h3 id="org776b7b5"><span class="section-number-3">7.3</span> Dualité</h3>
<div class="outline-text-3" id="text-7-3">
<p>
Le tenseur dual est donc :
</p>

<p>
\[\mathcal{A}^\dual = \sum_{i = 1}^r \sigma_i \cdot v_i \otimes u_i\]
</p>
</div>


<div id="outline-container-org46b1a9b" class="outline-4">
<h4 id="org46b1a9b"><span class="section-number-4">7.3.1</span> Propriétés</h4>
<div class="outline-text-4" id="text-7-3-1">
<p>
On retrouve sans surprise les représentation de :
</p>

\begin{align}
\mathcal{A}^\dual \cdot \mathcal{A} &= \sum_{i,j = 1}^r \sigma_i \cdot \sigma_j \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes v_j \\
&= \sum_{i = 1}^r \sigma_i^2 \cdot v_i \otimes v_i
\end{align}

<p>
et de :
</p>

\begin{align}
\mathcal{A} \cdot \mathcal{A}^\dual &= \sum_{i,j = 1}^r \sigma_i \cdot \sigma_j \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes u_j \\
&= \sum_{i = 1}^r \sigma_i^2 \cdot u_i \otimes u_i
\end{align}

<p>
en fonction de leurs valeurs et vecteurs propres.
</p>
</div>
</div>
</div>


<div id="outline-container-org99b31da" class="outline-3">
<h3 id="org99b31da"><span class="section-number-3">7.4</span> Inverse</h3>
<div class="outline-text-3" id="text-7-4">
<p>
Supposons que \((v_1,...,v_r)\) forme une base de \(E\) et que \((u_1,...u_r)\) forme une base de \(F\). Soit \(x \in E\) et \(y \in F\) tels que \(y = A(x) = \mathcal{A} \cdot x\). On a :
</p>

<p>
\[y = \sum_{i = 1}^r \scalaire{u_i}{y} \cdot u_i = \mathcal{A} \cdot x = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x}\]
</p>

<p>
On en déduit en comparant que \(\sigma_i \cdot \scalaire{v_i}{x} = \scalaire{u_i}{y}\), ce qui nous donne les produits scalaires correspondant aux coordonnées de \(x\) par rapport aux \(v_i\) :
</p>

<p>
\[\scalaire{v_i}{x} = \unsur{\sigma_i} \cdot \scalaire{u_i}{y}\]
</p>

<p>
On a donc :
</p>

<p>
\[x = \sum_i \scalaire{v_i}{x} \cdot v_i = \sum_i \unsur{\sigma_i} \cdot \scalaire{u_i}{y} \cdot v_i\]
</p>

<p>
Donc, si on pose :
</p>

<p>
\[\mathcal{A}^{-1} = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i\]
</p>

<p>
on a :
</p>

<p>
\[x = \mathcal{A}^{-1} \cdot y\]
</p>
</div>
</div>


<div id="outline-container-org1f5e459" class="outline-3">
<h3 id="org1f5e459"><span class="section-number-3">7.5</span> Pseudo-inverse</h3>
<div class="outline-text-3" id="text-7-5">
<p>
Nous ne supposons à présent plus que les suites de vecteurs \((u_1,...,u_r)\) et \((v_1,...,v_r)\) forment des bases de \(E\) et \(F\), mais nous définissons malgré tout par analogie le tenseur pseudo-inverse de \(A\) par :
</p>

<p>
\[\mathcal{A}^\pinverse = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i\]
</p>

<p>
Le pseudo-inverse \(A^\pinverse\) de l'application linéaire correspondante \(A\) est donc défini par :
</p>

<p>
\[A^\pinverse(y) = \mathcal{A}^\pinverse \cdot y = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{y}\]
</p>
</div>


<div id="outline-container-orgf1ec475" class="outline-4">
<h4 id="orgf1ec475"><span class="section-number-4">7.5.1</span> Tenseurs de projections</h4>
<div class="outline-text-4" id="text-7-5-1">
<p>
On voit que :
</p>

\begin{align}
\mathcal{A}^\pinverse \cdot \mathcal{A} &= \sum_{i,j = 1}^r \unsur{\sigma_i} \cdot \sigma_j \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes v_j \\
&= \sum_{i = 1}^r v_i \otimes v_i
\end{align}

<p>
correspond au tenseur de projection sur \(\combilin{v_1,...,v_r}\). De même :
</p>

\begin{align}
\mathcal{A} \cdot \mathcal{A}^\pinverse &= \sum_{i,j = 1}^r \sigma_i \cdot \unsur{\sigma_j} \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes u_j \\
&= \sum_{i = 1}^r u_i \otimes u_i
\end{align}

<p>
correspond au tenseur de projection sur \(\combilin{u_1,...,u_r}\).
</p>
</div>
</div>


<div id="outline-container-org8cbee69" class="outline-4">
<h4 id="org8cbee69"><span class="section-number-4">7.5.2</span> Dualité</h4>
<div class="outline-text-4" id="text-7-5-2">
<p>
On a clairement :
</p>

<div class="org-center">
<p>
\(
(\mathcal{A} \cdot \mathcal{A}^\pinverse)^\dual = \mathcal{A} \cdot \mathcal{A}^\pinverse \\
(\mathcal{A}^\pinverse \cdot \mathcal{A})^\dual = \mathcal{A}^\pinverse \cdot \mathcal{A}
\)
</p>
</div>
</div>
</div>


<div id="outline-container-orge23e36a" class="outline-4">
<h4 id="orge23e36a"><span class="section-number-4">7.5.3</span> Produits</h4>
<div class="outline-text-4" id="text-7-5-3">
<p>
On déduit des résultats ci-dessus que :
</p>

\begin{align}
\mathcal{A} \cdot \mathcal{A}^\pinverse \cdot \mathcal{A} &= \sum_{i,j = 1}^r \sigma_i \cdot \scalaire{v_i}{v_j} \cdot u_i \otimes v_j \\
&= \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i \\
&= \mathcal{A}
\end{align}

<p>
et :
</p>

\begin{align}
\mathcal{A}^\pinverse \cdot \mathcal{A} \cdot \mathcal{A}^\pinverse &= \sum_{i,j = 1}^r \unsur{\sigma_i} \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes u_j \\
&= \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i \\
&= \mathcal{A}^\pinverse
\end{align}
</div>
</div>


<div id="outline-container-org144730c" class="outline-4">
<h4 id="org144730c"><span class="section-number-4">7.5.4</span> Orthogonalité</h4>
<div class="outline-text-4" id="text-7-5-4">
<p>
Soit le tenseur identité \(\tenseuridentite\). On déduit de ce qui précède les propriétés d'orthogonalité :
</p>

<div class="org-center">
<p>
\(
\mathcal{A} \cdot (\tenseuridentite - \mathcal{A}^\pinverse \cdot \mathcal{A}) = 0 \\
\mathcal{A}^\pinverse \cdot (\tenseuridentite - \mathcal{A} \cdot \mathcal{A}^\pinverse) = 0
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org0e7b46a" class="outline-3">
<h3 id="org0e7b46a"><span class="section-number-3">7.6</span> Représentation matricielle</h3>
<div class="outline-text-3" id="text-7-6">
<p>
Soit une matrice \(A \in \matrice(\corps,m,n)\) et \(p = \min \{ m , n \}\). L'algorithme de décomposition en valeurs singulières est très simple. On évalue :
</p>

<div class="org-center">
<p>
\(
(\Lambda_1, U) = \schur(A \cdot A^\dual) \\
(\Lambda_2, V) = \schur(A^\dual \cdot A)
\)
</p>
</div>

<p>
On a alors \(U,\Lambda_1 \in \matrice(\corps,n,n)\) et \(V,\Lambda_2 \in \matrice(\corps,m,m)\). Comme les matrices \(A^\dual \cdot A\) et \(A \cdot A^\dual\) sont hermitiennes et que leurs valeurs propres sont identiques, les matrices « triangulaires » obtenues sont en fait diagonales et :
</p>

<div class="org-center">
<p>
\(
\Lambda_1 = \diagonale_n(\lambda_1,...\lambda_p) \\
\Lambda_2 = \diagonale_m(\lambda_1,...\lambda_p)
\)
</p>
</div>

<p>
On pose alors \(\sigma_i = \sqrt{\lambda_i}\) pour \(i \in \{1,2,...,p\}\) et on a \(\sigma_1 \ge \sigma_2 \ge ... \ge \sigma_r \strictsuperieur 0\) et \(\sigma_{r + 1} = ... = \sigma_p = 0\). Les colonnes de \(U\) et de \(V\) sont les vecteurs propres correspondant :
</p>

<div class="org-center">
<p>
\(
u_i = \colonne_i U \\
v_i = \colonne_i V
\)
</p>
</div>

<p>
On a également \(U^{-1} = U^\dual\) et \(V^{-1} = V^\dual\). La décomposition en valeurs singulières de \(A\) s'écrit :
</p>

<p>
\[A = \sum_{i = 1}^r \sigma_i \cdot u_i \otimes v_i = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\]
</p>

<p>
Si nous posons :
</p>

<p>
\[S = \diagonale_{m,n}(\sigma_1,...,\sigma_r)\]
</p>

<p>
on peut réécrire la décomposition de \(A\) sous la forme :
</p>

<p>
\[A = U \cdot S \cdot V^\dual\]
</p>

<p>
On note alors :
</p>

<p>
\[(U,S,V) = \singuliere(A)\]
</p>
</div>
</div>


<div id="outline-container-orgb5c7e7f" class="outline-3">
<h3 id="orgb5c7e7f"><span class="section-number-3">7.7</span> Pseudo-inverse</h3>
<div class="outline-text-3" id="text-7-7">
<p>
Le pseudo-inverse est donné par :
</p>

<p>
\[A^\pinverse = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot u_i^\dual\]
</p>

<p>
On a donc :
</p>

<p>
\[S^\pinverse = \diagonale_{n,m}\left(\unsur{\sigma_1},...,\unsur{\sigma_r}\right)\]
</p>

<p>
et :
</p>

<p>
\[A^\pinverse = V \cdot S^\pinverse \cdot U^\dual\]
</p>
</div>
</div>


<div id="outline-container-orgb9d4b4e" class="outline-3">
<h3 id="orgb9d4b4e"><span class="section-number-3">7.8</span> Systèmes linéaires</h3>
<div class="outline-text-3" id="text-7-8">
</div>
<div id="outline-container-org13ec1a0" class="outline-4">
<h4 id="org13ec1a0"><span class="section-number-4">7.8.1</span> Moindres carrés</h4>
<div class="outline-text-4" id="text-7-8-1">
<p>
Soit la matrice \(A \in \matrice(\corps,m,n)\), le vecteur matriciel \(b \in \corps^m\) et l'erreur produite par \(x \in \corps^n\) :
</p>

<p>
\[e(x) = b - A \cdot x\]
</p>

<p>
On dit aussi que \(e(x)\) est le résidu du système en \(x\). Nous allons tenter de minimiser :
</p>

<p>
\[\mathcal{E}(x) = e(x)^\dual \cdot e(x) = \norme{e(x)}^2\]
</p>

<p>
en utilisant la décomposition en valeurs singulières \(A = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\). Comme \((v_1,...,v_n)\), suite orthonormée et linéairement indépendante, forme une base de \(\corps^n\), on peut exprimer \(x\) en fonction de ses coordonnées dans cette base :
</p>

<p>
\[x = \sum_{i = 1}^n x_i \cdot v_i = \sum_{i = 1}^n \scalaire{v_i}{x} \cdot v_i\]
</p>

<p>
Comme \((u_1,...,u_m)\), suite orthonormée et linéairement indépendante, forme une base de \(\corps^m\), on peut exprimer \(b\) comme :
</p>

<p>
\[b = \sum_{i = 1}^m \scalaire{u_i}{b} \cdot u_i\]
</p>

<p>
On a également :
</p>

<p>
\[A \cdot x = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot \scalaire{v_i}{x} = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot x_i\]
</p>

<p>
On en conclut que l'erreur s'écrit :
</p>

<p>
\[e(x) = \sum_{i = 1}^r (\scalaire{u_i}{b} - \sigma_i \cdot x_i) \cdot u_i + \sum_{i = r + 1}^m \scalaire{u_i}{b} \cdot u_i\]
</p>

<p>
Posons :
</p>

<div class="org-center">
<p>
\(
e<sub>i</sub>(x) =
</p>
\begin{cases}
\scalaire{u_i}{b} - \sigma_i \cdot x_i & \text{ si } i \in \{1,...,r\} \\
\scalaire{u_i}{b} & \text{ si } i \in \{r + 1, ...,m\} \\
\end{cases}
<p>
\)
</p>
</div>

<p>
On a alors \(e(x) = \sum_{i = 1}^m e_i(x) \cdot u_i\) et :
</p>

<p>
\[\mathcal{E}(x) = \norme{e(x)}^2 = \sum_{i,j = 1}^m \conjaccent{e}_i(x) \cdot e_j(x) \cdot u_i^\dual \cdot u_j = \sum_{i = 1}^m \abs{e_i(x)}^2\]
</p>

<p>
On a donc :
</p>

<p>
\[\mathcal{E}(x) = \sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot x_i}^2 + \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2\]
</p>

<p>
Dans le cas où l'on travaille avec des réels, l'annulation de la dérivée par rapport aux \(x_i\) nous donne :
</p>

<p>
\[2 (\scalaire{u_i}{b} - \sigma_i \cdot x_i) = 0\]
</p>

<p>
lorsque \(i \in \{1,...,r\}\). Nous n'avons par contre aucune contrainte sur \(x_{r + 1},...,x_n\). Un choix satisfaisant les conditions ci-dessus est donc :
</p>

<div class="org-center">
<p>
\(
x<sub>i</sub> =
</p>
\begin{cases}
\scalaire{u_i}{b} / \sigma_i & \text{ si } i \in \{1,...,r\} \\
0 & \text{ si } i \in \{r + 1, ...,n\} \\
\end{cases}
<p>
\)
</p>
</div>

<p>
Notre \(x\) potentiellement optimal s'écrit donc :
</p>

<p>
\[x = \sum_{i = 1}^r \unsur{\sigma_i} \cdot \scalaire{u_i}{b} \cdot v_i\]
</p>

<p>
La somme ressemble à une expression faisant intervenir le pseudo-inverse. En effet, on a :
</p>

<p>
\[A^\pinverse \cdot b = \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{b} = x\]
</p>

<p>
Considérons à présent le cas général complexe. On voit que pour le choix \(x = A^\pinverse \cdot b\) :
</p>

<p>
\[\mathcal{E}(x) = \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2\]
</p>

<p>
On en déduit la borne inférieure de l'erreur :
</p>

<p>
\[\mathcal{E}(z) = \sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot \scalaire{v_i}{z}}^2 + \sum_{i = r + 1}^m \abs{\scalaire{u_i}{b}}^2 \ge \sum_{i = r + 1}^n \abs{\scalaire{u_i}{b}}^2 = \mathcal{E}(x)\]
</p>

<p>
pour tout \(z \in \setC^n\). Le choix \(x = A^\pinverse \cdot b\) minimise bien la norme de l'erreur sur \(\setC^n\) :
</p>

<p>
\[x = A^\pinverse \cdot b \in \arg\min_{z \in \setC^n} \mathcal{E}(z)\]
</p>

<p>
Les \(x_{r + 1},...,x_n\) étant des complexes arbitraires, nous allons montrer que l'ensemble optimal s'écrit :
</p>

<p>
\[\arg\min_{z \in \setC^n} \mathcal{E}(z) = \Gamma = \left\{ \left(A^\pinverse \cdot b + \sum_{i = r + 1}^n x_i \cdot v_i \right) : \ x_{r + 1},...,x_n \in \setC \right\}\]
</p>

<p>
En effet, on a \(\mathcal{E}(z) = \mathcal{E}(x)\) pour tout \(z \in \Gamma\). On voit aussi que tout choix de \(z \notin \Gamma\) provoque :
</p>

<p>
\[\sum_{i = 1}^r \abs{\scalaire{u_i}{b} - \sigma_i \cdot \scalaire{v_i}{z}}^2 \strictsuperieur 0\]
</p>

<p>
et donc \(\mathcal{E}(z) \strictsuperieur \mathcal{E}(x)\).
</p>
</div>
</div>


<div id="outline-container-org84058d1" class="outline-4">
<h4 id="org84058d1"><span class="section-number-4">7.8.2</span> Projection</h4>
<div class="outline-text-4" id="text-7-8-2">
<p>
On peut réécrire \(\Gamma\) sous la forme :
</p>

<p>
\[\Gamma = \{ A^\pinverse \cdot b \} + \combilin{v_{r + 1},...,v_n}\]
</p>

<p>
Soit la matrice de projection :
</p>

<p>
\[P = \sum_{i = r + 1}^n v_i \otimes v_i\]
</p>

<p>
On sait que \(P \cdot z \in \combilin{v_{r + 1},...,v_n}\) pour tout \(z \in \setC^n\) et que \(P \cdot y = y\) pour tout \(y \in \combilin{v_{r + 1},...,v_n}\). On en conclut que tout \(x \in \Gamma\) peut s'écrire sous la forme :
</p>

<p>
\[x = A^\pinverse \cdot b + P \cdot z\]
</p>

<p>
pour un certain \(z \in \corps^n\). La matrice de projection \(P\) est également la complémentaire de la projection sur \(\combilin{v_1,...,v_r}\). Or, on a a vu que \(A^\pinverse \cdot A\) est précisément cette matrice de projection. On retrouve donc fort logiquement :
</p>

<p>
\[I - A^\pinverse \cdot A = \sum_{i = 1}^n v_i \otimes v_i - \sum_{i = 1}^r v_i \otimes v_i = \sum_{i = r + 1}^n v_i \otimes v_i = P\]
</p>

<p>
On a donc en définitive des vecteurs optimaux de la forme :
</p>

<p>
\[x = A^\pinverse \cdot b + (I - A^\pinverse \cdot A) \cdot z\]
</p>
</div>
</div>


<div id="outline-container-org3b409e1" class="outline-4">
<h4 id="org3b409e1"><span class="section-number-4">7.8.3</span> Solutions</h4>
<div class="outline-text-4" id="text-7-8-3">
<p>
Soit l'espace des solutions :
</p>

<p>
\[S = \{ x \in \setC^n : A \cdot x = b \} = \{ x \in \setC^n : \mathcal{E}(x) = 0 \}\]
</p>

<p>
Si \(\scalaire{u_{r + 1}}{b} = ... = \scalaire{u_m}{b} = 0\), le minimum de l'erreur est nul et \(\mathcal{E}(x) = 0\) pour tout \(x \in \Gamma\). On en conclut que \(x \in S\), d'où \(\Gamma \subseteq S\). D'un autre coté, tout \(z \in S\) minimise \(\mathcal{E}(z) = 0\). On a donc également \(S \subseteq \Gamma\) et finalement \(\Gamma = S\).
</p>

<p>
Inversément, si \(S \ne \emptyset\), on conclut que \(\scalaire{u_{r + 1}}{b} = ... = \scalaire{u_m}{b} = 0\).
</p>
</div>
</div>


<div id="outline-container-org4d34d8c" class="outline-4">
<h4 id="org4d34d8c"><span class="section-number-4">7.8.4</span> Norme contrainte</h4>
<div class="outline-text-4" id="text-7-8-4">
<p>
Supposons que \(S \ne \emptyset\). Soit \(x \in \Gamma = S\), que l'on écrit sous la forme :
</p>

\begin{align}
x &= A^\pinverse \cdot b + \sum_{i = r + 1}^n x_i \cdot v_i \\
&= \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \cdot \scalaire{u_i}{b} + \sum_{i = r + 1}^n x_i \cdot v_i \\
\end{align}

<p>
Par orthonormalité des \(v_i\), on a :
</p>

<p>
\[\norme{x}^2 = x^\dual \cdot x = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot \abs{\scalaire{u_i}{b}}^2 + \sum_{i = r + 1}^n \abs{x_i}^2\]
</p>

<p>
On voit que :
</p>

<p>
\[\norme{x}^2 \ge \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot \abs{\scalaire{u_i}{b}}^2 = \norme{A^\pinverse \cdot b}^2\]
</p>

<p>
On en conclut que le choix \(x = A^\pinverse \cdot b\) minimise la norme de \(x\) sur \(S\) :
</p>

<p>
\[A^\pinverse \cdot b \in \arg\min_{z \in S} \norme{z}^2\]
</p>
</div>
</div>


<div id="outline-container-orge580181" class="outline-4">
<h4 id="orge580181"><span class="section-number-4">7.8.5</span> Lien avec les résultats précédents</h4>
<div class="outline-text-4" id="text-7-8-5">
<ul class="org-ul">
<li>On a montré précédemment en dérivant les expressions matricielles que le choix :</li>
</ul>

<p>
\[x = (A^\dual \cdot A)^{-1} \cdot A^\dual \cdot b\]
</p>

<p>
minimise également l'erreur \(\mathcal{E}\) sur \(\setR^n\) lorsque l'inverse de \(A^\dual \cdot A\) existe. Si tel est le cas, on a :
</p>

<p>
\[(A^\dual \cdot A)^{-1} = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot v_i \otimes v_i\]
</p>

<p>
et :
</p>

\begin{align}
(A^\dual \cdot A)^{-1} \cdot A^\dual &= \sum_{i,j = 1}^r \frac{\sigma_j}{\sigma_i^2} \cdot \scalaire{v_i}{v_j} \cdot v_i \otimes u_j \\
&= \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i = A^\pinverse
\end{align}

<ul class="org-ul">
<li>On a vu aussi en utilisant les multiplicateurs de lagrange que le choix :</li>
</ul>

<p>
\[x = A^\dual \cdot (A \cdot A^\dual)^{-1} \cdot b\]
</p>

<p>
minimise également la norme de \(x\) sur \(S\) lorsque l'inverse de \(A \cdot A^\dual\) existe. Si tel est le cas, on a :
</p>

<p>
\[(A \cdot A^\dual)^{-1} = \sum_{i = 1}^r \unsur{\sigma_i^2} \cdot u_i \otimes u_i\]
</p>

<p>
et :
</p>

\begin{align}
A^\dual \cdot (A \cdot A^\dual)^{-1} &= \sum_{i,j = 1}^r \frac{\sigma_i}{\sigma_j^2} \cdot \scalaire{u_i}{u_j} \cdot v_i \otimes u_j \\
&= \sum_{i = 1}^r \unsur{\sigma_i} \cdot v_i \otimes u_i = A^\pinverse
\end{align}
</div>
</div>
</div>


<div id="outline-container-orgeb38925" class="outline-3">
<h3 id="orgeb38925"><span class="section-number-3">7.9</span> Image et noyau</h3>
<div class="outline-text-3" id="text-7-9">
<p>
Tout vecteur \(b = A \cdot x = \sum_{i = 1}^r \sigma_i \cdot \scalaire{v_i}{x} \cdot u_i\) est exprimé comme une combinaison linéaire des \((u_1,...,u_r)\). On en conclut que \(\image A \subseteq \combilin{u_1,...,u_r}\). Réciproquement, si \(b \in \combilin{u_1,...,u_r}\), on a \(\scalaire{u_{r + 1}}{b} = \scalaire{u_m}{b} = 0\) et l'espace des solutions \(\{ x \in \setC^n : A \cdot x = b\}\) n'est pas vide. On en conclut que \(\combilin{u_1,...,u_r} \subseteq \image A\). D'où finalement :
</p>

<p>
\[\image A = \combilin{u_1,...,u_r}\]
</p>

<p>
Tout vecteur \(z \in \combilin{v_{r + 1},...,v_n}\) vérifie \(\scalaire{v_1}{z} = ... = \scalaire{v_r}{z} = 0\). On en déduit que \(A \cdot z = \sum_{i = 1}^r \sigma_i \cdot 0 \cdot u_i = 0\) et que \(\combilin{v_{r + 1},...,v_n} \subseteq \noyau A\). Réciproquement, si \(z \in \noyau A\), on a \(\sum_{i = 1}^r \sigma_i \cdot \scalaire{v_i}{z} \cdot u_i = 0\) ce qui implique \(\scalaire{v_1}{z} = ... = \scalaire{v_r}{z} = 0\). On en conclut que \(\noyau A \subseteq \combilin{v_{r + 1},...,v_n}\). D'où finalement :
</p>

<p>
\[\noyau A = \combilin{v_{r + 1},...,v_n}\]
</p>
</div>
</div>


<div id="outline-container-orgeb27a58" class="outline-3">
<h3 id="orgeb27a58"><span class="section-number-3">7.10</span> Normes</h3>
<div class="outline-text-3" id="text-7-10">
<p>
La décomposition en valeurs singulières permet d'évaluer facilement
la norme usuelle des applications linéaires :
</p>

<p>
\[\norme{A}_\lineaire = \sup_{x \ne 0} \frac{\norme{A \cdot x}}{\norme{x}} = \max \{\sigma_1,...,\sigma_r\}\]
</p>

<p>
ainsi que la norme de Frobénius :
</p>

<p>
\[\norme{A}_F = \sqrt{A^\dual : A} = \sqrt{\sum_{i = 1}^r \sigma_i^2}\]
</p>
</div>
</div>


<div id="outline-container-org9739a11" class="outline-3">
<h3 id="org9739a11"><span class="section-number-3">7.11</span> Fonctions de matrices</h3>
<div class="outline-text-3" id="text-7-11">
<p>
La décomposition en valeurs singulières permet d'étendre la définition
d'une fonction \(f : \setR \mapsto \setR\). Soit la décomposition de \(A\) :
</p>

<p>
\[A = \sum_{i = 1}^r \sigma_i \cdot u_i \cdot v_i^\dual\]
</p>

<p>
On définit alors :
</p>

<p>
\[f(A) = \sum_{i = 1}^r f(\sigma_i) \cdot u_i \cdot v_i^\dual\]
</p>
</div>
</div>
</div>


<div id="outline-container-orgbff7a3b" class="outline-2">
<h2 id="orgbff7a3b"><span class="section-number-2">8</span> Espaces de Hilbert</h2>
<div class="outline-text-2" id="text-8">
<div id="text-table-of-contents">
<ul>
<li><a href="#org95e825f">8.1. Définition</a></li>
<li><a href="#orgdad646a">8.2. Utilisation</a></li>
<li><a href="#org8d63a29">8.3. Complétude du noyau</a></li>
<li><a href="#org50a41a7">8.4. Complétude de l'image</a></li>
<li><a href="#orge633196">8.5. Complétude de l'espace orthogonal</a></li>
<li><a href="#org3ad1961">8.6. Théorème de projection</a></li>
<li><a href="#orgd89912d">8.7. Application projective</a></li>
<li><a href="#orgcc2d532">8.8. Orthogonalité</a></li>
<li><a href="#org92e2867">8.9. Identité locale</a></li>
<li><a href="#org4b9815a">8.10. Invariance</a></li>
<li><a href="#orgb7de77e">8.11. Somme directe</a></li>
<li><a href="#orgf695b78">8.12. Biorthogonal</a></li>
<li><a href="#org5397598">8.13. Théorème de représentation de Riesz</a></li>
<li><a href="#org7a3675a">8.14. Extension aux formes bilinéaires</a></li>
<li><a href="#org9f323e1">8.15. Application adjointe</a></li>
<li><a href="#orgc7fdc1b">8.16. Théorème de Lax-Milgram</a></li>
<li><a href="#org6cb58d2">8.17. Suite orthonormée</a></li>
<li><a href="#org7a5a94f">8.18. Inégalité de Bessel</a></li>
<li><a href="#orgdc69d93">8.19. Base hilbertienne</a></li>
<li><a href="#org7fd0767">8.20. Egalité de Parseval</a></li>
<li><a href="#org3426e88">8.21. Produit scalaire</a></li>
</ul>
</div>

<p>
\label{chap:hilbert}
</p>
</div>


<div id="outline-container-org95e825f" class="outline-3">
<h3 id="org95e825f"><span class="section-number-3">8.1</span> Définition</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Un espace de Hilbert \(H\) est un espace de Banach dont la distance découle d'un produit scalaire \(\scalaire{}{}\) défini sur \(H\) :
</p>

<p>
\[\distance(u,v) = \norme{u - v} = \sqrt{\scalaire{u - v}{u - v}}\]
</p>

<p>
Dans la suite, nous considérons un espace de Hilbert \(H\) sur \(\corps\).
</p>
</div>
</div>


<div id="outline-container-orgdad646a" class="outline-3">
<h3 id="orgdad646a"><span class="section-number-3">8.2</span> Utilisation</h3>
<div class="outline-text-3" id="text-8-2">
<p>
Les espaces de Hilbert permettent de généraliser en dimension infinie nombre de résultats valables en dimension finie. Parmi eux, les espaces fonctionnels sont très utilisés. Ils permettent entre-autres de relier la solution de certaines équations différentielles à des problèmes de minimisation.
</p>
</div>
</div>


<div id="outline-container-org8d63a29" class="outline-3">
<h3 id="org8d63a29"><span class="section-number-3">8.3</span> Complétude du noyau</h3>
<div class="outline-text-3" id="text-8-3">
<p>
Soit \(\varphi \in H^\dual\) et une suite de Cauchy \(\{x_1,x_2,...\} \subseteq \noyau \varphi \subseteq H\). L'espace \(H\) étant complet, cette suite converge vers \(x \in H\). Par continuité de \(\varphi\), on a :
</p>

<p>
\[\forme{\varphi}{x} = \lim_{n \to \infty} \forme{\varphi}{x_n} = 0\]
</p>

<p>
On en conclut que \(x \in \noyau \varphi\). L'espace vectoriel \(\noyau \varphi\) est donc complet.
</p>
</div>
</div>


<div id="outline-container-org50a41a7" class="outline-3">
<h3 id="org50a41a7"><span class="section-number-3">8.4</span> Complétude de l'image</h3>
<div class="outline-text-3" id="text-8-4">
<p>
Soit l'application linéaire continue \(A : H \mapsto H\) et une suite de Cauchy \(\{y_1,y_2,...\} \subseteq \image A \subseteq H\). L'espace \(H\) étant complet, cette suite converge vers \(y \in H\). Comme les \(y_i \in \image A\), on peut trouver des \(x_i \in H\) tels que \(A(x_i) = y_i\). Par continuité de \(A\), on a :
</p>

<p>
\[y = \lim_{n \to \infty} y_n = \lim_{n \to \infty} A(x_n) = A(x) \in \image A\]
</p>

<p>
On en conclut que \(y \in \image A\). L'espace vectoriel \(\image A\) est donc complet.
</p>
</div>
</div>


<div id="outline-container-orge633196" class="outline-3">
<h3 id="orge633196"><span class="section-number-3">8.5</span> Complétude de l'espace orthogonal</h3>
<div class="outline-text-3" id="text-8-5">
<p>
Soit \(V \subseteq H\). Considérons une suite de Cauchy \(\{x_1,x_2,...\} \subseteq V^\orthogonal \subseteq H\). Comme \(H\) est complet, cette suite est convergente vers \(x \in H\). Choisissons \(z \in V\). On a :
</p>

<p>
\[\scalaire{x - x_n}{z} = \scalaire{x}{z} - \scalaire{x_n}{z} = \scalaire{x}{z}\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\abs{\scalaire{x}{z}} = \abs{\scalaire{x - x_n}{z}} \le \norme{x - x_n} \cdot \norme{z}\]
</p>

<p>
Comme cette relation doit être valable pour tout \(n\) et que \(\norme{x - x_n}\) converge vers \(0\), on en déduit que :
</p>

<p>
\[\scalaire{x}{z} = 0\]
</p>

<p>
c'est-à-dire \(x \in V^\orthogonal\). On en conclut que \(V^\orthogonal\) est un espace complet.
</p>
</div>
</div>


<div id="outline-container-org3ad1961" class="outline-3">
<h3 id="org3ad1961"><span class="section-number-3">8.6</span> Théorème de projection</h3>
<div class="outline-text-3" id="text-8-6">
\begin{theoreme}
Soit $V \subseteq H$ un sous-espace vectoriel complet. Pour tout $x \in H$, il existe un unique $u \in V$ vérifiant :

\norme{$$x - u} = \inf_{z \in V} \norme{x - z} = \distance(x,V)$$
\end{theoreme}

\begin{demonstration}

Soit $x \in H$ et :

$$D = \{ \norme{x - z} : z \in V \} \subseteq \setR$$

L'ensemble $D$ est inclu dans $\setR$ et minoré puisque $0 \le D$. On en conclut que l'infimum $\lambda = \inf D$ existe. On a par définition $\distance(x,V) = \lambda$. Comme $D \subseteq \setR$, on a $\lambda \in \adh D$ et la distance au sens des réels est nulle :

$$\distance(\lambda,D) = \inf_{r \in D} \abs{\lambda - r} = 0$$

On peut donc contruire une suite de $z_n \in V$ tels que :

$$\lim_{n \to \infty} \norme{x - z_n} = \lambda$$

Choisissons $\epsilon \strictsuperieur 0$ et $m,n \in \setN$ tels que :

$$\max\{\norme{x - z_m} , \norme{x - z_n} \} \le \lambda + \epsilon$$

et appliquons l'égalité du parallèlogramme à :

#+BEGIN_CENTER
\(
v = x - z_m \\
w = x - z_n
\)
#+END_CENTER

On a alors :

#+BEGIN_CENTER
\(
v + w = 2 x - (z_m + z_n) \\
v - w = z_n - z_m
\)
#+END_CENTER

et donc :

$$\norme{2 x - (z_m + z_n)}^2 + \norme{z_n - z_m}^2 = 2 \left( \norme{x - z_m}^2 + \norme{x - z_m}^2 \right)$$

Comme :

$$\norme{2 x - (z_m + z_n)}^2 = \norme{2 \left(x - \frac{z_m + z_n}{2}\right)}^2 = 4 \norme{x - \frac{z_m + z_n}{2}}^2$$

on peut réécrire ce résultat sous la forme :

$$\norme{z_n - z_m}^2 + 4 \norme{x - \frac{z_m + z_n}{2}}^2 = 2 \left( \norme{x - z_m}^2 + \norme{x - z_m}^2 \right)$$

et donc :

$$\norme{z_n - z_m}^2 = 2 \left( \norme{x - z_m}^2 + \norme{x - z_m}^2 \right) - 4 \norme{x - \frac{z_m + z_n}{2}}^2$$

Comme $V$ est un espace vectoriel, on a $(z_m + z_n)/2 \in V$. Donc, par définition de l'infimum :

$$\norme{x - \frac{z_m + z_n}{2}} \ge \lambda$$

On a aussi :

$$\norme{x - z_m}^2 + \norme{x - z_m}^2 \le 2 (\lambda + \epsilon)^2$$

On en déduit que :

$$\norme{z_n - z_m}^2 \le 4 (\lambda + \epsilon)^2 - 4 \lambda^2 = 8 \lambda \cdot \epsilon + 4 \epsilon^2$$

ce qui montre que les $z_n$ forment une suite de Cauchy. L'espace $V$ étant complet, cette suite converge vers un certain $u \in V$. On a alors :

$$\norme{x - u} = \lim_{n \to \infty} \norme{x - z_n} = \lambda = \distance(x,V)$$

Nous avons donc prouvé l'existence d'un vecteur $u \in V$ minimisant la distance à $x$. Supposons à présent que $u,v \in V$ vérifient :

$$\norme{x - u} = \norme{x - v} = \lambda$$

Appliquons le parallélogramme à $u - x$ et $x - v$. On a :

#+BEGIN_CENTER
\(
(u - x) + (x - v) = u - v \\
(u - x) - (x - v) = u + v - 2 x
\)
#+END_CENTER

et :

\begin{align}
\norme{u - v}^2 + \norme{u + v - 2 x}^2 &= 2 ( \norme{u - x}^2 + \norme{x - v}^2 ) \\
&= 2 (\lambda^2 + \lambda^2) = 4 \lambda^2
\end{align}

On en conclut que :

\begin{align}
\norme{u - v}^2 &= 4 \lambda^2 - \norme{u + v - 2 x}^2 \\
&= 4 \lambda^2 - 4 \norme{\frac{u + v}{2} - x}^2
\end{align}

Mais comme $(u + v)/2 \in V$, on a :

$$\norme{\frac{u + v}{2} - x}^2 \ge \lambda^2$$

et :

$$0 \le \norme{u - v}^2 \le 4 \lambda^2 - 4 \lambda^2 = 0$$

Donc, $\norme{u - v} = 0$ et $u = v$, ce qui prouve l'unicité de la solution optimale.

\end{demonstration}
</div>
</div>


<div id="outline-container-orgd89912d" class="outline-3">
<h3 id="orgd89912d"><span class="section-number-3">8.7</span> Application projective</h3>
<div class="outline-text-3" id="text-8-7">
<p>
On peut donc définir l'application de projection \(P : H \mapsto V\) par :
</p>

<p>
\[\norme{x - P(x)} = \inf_{z \in V} \norme{x - z}\]
</p>

<p>
ou :
</p>

<p>
\[P(x) = \argument_H\inf_{z \in V} \norme{x - z}\]
</p>

<p>
Comme \(P(x) \in V\), cela revient à :
</p>

<p>
\[P(x) = \arg\min_{z \in V} \norme{x - z}\]
</p>
</div>
</div>


<div id="outline-container-orgcc2d532" class="outline-3">
<h3 id="orgcc2d532"><span class="section-number-3">8.8</span> Orthogonalité</h3>
<div class="outline-text-3" id="text-8-8">
<p>
Soit \(x \in H\) et \(u = P(x)\). L'écart \(e = x - u\) possède-t-il les mêmes propriétés d'orthogonalité qu'en dimension finie ? Soit \(\alpha \in \corps\) et \(v \in V\). On a \(u + \alpha \cdot v \in V\) et donc :
</p>

<p>
\[\norme{x - u}^2 = \norme{e}^2 \le \norme{x - u - \alpha \cdot v}^2 = \norme{e - \alpha \cdot v}^2\]
</p>

<p>
En développant ce dernier membre, on obtient :
</p>

<p>
\[\norme{e}^2 \le \norme{e}^2 - 2 \Re(\alpha \cdot \scalaire{e}{v}) + \abs{\alpha}^2 \cdot \norme{v}^2\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\abs{\alpha}^2 \cdot \norme{v}^2 - 2 \Re(\alpha \cdot \scalaire{e}{v}) \ge 0\]
</p>

<p>
Utilisant la définition du produit complexe, il vient :
</p>

<p>
\[\abs{\alpha}^2 \cdot \norme{v}^2 - 2 \Re(\alpha) \cdot \Re(\scalaire{e}{v}) + 2 \Im(\alpha) \cdot \Im(\scalaire{e}{v}) \ge 0\]
</p>

<p>
Choisissons \(\alpha = \gamma \in \setR\), avec \(\gamma \strictsuperieur 0\). On a \(\Re(\alpha) = \gamma\), \(\Im(\alpha) = 0\) et \(\abs{\alpha}^2 = \gamma^2\). Donc :
</p>

<p>
\[\gamma^2 \cdot \norme{v}^2 - 2 \gamma \cdot \Re(\scalaire{e}{v}) \ge 0\]
</p>

<p>
Si nous divisons par \(\gamma\) et que nous faisons passer le second terme dans le second membre, il vient :
</p>

<p>
\[2 \Re(\scalaire{e}{v}) \le \gamma \cdot \norme{v}^2\]
</p>

<p>
Comme ce doit être valable pour tout \(\gamma\) strictement positif, on en conclut que \(\Re(\scalaire{e}{v}) \le 0\). Recommençons le même procédée avec \(\alpha = - \gamma \strictinferieur 0\). On a :
</p>

<p>
\[\gamma^2 \cdot \norme{v}^2 + 2 \gamma \cdot \Re(\scalaire{e}{v}) \ge 0\]
</p>

<p>
et :
</p>

<p>
\[2 \Re(\scalaire{e}{v}) \ge - \gamma \cdot \norme{v}^2\]
</p>

<p>
Comme ce doit être valable pour tout \(\delta = - \gamma\) strictement négatif, on en conclut que \(\Re(\scalaire{e}{v}) \ge 0\). D'où finalement \(\Re(\scalaire{e}{v}) = 0\).
</p>

<p>
Choisissons à présent \(\alpha = \img \gamma\), où le réel \(\gamma \strictsuperieur 0\) et où \(\img = \sqrt{-1}\). On a \(\Re(\alpha) = 0\), \(\Im(\alpha) = \gamma\) et \(\abs{\alpha}^2 = \gamma^2\). Donc :
</p>

<p>
\[\gamma^2 \cdot \norme{v}^2 + 2 \gamma \cdot \Im(\scalaire{e}{v}) \ge 0\]
</p>

<p>
On en déduit que :
</p>

<p>
\[2 \Im(\scalaire{e}{v}) \ge - \gamma \cdot \norme{v}^2\]
</p>

<p>
Comme ce doit être valable pour tout \(\delta = - \gamma\) strictement négatif, on en conclut que \(\Im(\scalaire{e}{v}) \ge 0\). Recommençons le même procédée avec \(\alpha = - \img \gamma\), avec \(\gamma \strictsuperieur 0\). On a :
</p>

<p>
\[\gamma^2 \cdot \norme{v}^2 - 2 \gamma \cdot \Im(\scalaire{e}{v}) \ge 0\]
</p>

<p>
et :
</p>

<p>
\[2 \Im(\scalaire{e}{v}) \le \gamma \cdot \norme{v}^2\]
</p>

<p>
Comme ce doit être valable pour tout \(\gamma\) strictement positif, on en conclut que \(\Im(\scalaire{e}{v}) \le 0\). D'où finalement \(\Im(\scalaire{e}{v}) = 0\). Ce produit scalaire ayant des parties réelles et imaginaires nulles, il est nul :
</p>

<p>
\[\scalaire{e}{v} = 0\]
</p>

<p>
Cette relation d'orthogonalité étant valable pour tout \(v \in V\), on en conclut que \(e \in V^\orthogonal\).
</p>
</div>
</div>


<div id="outline-container-org92e2867" class="outline-3">
<h3 id="org92e2867"><span class="section-number-3">8.9</span> Identité locale</h3>
<div class="outline-text-3" id="text-8-9">
<p>
Soit \(v \in V\). Il est clair que le choix \(u = v\) minimise la distance \(\norme{v - u} \ge 0\) sur \(u \in V\) puisque \(\norme{v - v} = 0\). Par unicité de la solution optimale, on en déduit que \(P(v) = v\) pour tout \(v \in V\).
</p>
</div>
</div>


<div id="outline-container-org4b9815a" class="outline-3">
<h3 id="org4b9815a"><span class="section-number-3">8.10</span> Invariance</h3>
<div class="outline-text-3" id="text-8-10">
<p>
Comme \(v = P(x) \in V\) pour tout \(x \in H\), on a :
</p>

<p>
\[P^2(x) = P \circ P(x) = P(v) = v = P(x)\]
</p>

<p>
d'où \(P^2 = P\).
</p>
</div>
</div>


<div id="outline-container-orgb7de77e" class="outline-3">
<h3 id="orgb7de77e"><span class="section-number-3">8.11</span> Somme directe</h3>
<div class="outline-text-3" id="text-8-11">
<p>
On peut donc exprimer tout \(x \in H\) comme une somme :
</p>

<p>
\[x = u + e\]
</p>

<p>
où \(u = P(x) \in V\) et \(e = x - P(x) \in V^\orthogonal\). Nous allons voir que cette décomposition est unique. Soit \(x \in H\) et les vecteurs \(u,v \in V\) et \(y,z \in V^\orthogonal\) tels que :
</p>

<p>
\[x = u + y = v + z\]
</p>

<p>
On a :
</p>

<p>
\[0 = \norme{x - x}^2 = \norme{u + y - v - z}^2 = \norme{(u - v) + (y - z)}^2\]
</p>

<p>
Comme \(u - v \in V\) et \(y - z \in V^\orthogonal\), on a \(\scalaire{u - v}{y - z} = 0\). On peut donc appliquer le théorème de Pythagore. On obtient :
</p>

<p>
\[0 = \norme{(u - v) + (y - z)}^2 = \norme{u - v}^2 + \norme{y - z}^2\]
</p>

<p>
ce qui n'est possible que si \(\norme{u - v} = \norme{y - z} = 0\), c'est-à-dire \(u = v\) et \(y = z\), ce qui prouve l'unicité de la décomposition. L'espace \(H\) est donc la somme directe de \(V\) et de \(V^\orthogonal\) :
</p>

<p>
\[H = V \bigoplus V^\orthogonal\]
</p>
</div>
</div>


<div id="outline-container-orgf695b78" class="outline-3">
<h3 id="orgf695b78"><span class="section-number-3">8.12</span> Biorthogonal</h3>
<div class="outline-text-3" id="text-8-12">
<ul class="org-ul">
<li>Soit \(x \in V\). Pour tout \(z \in V^\orthogonal\), on a :</li>
</ul>

<p>
\[\scalaire{x}{z} = 0\]
</p>

<p>
Donc \(x \in (V^\orthogonal)^\orthogonal\) et \(V \subseteq (V^\orthogonal)^\orthogonal\).
</p>

<ul class="org-ul">
<li>Soit \(x \in (V^\orthogonal)^\orthogonal \subseteq H\). On pose \(u = P(x) \in V\) et \(v = x - P(x) \in V^\orthogonal\). On a donc \(x = u + v\). Par définition de \((V^\orthogonal)^\orthogonal\), on a :</li>
</ul>

<p>
\[\scalaire{x}{z} = 0\]
</p>

<p>
pour tout \(z \in V^\orthogonal\). Comme \(u \in V\), on a aussi \(\scalaire{u}{z} = 0\) et finalement :
</p>

<p>
\[0 = \scalaire{x}{z} = \scalaire{u}{z} + \scalaire{v}{z} = \scalaire{v}{z}\]
</p>

<p>
Si on choisit \(z = v\), cela donne \(\scalaire{v}{v} = 0\), d'où \(v = 0\) et \(x = u \in V\). On en conclut que \((V^\orthogonal)^\orthogonal \subseteq V\).
</p>


<p>
On conclut de ces deux inclusions que :
</p>

<p>
\[(V^\orthogonal)^\orthogonal = V\]
</p>
</div>
</div>


<div id="outline-container-org5397598" class="outline-3">
<h3 id="org5397598"><span class="section-number-3">8.13</span> Théorème de représentation de Riesz</h3>
<div class="outline-text-3" id="text-8-13">
<p>
Nous allons à présent établir une équivalence entre les formes linéaires de \(H^\dual\) et le produit scalaire sur \(H\).
</p>

\begin{theoreme}
Pour toute forme linéaire $\varphi \in H^\dual$, il existe un et un seul $u \in H$ tel que :

$$\forme{\varphi}{x} = \scalaire{u}{x}$$

pour tout $x \in H$. On dit que $u$ représente $\varphi$ sur $H$.
\end{theoreme}

\begin{demonstration}

Soit le noyau :

$$N = \noyau \varphi = \{ x \in H : \forme{\varphi}{x} = 0 \}$$

  - Si $N = H$, il suffit de choisir $u = 0$. On a alors :

$$\forme{\varphi}{x} = 0 = \scalaire{0}{x} = \scalaire{u}{x}$$

pour tout $x \in H$. Pour prouver l'unicité, si on a aussi $v \in H$ représente également $\varphi$, le choix $x = v$ nous donne :

$$\forme{\varphi}{v} = 0 = \scalaire{v}{v}$$

ce qui implique que $v = 0$.

  - Dans le cas contraire, on a $H \setminus N \ne \emptyset$. Comme $N$ est complet, on peut lui appliquer les résultats relatifs aux projections, dont la somme directe $H = N \bigoplus N^\orthogonal$. Choisissons $a \in H \setminus N$. On a $\forme{\varphi}{a} \ne 0$ et une unique décomposition $a = b + c$, où $b \in N$ et $c \in N^\orthogonal$. On a donc par définition $\forme{\varphi}{b} = 0$ et :

$$0 \ne \forme{\varphi}{a} = \forme{\varphi}{b} + \forme{\varphi}{c} = \forme{\varphi}{c}$$

En partant de vecteurs de la forme $\gamma \cdot c$, où $\gamma \in \corps$, on peut obtenir la valeur de $\varphi$ en n'importe quel $x \in H$ :

$$\forme{\varphi}{\gamma \cdot c} = \gamma \cdot \forme{\varphi}{c} = \forme{\varphi}{x}$$

Il suffit donc de choisir :

$$\gamma = \frac{ \forme{\varphi}{x} }{ \forme{\varphi}{c} }$$

Considérons un $x \in H$ quelconque et sa décomposition unique $x = y + z$, où $y \in N$ et $z \in N^\orthogonal$. Si :

$$w = \frac{ \forme{\varphi}{x} }{ \forme{\varphi}{c} } \cdot c$$

on a $\forme{\varphi}{w} = \forme{\varphi}{x}$. Posons $v = x - w$. On a alors :

$$\forme{\varphi}{v} = \forme{\varphi}{x} - \forme{\varphi}{w} = 0$$

On en déduit que $v \in N$. Comme on a aussi $w \in N^\orthogonal$ et $x = v + w$, on conclut par unicité de la décomposition que $v = y$ et $w = z$. Pour tout $u \in H$, on a :

$$\scalaire{u}{x} = \scalaire{u}{v} + \scalaire{u}{w}$$

Par analogie avec $\forme{\varphi}{v} = 0$, on voudrait bien que $\scalaire{u}{v} = 0$. Pour cela, il suffit de choisir $u \in N^\orthogonal$, par exemple $u = \lambda \cdot c$ pour un certain $\lambda \in \corps$. Si on veut que $u$ représente $\varphi$, il faut en particulier que $\scalaire{u}{c} = \forme{\varphi}{c}$, c'est-à-dire :

$$\scalaire{\lambda \cdot c}{c} = \conjaccent{\lambda} \cdot \scalaire{c}{c} = \forme{\varphi}{c}$$

d'où :

$$\lambda = \frac{ \conjaccent{\forme{\varphi}{c}} }{ \scalaire{c}{c} }$$

et :

$$u = \frac{ \conjaccent{\forme{\varphi}{c}} }{ \scalaire{c}{c} } \cdot c$$

Soit $x \in H$. On a la décomposition :

$$x = \frac{ \forme{\varphi}{x} }{ \forme{\varphi}{c} } \cdot c + v$$

où $v \in N$. Donc :

\begin{align}
\scalaire{u}{x} &= \frac{ \forme{\varphi}{x} }{ \forme{\varphi}{c} } \cdot \frac{ \forme{\varphi}{c} }{ \scalaire{c}{c} } \cdot \scalaire{c}{c} + \scalaire{u}{v} \\
&= \forme{\varphi}{x}
\end{align}

Nous avons prouvé l'existence d'un $u \in H$ représentant $\varphi$. Pour l'unicité, si $u$ et $p$ représentent $\varphi$, on a :

$$\scalaire{u - p}{x} = \scalaire{u}{x} - \scalaire{p}{x} = \forme{\varphi}{x} - \forme{\varphi}{x} = 0$$

pour tout $x \in H$, et en particulier pour $x = u - p$, d'où :

$$\norme{u - p}^2 = \scalaire{u - p}{u - p} = 0$$

ce qui implique $u - p = 0$ et donc $u = p$.

\end{demonstration}
</div>
</div>


<div id="outline-container-org7a3675a" class="outline-3">
<h3 id="org7a3675a"><span class="section-number-3">8.14</span> Extension aux formes bilinéaires</h3>
<div class="outline-text-3" id="text-8-14">
\begin{theoreme}
Si $\vartheta : H \times H \mapsto \corps$ est une forme bilinéaire de norme finie sur $H$, il existe une unique application linéaire et continue $A : H \mapsto H$ telle que :

$$\biforme{u}{\vartheta}{v} = \scalaire{A(u)}{v}$$

pour tout $u,v \in H$.
\end{theoreme}

\begin{demonstration}
Pour tout $u \in H$, on définit la forme linéaire $\varphi_u : H \mapsto \corps$ par :

$$\forme{\varphi_u}{x} = \biforme{u}{\vartheta}{x}$$

pour tout $x \in H$. Pour $u \in H$ fixé, $\varphi_u$ est continue car :

$$\norme{\forme{\varphi_u}{x}} = \norme{\biforme{u}{\vartheta}{x}} \le \norme{\vartheta}_\lineaire \cdot \norme{u} \cdot \norme{x}$$

d'où $\norme{\varphi_u} \le {\vartheta}_\lineaire \cdot \norme{u} \strictinferieur +\infty$. On peut donc trouver un unique représentant $A(u) \in H$ tel que :

$$\scalaire{A(u)}{x} = \forme{\varphi_u}{x} = \biforme{u}{\vartheta}{x}$$

pour tout $x \in H$, ce qui définit l'application $A : u \in H \mapsto A(u) \in H$. Cette application est linéaire car :

\begin{align}
\scalaire{A(\alpha \cdot u + \beta \cdot v)}{x} &= \biforme{\alpha \cdot u + \beta \cdot v}{\vartheta}{x} \\
&= \alpha \cdot \biforme{u}{\vartheta}{x} + \beta \cdot \biforme{v}{\vartheta}{x} \\
&= \alpha \cdot \scalaire{A(u)}{x} + \beta \cdot \scalaire{A(v)}{x}
\end{align}

pour tout $u,v,x \in H$ et $\alpha,\beta \in \corps$. Elle est également continue car :

$$\norme{A(u)}^2 = \scalaire{A(u)}{A(u)} = \biforme{u}{\vartheta}{A(u)} \le \norme{\vartheta}_\lineaire \cdot \norme{u} \cdot \norme{A(u)}$$

On a donc soit $A = 0$ et a fortiori $A$ continue, soit :

\norme{$$A(u)} \le \norme{\vartheta}_\lineaire \cdot \norme{u} \strictinferieur +\infty$$
\end{demonstration}
</div>
</div>


<div id="outline-container-org9f323e1" class="outline-3">
<h3 id="org9f323e1"><span class="section-number-3">8.15</span> Application adjointe</h3>
<div class="outline-text-3" id="text-8-15">
\begin{theoreme}
Soit une application $A : H \mapsto H$ linéaire et continue. Il existe une unique application $A^\dual : H \mapsto H$ telle que :

$$\scalaire{A^\dual(v)}{u} = \scalaire{v}{A(u)}$$

pour tout $(u,v) \in H^2$.
\end{theoreme}

\begin{demonstration}
Choisissons $v \in H$. L'application $\varphi_v : u \mapsto \scalaire{v}{A(u)}$ est une forme linéaire. Elle est continue car :

$$\abs{\forme{\varphi_v}{u}} = \abs{\scalaire{v}{A(u)}} \le \norme{v} \cdot \norme{A(u)} \le \norme{v} \cdot \norme{A} \cdot \norme{u}$$

On a donc :

$$\abs{\varphi_v} \le \norme{A} \cdot \norme{v}$$

Le théorème de Riesz nous dit qu'il existe un unique $A^\dual(v) \in H$ tel que :

$$\scalaire{A^\dual(v)}{u} = \forme{\varphi_v}{u} = \scalaire{v}{A(u)}$$

pour tout $u \in H$. Comme ce résultat est également valable quel que soit $v \in H$, nous avons défini l'application $A^\dual : H \mapsto H$ demandée.
\end{demonstration}
</div>
</div>


<div id="outline-container-orgc7fdc1b" class="outline-3">
<h3 id="orgc7fdc1b"><span class="section-number-3">8.16</span> Théorème de Lax-Milgram</h3>
<div class="outline-text-3" id="text-8-16">
\begin{theoreme}
Soit une forme bilinéaire $\vartheta : H \times H \mapsto \corps$ de norme finie. Nous supposons qu'il existe un réel $\varrho \strictsuperieur 0$ tel que :

$$\biforme{u}{\vartheta}{u} \ge \varrho \cdot \norme{u}^2$$

pour tout $u \in H$. On dit que $\vartheta$ est coercive. Soit une forme linéaire et continue $\varphi : H \mapsto \corps$. Nous allons montrer qu'il existe un unique $s \in H$ tel que :

$$\biforme{s}{\vartheta}{v} = \forme{\varphi}{v}$$

pour tout $v \in H$.

\end{theoreme}

\begin{demonstration}

En appliquant le théorème de Riesz, on peut trouver un unique $f \in H$ qui représente $\varphi$ sur $H$ :

$$\forme{\varphi}{v} = \scalaire{f}{v}$$

pour tout $v \in H$. On dispose aussi d'une application linéaire continue $A$ telle que :

$$\biforme{u}{\vartheta}{v} = \scalaire{A(u)}{v}$$

pour tout $u,v \in H$. Pour tout $s$ vérifiant la condition du théorème, on doit donc avoir :

$$\scalaire{f}{v} = \forme{\varphi}{v} = \biforme{s}{\vartheta}{v} = \scalaire{A(s)}{v}$$

et donc $\scalaire{f}{v} = \scalaire{A(s)}{v}$ pour tout $v \in H$. Par linéarité, on
en déduit que :

$$\scalaire{f - A(s)}{v} = 0$$

Le cas particulier $v = f - A(s)$ nous donne :

$$\scalaire{f - A(s)}{f - A(s)} = \norme{f - A(s)}^2 = 0$$

On en déduit que $f - A(s) = 0$, autrement dit $A(s) = f$.

On sait que l'image $V = \image A \subseteq H$ est un espace complet. On a dès lors la somme directe $H = V \bigoplus V^\orthogonal$. Soit $u \in V^\orthogonal$. On a $\scalaire{A(x)}{u} = 0$ pour tout $x \in H$. Le choix $x = u$ combiné avec la coercivité de $\vartheta$ nous donne :

$$0 \le \varrho \cdot \norme{u}^2 \le \biforme{u}{\vartheta}{u} = \scalaire{A(u)}{u} = 0$$

Divisant alors par $\varrho$ strictement positif, on obtient $\norme{u}^2 = 0$, ce qui n'est possible que si $u = 0$. On en déduit que $V^\orthogonal = \{0\}$. Pour tout $x \in H$, on a donc la décomposition $x = y + 0 = y$ avec $y \in V$. On en déduit que $H = V = \image A$. Donc $f \in \image A$, ce qui prouve l'existence d'au moins un $s \in H$ tel que $A(s) = f$.

D'un autre coté, si $s,t \in H$ vérifient $A(s) = A(t) = f$, on a $A(s - t) = A(s) - A(t) = f - f = 0$. Donc :

$$0 \le \varrho \cdot \norme{s - t}^2 \le \biforme{s - t}{\vartheta}{s - t} = \scalaire{A(s - t)}{s - t} = \scalaire{0}{s - t} = 0$$

ce qui implique que $\norme{s - t}^2 = 0$, d'où $s = t$. La solution $s$ est donc unique.

\end{demonstration}
</div>


<div id="outline-container-org56dba3f" class="outline-4">
<h4 id="org56dba3f"><span class="section-number-4">8.16.1</span> Inverse</h4>
<div class="outline-text-4" id="text-8-16-1">
<p>
Nous avons également prouvé que pour tout \(v \in H\), il existe un unique \(u \in H\) vérifiant \(A(u) = v\). L'application \(A\) est donc inversible et \(A^{-1}(v) = u\).
</p>
</div>
</div>
</div>


<div id="outline-container-org6cb58d2" class="outline-3">
<h3 id="org6cb58d2"><span class="section-number-3">8.17</span> Suite orthonormée</h3>
<div class="outline-text-3" id="text-8-17">
<p>
Si une suite \(\{ u_i \in H : i \in \setN\}\) vérifie :
</p>

<p>
\[\scalaire{u_i}{u_j} = \delta_{ij}\]
</p>

<p>
pour tout \(i,j \in \setN\), on dit qu'elle est orthonormée. Dans la suite, nous considérons une suite \(\{ u_i \in H : i \in \setN\}\) orthonormée.
</p>
</div>
</div>


<div id="outline-container-org7a5a94f" class="outline-3">
<h3 id="org7a5a94f"><span class="section-number-3">8.18</span> Inégalité de Bessel</h3>
<div class="outline-text-3" id="text-8-18">
<p>
Soit \(x \in H\) et une suite orthonormée \(\{ u_i \in H : i \in \setN\}\). Par analogie avec les projections sur des espaces de dimension finie, on pose (sous réserve de convergence) :
</p>

<p>
\[p = \sum_{i = 1}^{+\infty} \scalaire{u_i}{x} \cdot u_i\]
</p>

<p>
Soit \(e = x - p\). On a :
</p>

\begin{align}
\scalaire{u_k}{e} &= \scalaire{u_k}{x} - \sum_i \scalaire{u_i}{x} \scalaire{u_k}{u_i} \\
&= \scalaire{u_k}{x} - \sum_i \scalaire{u_i}{x} \delta_{ik} \\
&= \scalaire{u_k}{x} - \scalaire{u_k}{x} \\
&= 0
\end{align}

<p>
On en conclut que :
</p>

<p>
\[\scalaire{p}{e} = \sum_i \scalaire{x}{u_i} \cdot \scalaire{u_i}{e} = 0\]
</p>

<p>
On a donc :
</p>

<p>
\[\norme{x}^2 = \norme{p + e}^2 = \norme{p}^2 + \norme{e}^2\]
</p>

<p>
d'où :
</p>

<p>
\[\norme{x}^2 - \norme{p}^2 = \norme{e}^2 \ge 0\]
</p>

<p>
Par orthonormalité, la norme de \(p\) vérifie :
</p>

<p>
\[\norme{p}^2 = \sum_i \abs{\scalaire{u_i}{x}}^2\]
</p>

<p>
d'où :
</p>

<p>
\[\norme{x}^2 - \sum_i \abs{\scalaire{u_i}{x}}^2 \ge 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\sum_i \abs{\scalaire{u_i}{x}}^2 \le \norme{x}^2\]
</p>
</div>
</div>


<div id="outline-container-orgdc69d93" class="outline-3">
<h3 id="orgdc69d93"><span class="section-number-3">8.19</span> Base hilbertienne</h3>
<div class="outline-text-3" id="text-8-19">
<p>
Si, pour tout \(x \in H\), la suite des projections finies :
</p>

<p>
\[p_n = \sum_{i = 1}^n \scalaire{u_i}{x} \cdot u_i\]
</p>

<p>
converge vers \(x\) :
</p>

<p>
\[x = \lim_{n \to \infty} \sum_{i = 1}^n \scalaire{u_i}{x} \cdot u_i\]
</p>

<p>
au sens de la distance dérivant du produit scalaire, on dit que les \(u_i\) forment une base de Hilbert (ou une base hilbertienne) de \(H\). On a alors :
</p>

<p>
\[x = \sum_{i = 1}^{+\infty} \scalaire{u_i}{x} \cdot u_i\]
</p>

<p>
Les scalaires :
</p>

<p>
\[x_i = \scalaire{u_i}{x}\]
</p>

<p>
sont appelés les coordonnées de \(x\) par rapport aux \(u_i\). Dans la suite, nous considérons une suite \(\{ u_i \in H : i \in \setN \}\) formant une base hilbertienne de \(H\).
</p>
</div>
</div>


<div id="outline-container-org7fd0767" class="outline-3">
<h3 id="org7fd0767"><span class="section-number-3">8.20</span> Egalité de Parseval</h3>
<div class="outline-text-3" id="text-8-20">
<p>
Soit \(x \in H\) et  \(\epsilon \strictsuperieur 0\). On peut trouver un \(n \in \setN\) tel que :
</p>

<p>
\[D = \norme{x - \sum_{i = 1}^n \scalaire{u_i}{x} \cdot u_i} \le \epsilon\]
</p>

<p>
Mais les propriétés des projections nous disent que :
</p>

<p>
\[0 \le D^2 = \norme{x}^2 - \sum_{i = 1}^n \abs{\scalaire{u_i}{x}}^2\]
</p>

<p>
et donc :
</p>

<p>
\[0 \le \norme{x}^2 - \sum_{i = 1}^n \abs{\scalaire{u_i}{x}}^2 \le \epsilon^2\]
</p>

<p>
En faisant tendre \(n \to \infty\), on a \(\epsilon \to 0\) et donc :
</p>

<p>
\[0 \le \norme{x}^2 - \sum_{i = 1}^{+\infty} \abs{\scalaire{u_i}{x}}^2 \le 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\norme{x}^2 = \sum_{i = 1}^{+\infty} \abs{\scalaire{u_i}{x}}^2\]
</p>
</div>
</div>


<div id="outline-container-org3426e88" class="outline-3">
<h3 id="org3426e88"><span class="section-number-3">8.21</span> Produit scalaire</h3>
<div class="outline-text-3" id="text-8-21">
<p>
Soit \(x,y \in E\). On a :
</p>

<div class="org-center">
<p>
\(
x = \sum_{i = 1}^{+\infty} x_i \cdot u_i \\
y = \sum_{i = 1}^{+\infty} y_i \cdot u_i
\)
</p>
</div>

<p>
où \(x_i = \scalaire{u_i}{x}\) et \(y_i = \scalaire{u_i}{y}\). Par orthonormalité, leur produit scalaire s'écrit :
</p>

<p>
\[\scalaire{x}{y} = \lim_{n \to \infty} \sum_{i = 1}^n \conjaccent{x}_i \cdot y_i\]
</p>

<p>
On a donc :
</p>

<p>
\[\scalaire{x}{y} = \sum_{i = 1}^{+\infty} \conjaccent{x}_i \cdot y_i\]
</p>
</div>
</div>
</div>


<div id="outline-container-org6212f90" class="outline-2">
<h2 id="org6212f90"><span class="section-number-2">9</span> Théorie spectrale</h2>
<div class="outline-text-2" id="text-9">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgfa119fa">9.1. Progression géométrique</a></li>
<li><a href="#orgaaa7a84">9.2. Convergence</a></li>
<li><a href="#org55fcacf">9.3. Exponentielle</a></li>
</ul>
</div>

<p>
\label{spectral}
</p>
</div>


<div id="outline-container-orgfa119fa" class="outline-3">
<h3 id="orgfa119fa"><span class="section-number-3">9.1</span> Progression géométrique</h3>
<div class="outline-text-3" id="text-9-1">
<p>
Soit un espace de Hilbert \(H\) et une application linéaire \(A : H \mapsto H\). On voit que :
</p>

\begin{align}
\sum_{k = 0}^n A^k &= \identite + A + A^2 + ... + A^n \\
A \circ \sum_{k = 0}^n A^k &= A + A^2 + A^3 + ... + A^{n + 1}
\end{align}

<p>
En soustrayant ces deux équations, on obtient :
</p>

<p>
\[(\identite - A) \circ \sum_{k = 0}^n A^k = \identite - A^{n + 1}\]
</p>

<p>
On montre de même que :
</p>

<p>
\[\left[ \sum_{k = 0}^n A^k \right] \circ (\identite - A) = \identite - A^{n + 1}\]
</p>
</div>


<div id="outline-container-org20955f9" class="outline-4">
<h4 id="org20955f9"><span class="section-number-4">9.1.1</span> Infinie</h4>
<div class="outline-text-4" id="text-9-1-1">
<p>
Si \(\norme{A} \strictinferieur 1\), on a \(\norme{A^n} \le \norme{A}^n \to 0\) lorsque \(n \to \infty\) et donc \(A^n \to 0\). On en déduit que :
</p>

<p>
\[(\identite - A) \circ \sum_{k = 0}^{+\infty} A^k = \lim_{n \to \infty} (\identite - A^{n + 1}) = \identite\]
</p>

<p>
On a aussi :
</p>

<p>
\[\left[ \sum_{k = 0}^{+\infty} A^k \right] \circ (\identite - A) = \identite\]
</p>

<p>
On en déduit que :
</p>

<p>
\[(\identite - A)^{-1} = \sum_{k = 0}^{+\infty} A^k\]
</p>
</div>
</div>
</div>


<div id="outline-container-orgaaa7a84" class="outline-3">
<h3 id="orgaaa7a84"><span class="section-number-3">9.2</span> Convergence</h3>
<div class="outline-text-3" id="text-9-2">
<p>
Soit une application linéaire continue \(A : H \mapsto H\). Choisissons \(\lambda \in \setC\) tel que \(\norme{A} \strictinferieur \abs{\lambda}\). On a :
</p>

<p>
\[\norme{A^k} \le \norme{A}^k \strictinferieur \abs{\lambda}^k\]
</p>

<p>
Posons \(r = \norme{A} / \abs{\lambda} \strictinferieur 1\) et divisons par le module de \(\lambda\) puissance \(k\) :
</p>

<p>
\[\frac{ \norme{A^k} }{ \abs{\lambda}^k } \le \frac{ \norme{A}^k }{ \abs{\lambda}^k } = r^k \strictinferieur 1\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\sum_{k = 0}^n \frac{ \norme{A^k} }{ \abs{\lambda}^k } \le \sum_{k = 0}^n r^k = \frac{1 - r^k}{1 - r} \le \unsur{1 - r}\]
</p>

<p>
La suite des :
</p>

<p>
\[S_n = \sum_{k = 0}^n \frac{ \norme{A^k} }{ \abs{\lambda}^k }\]
</p>

<p>
étant croissante et bornée, elle converge vers son supremum :
</p>

<p>
\[S = \sum_{k = 0}^{+\infty} \frac{ \norme{A^k} }{ \abs{\lambda}^k } = \lim_{n \to \infty} S_n = \sup_{n \in \setN} S_n\]
</p>

<p>
Soit \(x \in H\) et la suite définie par \(u_0 = x\) et :
</p>

<p>
\[u_n = \sum_{k = 0}^n \unsur{\lambda^k} \cdot A^k(x)\]
</p>

<p>
Pour tout \(m,n \in \setN\) avec \(m \ge n\), on a :
</p>

<p>
\[\norme{u_m - u_n} = \norme{\sum_{k = n + 1}^m \unsur{\lambda^k} \cdot A^k(x)} \le \sum_{k = n + 1}^m \frac{ \norme{A^k(x)} }{ \abs{\lambda}^k }\]
</p>

<p>
Majorons par la norme de \(A^k\), puis la norme de \(A\) puissance \(k\) :
</p>

<p>
\[\norme{u_m - u_n} \le \left[ \sum_{k = n + 1}^m \frac{ \norme{A^k} }{ \abs{\lambda}^k } \right] \cdot \norme{x} \le \left[ \sum_{k = n + 1}^m \frac{ \norme{A}^k }{ \abs{\lambda}^k } \right] \cdot \norme{x}\]
</p>

<p>
et effectuons le changement de variable \(i = k - (n + 1)\). Il vient :
</p>

<p>
\[\norme{u_m - u_n} \le \frac{ \norme{A}^{n + 1} }{ \abs{\lambda}^{n + 1} } \left[ \sum_{i = 0}^{m - n - 1} \frac{ \norme{A}^i }{ \abs{\lambda}^i } \right] \cdot \norme{x} = r^{n + 1} \cdot S_{m - n - 1} \cdot \norme{x}\]
</p>

<p>
Mais comme \(S_{m - n - 1} \le S\), on a finalement :
</p>

<p>
\[\norme{u_m - u_n} \le r^{n + 1} \cdot S \cdot \norme{x}\]
</p>

<p>
qui converge vers \(0\) lorsque \(n \to \infty\). La suite des \(u_n\) est donc de Cauchy et converge vers un certain \(L(x) \in H\), ce qui définit l'application \(L : H \mapsto H\), que l'on note :
</p>

<p>
\[L = \sum_{k = 0}^{+\infty} \unsur{\lambda^k} \cdot A^k\]
</p>
</div>


<div id="outline-container-org0f68c30" class="outline-4">
<h4 id="org0f68c30"><span class="section-number-4">9.2.1</span> Continuité</h4>
<div class="outline-text-4" id="text-9-2-1">
<p>
Cette application est de norme finie et donc continue car pour tout \(n \in \setN\) :
</p>

<p>
\[\norme{u_n} \le \left[ \sum_{k = 0}^n \frac{ \norme{A}^k }{ \abs{\lambda}^k } \right] \cdot \norme{x} = \frac{ 1 - r^{n + 1} }{1 - r} \cdot \norme{x} \le \frac{\norme{x}}{1 - r}\]
</p>

<p>
On a donc :
</p>

<p>
\[\norme{L(x)} = \lim_{n \to \infty} \norme{u_n} \le \frac{\norme{x}}{1 - r}\]
</p>

<p>
d'où :
</p>

<p>
\[\norme{L} \le \unsur{1 - r}\]
</p>
</div>
</div>


<div id="outline-container-org12e7554" class="outline-4">
<h4 id="org12e7554"><span class="section-number-4">9.2.2</span> Inverse</h4>
<div class="outline-text-4" id="text-9-2-2">
<p>
Comme l'application \(B = A / \lambda\) vérifie \(\norme{B} \strictinferieur 1\), on a :
</p>

<div class="org-center">
<p>
\(
(\lambda \cdot \identite - A) \circ (\unsur{\lambda} \cdot L) = (\identite - \unsur{\lambda} \cdot A) \circ L = \identite \\
(\unsur{\lambda} \cdot L) \circ (\lambda \cdot \identite - A) = L \circ (\identite - \unsur{\lambda} \cdot A) = \identite
\)
</p>
</div>

<p>
et donc :
</p>

<p>
\[(\lambda \cdot \identite - A)^{-1} = \unsur{\lambda} \cdot L\]
</p>
</div>
</div>
</div>


<div id="outline-container-org55fcacf" class="outline-3">
<h3 id="org55fcacf"><span class="section-number-3">9.3</span> Exponentielle</h3>
<div class="outline-text-3" id="text-9-3">
<p>
Soit une application linéaire continue \(A : H \mapsto H\). Sous réserve de convergence, on définit l'opérateur \(\exp(A)\) associé par :
</p>

<p>
\[\exp(A) = \sum_{k = 0}^{+\infty} \unsur{k !} \cdot A^k\]
</p>

<p>
On a donc :
</p>

<p>
\[\exp(A)(u) = \sum_{k = 0}^{+\infty} \unsur{k !} \cdot A^k(u)\]
</p>

<p>
pour tout \(u \in H\).
</p>
</div>
</div>
</div>


<div id="outline-container-orgdbdcf00" class="outline-2">
<h2 id="orgdbdcf00"><span class="section-number-2">10</span> Calcul variationnel</h2>
<div class="outline-text-2" id="text-10">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgc0ab8d8">10.1. Méthode des variations</a></li>
<li><a href="#org3502c2d">10.2. Discrétisation</a></li>
<li><a href="#org4682e61">10.3. Moindres carrés</a></li>
<li><a href="#org66a283e">10.4. Lax-Milgram</a></li>
<li><a href="#org3f2f064">10.5. Valeurs propres</a></li>
</ul>
</div>

<p>
\label{chap:varia}
</p>
</div>


<div id="outline-container-orgc0ab8d8" class="outline-3">
<h3 id="orgc0ab8d8"><span class="section-number-3">10.1</span> Méthode des variations</h3>
<div class="outline-text-3" id="text-10-1">
<p>
Soit l'espace fonctionnel \(\mathcal{F}\) et la forme \(I : \mathcal{F} \mapsto \setR\). Un problème variationnel consiste à chercher une fonction \(u\) qui minimise \(I\) sur \(\mathcal{F}\) :
</p>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v\in\mathcal{F}\). L'astuce consiste à transformer ce problème en considérant la famille de fonctions \(\{ J_w : w \in \mathcal{F} \}\) définies par :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). Comme \(\mathcal{F}\) est un espace vectoriel, \(u + \epsilon \cdot w \in \mathcal{F}\). On en déduit que :
</p>

<p>
\[J_w(0) = I(u) \le J_w(\epsilon)\]
</p>

<p>
Si les fonctions \(J_w\) sont dérivables, les propriétés des extrema des fonctions \(\setR \mapsto \setR\) nous disent que :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = 0\]
</p>

<p>
pour toute variation \(w \in \mathcal{F}\). Si la dérivée seconde existe, on doit également avoir :
</p>

<p>
\[\OOD{J_w}{\epsilon}(0) \ge 0\]
</p>

<p>
Ces équations nous permettent de caractériser la solution \(u\) de notre problème variationnel.
</p>
</div>
</div>


<div id="outline-container-org3502c2d" class="outline-3">
<h3 id="org3502c2d"><span class="section-number-3">10.2</span> Discrétisation</h3>
<div class="outline-text-3" id="text-10-2">
<p>
Une technique couramment employée pour résoudre les problèmes variationnels
est de choisir une suite de fonctions \(\varphi_i \in \mathcal{F}\) linéairement indépendantes et de minimiser sur l'espace vectoriel \(\mathcal{F}_n = \combilin{\varphi_1,\varphi_2,...,\varphi_n} \subseteq \mathcal{F}\). On espère que la solution obtenue sera proche de la solution exacte. Ce sera par exemple le cas si on a schématiquement :
</p>

<p>
\[\lim_{n \to \infty} \adh \mathcal{F}_n = \mathcal{F}\]
</p>

<p>
au sens de la distance \(\distance\) définie sur \(\mathcal{F}\). Pour toute précision \(\epsilon > 0\), on pourra alors trouver un \(n \in \setN\) assez grand et un \(u_n\in \mathcal{F}_n\) tels que :
</p>

<p>
\[\distance(u_n,u) \le \epsilon\]
</p>
</div>
</div>


<div id="outline-container-org4682e61" class="outline-3">
<h3 id="org4682e61"><span class="section-number-3">10.3</span> Moindres carrés</h3>
<div class="outline-text-3" id="text-10-3">
<p>
Soit \(f : A \mapsto \setR\) et le sous-ensemble \(\mathcal{F} \subseteq \fonction(A,\setR)\). On cherche la fonction \(u \in \mathcal{F}\) qui se rapproche le plus possible de \(f\) au sens intégral des moindres carrés. On cherche donc le \(u\) qui minimise la fonctionnelle :
</p>

<p>
\[I(u) = \int_A \Big[ u(x) - f(x) \Big]^2 dx\]
</p>

<p>
Afin de résoudre ce problème, on pose :
</p>

<p>
\[J_v(\epsilon) = I(u + \epsilon \cdot v) = \int_A \Big[ u(x) + \epsilon \cdot v(x) - f(x) \Big]^2 dx\]
</p>

<p>
pour tout \(\epsilon \in \setR\) et \(v \in \mathcal{F}\). La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \int_A 2 \big[ u(x) + \epsilon \cdot v(x) - f(x) \big] \cdot v(x) \ dx\]
</p>

<p>
Comme elle doit s'annuler en \(\epsilon = 0\), on a :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = 2 \int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
donc :
</p>

<p>
\[\int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
pour tout \(v \in F\).
</p>
</div>


<div id="outline-container-org87ca532" class="outline-4">
<h4 id="org87ca532"><span class="section-number-4">10.3.1</span> Discrétisation</h4>
<div class="outline-text-4" id="text-10-3-1">
<p>
On résout approximativement ce problème en posant :
</p>

<p>
\[u_n(x) = \sum_{i = 1}^n U_i \cdot \varphi_i(x)\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont des fonctions connues et où les \(U_i\) sont des réels à déterminer. Comme on désire que \(u_n \approx u\), on impose :
</p>

<p>
\[\int_A (u_n(x) - f(x)) \cdot \varphi_i(x) \ dx = 0\]
</p>

<p>
On a alors :
</p>

<p>
\[\int_A \varphi_i \sum_j U_j \cdot \varphi_j \ dx = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
ou :
</p>

<p>
\[\sum_j \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right] \cdot U_j = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
Définissons les matrices \(A \in \matrice(\setR,n,n)\), \(B \in \matrice(\setR,n,1)\) et \(U \in \matrice(\setR,n,1)\) :
</p>

\begin{align}
A &= \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right]_{i,j} \\
B &= \left[ \int_A \varphi_i \cdot f \ dx \right]_i \\
U &= \left[ U_i \right]_i
\end{align}

<p>
Le problème peut alors s'exprimer sous forme matricielle :
</p>

<p>
\[A \cdot U = B\]
</p>

<p>
Si la matrice \(A\) est inversible, la solution est donnée par :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
et nous en déduisons notre approximation \(u_n = \sum_i U_i \cdot \varphi_i\).
</p>
</div>
</div>
</div>


<div id="outline-container-org66a283e" class="outline-3">
<h3 id="org66a283e"><span class="section-number-3">10.4</span> Lax-Milgram</h3>
<div class="outline-text-3" id="text-10-4">
<p>
Soit un espace fonctionnel de Hilbert \(\mathcal{F}\). Nous considérons une forme bilinéaire \(a : \mathcal{F} \times \mathcal{F} \mapsto \setR\), de norme finie, coercive et symétrique :
</p>

<p>
\[\biforme{u}{a}{v} = \biforme{v}{a}{u}\]
</p>

<p>
pour tout \(u,v \in F\). Nous considérons également une forme linéaire continue \(b : \mathcal{F} \mapsto \setR\) et nous définissons la fonctionnelle \(I : \mathcal{F} \mapsto \setR\) par :
</p>

<p>
\[I(v) = \unsur{2} \biforme{v}{a}{v} - \forme{b}{v}\]
</p>


<ul class="org-ul">
<li>Supposons que \(I\) atteigne un minimum global en \(u\). On a alors :</li>
</ul>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v \in F\). Choisissons un quelconque \(w \in \mathcal{F}\) et posons :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon \in \setR\). Tenant compte des propriétés de \(a\) et \(b\), on obtient :
</p>

<p>
\[J_w(\epsilon) = \unsur{2} \biforme{u}{a}{u} + \epsilon \cdot \biforme{u}{a}{w} + \frac{\epsilon^2}{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \epsilon \cdot \forme{b}{w}\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \biforme{u}{a}{w} + \epsilon \cdot \biforme{w}{a}{w} - \forme{b}{w}\]
</p>

<p>
La condition extrémale sur \(u\) nous dit que \(J_w(0) \le J_w(\epsilon)\) pour tout \(\epsilon \in \setR\). On doit donc avoir :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = \biforme{u}{a}{w} - \forme{b}{w} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Le théorème de Lax-Milgram nous dit qu'il existe un unique \(u \in  \mathcal{F}\) vérifiant cette condition.
</p>

<ul class="org-ul">
<li>Supposons à présent que \(u \in \mathcal{F}\) soit l'unique élément de \(\mathcal{F}\) vérifiant :</li>
</ul>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Choisissons \(v \in \mathcal{F}\) et posons \(w = v - u\). Comme \(\biforme{u}{a}{w} = \forme{b}{w}\), on a :
</p>

\begin{align}
I(v) &= I(u + w) \\
&= \unsur{2} \biforme{u}{a}{u} + \biforme{u}{a}{w} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \forme{b}{w} \\
&= \unsur{2} \biforme{u}{a}{u} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} \\
&= I(u) + \unsur{2} \biforme{w}{a}{w} \ge I(u)
\end{align}

<p>
On a donc :
</p>

<p>
\[u = \arg\min_{ v \in \mathcal{F} } I(v)\]
</p>
</div>



<div id="outline-container-orgd95b705" class="outline-4">
<h4 id="orgd95b705"><span class="section-number-4">10.4.1</span> Orthogonalité</h4>
<div class="outline-text-4" id="text-10-4-1">
<p>
Soit le sous-espace vectoriel \(\mathcal{G} \subseteq \mathcal{F}\) et :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } I(z)\]
</p>

<p>
On a alors :
</p>

<p>
\[\biforme{v}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{G}\).
</p>

<p>
Supposons que \(u \in \mathcal{F}\) minimise \(I\) sur \(\mathcal{F}\) et posons \(e = v - u\). On a :
</p>

<p>
\[\biforme{e}{a}{w} = \biforme{v}{a}{w} - \biforme{u}{a}{w} = \forme{b}{w} - \forme{b}{w} = 0\]
</p>

<p>
Cette propriété est similaire aux propriétés d'orthogonalité vue dans les projections. On est tenté d'en déduire que le \(v\) en question minimise la « norme » de l'écart \(e\) au sens de \(a\). Soit \(z \in \mathcal{G}\) et \(\delta = z - v\). On a \(z - u = z - v + v - u = \delta + e\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + 2 \biforme{e}{a}{\delta} + \biforme{e}{a}{e}\]
</p>

<p>
Mais comme \(\delta \in \mathcal{G}\), on a \(\biforme{e}{a}{\delta} = 0\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + \biforme{e}{a}{e} \ge \biforme{e}{a}{e}\]
</p>

<p>
ce qui prouve que :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } \biforme{z - u}{a}{z - u}\]
</p>
</div>
</div>


<div id="outline-container-org7568877" class="outline-4">
<h4 id="org7568877"><span class="section-number-4">10.4.2</span> Borne inférieure</h4>
<div class="outline-text-4" id="text-10-4-2">
<p>
Comme \(a\) est coercive, on peut trouver un réel \(\varrho \strictsuperieur 0\) tel que :
</p>

<p>
\[a(u,u) \ge \varrho \cdot \norme{u}^2\]
</p>

<p>
pour tout \(u \in \mathcal{F}\). On sait aussi que :
</p>

<p>
\[\norme{b} = \sup \{ \abs{b(u)} : u \in \mathcal{F}, \ \norme{u} = 1 \} \strictinferieur +\infty\]
</p>

<p>
Posons :
</p>

<p>
\[K(\epsilon) = I(\epsilon \cdot v) = \frac{\epsilon^2}{2} \cdot \biforme{v}{a}{v} - \epsilon \cdot \forme{b}{v}\]
</p>

<p>
et cherchons la valeur de \(\epsilon = \gamma\) qui minimise cette fonction. On trouve :
</p>

<p>
\[\OD{K}{\epsilon}(\gamma) = \gamma \cdot \biforme{v}{a}{v} - \forme{b}{v} = 0\]
</p>

<p>
Donc :
</p>

<p>
\[\gamma = \frac{ \forme{b}{v} }{ \biforme{v}{a}{v} }\]
</p>

<p>
et :
</p>

<p>
\[K(\gamma) = \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } - \frac{ \forme{b}{v}^2 }{ \biforme{v}{a}{v} } = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
On en déduit que :
</p>

<p>
\[I(v) = K(1) \ge K(\gamma) = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
Mais comme :
</p>

<div class="org-center">
<p>
\(
\forme{b}{v}^2 \le \norme{b}^2 \cdot \norme{v}^2 \\
\biforme{v}{a}{v} \ge \varrho \cdot \norme{v}^2
\)
</p>
</div>

<p>
on a :
</p>

<p>
\[\frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } \le \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
et :
</p>

<p>
\[I(v) \ge - \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
Ce résultat étant valable pour tout \(v \in \mathcal{F}\), on a la borne inférieure :
</p>

<p>
\[\inf_{ v \in \mathcal{F} } I(v) \ge - \frac{\norme{b}^2}{2\varrho}\]
</p>
</div>
</div>


<div id="outline-container-org683d1cb" class="outline-4">
<h4 id="org683d1cb"><span class="section-number-4">10.4.3</span> Discrétisation</h4>
<div class="outline-text-4" id="text-10-4-3">
<p>
Afin de trouver une approximation \(u_n \approx u\), on pose :
</p>

<p>
\[u_n = \sum_{i = 1}^n U_i \cdot \varphi_i\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont connues et où les \(U_i\) sont des réels à déterminer. La linéarité de \(a\) et \(b\) nous permet de développer :
</p>

<p>
\[I(u_n) = \unsur{2} \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j - \sum_{i=1}^n \forme{b}{\varphi_i} U_i\]
</p>

<p>
Si nous définissons les matrices :
</p>

\begin{align}
A &= \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \\
B &= \left[ \forme{b}{\varphi_i} \right]_i \\
U &= \left[ U_i \right]_i
\end{align}

<p>
on peut réécrire \(I(u_n)\) sous forme matricielle :
</p>

<p>
\[I(u_n) = J(U) = \unsur{2} U^\dual \cdot A \cdot U - U^\dual \cdot B\]
</p>

<p>
La condition \(\partial J(U) = 0\) nous amène à :
</p>

<p>
\[A \cdot U - B = 0\]
</p>

<p>
Si la matrice \(A\) est inversible, on en déduit :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
ce qui nous donne \(U\) et donc \(u_n\).
</p>
</div>
</div>
</div>


<div id="outline-container-org3f2f064" class="outline-3">
<h3 id="org3f2f064"><span class="section-number-3">10.5</span> Valeurs propres</h3>
<div class="outline-text-3" id="text-10-5">
<p>
Soit un espace vectoriel \(E\) et les formes bilinéaires \(a,b : E \times E \mapsto \setR\). Nous supposons que \(a,b\) sont symétriques et définies positives. Nous allons tenter de minimiser la fonctionnelle :
</p>

<p>
\[I(v) = \biforme{v}{a}{v}\]
</p>

<p>
sur l'ensemble :
</p>

<p>
\[\Omega = \{ v \in E : \biforme{v}{b}{v} = 1 \}\]
</p>

<p>
L'espace \(\Omega\) n'est malheureusement pas un sous-espace vectoriel. Par exemple, si \(u\) appartient à \(\Omega\), on a :
</p>

<p>
\[\biforme{2 u}{b}{2 u} = 4 \biforme{u}{b}{u} = 4 \ne 1\]
</p>

<p>
Donc \(2 u \notin \Omega\). Par conséquent, nous ne pouvons pas utiliser les techniques de projection sur un espace vectoriel pour résoudre ce problème. Nous allons donc employer les techniques de minimisation sous contraintes. Définissons le lagrangien :
</p>

<p>
\[\lagrangien(v,y) = \biforme{v}{a}{v} + y \cdot (1 - \biforme{v}{b}{v})\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). La fonction \(u\) minimisant \(I\) sur \(\Omega\) peut dès lors s'obtenir via le point de selle \((u,\lambda)\) :
</p>

<p>
\[\lagrangien(u,y) \le \lagrangien(u,\lambda) \le \lagrangien(v,\lambda)\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). Nous allons évaluer le minimum sur \(v\) en utilisant la méthode des variations. Soit \(w \in E\) et \(\epsilon \in \setR\). On pose :
</p>

\begin{align}
J_v(\epsilon) &= \lagrangien(u + \epsilon \cdot w, \lambda) \\
&= \biforme{u + \epsilon \cdot w}{a}{u + \epsilon \cdot w} + \lambda \cdot [ 1 - \biforme{u + \epsilon \cdot w}{b}{u + \epsilon \cdot w} ]
\end{align}

<p>
Utilisant les propriétés de \(a,b\) et la contrainte \(\biforme{u}{b}{u} = 1\), il vient :
</p>

<div class="org-center">
<p>
\(
J_v(\epsilon) = \biforme{u}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{u} + \epsilon^2 \cdot \biforme{w}{a}{w} \\
\qquad - \lambda \cdot [ 2 \epsilon \cdot \biforme{w}{b}{u} + \epsilon^2 \cdot \biforme{w}{b}{w} ]
\)
</p>
</div>

<p>
Les propriétés du point de selle en \((u,\lambda)\) nous garantissent que :
</p>

<p>
\[J_v(0) \le J_v(\epsilon)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). La dérivée :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = 2 \biforme{w}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{w} - 2 \lambda \cdot [ \biforme{w}{b}{u} + \epsilon \cdot \biforme{w}{b}{w} ]\]
</p>

<p>
doit donc s'annuler en \(\epsilon = 0\) :
</p>

<p>
\[\OD{J_v^\lambda}{\epsilon}(0) = 2 \biforme{w}{a}{u} - 2 \lambda \cdot \biforme{w}{b}{u} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{w}{a}{u} = \lambda \cdot \biforme{w}{b}{u}\]
</p>

<p>
pour tout \(w \in E\). On dit alors que \(\lambda\) est valeur propre de \(a,b\) correspondant à la fonction propre \(u\).
</p>
</div>


<div id="outline-container-org1ff2d09" class="outline-4">
<h4 id="org1ff2d09"><span class="section-number-4">10.5.1</span> Propriétés extrémales</h4>
<div class="outline-text-4" id="text-10-5-1">
<p>
Si nous choisissons \(w = u\), nous obtenons :
</p>

<p>
\[\biforme{u}{a}{u} = \lambda \cdot \biforme{u}{b}{u} = \lambda\]
</p>

<p>
La valeur propre est donc la valeur minimale de \(I\) sur \(\Omega\) :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \min_{v \in \Omega} \biforme{v}{a}{v}\]
</p>
</div>
</div>


<div id="outline-container-orgd58193a" class="outline-4">
<h4 id="orgd58193a"><span class="section-number-4">10.5.2</span> Rapport de Rayleigh</h4>
<div class="outline-text-4" id="text-10-5-2">
<p>
Supposons que \(b\) soit strictement définie positive. Posons \(x = \alpha \cdot u\), pour un certain \(\alpha \in \setR\) non nul. On a \(\biforme{x}{a}{x} = \alpha^2 \cdot \biforme{u}{a}{u}\) et \(\biforme{x}{b}{x} = \alpha^2 \cdot \biforme{u}{b}{u} = \alpha^2\). Donc :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \frac{ \biforme{x}{a}{x} }{ \biforme{x}{b}{x} }\]
</p>

<p>
Considérons la même expression pour un quelconque \(z \in E\) non nul :
</p>

<p>
\[R(z) = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} }\]
</p>

<p>
On dit que \(R(z)\) est le rapport de Rayleigh de \(z\). Soit \(v = z / \sqrt{ \biforme{z}{b}{z} }\). On a :
</p>

<p>
\[\biforme{v}{a}{v} = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} } = R(z)\]
</p>

<p>
et :
</p>

<p>
\[\biforme{v}{b}{v} = \frac{ \biforme{z}{b}{z} }{ \biforme{z}{b}{z} } = 1\]
</p>

<p>
ce qui prouve que \(v \in \Omega\). On a donc :
</p>

<p>
\[\lambda = R(x) \le \biforme{v}{a}{v} = R(z)\]
</p>

<p>
On en conclut que \(x\) minimise le rapport de Rayleigh sur \(E_0 = E \setminus \{0\}\) :
</p>

<p>
\[\lambda = R(x) = \arg\min_{z \in E_0} R(z) = \arg\min_{z \ne 0} R(z)\]
</p>

<p>
Comme \(\Omega \subseteq F\), on en conclut que la réciproque est vraie : si \(x\) minimise \(R\) sur \(E_0\), le vecteur \(x/\sqrt{ \biforme{x}{b}{x} }\) minimise la fonctionnelle \(I\) sur \(\Omega\). Les deux problèmes de minimisation sont donc équivalents.
</p>
</div>
</div>


<div id="outline-container-org868ac5d" class="outline-4">
<h4 id="org868ac5d"><span class="section-number-4">10.5.3</span> Suite de vecteurs propres</h4>
<div class="outline-text-4" id="text-10-5-3">
<p>
On peut en fait définir une suite de vecteurs et de valeurs propres. Soit \(\Omega_1 = \Omega\) et \(e_1 = u\). On pose récursivement :
</p>

<p>
\[\Omega_{n + 1} = \{ v \in \Omega : \biforme{v}{b}{e_1} = ... = \biforme{v}{b}{e_n} = 0 \}\]
</p>

<p>
et :
</p>

<p>
\[e_{n + 1} \in \arg\min_{ v \in \Omega_{n + 1} } \biforme{v}{a}{v}\]
</p>

<p>
On aura alors bien sûr \(\Omega_{n + 1} \subseteq \Omega_n \subseteq ... \Omega_1\). Les propriétés extrémales des valeurs propres nous montrent que \(\lambda_{n + 1} \ge \lambda_n \ge ... \ge \lambda_1\).
</p>
</div>
</div>


<div id="outline-container-orgfda095b" class="outline-4">
<h4 id="orgfda095b"><span class="section-number-4">10.5.4</span> Discrétisation</h4>
<div class="outline-text-4" id="text-10-5-4">
<p>
On pose :
</p>

<p>
\[u_n = \sum_{i=1}^n U_i \cdot \varphi_i\]
</p>

<p>
On a alors :
</p>

<div class="org-center">
<p>
\(
\biforme{u_n}{a}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j \\
\biforme{u_n}{b}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{b}{\varphi_j} \cdot U_j
\)
</p>
</div>

<p>
Avec les matrices :
</p>

<div class="org-center">
<p>
\(
A = \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \\
B = \left[ \biforme{\varphi_i}{b}{\varphi_j} \right]_{i,j}
\)
</p>
</div>

<p>
le lagrangien peut s'écrire :
</p>

<p>
\[\lagrangien(u_n,y) = U^\dual \cdot A \cdot U + y \cdot \left[ 1 - U^\dual \cdot B \cdot U \right]\]
</p>

<p>
Les conditions :
</p>

<div class="org-center">
<p>
\(
\partial_v \lagrangien(u_n,\lambda) = 2 A \cdot U - 2 \lambda \cdot B \cdot U = 0 \\
\partial_y \lagrangien(u_n,\lambda) = 1 - U^\dual \cdot B \cdot U = 0
\)
</p>
</div>

<p>
nous amènent au problème :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot B \cdot U \\
U^\dual \cdot B \cdot U = 1
\)
</p>
</div>

<p>
à résoudre en \(U\). Notons que si on choisit les \(\varphi_i\) « orthonormées » dans le sens du pseudo-produit scalaire introduit par \(b\), on a :
</p>

<p>
\[\biforme{\varphi_i}{b}{\varphi_j} = \delta_{ij}\]
</p>

<p>
et \(B = I\). On peut par exemple construire une telle suite de \(\varphi_i\) en utilisant la méthode de Gram-Schmidt. Le problème se simplifie alors en :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot U \\
U^\dual \cdot U = 1
\)
</p>
</div>
</div>
</div>
</div>
</div>


<div id="outline-container-org1693bbb" class="outline-2">
<h2 id="org1693bbb"><span class="section-number-2">11</span> Algorithmes d'optimisation contrainte</h2>
<div class="outline-text-2" id="text-11">
<div id="text-table-of-contents">
<ul>
<li><a href="#org5d0775a">11.1. Introduction</a></li>
<li><a href="#org6f353db">11.2. Contraintes linéaires</a></li>
<li><a href="#orgf26c6e2">11.3. Contraintes d'inégalité</a></li>
</ul>
</div>

<p>
\label{chap:algocont}
</p>
</div>


<div id="outline-container-org5d0775a" class="outline-3">
<h3 id="org5d0775a"><span class="section-number-3">11.1</span> Introduction</h3>
<div class="outline-text-3" id="text-11-1">
<p>
Nous allons présenter des algorithmes permettant de résoudre approximativement des problèmes de minimisation d'une fonction \(\varphi\) sur un ensemble \(\Omega \subseteq \setR^n\). Ces algorithmes partent d'un point initial \(x_0 \in \Omega\) et itèrent schématiquement comme suit :
</p>

<p>
\[x_{k + 1} = I(x_k) = x_k + p_k\]
</p>

<p>
pour un certain \(p_k \in \setR^n\). On espère bien entendu que la suite converge et que :
</p>

<p>
\[x_N \approx \lim_{k \to \infty} x_k = \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
pour \(N\) assez grand. Nous adoptons les notations :
</p>

<p>
\[J = \partial \varphi\]
</p>

<p>
pour le gradient, de taille \((n,1)\) et :
</p>

<p>
\[H = \partial^2 \varphi\]
</p>

<p>
pour la hessienne, de taille \((n,n)\). On note également :
</p>

<p>
\[\Phi_k = \Phi(x_k)\]
</p>

<p>
pour toute fonction \(\Phi\) (par exemple, \(\Phi \in \{\varphi,J,H\}\)).
</p>
</div>
</div>


<div id="outline-container-org6f353db" class="outline-3">
<h3 id="org6f353db"><span class="section-number-3">11.2</span> Contraintes linéaires</h3>
<div class="outline-text-3" id="text-11-2">
<p>
Nous considérons le cas de contraintes linéaires :
</p>

<p>
\[\Omega = \{ x \in \setR^n : A \cdot x = b \}\]
</p>

<p>
où \(A\) est une matrice de taille \((m,n)\) et \(b\) un vecteur de taille \((m,1)\). On choisit généralement \(x_0 = 0\). L'itération \(k\) part d'un \(x_k\) satisfaisant les contraintes :
</p>

<p>
\[A \cdot x_k = b\]
</p>

<p>
Si on veut que \(x_{k + 1} = x_k + s_k \in \Omega\), il est nécessaire et suffisant que \(A \cdot (x_k + s_k) = b\), ou que :
</p>

<p>
\[A \cdot s_k = A \cdot (x_k + s_k) - A \cdot x_k = b - b = 0\]
</p>

<p>
On doit donc avoir \(s_k \in \noyau A\). Soit les \(u_i \in \setR^m\), \(v_i \in \setR^n\) et \(\sigma_i \in \setR\) constituant la décomposition en valeurs singulières de \(A\). On forme une matrice à partir des vecteurs de base de \(\noyau A\) :
</p>

<p>
\[V = [v_{r + 1} \ ... \ v_n]\]
</p>

<p>
On a alors :
</p>

<p>
\[s_k = \sum_{i = r + 1}^n p_{k,i} \cdot v_i = V \cdot p_k\]
</p>

<p>
où \(p_k = [p_{k, r + 1} ... p_{k,n}]^\dual\).
</p>
</div>


<div id="outline-container-orged49395" class="outline-4">
<h4 id="orged49395"><span class="section-number-4">11.2.1</span> Newton  projeté</h4>
<div class="outline-text-4" id="text-11-2-1">
<p>
Il s'agit de l'adaptation de la méthode de Newton :
</p>

<p>
\[x_{k + 1} = x_k + V \cdot p_k\]
</p>

<p>
On minimise le développement d'ordre deux :
</p>

<p>
\[\varphi_{k+1} \approx \varphi_k + J_k^\dual \cdot V \cdot p_k + \unsur{2} \cdot p_k^\dual \cdot V^\dual \cdot H_k \cdot V \cdot p_k\]
</p>

<p>
L'annulation du gradient par rapport à \(p_k\) nous donne :
</p>

<p>
\[V^\dual \cdot J_k + V^\dual \cdot H_k \cdot V \cdot p_k = 0\]
</p>

<p>
et donc :
</p>

<p>
\[p_k = - (V^\dual \cdot H_k \cdot V)^{-1} \cdot V^\dual \cdot J_k\]
</p>
</div>
</div>
</div>


<div id="outline-container-orgf26c6e2" class="outline-3">
<h3 id="orgf26c6e2"><span class="section-number-3">11.3</span> Contraintes d'inégalité</h3>
<div class="outline-text-3" id="text-11-3">
<p>
Examinons à présent le cas où :
</p>

<p>
\[\Omega = \{ x \in \setR^n : \omega(x) \le 0 \}\]
</p>

<p>
Nous laissons à présent tomber le \(k\) des itérations, afin d'alléger
les notations.
</p>
</div>


<div id="outline-container-orgd15a446" class="outline-4">
<h4 id="orgd15a446"><span class="section-number-4">11.3.1</span> Méthodes de penalité</h4>
<div class="outline-text-4" id="text-11-3-1">
<p>
La méthode de pénalité consiste à ajouter une fonction positive à \(\varphi\) lorsque \(x\) sort de \(\Omega\). Si l'on augmente la valeur de la fonction pénalité, on rapproche alors le minimum global de \(\Omega\). La solution à notre problème contraint devrait donc être approchée en faisant tendre l'amplitude de la pénalité vers l'infini. Soit la fonction \(\varpi : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\varpi_i(x) = \max\{\omega_i(x),0\}\]
</p>

<p>
On a par construction \(\varpi(x) = 0\) pour tout \(x \in \Omega\) et \(\varpi(x) \strictsuperieur 0\) pour tout \(x \notin \Omega\). On ajoute la somme des carrés \(\varpi(x)^\dual \cdot \varpi(x) = \sum_i \varpi_i(x)^2\) multipliée par un paramètre réel \(k \ge 0\) à la fonction objectif pour obtenir l'objectif modifié :
</p>

<p>
\[\psi_k(x) = \varphi(x) + k \cdot \varpi(x)^\dual \cdot \varpi(x)\]
</p>

<p>
On utilise ensuite un algorithme de minimisation libre pour évaluer le minimum global :
</p>

<p>
\[\mu(k) = \arg\min_{x \in \setR^n} \psi_k(x)\]
</p>

<p>
On espère que \(\mu\) converge à l'infini et que :
</p>

<p>
\[\lim_{k \to \infty} \mu(k) = \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
Il suffit dans ce cas de choisir \(k\) assez grand pour obtenir une estimation de la solution du problème contraint.
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org2639068" class="outline-2">
<h2 id="org2639068"><span class="section-number-2">12</span> Réseaux de neurones</h2>
<div class="outline-text-2" id="text-12">
<div id="text-table-of-contents">
<ul>
<li><a href="#org6d86202">12.1. Définition</a></li>
<li><a href="#orgea2a903">12.2. Perceptron à une couche</a></li>
<li><a href="#org8c456c3">12.3. Entrainement</a></li>
</ul>
</div>
</div>


<div id="outline-container-org6d86202" class="outline-3">
<h3 id="org6d86202"><span class="section-number-3">12.1</span> Définition</h3>
<div class="outline-text-3" id="text-12-1">
<p>
Commençons par la description d'un neurone \(i\) de fonction caractéristique
\(\sigma\). La relation entre les entrées \(x_j\) et la sortie \(y_i\) s'écrit :
</p>

<p>
\[y_i = \sigma\left( \sum_j ( w_{ij} \ x_j ) + b_i \right)\]
</p>

<p>
Un réseau de neurones est composé de neurones reliés entres eux (la sortie d'un neurone peut servir d'entrée à un autre).
</p>

<p>
La fonction caractéristique est généralement l'une de celles
décrites ci-dessous :
</p>

<div class="org-center">
<p>
\(
\sigma(x) = \mt{sign}(x) \\
\sigma(x) = \tanh(x) \\
\sigma(x) = \exp(-x^2) \\
\sigma(x) = x \exp(-x^2)
\)
</p>
</div>
</div>
</div>


<div id="outline-container-orgea2a903" class="outline-3">
<h3 id="orgea2a903"><span class="section-number-3">12.2</span> Perceptron à une couche</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Le perceptron monocouche est composé d'une rangée de neurones reliant les
entrées \(x_i\) aux sorties \(y_i\) (le perceptron multicouche est composé de monocouches assemblées
l'une à la suite de l'autre). La relation entrées-sorties s'écrit :
</p>

<p>
\[y_i = P_{\theta}(x) = c + \sum_j v_j \ \sigma\left( \sum_k ( w_{jk} \ x_k ) + b_j \right)\]
</p>

<p>
On écrit \(y_i = P_{\theta}(x)\) pour mettre en évidence l'influence des paramètres du résau \(\theta = (v,w,b,c)\) sur la sortie \(y\).
</p>
</div>
</div>


<div id="outline-container-org8c456c3" class="outline-3">
<h3 id="org8c456c3"><span class="section-number-3">12.3</span> Entrainement</h3>
<div class="outline-text-3" id="text-12-3">
<p>
Les réseaux de neurones sont principalement utilisés afin de calquer le comportement d'un système difficille à modéliser par d'autres méthodes. On dispose d'un certain nombre de vecteurs \(y^{(n)}\in\setR^M\), \(x^{(n)}\in\setR^{N}\), où \(n=1,...,K\). On aimerait bien trouver le vecteur des paramètres, \(\theta\), qui correspond le mieux à cette série d'entrées-sorties. On va alors entrainer le réseau de neurones défini par \(y=R_{\theta}(x)\)  en  utilisant une méthode d'optimisation non linéaire afin d'obtenir la solution de
</p>

<p>
\[\theta^* = \arg\min_{\theta} \sum_n \norme{ y^{(n)} - R_{\theta}\left( x^{(n)} \right) }^2\]
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2019-05-07 mar 08:20</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
