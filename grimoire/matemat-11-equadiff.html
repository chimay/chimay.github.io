<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2019-05-07 mar 08:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 11 : Équations différentielles</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="chimay" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Eclats de vers : Matemat 11 : Équations différentielles</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="file:///home/david/racine/site/orgmode/index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents">
<h2>Table des matières</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgcf05c78">1. Equations différentielles ordinaires</a></li>
<li><a href="#org9e33afa">2. Exponentielle</a></li>
<li><a href="#orga402cba">3. Logarithme</a></li>
<li><a href="#orgee91506">4. Fonctions hyperboliques</a></li>
<li><a href="#orgf93705e">5. Exponentielle matricielle</a></li>
<li><a href="#orgdd4ab04">6. Fonctions trigonométriques</a></li>
<li><a href="#org3375da3">7. Fonctions trigonométriques inverses</a></li>
<li><a href="#orgf38d075">8. Equations aux dérivées partielles</a></li>
<li><a href="#org60bf838">9. Algorithmes de résolution d'EDO</a></li>
<li><a href="#orgb269bba">10. Algorithmes de résolution d'EDP</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-orgcf05c78" class="outline-2">
<h2 id="orgcf05c78"><span class="section-number-2">1</span> Equations différentielles ordinaires</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgda5fd1e">1.1. Fonctions Lipschitziennes</a></li>
<li><a href="#org4dc8812">1.2. Problème différentiel d'ordre un</a></li>
<li><a href="#orgc49ea15">1.3. Problème différentiel d'ordre quelconque</a></li>
<li><a href="#org5bc031d">1.4. Problème aux limites</a></li>
<li><a href="#org8a1b273">1.5. Sturm-Liouville</a></li>
<li><a href="#orga199adb">1.6. Séparation des variables</a></li>
<li><a href="#orge56f88f">1.7. Dérivées des fonctions usuelles</a></li>
</ul>
</div>

<p>
\label{chap:edo}
</p>
</div>


<div id="outline-container-orgda5fd1e" class="outline-3">
<h3 id="orgda5fd1e"><span class="section-number-3">1.1</span> Fonctions Lipschitziennes</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Les fonctions Lipschitziennes sont des fonctions à variations bornées :
</p>

<p>
\[\lipschitz(A,B) = \{ f \in \fonction(A,B) : \exists L \in \setR : \forall x,y \in A : \norme{f(x)-f(y)} \le L \norme{x-y} \}\]
</p>
</div>
</div>


<div id="outline-container-org4dc8812" class="outline-3">
<h3 id="org4dc8812"><span class="section-number-3">1.2</span> Problème différentiel d'ordre un</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Soit \(f\in\lipschitz( \setR \times \setR^n , \setR)\), et l'application \(A\) définie par :
</p>

<p>
\[A(u)(t) = u_0 + \int_0^t f(s, u(s)) \ ds\]
</p>

<p>
pour toute fonction \(u : U \subseteq \setR \mapsto \setR\).
</p>

<p>
On peut montrer que \(A\) est contractante pour la distance définie pour toutes fonctions \(u,v\) par :
</p>

<p>
\[\distance(u,v) = \sup_{a \le t \le b} \norme{u(t) - v(t)}\]
</p>

<p>
où \(\norme{.}\) est la norme usuelle sur \(\setR^n\) :
</p>

<p>
\[\norme{x} = \sqrt{ \sum_{i=1}^n x_i^2 }\]
</p>

<p>
Cette application admet donc un unique point fixe \(u\) tel que :
</p>

<p>
\[u = A(u)\]
</p>

<p>
En dérivant cette relation, on obtient :
</p>

<p>
\[\OD{u}{t}(t) = \OD{}{t} A(u)(t) = \OD{}{t} \int_0^t f(s, u(s)) \ ds\]
</p>

<p>
La dérivée de l'intégrale vaut \(f(t, u(t)\) et on a :
</p>

<p>
\[\OD{u}{t}(t) = f(t, u(t))\]
</p>

<p>
On a aussi :
</p>

<p>
\[u(0) = u_0 + \int_0^0 f(s, u(s)) \ ds = u_0\]
</p>

<p>
Notre point fixe \(u\) est donc solution du problème différentiel :
</p>

\begin{align}
\OD{u}{t}(t) &= f(t,u(t)) \\ \\
u(0) &= u_0
\end{align}

<p>
Inversément, en intégrant la première équation ci-dessous entre \(0\) et \(t\), on obtient la relation :
</p>

<p>
\[u(t) - u_0 = \int_0^t f(s, u(s)) \ ds\]
</p>

<p>
autrement dit :
</p>

<p>
\[u(t) = u_0 + \int_0^t f(s, u(s)) \ ds = A(u)\]
</p>

<p>
Toute solution du problème différentiel est donc point fixe de \(A\). Comme ce point fixe
est unique, on en conclut que la solution du problème différentiel l'est aussi.
</p>
</div>


<div id="outline-container-org9c987f8" class="outline-4">
<h4 id="org9c987f8"><span class="section-number-4">1.2.1</span> Convergence</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
La série des \(u^{(n)}\) définie par :
</p>

<p>
\[u^{(n)}(t) = A\big(u^{(n-1)}\big) = u_0 + \int_0^t f\big(s,u^{(n-1)}(s)\big) \ ds\]
</p>

<p>
converge au sens de la distance \(\sup\) définie ci-dessus vers la solution de ce problème différentiel :
</p>

<p>
\[\lim_{n \to +\infty} \sup_{a \le t \le b} \norme{u(t) - u^{(n)}(t)} = 0\]
</p>
</div>
</div>


<div id="outline-container-org1aec164" class="outline-4">
<h4 id="org1aec164"><span class="section-number-4">1.2.2</span> Notation</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
Pour toute fonction :
</p>

<p>
\[u : \setR \mapsto \setR, \ t \mapsto u(t)\]
</p>

<p>
on note aussi :
</p>

<div class="org-center">
<p>
\(
\dot{u} = \OD{u}{t} \\
\ddot{u} = \OOD{u}{t}
\)
</p>
</div>

<p>
ou :
</p>

<div class="org-center">
<p>
\(
u'(t) = \OD{u}{t}(t) \\
u''(t) = \OOD{u}{t}(t)
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orgc49ea15" class="outline-3">
<h3 id="orgc49ea15"><span class="section-number-3">1.3</span> Problème différentiel d'ordre quelconque</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Soit les fonctions :
</p>

<p>
\[a_0, a_1, ..., a_{n - 1} : \setR \mapsto \setR\]
</p>

<p>
et une solution \(u : \setR \mapsto \setR\) du problème différentiel d'ordre \(n\) :
</p>

\begin{align}
a_0(t) \cdot u(t) + \sum_{i=1}^{n-1} a_i(t) \cdot \NOD{u}{t}{i}(t) &= 0 \\ \\
u(0) &= U_0 \\ \\
\NOD{u}{t}{i}(0) &= U_i \qquad (i=1,...,n - 1)
\end{align}

<p>
Ce problème peut se ramener à un problème différentiel d'ordre un. Pour cela on définit la fonction \(v : \setR \mapsto \setR^n\) par :
</p>

<div class="org-center">
<p>
\(
v(t) = \Big(v_i(t)\Big)_{i = 0, ..., n - 1} = \Big( \NOD{u}{t}{i}(t) \Big)_{i = 0, ..., n - 1}
\)
</p>
</div>

<p>
pour tout \(t \in \setR\). On voit alors que :
</p>

<div class="org-center">
<p>
\(
\OD{v}{t} =
</p>
\begin{Matrix}{ccccc}
0 & 1 & 0 & \hdots & \\
0 & 0 & 1 & 0 & \hots \\
\vdots & & & & \\
0 & \hdots & \hdots & 0 & 1 \\
-a_0/a_n & -a_1/a_n & \hdots & \hdots & -a_{n-1}/a_n
\end{Matrix}
<p>
&sdot;
v
\)
</p>
</div>

<p>
La condition initiale s'écrit :
</p>

<div class="org-center">
<p>
\(
v(0) = (U_i)_{i = 0, ..., n - 1}
\)
</p>
</div>

<p>
Comme il existe une et une seule solution \(v\) au problème d'ordre un associé, le problème différentiel d'ordre \(n\) admet également une unique solution :
</p>

<p>
\[u : t \mapsto v_0(t)\]
</p>
</div>
</div>


<div id="outline-container-org5bc031d" class="outline-3">
<h3 id="org5bc031d"><span class="section-number-3">1.4</span> Problème aux limites</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Soit la fonctionnelle \(I : \continue^2([a,b],\setR) \mapsto \setR\). Nous allons tenter de minimiser \(I\) sur l'ensemble :
</p>

<p>
\[\mathcal{F} = \{ u \in \continue^2([a,b],\setR) : u(a) = U_1, \ u(b) = U_2 \}\]
</p>

<p>
On voit que les valeurs de toute fonction \(u \in \mathcal{F}\) sont contraintes aux extrémités du domaine de \(u\). On parle dans ce cas de problème aux limites.
</p>

<p>
Soit \(u \in \mathcal{F}\) et la fonction \(w\) appartenant à l'ensemble :
</p>

<p>
\[\mathcal{W} = \{ w \in \continue^2([a,b],\setR) : w(a) = w(b) = 0 \}\]
</p>

<p>
On a alors \(u + \epsilon \cdot w \in \mathcal{F}\) pour tout \(w \in \mathcal{W}\) et tout \(\epsilon \in \setR\), car :
</p>

<div class="org-center">
<p>
\(
u(a) + \epsilon \cdot w(a) = u(a) = U_1 \\
u(b) + \epsilon \cdot w(b) = u(b) = U_2
\)
</p>
</div>

<p>
On considère la famille de fonctions \(J_w : \setR \mapsto \setR\) définies par :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(w \in \mathcal{W}\) et tout \(\epsilon \in \setR\). Si \(u\) minimise \(I\) sur \(\mathcal{F}\), on a évidemment \(J_w(\epsilon) \ge J_w(0)\) pour tout \(w \in \mathcal{W}\) et pour tout \(\epsilon \in \setR\). Il est par conséquent nécessaire que la condition de stationarité :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = 0\]
</p>

<p>
soit satisfaite pour tout \(w\in\mathcal{W}\).
</p>
</div>


<div id="outline-container-org61c72c7" class="outline-4">
<h4 id="section:eulerLagrange"><a id="org61c72c7"></a><span class="section-number-4">1.4.1</span> Équation d’Euler - Lagrange</h4>
<div class="outline-text-4" id="text-section:eulerLagrange">
<p>
Un exemple typique de fonctionnelle \(I\) est définie pour tout \(u \in \continue^2([a,b],\setR)\) par :
</p>

<p>
\[I(u) = \int_a^b f(t, u(t), u'(t)) \ dt\]
</p>

<p>
avec :
</p>

<p>
\[f\in \continue^2([a,b]\times\setR^2,\setR), \ (t,u,v) \mapsto f(t,u,v)\]
</p>

<p>
On a :
</p>

<p>
\[J_w(\epsilon) = \int_a^b f(t, u + \epsilon \cdot w, u' + \epsilon \cdot w') \ dt\]
</p>

<p>
Donc :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = \int_a^b \left(
\deriveepartielle{f}{u}(t,u,u') \cdot w +
\deriveepartielle{f}{v}(t,u,u') \cdot w' \right) dt = 0\]
</p>

<p>
Nous allons tenter d'intégrer par parties le deuxième terme de l’intégrale. On sait que :
</p>

<p>
\[\OD{}{t}\left[\deriveepartielle{f}{v} \ w \right] =
\OD{}{t}\left[ \deriveepartielle{f}{v} \right] \ w + \deriveepartielle{f}{v} \ w'\]
</p>

<p>
En intégrant, nous obtenons :
</p>

<p>
\[\int_a^b \OD{}{t}\left[\deriveepartielle{f}{v} \ w \right] dt =
\int_a^b \OD{}{t} \left[ \deriveepartielle{f}{v} \right] \ w \ dt +
\int_a^b \deriveepartielle{f}{v} \ w' \ dt\]
</p>

<p>
En utilisant le théorème fondamental et les conditions sur \(w\), on arrive à :
</p>

<p>
\[\int_a^b \OD{}{t}\left[\deriveepartielle{f}{v} \ w \right] dt = \deriveepartielle{f}{v}(b,u(b),u'(b)) \ w(b) - \deriveepartielle{f}{v}(a,u(a),u'(a)) \ w(a) = 0\]
</p>

<p>
On en déduit que :
</p>

<p>
\[0 = \int_a^b \OD{}{t} \left[ \deriveepartielle{f}{v} \right] \ w \ dt +
\int_a^b \deriveepartielle{f}{v} \ w' \ dt\]
</p>

<p>
et :
</p>

<p>
\[\int_a^b \deriveepartielle{f}{v} \ w' \ dt = - \int_a^b
\OD{}{t} \left[ \deriveepartielle{f}{v} \right] \ w \ dt\]
</p>

<p>
La condition de stationarité sur \(J_w\) devient alors :
</p>

<p>
\[\int_a^b \left( \deriveepartielle{f}{u} - \OD{}{t} \deriveepartielle{f}{v}  \right) \ w \ dt = 0\]
</p>

<p>
Comme cette équation est valable pour tout les \(w\) dans \(\mathcal{W}\),
on en déduit que \(u\) vérifie l'équation différentielle d’Euler - Lagrange :
</p>

<p>
\[\deriveepartielle{f}{u} - \OD{}{t} \deriveepartielle{f}{v} = 0\]
</p>

<p>
où les dérivées de \(f\) sont bien entendu évaluées en \((t,u(t),u'(t))\).
</p>

<p>
Il es possible de détailler la dérivation temporelle du second terme :
</p>

<p>
\[\OD{}{t}\left[\deriveepartielle{f}{v} \right] = \dfdxdy{f}{t}{v} + \dfdxdy{f}{u}{v} \ u' + \dfdxdy{f}{v}{v} \ u''\]
</p>

<p>
L’équation d’Euler - Lagrange devient alors :
</p>

<p>
\[\deriveepartielle{f}{u} - \dfdxdy{f}{t}{v} - \dfdxdy{f}{u}{v} \ u' - \dfdxdy{f}{v}{v} \cdot u'' = 0\]
</p>
</div>
</div>


<div id="outline-container-org987e3d5" class="outline-4">
<h4 id="org987e3d5"><span class="section-number-4">1.4.2</span> Euler-Lagrange avec contraintes</h4>
<div class="outline-text-4" id="text-1-4-2">
<p>
Nous tentons cette fois de minimiser :
</p>

<p>
\[I(u) = \int_a^b f(t, u(t), u'(t)) \ dt\]
</p>

<p>
mais en respectant les \(m\) contraintes :
</p>

<p>
\[g_i(t,u(t),u'(t)) = 0\]
</p>

<p>
pour tout \(i \in \{1, 2, ..., m\}\), où :
</p>

<p>
\[g_i\in \continue^1([a,b]\times\setR^2,\setR), \ (t,u,v) \mapsto g(t,u,v)\]
</p>

<p>
Nous devons donc minimiser \(u\) sur l’espace :
</p>

<p>
\[\mathcal{G} = \{ u \in \mathcal{F} : g_i(t,u(t),u'(t)) = 0  \ \ \ \forall i \in \{1,2,...,m\} \}\]
</p>

<p>
Comme la fonction \(g\) prend des valeurs nulles entre \(a\) et \(b\), son
intégrale y est également nulle :
</p>

<p>
\[\int_a^b g_i(t,u(t),u'(t)) \ dt = 0\]
</p>

<p>
Nous pouvons même multiplier \(g_i\) par un multiplicateur de lagrange :
</p>

<p>
\[\lambda_i \in \continue([a,b]\times\setR^2,\setR), \ t \mapsto \lambda_i(t)\]
</p>

<p>
et obtenir le même résultat :
</p>

<p>
\[\int_a^b \lambda_i(t) \cdot g_i(t,u(t),u'(t)) \ dt = 0\]
</p>

<p>
Définissons la fonctionnelle étendue :
</p>

<p>
\[H(u) = \int_a^b \left( f(t, u(t), u'(t)) +
\sum_{i=1}^m \lambda_i(t) \cdot g_i(t,u(t),u'(t)) \right) \ dt\]
</p>

<p>
Comme \(u\) doit respecter les contraintes \(g_i\), on a :
</p>

<p>
\[H(u) = I(u)\]
</p>

<p>
Soit :
</p>

<p>
\[\mathcal{X} = \{ u \in \mathcal{W} : g_i(t,u(t),u'(t)) = 0 \ \ \ \forall i \in \{1,2,...,m\} \}\]
</p>

<p>
et \(w \in \mathcal{X}\). On a :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w) = H(u + \epsilon \cdot w)\]
</p>

<p>
En développant, nous obtenons :
</p>

<p>
\[J_w(\epsilon) = \int_a^b \left(
f(t, u + \epsilon \cdot w, u' + \epsilon \cdot w') +
\sum_{i=1}^m \lambda_i(t) \cdot g_i(t, u + \epsilon \cdot w ,u' + \epsilon \cdot w')
\right) \ dt\]
</p>

<p>
Donc :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = \int_a^b \left[
\deriveepartielle{f}{u}(t,u,u') \cdot w +
\deriveepartielle{f}{v}(t,u,u') \cdot w' +
\sum_{i=1}^m \lambda_i(t) \cdot \deriveepartielle{g_i}{u}(t,u,u') \cdot w +
\sum_{i=1}^m \lambda_i(t) \cdot \deriveepartielle{g_i}{v}(t,u,u') \cdot w' +
\right] dt = 0\]
</p>

<p>
En utilisons l’intégration par parties et les conditions sur \(w\), nous
arrivons à :
</p>

<p>
\[\int_a^b \deriveepartielle{f}{v} \ w' \ dt = - \int_a^b
\OD{}{t} \left[ \deriveepartielle{f}{v} \right] \ w \ dt\]
</p>

<p>
et :
</p>

<p>
\[\int_a^b \lambda_i \cdot \deriveepartielle{g_i}{v} \ w' \ dt = - \int_a^b
\OD{}{t} \left[ \lambda_i \cdot \deriveepartielle{g_i}{v} \right] \ w \ dt\]
</p>

<p>
La condition de stationarité sur \(J_w\) devient alors :
</p>

<p>
\[\int_a^b \left(
\deriveepartielle{f}{u} - \OD{}{t} \deriveepartielle{f}{v} +
\sum_{i=1}^m \lambda_i \cdot \deriveepartielle{g_i}{u} -
\sum_{i=1}^m \OD{}{t} \left[ \lambda_i \cdot \deriveepartielle{g_i}{v} \right]
\right) \ w \ dt = 0\]
</p>

<p>
Comme cette équation est valable pour tout les \(w\) dans \(\mathcal{W}\),
on en déduit que \(u\) vérifie l'équation différentielle d’Euler -
Lagrange sous contrainte :
</p>

<p>
\[\deriveepartielle{f}{u} - \OD{}{t} \deriveepartielle{f}{v} +
\sum_{i=1}^m \lambda_i \cdot \deriveepartielle{g_i}{u} -
\sum_{i=1}^m \OD{}{t} \left[ \lambda_i \cdot \deriveepartielle{g_i}{v} \right] = 0\]
</p>

<p>
où les dérivées de \(f\) et des \(g_i\) sont bien entendu évaluées en
\((t,u(t),u'(t))\).
</p>
</div>
</div>
</div>


<div id="outline-container-org8a1b273" class="outline-3">
<h3 id="org8a1b273"><span class="section-number-3">1.5</span> Sturm-Liouville</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Nous considérons à présent une application importante du théorème
de Lax-milgram. Soit l'espace :
</p>

<p>
\[F = \{u \in \continue^2([a,b],\setR) : u(a) = u(b) = 0\}\]
</p>

<p>
et les fonctions :
</p>

<p>
\[p, q, f : \setR \mapsto \setR\]
</p>

<p>
Considérons la fonctionnelle \(\mathcal{L} : F \mapsto \Cont([a,b],\setR)\) définie par :
</p>

<p>
\[\mathcal{L}(u) = \OD{}{t}\left[p \cdot \OD{u}{t} \right] - q \cdot u + f \\\]
</p>

<p>
et le problème différentiel avec conditions aux limites associé :
</p>

\begin{align}
\mathcal{L}(u) &= 0 \\
u(a) = u(b) &= 0
\end{align}

<p>
Choisissons \(v\in F\) et intégrons l'équation :
</p>

<p>
\[\mathcal{L}(u) \cdot v = 0\]
</p>

<p>
sur \([a,b]\). On obtient :
</p>

<p>
\[- \int_a^b \OD{}{t} \Big[ p(t) \ \OD{u}{t}(t) \Big] \ v(t) \ dt + \int_a^b q(t) \ u(t) \ v(t) \ dt = \int_a^b f(t) \ v(t) \ dt\]
</p>

<p>
Nous allons tenter d'intégrer par parties. On a :
</p>

<p>
\[\OD{}{t} \Big[ p(t) \ \OD{u}{t}(t) \ v(t) \Big] = \OD{}{t} \Big[ p(t) \ \OD{u}{t}(t) \Big] \ v(t) + p(t) \ \OD{u}{t}(t) \ \OD{v}{t}(t)\]
</p>

<p>
En appliquant le théorème fondamental, on obtient :
</p>

<p>
\[\int_a^b \OD{}{t} \Big[ p(t) \ \OD{u}{t}(t) \ v(t) \Big] \ dt = p(b) \ \OD{u}{t}(b) \ v(b) - p(a) \ \OD{u}{t}(a) \ v(a) = 0\]
</p>

<p>
On en conclut que :
</p>

<p>
\[\int_a^b \OD{}{t} \Big[ p(t) \ \OD{u}{t}(t) \Big] \ v(t) \ dt = - \int_a^b p(t) \ \OD{u}{t}(t) \ \OD{v}{t}(t) \ dt\]
</p>

<p>
L'intégrale de \(\mathcal{L}(u) \cdot v = 0\) devient :
</p>

<p>
\[\int_a^b \Big[ p(t) \ \OD{u}{t}(t) \ \OD{v}{t}(t) + q(t) \ u(t) \ v(t) \Big] \ dt = \int_a^b f(t) \ v(t) \ dt\]
</p>

<p>
Donc, si on définit
</p>

\begin{align}
a(u,v) &= \int_a^b \left[ p(t) \cdot \OD{u}{t}(t) \cdot \OD{v}{t}(t) + q(t) \cdot u(t) \cdot v(t) \right] \ dt \\ \\
b(v) &= \int_a^b f(t) \cdot v(t) \ dt
\end{align}

<p>
on a :
</p>

<p>
\[a(u,v) = b(v)\]
</p>

<p>
pour tout \(v \in F\). En appliquant le théorème de Lax-Milgram, on en déduit que la solution du probléme :
</p>

\begin{align}
\mathcal{L}(u) &= 0 \\
u(a) = u(b) &= 0
\end{align}

<p>
minimise sur \(F\) la fonctionnelle \(I\) définie pour toute fonction \(v \in \continue^2([a,b],\setR)\) par :
</p>

<p>
\[I(v) = \int_a^b \Big[ p(x) \ \left(\OD{v}{x}(x)\right)^2 + q(x) \ v(x)^2 \Big] \ dx - \int_a^b f(x) \ v(x) \ dx\]
</p>
</div>
</div>


<div id="outline-container-orga199adb" class="outline-3">
<h3 id="orga199adb"><span class="section-number-3">1.6</span> Séparation des variables</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Soit les fonctions :
</p>

<p>
\[a, b : \setR \mapsto \setR\]
</p>

<p>
et \(f : \setR^2 \mapsto \setR\) définie par :
</p>

<p>
\[f(t, u) = a(t) \cdot b(u)\]
</p>

<p>
Si \(f\) est lipschitzienne, le probléme différentiel :
</p>

\begin{align}
\OD{u}{t}(t) &= f(t, u(t)) = a(t) \cdot b\big( u(t) \big) \\ \\
u(0) &= u_0
\end{align}

<p>
admet une unique solution. En faisant passer \(u\) dans le premier membre et \(dt\) dans le second, la première équation peut se réécrire symboliquement :
</p>

<p>
\[\frac{du}{a(u)} = b(t) dt\]
</p>

<p>
En intégrant les deux membres, il vient :
</p>

<p>
\[\int_{u(0)}^{u(s)} \frac{du}{A(u)} = \int_0^s B(t) dt\]
</p>
</div>
</div>


<div id="outline-container-orge56f88f" class="outline-3">
<h3 id="orge56f88f"><span class="section-number-3">1.7</span> Dérivées des fonctions usuelles</h3>
<div class="outline-text-3" id="text-1-7">
</div>
<div id="outline-container-org19cc25b" class="outline-4">
<h4 id="org19cc25b"><span class="section-number-4">1.7.1</span> Arcsinus</h4>
<div class="outline-text-4" id="text-1-7-1">
<p>
AFAIRE : ARRANGER LA FIN DU CHAPITRE
</p>

<p>
Soit la relation :
</p>

<div class="org-center">
<p>
\(
y = \sin(x) \\
x = \arcsin(y)
\)
</p>
</div>

<p>
Comme
</p>

<div class="org-center">
<p>
\(
\OD{y}{x} = \cos(x) \\
\sin(x)^2 + \cos(x)^2 = 1
\)
</p>
</div>

<p>
on a 
</p>

<div class="org-center">
<p>
\(
\OD{y}{x} = \sqrt{1-y^2} \\
\OD{}{y}\arcsin(y) = \unsur{\sqrt{1-y^2}}
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org540e494" class="outline-4">
<h4 id="org540e494"><span class="section-number-4">1.7.2</span> Table</h4>
<div class="outline-text-4" id="text-1-7-2">
<div class="org-center">
<p>
\(
\OD{\tan(x)}{x} = 1 + \tan(x)^2 \\
\OD{\arcsin(x)}{x} = \frac{1}{\sqrt{1-x^2}} \\
\OD{\arccos(x)}{x} = -\frac{1}{\sqrt{1-x^2}} \\
\OD{\arctan(x)}{x} = \frac{1}{1+x^2} \\
\)
</p>
</div>

<p>
% <code>=================================================================</code>
</p>

<div class="org-center">
<p>
\(
\cos(x) = \sum_{k=0}^{+\infty} \frac{(-1)^k}{(2k)!} x^{2k} \\
\sin(x) = \sum_{k=0}^{+\infty} \frac{(-1)^k}{(2k+1)!} x^{2k+1}
\)
</p>
</div>

<p>
% <code>=================================================================</code>
</p>
</div>
</div>


<div id="outline-container-orgcf50852" class="outline-4">
<h4 id="orgcf50852"><span class="section-number-4">1.7.3</span> Fonctions usuelles</h4>
<div class="outline-text-4" id="text-1-7-3">
<p>
Le théorème fondamental appliqué aux dérivées des fonctions usuelles du chapitre \ref{chap:differ}
nous permet d'obtenir les résultats suivants :
</p>

<div class="org-center">
<p>
\(
\int_0^x {\frac{1}{\sqrt{1-\xi^2}}d\xi} = \arcsin(x) \\
\int_0^x {\frac{1}{1+\xi^2}d\xi} = \arctan(x)
\)
</p>
</div>
</div>
</div>
</div>
</div>


<div id="outline-container-org9e33afa" class="outline-2">
<h2 id="org9e33afa"><span class="section-number-2">2</span> Exponentielle</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents">
<ul>
<li><a href="#org1785c5e">2.1. Dépendances</a></li>
<li><a href="#orgd56c8a7">2.2. Introduction</a></li>
<li><a href="#org29f0e3a">2.3. Développement de Taylor</a></li>
<li><a href="#orga822d1a">2.4. Additivité</a></li>
<li><a href="#org4f4838e">2.5. Miroir</a></li>
<li><a href="#org786ffaa">2.6. Limites</a></li>
<li><a href="#org16d2d97">2.7. Image</a></li>
<li><a href="#org0a60b40">2.8. Intégrale</a></li>
</ul>
</div>
</div>


<div id="outline-container-org1785c5e" class="outline-3">
<h3 id="org1785c5e"><span class="section-number-3">2.1</span> Dépendances</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:edo} : Équations différentielles ordinaires</li>
</ul>
</div>
</div>



<div id="outline-container-orgd56c8a7" class="outline-3">
<h3 id="orgd56c8a7"><span class="section-number-3">2.2</span> Introduction</h3>
<div class="outline-text-3" id="text-2-2">
<p>
L'exponentielle est définie comme l'unique solution \(\exp : \setR \mapsto \setR\) du problème différentiel :
</p>

\begin{align}
\OD{\exp}{t}(t) &= \exp(t) \\ \\
\exp(0) &= 1
\end{align}
</div>
</div>


<div id="outline-container-org29f0e3a" class="outline-3">
<h3 id="org29f0e3a"><span class="section-number-3">2.3</span> Développement de Taylor</h3>
<div class="outline-text-3" id="text-2-3">
<p>
On a :
</p>

<p>
\[\OD{\exp}{t}(0) = \exp(0) = 1\]
</p>

<p>
On montre par récurrence que :
</p>

<p>
\[\NOD{\exp}{t}{k}(0) = \NOD{\exp}{t}{k - 1}(0) = 1\]
</p>

<p>
Le développement de Taylor autour de \(0\) s'écrit donc :
</p>

<p>
\[\exp(t) = \sum_{k = 0}^{+\infty} \frac{t^k}{k !}\]
</p>
</div>
</div>


<div id="outline-container-orga822d1a" class="outline-3">
<h3 id="orga822d1a"><span class="section-number-3">2.4</span> Additivité</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Soit \(t \in \setR\). On remarque que les applications \(f,g : \setR \mapsto \setR\) définies par :
</p>

\begin{align}
f &:& s \mapsto \exp(s + t) \\
g &:& s \mapsto \exp(s) \cdot \exp(t)
\end{align}

<p>
pour tout \(s \in \setR\) vérifient :
</p>

\begin{align}
\partial f(s) &= \exp(s + t) = f(s) \\
f(0) &= \exp(0 + t) = \exp(t)
\end{align}

<p>
et :
</p>

\begin{align}
\partial g(s) &= \exp(s) \cdot \exp(t) = g(s) \\
g(0) &= \exp(0) \cdot \exp(t) = 1 \cdot \exp(t) = \exp(t)
\end{align}

<p>
Par unicité de la solution en \(u\) du problème différentiel :
</p>

\begin{align}
\partial u(s) &= u(s) \\
u(0) &= \exp(t)
\end{align}

<p>
on en déduit que :
</p>

<p>
\[\exp(s + t) = \exp(s) \cdot \exp(t)\]
</p>
</div>
</div>


<div id="outline-container-org4f4838e" class="outline-3">
<h3 id="org4f4838e"><span class="section-number-3">2.5</span> Miroir</h3>
<div class="outline-text-3" id="text-2-5">
<p>
On déduit de l'additivité que :
</p>

<p>
\[1 = \exp(0) = \exp(t - t) = \exp(t) \cdot \exp(-t)\]
</p>

<p>
pour tout \(t \in \setR\). On en conclut que :
</p>

<p>
\[\exp(-t) = \unsur{\exp(t)}\]
</p>
</div>
</div>


<div id="outline-container-org786ffaa" class="outline-3">
<h3 id="org786ffaa"><span class="section-number-3">2.6</span> Limites</h3>
<div class="outline-text-3" id="text-2-6">
<p>
On a :
</p>

<p>
\[\lim_{t \to +\infty} \exp(t) = \lim_{t \to +\infty} (1 + t + \frac{t^2}{2} + ...) \ge \lim_{t \to +\infty} t = +\infty\]
</p>

<p>
La limite à l'infini positif est donc infinie :
</p>

<p>
\[\lim_{t \to +\infty} \exp(t) = +\infty\]
</p>

<p>
En utilisant le changement de variable \(t = -s\), on obtient la limite à l'infini négatif :
</p>

<p>
\[\lim_{s \to -\infty} \exp(s) = \lim_{t \to +\infty} \exp(-t) = \lim_{t \to +\infty} \unsur{\exp(t)} = 0\]
</p>
</div>
</div>


<div id="outline-container-org16d2d97" class="outline-3">
<h3 id="org16d2d97"><span class="section-number-3">2.7</span> Image</h3>
<div class="outline-text-3" id="text-2-7">
<p>
Si \(t \ge 0\) il est clair que \(\exp(t) \strictsuperieur 0\) puisqu'il s'agit d'une somme infinie de termes strictement positifs. Si \(s \le 0\), on a \(t = - s \ge 0\) et :
</p>

<p>
\[\exp(s) = \exp(-t) = \unsur{\exp(t)} \strictsuperieur 0\]
</p>

<p>
On en conclut que :
</p>

<p>
\[\exp : \setR \mapsto \setR^+ \setminus \{0\}\]
</p>

<p>
Comme la fonction \(\exp\) est continue et croît avec \(t\) sur \(\setR\) de :
</p>

<p>
\[\lim_{t \to -\infty} \exp(t) = 0\]
</p>

<p>
jusqu'à :
</p>

<p>
\[\lim_{t \to +\infty} \exp(t) = +\infty\]
</p>

<p>
on a :
</p>

<p>
\[\exp(\setR) = \ ]0,+\infty[ \ = \setR^+ \setminus \{ 0 \}\]
</p>
</div>


<div id="outline-container-orgaa9ed8a" class="outline-4">
<h4 id="orgaa9ed8a"><span class="section-number-4">2.7.1</span> Réels positifs</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
Comme la fonction \(\exp\) est continue et croît avec \(t\) sur \(\setR^+\) de :
</p>

<p>
\[\exp(0) = 1\]
</p>

<p>
jusqu'à :
</p>

<p>
\[\lim_{t \to +\infty} \exp(t) = +\infty\]
</p>

<p>
on a :
</p>

<p>
\[\exp(\setR^+) = [1,+\infty[\]
</p>
</div>
</div>


<div id="outline-container-orgfd0f23d" class="outline-4">
<h4 id="orgfd0f23d"><span class="section-number-4">2.7.2</span> Réels négatifs</h4>
<div class="outline-text-4" id="text-2-7-2">
<p>
Comme la fonction \(\exp\) est continue et croît avec \(s\) sur \(\setR^-\) de :
</p>

<p>
\[\lim_{s \to -\infty} \exp(s) = 0\]
</p>

<p>
jusqu'à :
</p>

<p>
\[\exp(0) = 1\]
</p>

<p>
on a :
</p>

<p>
\[\exp(\setR^-) = \ ]0,1]\]
</p>
</div>
</div>
</div>


<div id="outline-container-org0a60b40" class="outline-3">
<h3 id="org0a60b40"><span class="section-number-3">2.8</span> Intégrale</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Comme la fonction \(\exp\) est une primitive d'elle-même, on a :
</p>

<p>
\[\int_a^b \exp(t) \ dt = \exp(b) - \exp(a)\]
</p>

<p>
En faisant tendre \(a\) vers \(-\infty\), on voit que :
</p>

<p>
\[\int_{-\infty}^b \exp(t) \ dt = \lim_{a \to -\infty} } \Big(\exp(b) - \exp(a)\Big) = \exp(b)\]
</p>

<p>
Les autres intégrales à bornes infinies sont infinies :
</p>

<p>
\[\int_{-\infty}^{+\infty} \exp(t) \ dt = \lim_{ \substack{ a \to -\infty \\ b \to +\infty } } \Big(\exp(b) - \exp(a)\Big) = +\infty\]
</p>

<p>
\[\int_a^{+\infty} \exp(t) \ dt = \lim_{b \to +\infty} \Big(\exp(b) - \exp(a)\Big) = +\infty\]
</p>
</div>
</div>
</div>


<div id="outline-container-orga402cba" class="outline-2">
<h2 id="orga402cba"><span class="section-number-2">3</span> Logarithme</h2>
<div class="outline-text-2" id="text-3">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgebc0d37">3.1. Introduction</a></li>
<li><a href="#org4b2099f">3.2. Valeurs particulières</a></li>
<li><a href="#org55d3695">3.3. Dérivée</a></li>
<li><a href="#org8b0971a">3.4. Développement de Taylor</a></li>
<li><a href="#orgaa4e75c">3.5. Additivité</a></li>
<li><a href="#org864bf8e">3.6. Miroir</a></li>
<li><a href="#org87d39bd">3.7. Soustraction</a></li>
<li><a href="#org55bdbbe">3.8. Intégrale de \(x \mapsto 1/x\)</a></li>
<li><a href="#org634a0ea">3.9. Gaussienne</a></li>
</ul>
</div>

<p>
\label{chapter:log}
</p>
</div>


<div id="outline-container-orgebc0d37" class="outline-3">
<h3 id="orgebc0d37"><span class="section-number-3">3.1</span> Introduction</h3>
<div class="outline-text-3" id="text-3-1">
<p>
La fonction \(\exp : \setR \mapsto \setR^+ \setminus \{ 0 \}\) étant strictement croissante et d'image égale à \(\setR^+ \setminus \{ 0 \}\), elle est inversible. On définit le logarithme :
</p>

<p>
\[\ln : \setR^+ \setminus \{ 0 \} \mapsto \setR\]
</p>

<p>
comme la fonction inverse de \(\exp\) :
</p>

<p>
\[\ln = \exp^{-1}\]
</p>

<p>
Pour tout \(x,y \in \setR\) tels que \(y = \exp(x) \strictsuperieur 0\), on a donc :
</p>

<p>
\[\ln(y) = x\]
</p>
</div>
</div>


<div id="outline-container-org4b2099f" class="outline-3">
<h3 id="org4b2099f"><span class="section-number-3">3.2</span> Valeurs particulières</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Le cas particulier \(x = 0\) et \(y = \exp(0) = 1\) nous montre que :
</p>

<p>
\[\ln(1) = 0\]
</p>
</div>
</div>


<div id="outline-container-org55d3695" class="outline-3">
<h3 id="org55d3695"><span class="section-number-3">3.3</span> Dérivée</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Soit les réels \(x,y\) tels que :
</p>

<p>
\[x = \ln(y)\]
</p>

<p>
On a alors par définition  :
</p>

<p>
\[y = \exp(x)\]
</p>

<p>
La dérivée de cette relation s'écrit symboliquement :
</p>

<p>
\[\OD{y}{x} = \exp(x) = y\]
</p>

<p>
Comme la dérivée d'une fonction inverse est l'inverse de la dérivée, on a :
</p>

<p>
\[\OD{x}{y} = \unsur{y}\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\OD{\ln}{y}(y) = \unsur{y}\]
</p>
</div>
</div>


<div id="outline-container-org8b0971a" class="outline-3">
<h3 id="org8b0971a"><span class="section-number-3">3.4</span> Développement de Taylor</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Soit la fonction \(u : \setR \mapsto \setR\) définie par :
</p>

<p>
\[u(t) = \ln(1 + t)\]
</p>

<p>
pour tout réel \(t\). On a :
</p>

<p>
\[u(0) = \ln(1 + 0) = \ln(1) = 0\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\partial u(t) = \unsur{1 + t}\]
</p>

<p>
et en particulier :
</p>

<p>
\[\partial u(0) = \unsur{1 + 0} = 1\]
</p>

<p>
On procède de même pour la dérivée seconde :
</p>

<p>
\[\partial^2 u(t) = -\unsur{(1 + t)^2}\]
</p>

<p>
et en particulier :
</p>

<p>
\[\partial^2 u(0) = -\unsur{(1 + 0)^2} = -1\]
</p>

<p>
on procède de même pour la dérivée tierce :
</p>

<p>
\[\partial^3 u(t) = \frac{2}{(1 + t)^3}\]
</p>

<p>
et en particulier :
</p>

<p>
\[\partial^3 u(0) = \frac{2}{(1 + 0)^3} = 2\]
</p>

<p>
on procède de même pour la dérivée quarte :
</p>

<p>
\[\partial^4 u(t) = \frac{-6}{(1 + t)^4}\]
</p>

<p>
et en particulier :
</p>

<p>
\[\partial^4 u(0) = \frac{-6}{(1 + 0)^4} = -6\]
</p>

<p>
On voit que :
</p>

<p>
\[\partial^k u(0) = (-1)^{1+k} \cdot (k - 1) !\]
</p>

<p>
pour tout \(k \in \setN\) vérifiant \(k \ge 1\). Le développement de Taylor s'écrit donc :
</p>

<p>
\[\ln(1+t) = \sum_{k=1}^{+\infty} \frac{(-1)^{1+k} \cdot (k - 1) !}{k !} \ t^k\]
</p>

<p>
Comme \(k ! = k \cdot (k - 1) !\), on a :
</p>

<p>
\[\frac{(k - 1) !}{k !} = \unsur{k}\]
</p>

<p>
Le développement s'écrit donc finalement :
</p>

<p>
\[\ln(1+t) = \sum_{k=1}^{+\infty} \frac{(-1)^{1+k}}{k} \ t^k\]
</p>

<p>
En posant \(x = 1 + t\), on obtient la forme équivalente :
</p>

<p>
\[\ln(x) = \sum_{k=1}^{+\infty} \frac{(-1)^{1+k}}{k} \ (x - 1)^k\]
</p>
</div>
</div>


<div id="outline-container-orgaa4e75c" class="outline-3">
<h3 id="orgaa4e75c"><span class="section-number-3">3.5</span> Additivité</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Soit \(a, b \in \setR\). En utilisant l'additivité de l'exponentielle, on obtient :
</p>

<p>
\[\exp\Big[\ln(a \cdot b)\Big] = a \cdot b = \exp\big[\ln(a)\big] \cdot \exp\big[\ln(b)\big] = \exp\Big[\ln(a) + \ln(b)\Big]\]
</p>

<p>
En prenant le logarithme de cette égalité, on en déduit que :
</p>

<p>
\[\ln(a \cdot b) = \ln(a) + \ln(b)\]
</p>
</div>
</div>


<div id="outline-container-org864bf8e" class="outline-3">
<h3 id="org864bf8e"><span class="section-number-3">3.6</span> Miroir</h3>
<div class="outline-text-3" id="text-3-6">
<p>
Soit \(a \in \setR\). On a :
</p>

<p>
\[\ln(a) + \ln\left(\unsur{a}\right) = \ln\left(a \cdot \unsur{a}\right) = \ln(1) = 0\]
</p>

<p>
On en conclut que :
</p>

<p>
\[\ln\left(\unsur{a}\right) = - \ln(a)\]
</p>
</div>
</div>


<div id="outline-container-org87d39bd" class="outline-3">
<h3 id="org87d39bd"><span class="section-number-3">3.7</span> Soustraction</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Soit les réels \(a, b\). On a :
</p>

<p>
\[\ln\left(\frac{a}{b}\right) = \ln(a) + \ln\left(\unsur{b}\right) = \ln(a) - \ln(b)\]
</p>
</div>
</div>


<div id="outline-container-org55bdbbe" class="outline-3">
<h3 id="org55bdbbe"><span class="section-number-3">3.8</span> Intégrale de \(x \mapsto 1/x\)</h3>
<div class="outline-text-3" id="text-3-8">
<p>
Comme \(\ln\) est une primitive de la fonction :
</p>

<p>
\[u : \setR \setminus \{ 0 \}, \ x \mapsto 1/x\]
</p>

<p>
On a :
</p>

<p>
\[\int_a^b \unsur{x} \ dx = \ln(b) - \ln(a) = \ln\left[\frac{b}{a}\right]\]
</p>
</div>
</div>


<div id="outline-container-org634a0ea" class="outline-3">
<h3 id="org634a0ea"><span class="section-number-3">3.9</span> Gaussienne</h3>
<div class="outline-text-3" id="text-3-9">
<p>
Soit les réels \(\gamma\) et \(u_0\). Nous cherchons la fonction \(u : \setR \mapsto \setR\) solution du problème différentiel :
</p>

\begin{align}
\OD{u}{t} &= \gamma \cdot t \cdot u \\ \\
u(0) &= u_0
\end{align}

<p>
en procédant par séparation de variables :
</p>

<p>
\[\frac{du}{u} = \gamma \cdot t \ dt\]
</p>

<p>
En intégrant :
</p>

<p>
\[\int_{u_0}^{u(s)} \frac{du}{u} = \int_0^s \gamma \cdot t \ dt\]
</p>

<p>
on obtient :
</p>

<p>
\[\ln(u(s))-\ln(u_0) =  \gamma \cdot \frac{s^2}{2}\]
</p>

<p>
ou :
</p>

<p>
\[\ln\left(\frac{u(s)}{u_0}\right) =  \gamma \cdot \frac{s^2}{2}\]
</p>

<p>
En prenant l'exponentielle, on arrive à la solution :
</p>

<p>
\[u(s) =  u_0 \cdot \exp\left( \gamma \cdot \frac{s^2}{2} \right)\]
</p>

<p>
Une fonction de cette forme est appelée gaussienne.
</p>
</div>
</div>
</div>


<div id="outline-container-orgee91506" class="outline-2">
<h2 id="orgee91506"><span class="section-number-2">4</span> Fonctions hyperboliques</h2>
<div class="outline-text-2" id="text-4">
<div id="text-table-of-contents">
<ul>
<li><a href="#org3b47cdc">4.1. Introduction</a></li>
<li><a href="#org5fb3091">4.2. Relation fondamentale</a></li>
<li><a href="#org5e7d8c6">4.3. Dérivées</a></li>
<li><a href="#org7d95896">4.4. Intégrales</a></li>
<li><a href="#orgd612cf1">4.5. Tangente</a></li>
</ul>
</div>
</div>


<div id="outline-container-org3b47cdc" class="outline-3">
<h3 id="org3b47cdc"><span class="section-number-3">4.1</span> Introduction</h3>
<div class="outline-text-3" id="text-4-1">
<p>
Le cosinus hyperbolique \(\cosh\) est défini comme étant la composante paire de l'exponentielle. On a donc :
</p>

<p>
\[\cosh(x) = \unsur{2} \ \Big[ \exp(x) + \exp(-x) \Big]\]
</p>

<p>
pour tout \(x \in \setR\). Le sinus hyperbolique \(\sinh\) est défini comme étant la composante impaire de l'exponentielle. On a donc :
</p>

<p>
\[\sinh(x) = \unsur{2} \ \Big[ \exp(x) - \exp(-x) \Big]\]
</p>

<p>
pour tout \(x \in \setR\).
</p>
</div>


<div id="outline-container-orgea831ef" class="outline-4">
<h4 id="orgea831ef"><span class="section-number-4">4.1.1</span> Décomposition</h4>
<div class="outline-text-4" id="text-4-1-1">
<p>
On a :
</p>

<p>
\[\exp = \cosh + \sinh\]
</p>

<p>
avec :
</p>

\begin{align}
\cosh(x) &= \cosh(-x) \\
\sinh(x) &= -\sinh(-x)
\end{align}

<p>
pour tout réel \(x\).
</p>
</div>
</div>


<div id="outline-container-org2614515" class="outline-4">
<h4 id="org2614515"><span class="section-number-4">4.1.2</span> Valeurs particulières</h4>
<div class="outline-text-4" id="text-4-1-2">
<p>
On a :
</p>

<p>
\[\cosh(0) = \unsur{2} \Big[ \exp(0) + \exp(0) \Big] = \unsur{2} (1 + 1) = 1\]
</p>

<p>
et :
</p>

<p>
\[\sinh(0) = \unsur{2} \Big[ \exp(0) - \exp(0) \Big] = 0\]
</p>
</div>
</div>
</div>


<div id="outline-container-org5fb3091" class="outline-3">
<h3 id="org5fb3091"><span class="section-number-3">4.2</span> Relation fondamentale</h3>
<div class="outline-text-3" id="text-4-2">
<p>
Soit un réel \(x\) et :
</p>

<div class="org-center">
<p>
\(
c = \cosh(x) \\
s = \sinh(x)
\)
</p>
</div>

<p>
Le carré du cosinus hyperbolique se développe en :
</p>

<p>
\[c^2 = \unsur{4} \ \Big[ \exp(x)^2 + 2 \ \exp(x) \cdot \exp(-x) + \exp(-x)^2 \Big]\]
</p>

<p>
Comme \(\exp(x) \cdot \exp(-x) = 1\), le développement devient :
</p>

<p>
\[c^2 = \unsur{4} \ \Big[ \exp(x)^2  + \exp(-x)^2 + 2\Big]\]
</p>

<p>
Le carré du sinus hyperbolique se développe en :
</p>

<p>
\[s^2 = \unsur{4} \ \Big[ \exp(x)^2 - 2 \ \exp(x) \cdot \exp(-x) + \exp(-x)^2 \Big]\]
</p>

<p>
Comme \(\exp(x) \cdot \exp(-x) = 1\), le développement devient :
</p>

<p>
\[s^2 = \unsur{4} \ \Big[ \exp(x)^2  + \exp(-x)^2 - 2\Big]\]
</p>

<p>
En soustrayant ces deux équations, on obtient :
</p>

\begin{align}
c^2 - s^2 &= \frac{\exp(x)^2  + \exp(-x)^2 + 2 - \exp(x)^2  - \exp(-x)^2 + 2}{4} \\
&= \frac{4}{4} = 1
\end{align}

<p>
On a donc :
</p>

<p>
\[\cosh(x)^2 - \sinh(x)^2 = 1\]
</p>
</div>
</div>


<div id="outline-container-org5e7d8c6" class="outline-3">
<h3 id="org5e7d8c6"><span class="section-number-3">4.3</span> Dérivées</h3>
<div class="outline-text-3" id="text-4-3">
<p>
Pour tout réel \(x\), on a :
</p>

<p>
\[\OD{\cosh}{x}(x) = \unsur{2} \Big[ \exp(x) - \exp(-x) \Big] = \sinh(x)\]
</p>

<p>
et :
</p>

<p>
\[\OD{\sinh}{x}(x) = \unsur{2} \Big[ \exp(x) + \exp(-x) \Big] = \cosh(x)\]
</p>
</div>
</div>


<div id="outline-container-org7d95896" class="outline-3">
<h3 id="org7d95896"><span class="section-number-3">4.4</span> Intégrales</h3>
<div class="outline-text-3" id="text-4-4">
<p>
Comme \(\sinh\) est une primitive de \(\cosh\), on a :
</p>

<p>
\[\int_a^b \cosh(x) \ dx = \sinh(b) - \sinh(a)\]
</p>

<p>
Comme \(\cosh\) est une primitive de \(\sinh\), on a :
</p>

<p>
\[\int_a^b \sinh(x) \ dx = \cosh(b) - \cosh(a)\]
</p>
</div>
</div>


<div id="outline-container-orgd612cf1" class="outline-3">
<h3 id="orgd612cf1"><span class="section-number-3">4.5</span> Tangente</h3>
<div class="outline-text-3" id="text-4-5">
<p>
La tangente hyperbolique \(\tanh\) est définie par :
</p>

<p>
\[\tanh(x) = \frac{\sinh x}{\cosh x}\]
</p>

<p>
pour tout \(x \in \setR\).
</p>
</div>


<div id="outline-container-org4f63a1d" class="outline-4">
<h4 id="org4f63a1d"><span class="section-number-4">4.5.1</span> Dérivée</h4>
<div class="outline-text-4" id="text-4-5-1">
<p>
On a :
</p>

<p>
\[\OD{\tanh}{x}(x) = \frac{\cosh(x)}{\cosh(x)} - \frac{\sinh(x) \cdot \sinh(x)}{\cosh(x)^2} = 1 - \tanh(x)^2\]
</p>
</div>
</div>


<div id="outline-container-org9a76402" class="outline-4">
<h4 id="org9a76402"><span class="section-number-4">4.5.2</span> Problème différentiel</h4>
<div class="outline-text-4" id="text-4-5-2">
<p>
Comme :
</p>

<p>
\[\tanh(0) = \frac{\sinh(0)}{\cosh(0)} = \frac{0}{1} = 0\]
</p>

<p>
la tangente hyperbolique est solution \(u : \setR \mapsto \setR\) du problème différentiel :
</p>

\begin{align}
\partial u(t) &= 1 - u(t)^2 \\
u(0) &= 0
\end{align}

<p>
vérifié pour tout \(t \in \setR\).
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orgf93705e" class="outline-2">
<h2 id="orgf93705e"><span class="section-number-2">5</span> Exponentielle matricielle</h2>
<div class="outline-text-2" id="text-5">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgbc836a5">5.1. Introduction</a></li>
<li><a href="#org6f843b6">5.2. Matrice nulle</a></li>
<li><a href="#org5d3de08">5.3. Développement de Taylor</a></li>
<li><a href="#org8580456">5.4. Développement en série de l'exponentielle</a></li>
<li><a href="#orga86433b">5.5. Additivité</a></li>
<li><a href="#orge0072ec">5.6. Miroir</a></li>
<li><a href="#org848beb4">5.7. Solution vectorielle</a></li>
<li><a href="#org9458119">5.8. Valeurs propres</a></li>
<li><a href="#org1f56773">5.9. Dérivée</a></li>
<li><a href="#org1f1847f">5.10. Intégrale</a></li>
<li><a href="#org5ae77fb">5.11. Systèmes linéaires</a></li>
<li><a href="#orgb8c651b">5.12. Conditions initiales</a></li>
</ul>
</div>

<p>
\label{chap:expomat}
</p>
</div>


<div id="outline-container-orgbc836a5" class="outline-3">
<h3 id="orgbc836a5"><span class="section-number-3">5.1</span> Introduction</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Soit une matrice \(A\in\mathfrak{M}(\setR,n,n)\) et la fonction :
</p>

<p>
\[E_A : \setR \mapsto \in\mathfrak{M}(\setR,n,n)\]
</p>

<p>
définie comme étant l'unique solution de :
</p>

<div class="org-center">
<p>
\(
\OD{E_A}{t} = A \cdot E_A \\ \\
E_A(0) = I
\)
</p>
</div>

<p>
On définit alors l'exponentielle matricielle par :
</p>

<p>
\[\exp(A) = E_A(1)\]
</p>
</div>
</div>


<div id="outline-container-org6f843b6" class="outline-3">
<h3 id="org6f843b6"><span class="section-number-3">5.2</span> Matrice nulle</h3>
<div class="outline-text-3" id="text-5-2">
<p>
Dans le cas où \(A = 0\), on a :
</p>

<p>
\[\OD{E_0}{t} = 0 \cdot E_0 = 0\]
</p>

<p>
En intégrant, on voit que :
</p>

<p>
\[E_0(t) - E_0(0) = \int_0^t 0 \ dt = 0\]
</p>

<p>
La fonction \(E_0\) est donc constante et vaut \(E_0(t) = E_0(0) = I\) pour tout \(t \in \setR\). On en conclut que :
</p>

<p>
\[\exp(0) = I\]
</p>
</div>
</div>


<div id="outline-container-org5d3de08" class="outline-3">
<h3 id="org5d3de08"><span class="section-number-3">5.3</span> Développement de Taylor</h3>
<div class="outline-text-3" id="text-5-3">
<p>
Soit la fonction :
</p>

<p>
\[u : \setR \mapsto \matrice(\setR, n, n), \ t \mapsto \exp(A \cdot t)\]
</p>

<p>
On a :
</p>

<p>
\[u(0) = \exp(A \cdot 0) = \exp(0) = I\]
</p>

<p>
et :
</p>

<p>
\[\OD{u}{t}(0) = A \cdot u(0) = A \cdot I = A\]
</p>

<p>
On montre par récurrence que :
</p>

<p>
\[\NOD{u}{t}{k}(0) = A \cdot \NOD{u}{t}{k - 1}(0) = A \cdot A^{k - 1} = A^k\]
</p>

<p>
En évaluant le développement de Taylor de \(u\) autour de \(t=0\) on obtient :
</p>

<p>
\[\exp(A \cdot t) = \sum_{k=0}^{+\infty} \frac{1}{k!} \cdot A^k \cdot t^k\]
</p>

<p>
Évaluons la dérivée de ce développement :
</p>

\begin{align}
\OD{}{t} \exp(A \cdot t) &= \sum_{k=1}^{+\infty} \unsur{k!} \cdot A^k \cdot k \cdot t^{k - 1} \\
&= A \cdot \sum_{k=1}^{+\infty} \unsur{(k - 1) !} \cdot A^{k - 1} \cdot t^{k - 1} \\
&= A \cdot \sum_{k=0}^{+\infty} \unsur{k!} \cdot A^k \cdot k \cdot t^k \\
&= A \cdot \exp(A \cdot t)
\end{align}

<p>
On a aussi :
</p>

<p>
\[\exp(A \cdot 0) &= I + \sum_{k=1}^{+\infty} \unsur{k!} \cdot A^k \cdot 0^k = I\]
</p>

<p>
La fonction \(t \mapsto \exp(A \cdot t)\) est donc identique à la solution \(E\) :
</p>

<p>
\[E(t) = \exp(A \cdot t)\]
</p>
</div>
</div>


<div id="outline-container-org8580456" class="outline-3">
<h3 id="org8580456"><span class="section-number-3">5.4</span> Développement en série de l'exponentielle</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Le cas particulier \(t = 1\) nous donne le développement de l'exponentielle matricielle :
</p>

<p>
\[\exp(A) = \sum_{k=0}^{+\infty} \frac{1}{k!} \cdot A^k\]
</p>
</div>


<div id="outline-container-orgf23e38d" class="outline-5">
<h5 id="orgf23e38d"><span class="section-number-5">5.4.0.1</span> Sur \(\setR\)</h5>
<div class="outline-text-5" id="text-5-4-0-1">
<p>
Quand \(n=1\) et \(A=1\), on retrouve le développement de l'exponentielle usuelle :
</p>

<p>
\[\exp(t) = \sum_{k=0}^{+\infty} \frac{t^k}{k!}\]
</p>
</div>
</div>
</div>


<div id="outline-container-orga86433b" class="outline-3">
<h3 id="orga86433b"><span class="section-number-3">5.5</span> Additivité</h3>
<div class="outline-text-3" id="text-5-5">
<p>
Soit les fonctions \(f, g : \setR \mapsto \setR\) définies par :
</p>

\begin{align}
f &:& s \mapsto \exp\Big(A \cdot (s + t) \Big) \\
g &:& s \mapsto \exp(A \cdot s) \cdot \exp(A \cdot t)
\end{align}

<p>
pour tout \(s \in \setR\). On a :
</p>

\begin{align}
\partial f(s) &= A \cdot \exp\Big(A \cdot (s + t) \Big) = A \cdot f(s) \\
f(0) &= \exp\Big(A \cdot (0 + t) \Big) = \exp(A \cdot t)
\end{align}

<p>
et :
</p>

\begin{align}
\partial g(s) &= A \cdot \exp(A \cdot s) \cdot \exp(t) = A \cdot g(s) \\
g(0) &= \exp(A \cdot 0) \cdot \exp(A \cdot t) = I \cdot \exp(A \cdot t) = \exp(A \cdot t)
\end{align}

<p>
Par unicité de la solution en \(u\) du problème différentiel :
</p>

\begin{align}
\partial u(s) &= A \cdot u(s) \\
u(0) &= \exp(A \cdot t)
\end{align}

<p>
on en déduit que :
</p>

<p>
\[\exp\Big(A \cdot (s + t) \Big) = \exp(A \cdot s) \cdot \exp(A \cdot t)\]
</p>
</div>
</div>


<div id="outline-container-orge0072ec" class="outline-3">
<h3 id="orge0072ec"><span class="section-number-3">5.6</span> Miroir</h3>
<div class="outline-text-3" id="text-5-6">
<p>
L'additivité nous dit que :
</p>

<p>
\[\exp(A \cdot (t - t)) = \exp(A \cdot t) \cdot \exp(A \cdot (-t)) = \exp(A \cdot t) \cdot \exp(- A \cdot t)\]
</p>

<p>
Mais la condition initiale nous dit que :
</p>

<p>
\[\exp(A \cdot (t - t)) = \exp(A \cdot 0) = I\]
</p>

<p>
On a donc :
</p>

<p>
\[\exp(A \cdot t) \cdot \exp(- A \cdot t) = I\]
</p>

<p>
Comme les matrices sont carrées, on en déduit que l'inverse matriciel de \(\exp(A \cdot t)\) existe et s'écrit :
</p>

<p>
\[\exp(A \cdot t)^{-1} = \exp(- A \cdot t)\]
</p>

<p>
Le cas particulier \(t = 1\) nous donne :
</p>

<p>
\[\exp(A)^{-1} = \exp(- A)\]
</p>
</div>
</div>


<div id="outline-container-org848beb4" class="outline-3">
<h3 id="org848beb4"><span class="section-number-3">5.7</span> Solution vectorielle</h3>
<div class="outline-text-3" id="text-5-7">
<p>
Soit un vecteur \(x_0 \in \setR^n\) et la fonction \(x : \setR \mapsto \setR^n\) définie par :
</p>

<p>
\[x(t) = \exp(A \cdot t) \cdot x_0\]
</p>

<p>
pour tout \(t \in \setR\). On a :
</p>

<p>
\[\dot{x}(t) = A \cdot \exp(A \cdot t) \cdot x_0 = A \cdot x\]
</p>

<p>
et :
</p>

<p>
\[x(0) = \exp(A \cdot 0) \cdot x_0 = I \cdot x_0 = x_0\]
</p>

<p>
Notre fonction \(x\) est donc l'unique solution de l'équation différentielle :
</p>

<div class="org-center">
<p>
\(
\OD{x}{t} = A \cdot x \\ \\
x(0) = x_0
\)
</p>
</div>
</div>


<div id="outline-container-orgc42b45e" class="outline-5">
<h5 id="orgc42b45e"><span class="section-number-5">5.7.0.1</span> Sur \(\setR\)</h5>
<div class="outline-text-5" id="text-5-7-0-1">
<p>
Dans le cas où \(n=1\), et \(A = 1\), on obtient l'exponentielle
usuelle, qui est donc solution de :
</p>

\begin{align}
\dot{u} &= u \\
u(0) &= 1
\end{align}
</div>
</div>
</div>


<div id="outline-container-org9458119" class="outline-3">
<h3 id="org9458119"><span class="section-number-3">5.8</span> Valeurs propres</h3>
<div class="outline-text-3" id="text-5-8">
<p>
Il existe un lien entre l'exponentielle d'une matrice hermitienne et ses valeurs propres. Soit la fonction \(X : \setR \mapsto \setR^n\) vérifiant l'équation différentielle :
</p>

<p>
\[\dot{X}(t) = A \cdot X(t)\]
</p>

<p>
où \(A\) est une matrice carrée hermitienne. Comme \(A = A^\dual\), on sait que la forme de Schur :
</p>

<p>
\[A = U \cdot \Lambda \cdot U^\dual\]
</p>

<p>
nous donne une matrice carrée unitaire \(U\) qui vérifie par conséquent :
</p>

<p>
\[U^\dual = U^{-1}\]
</p>

<p>
et une matrice diagonale :
</p>

<p>
\[\Lambda = (\lambda_i \cdot \delta_{ij})_{i,j}\]
</p>

<p>
où les \(\lambda_i\) sont les valeurs propres de \(A\). Si on effectue le changement de variable :
</p>

<p>
\[X = U \cdot Y \quad\Leftrightarrow\quad Y = U^\dual \cdot X\]
</p>

<p>
l'équation différentielle devient :
</p>

<p>
\[U \cdot \dot{Y} = A \cdot U \cdot Y \\\]
</p>

<p>
En multipliant à gauche par \(U^\dual\), on obtient :
</p>

<p>
\[\dot{Y} = U^\dual \cdot A \cdot U \cdot Y = \Lambda \cdot Y\]
</p>

<p>
Exprimée en terme de composantes \(Y = (y_i)_i\), cette dernière équation devient :
</p>

<p>
\[\dot{y}_i = \lambda_i \cdot y_i\]
</p>

<p>
dont la solution est :
</p>

<p>
\[y_i(t) = y_{i}(0) \cdot \exp(\lambda_i \cdot t)\]
</p>

<p>
Comme :
</p>

<p>
\[\sum_k \unsur{k !} \ \Lambda^k \cdot t^k = \Bigg( \sum_k \unsur{k !} \ \lambda_i^k \cdot t^k \cdot \indicatrice_{ij} \Bigg)_{i,j}\]
</p>

<p>
on voit que :
</p>

<p>
\[\exp(\Lambda \cdot t) = \Big( \exp(\lambda_i \cdot t) \cdot \indicatrice_{ij} \Big)_{i,j}\]
</p>

<p>
On en conclut que :
</p>

<p>
\[Y(t) = \exp(\Lambda \cdot t) \cdot Y(0)\]
</p>

<p>
La condition initiale sur \(Y\) est liée à celle sur \(X\) par :
</p>

<p>
\[Y(0) = U^\dual \cdot X(0)\]
</p>

<p>
On a donc :
</p>

<p>
\[Y(t) = \exp(\Lambda \cdot t) \cdot U^\dual \cdot X(0)\]
</p>

<p>
et :
</p>

<p>
\[X(t) = U \cdot Y(t) = U \cdot \exp(\Lambda \cdot t) \cdot U^\dual \cdot X(0)\]
</p>

<p>
Par définition de l'exponentielle matricielle, on a aussi :
</p>

<p>
\[X(t) = \exp(A \cdot t) \cdot X(0)\]
</p>

<p>
On en conclut que :
</p>

<p>
\[\exp(A \cdot t) \cdot X(0) = U \cdot \exp(\Lambda \cdot t) \cdot U^\dual \cdot X(0)\]
</p>

<p>
Au point \(t = 1\), on a :
</p>

<p>
\[\exp(A) \cdot X(0) = U \cdot \exp(\Lambda) \cdot U^\dual \cdot X(0)\]
</p>

<p>
Cette relation étant vérifiée quelque soit \(X(0) \in \setR^n\), on en conclut la relation liant
l'exponentielle d'une matrice hermitienne à ses valeurs propres :
</p>

<p>
\[\exp(A) = U \cdot \exp(\Lambda) \cdot U^\dual\]
</p>
</div>
</div>


<div id="outline-container-org1f56773" class="outline-3">
<h3 id="org1f56773"><span class="section-number-3">5.9</span> Dérivée</h3>
<div class="outline-text-3" id="text-5-9">
<p>
AFAIRE : dérivée de u(t) = exp( L(t) ), arranger la fin du chapitre
</p>

<p>
\[\OD{u}{t}(t) = \OD{L}{t}(t) \cdot u(t)\] ???????
</p>
</div>
</div>


<div id="outline-container-org1f1847f" class="outline-3">
<h3 id="org1f1847f"><span class="section-number-3">5.10</span> Intégrale</h3>
<div class="outline-text-3" id="text-5-10">
<p>
Soit la fonction \(R\) :
</p>

<p>
\[R : \setR\mapsto\mathfrak{M}(\setR,n,n)\]
</p>

<p>
solution de :
</p>

\begin{align}
\dot{R}(t) &= L(t) \cdot R(t) \\
R(0) &= I
\end{align}

<p>
On vérifie que :
</p>

<p>
\[R(t) = \exp\int_0^t L(s) ds\]
</p>
</div>
</div>


<div id="outline-container-org5ae77fb" class="outline-3">
<h3 id="org5ae77fb"><span class="section-number-3">5.11</span> Systèmes linéaires</h3>
<div class="outline-text-3" id="text-5-11">
<p>
\label{sec:edo_sys_lin}
</p>

<p>
Considérons à présent le problème linéaire suivant :
</p>

<div class="org-center">
<p>
\(
\dot{u}(t) = L(t) \cdot u(t) + b(t) \\ \\
u(0) = u_0
\)
</p>
</div>

<p>
où on a :
</p>

\begin{align}
L &:& \setR\mapsto\mathfrak{M}(\setR,n,n) \\
b &:& \setR\mapsto\mathfrak{M}(\setR,n,1) \equiv \setR^n \\
u &:& \setR\mapsto\mathfrak{M}(\setR,n,1) \equiv \setR^n
\end{align}

<p>
Nous allons effectuer un changement de variable afin de résoudre ce problème.
Nous supposons par la suite que \(R(t)\) est inversible pour tout \(t\).
Posons \(u = R \cdot x\). On constate tout de suite en utilisant \(R(0) = I\) que
\(x(0) = u_0\).  On obtient aussi, en dérivant \(u = R \cdot x\) :
</p>

<p>
\[\dot{u} = \dot{R} \cdot x + R \cdot \dot{x} = L \cdot R \cdot x + R \cdot \dot{x}\]
</p>

<p>
En comparant avec l'équation différentielle dont \(u\) est solution :
</p>

<p>
\[\dot{u} = L \cdot u + b = L \cdot R \cdot x + b\]
</p>

<p>
on obtient :
</p>

<div class="org-center">
<p>
\(
\dot{x} = R^{-1} \cdot b \\
x(0) = u_0
\)
</p>
</div>

<p>
On en déduit que :
</p>

<p>
\[x(t) = u_0 + \int_0^t \left[ R(s) \right]^{-1} \cdot b(s) ds\]
</p>

<p>
et :
</p>

<p>
\[u(t) = R(t) \cdot u_0 + \int_0^t R(t) \cdot [R(s)]^{-1} \cdot b(s) ds\]
</p>

<p>
Dans le cas où \(L(t) = L\) ne dépend pas de \(t\), on peut montrer
que
</p>

<p>
\[R(s+t) = R(s) \cdot R(t)\]
</p>

<p>
en vérifiant que \(\varphi(s) = R(s+t)\) et \(\psi(s) = R(s) \cdot R(t)\)
sont solutions en \(w\) de :
</p>

<div class="org-center">
<p>
\(
\OD{w}{s}(s) = L \cdot w(s) \\ \\
w(0) = R(t)
\)
</p>
</div>

<p>
On a alors évidemment \(R(-s) = [R(s)]^{-1}\) et
</p>

<p>
\[u(t) = R(t) \cdot u_0 + \int_0^t R(t-s) \cdot b(s) ds\]
</p>

<p>
La solution est donc donnée par l'intégrale de convolution de \(R\) et \(b\).
</p>
</div>
</div>


<div id="outline-container-orgb8c651b" class="outline-3">
<h3 id="orgb8c651b"><span class="section-number-3">5.12</span> Conditions initiales</h3>
<div class="outline-text-3" id="text-5-12">
<p>
Nous allons à présent étudier ce qu'il se passe lorsqu'on dérive la solution par rapport à la condition initiale \(u_0 = x\). Posons \(u(x,t)\) la solution de :
</p>

<div class="org-center">
<p>
\(
\deriveepartielle{u}{t}(x,t) = f(t,u(x,t)) \\
u(x,0) = x
\)
</p>
</div>

<p>
Nous allons utiliser la notation
</p>

<p>
\[u_x(x,t) = \deriveepartielle{u}{x^T}(x,t)\]
</p>

<p>
En intervertissant l'ordre de dérivation, on arrive à
</p>

<div class="org-center">
<p>
\(
\deriveepartielle{u_x}{t}(x,t) = \deriveepartielle{}{x^T}\deriveepartielle{u}{t}(x,t) \\
\deriveepartielle{u_x}{t}(x,t) = \deriveepartielle{f}{u^T}(t,u(x,t)) \cdot u_x(x,t)
\)
</p>
</div>

<p>
Par ailleurs, il est clair que :
</p>

<p>
\[u_x(x,0) = I\]
</p>

<p>
Utilisant les résultats de la section \ref{sec:edo_sys_lin} avec :
</p>

<div class="org-center">
<p>
\(
L(t) \mapsto \deriveepartielle{f}{u^T}(t,u(x,t)) \\
R(t) \mapsto u_x(x,t)
\)
</p>
</div>

<p>
nous obtenons :
</p>

<p>
\[u_x(x,t) = \exp\int_0^t \deriveepartielle{f}{u^T}(s,u(x,s)) ds\]
</p>
</div>
</div>
</div>


<div id="outline-container-orgdd4ab04" class="outline-2">
<h2 id="orgdd4ab04"><span class="section-number-2">6</span> Fonctions trigonométriques</h2>
<div class="outline-text-2" id="text-6">
<div id="text-table-of-contents">
<ul>
<li><a href="#org00d3041">6.1. Dépendances</a></li>
<li><a href="#org412a127">6.2. Introduction</a></li>
<li><a href="#org18d5b40">6.3. Angle nul</a></li>
<li><a href="#orgb0bf172">6.4. Produit scalaire</a></li>
<li><a href="#orgaae41c2">6.5. Différentielle</a></li>
<li><a href="#org0c89bbb">6.6. Additivité</a></li>
<li><a href="#orge4072cf">6.7. Dérivées</a></li>
<li><a href="#org8cd7ddb">6.8. Équations différentielles</a></li>
<li><a href="#org6fde53d">6.9. Racines</a></li>
<li><a href="#org1580aec">6.10. Périodicité</a></li>
<li><a href="#org60d5dff">6.11. Angle double</a></li>
<li><a href="#orgccc580c">6.12. Intégrale</a></li>
<li><a href="#orgd0e2691">6.13. Tangente</a></li>
<li><a href="#org3e13fd8">6.14. Angle entre vecteurs</a></li>
<li><a href="#orgcb5c1fe">6.15. Angles entre espaces</a></li>
<li><a href="#orgb7e9aaf">6.16. Coordonnées polaires</a></li>
</ul>
</div>
</div>


<div id="outline-container-org00d3041" class="outline-3">
<h3 id="org00d3041"><span class="section-number-3">6.1</span> Dépendances</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:complexe} : Les complexes</li>
</ul>
</div>
</div>



<div id="outline-container-org412a127" class="outline-3">
<h3 id="org412a127"><span class="section-number-3">6.2</span> Introduction</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Les fonctions trigonométriques cosinus (\(\cos\)), sinus (\(\sin\)) et associées peuvent se définir
à partir des rotations dans le plan \(\setR^2\). Pour cela, commençons par définir ce qu'est
une rotation. Soit la fonction :
</p>

<p>
\[Q : \setR\mapsto \matrice(\setR, 2, 2), \qquad \theta \mapsto Q(\theta)\]
</p>

<p>
qui associe à chaque valeur de l'angle de rotation \(\theta \in \setR\) une matrice carrée réelle représentant une rotation dans le plan \(\setR^2\).
</p>
</div>
</div>


<div id="outline-container-org18d5b40" class="outline-3">
<h3 id="org18d5b40"><span class="section-number-3">6.3</span> Angle nul</h3>
<div class="outline-text-3" id="text-6-3">
<p>
Il semble logique de demander qu'une rotation d'angle \(0\) d'un vecteur ne modifie pas ce vecteur, c'est-à-dire :
</p>

<p>
\[Q(0) = I\]
</p>
</div>
</div>


<div id="outline-container-orgb0bf172" class="outline-3">
<h3 id="orgb0bf172"><span class="section-number-3">6.4</span> Produit scalaire</h3>
<div class="outline-text-3" id="text-6-4">
<p>
Une rotation doit conserver les angles entre les vecteurs, ainsi que leur norme. Autrement dit, le produit scalaire sur \(\setR^2\) :
</p>

<p>
\[\scalaire{x}{y} = x^\dual \cdot y\]
</p>

<p>
doit être conservé :
</p>

<p>
\[\scalaire{Q(\theta) \cdot x}{Q(\theta) \cdot y} = \scalaire{x}{y}\]
</p>

<p>
pour tout \(x,y\in\setR^2\), c'est-à-dire :
</p>

<p>
\[(Q(\theta) \cdot x)^\dual \cdot (Q(\theta) \cdot y) = x^\dual \cdot Q(\theta)^\dual \cdot Q(\theta) \cdot y = x^\dual \cdot y\]
</p>

<p>
On en déduit que :
</p>

<p>
\[Q(\theta)^\dual \cdot Q(\theta) = I\]
</p>

<p>
Comme \(Q(\theta)\) est carrée, on a :
</p>

<p>
\[Q(\theta)^\dual  = Q(\theta)^{-1}\]
</p>

<p>
où le \(^{-1}\) désigne l'inverse matriciel. Quelques calculs suffisent à nous montrer que pour satisfaire cette condition, la forme de la matrice doit être l'une des deux solutions suivantes :
</p>

<div class="org-center">
<p>
\(
</p>
\begin{Matrix}{cc}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{Matrix}
<p>
\qquad\mathrm{ou}\qquad
</p>
\begin{Matrix}{cc}
\cos(\theta) & \sin(\theta) \\
\sin(\theta) & -\cos(\theta)
\end{Matrix}
<p>
\)
</p>
</div>

<p>
où \(\cos, \sin : \setR \mapsto \setR\) sont des fonctions à déterminer vérifiant la relation fondamentale :
</p>

<p>
\[\cos(\theta)^2 + \sin(\theta)^2 = 1\]
</p>

<p>
Mais comme \(Q(0)=I\), l'élément \((1,1)\) de la matrice doit être identique à l'élément
\((2,2)\) et on a :
</p>

<div class="org-center">
<p>
\(
Q(&theta;) =
</p>
\begin{Matrix}{cc}
\cos(\theta) & -\sin(\theta) \\
\sin(\theta) & \cos(\theta)
\end{Matrix}
<p>
\)
</p>
</div>

<p>
avec :
</p>

<div class="org-center">
<p>
\(
\cos(0) = 1 \\
\sin(0) = 0
\)
</p>
</div>
</div>


<div id="outline-container-orgc446b73" class="outline-4">
<h4 id="orgc446b73"><span class="section-number-4">6.4.1</span> Relation fondamentale et bornes</h4>
<div class="outline-text-4" id="text-6-4-1">
<p>
Soit \(x \in \setR\). Comme les fonctions \(\cos\) et \(\sin\) sont à valeurs dans \(\setR\), on a :
</p>

<div class="org-center">
<p>
\(
\cos(x)^2 \ge 0 \\
\sin(x)^2 \ge 0
\)
</p>
</div>

<p>
On déduit de la relation fondamentale :
</p>

<p>
\[\cos(x)^2 + \sin(x)^2 = 1\]
</p>

<p>
les inégalités :
</p>

\begin{align}
\cos(x)^2 = 1 - \sin(x)^2 \le 1 \\
\sin(x)^2 = 1 - \cos(x)^2 \le 1
\end{align}

<p>
On en déduit les bornes :
</p>

<div class="org-center">
<p>
\(
-1 \le \cos \le 1 \\
-1 \le \sin \le 1
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orgaae41c2" class="outline-3">
<h3 id="orgaae41c2"><span class="section-number-3">6.5</span> Différentielle</h3>
<div class="outline-text-3" id="text-6-5">
<p>
Posons \(x = \cos(\theta)\) et \(y = \sin(\theta)\). En différentiant la condition :
</p>

<p>
\[x^2 + y^2 = 1\]
</p>

<p>
on obtient :
</p>

<p>
\[2 \ x \ dx + 2 \ y \ dy = 0\]
</p>

<p>
En particulier, si \((x,y) = (1,0)\), le vecteur \((dx,dy)\) doit être
de la forme :
</p>

<div class="org-center">
<p>
\(
dx = 0 \\
dy = \delta
\)
</p>
</div>

<p>
Une rotation infinitésimale doit donc modifier le vecteur \((1,0)\) en :
</p>

<p>
\[(1,0)+(dx,dy)=(1,\delta)\]
</p>

<p>
On en conclut que :
</p>

<div class="org-center">
<p>
\(
Q(&delta;) &sdot;
</p>
\begin{Matrix}{c}
1 \\
0
\end{Matrix} \approx
\begin{Matrix}{c}
1 \\
\delta
\end{Matrix}
<p>
\)
</p>
</div>

<p>
Compte tenu des propriétés de symétrie de \(Q(\delta)\), on a donc :
</p>

<div class="org-center">
<p>
\(
Q(&delta;) &asymp;
</p>
\begin{Matrix}{cc}
1 & -\delta \\
\delta & 1
\end{Matrix}
<p>
\)
</p>
</div>

<p>
lorsque \(\delta\) suffisamment proche de \(0\). Plus précisément, on a :
</p>

<div class="org-center">
<p>
\(
Q(&delta;) =
</p>
\begin{Matrix}{cc}
1 & -\delta \\
\delta & 1
\end{Matrix}
<ul class="org-ul">
<li></li>
</ul>
\begin{Matrix}{cc}
E_{11} & E_{12} \\
E_{21} & E_{22}
\end{Matrix}
<p>
\)
</p>
</div>

<p>
On impose que les valeurs absolues des composantes de l'erreur convergent plus vite vers zéro que \(\delta\) :
</p>

<p>
\[\lim_{\delta\to 0} \frac{\abs{E_{ij}(\delta)}}{\delta} = 0\]
</p>

<p>
D'après la forme des matrices, il est clair que :
</p>

<div class="org-center">
<p>
\(
E_{11} = E_{22} \\
E_{12} = -E_{21}
\)
</p>
</div>

<p>
On en déduit qu'il suffit de vérifier la convergence des composantes \((1,1)\) et \((2,1)\). La première nous dit que :
</p>

<p>
\[\lim_{\delta\to 0} \frac{\cos(\delta) - 1}{\delta} = 0\]
</p>

<p>
et la seconde :
</p>

<p>
\[\lim_{\delta\to 0} \frac{\sin(\delta)-\delta}{\delta} = 0\]
</p>

<p>
ou :
</p>

<p>
\[\lim_{\delta\to 0} \frac{\sin(\delta)}{\delta} = 1\]
</p>
</div>
</div>


<div id="outline-container-org0c89bbb" class="outline-3">
<h3 id="org0c89bbb"><span class="section-number-3">6.6</span> Additivité</h3>
<div class="outline-text-3" id="text-6-6">
<p>
Une rotation d'angle \(\theta_1\) suivie d'une rotation d'angle \(\theta_2\) doit
donner le même résultat qu'une rotation directe d'angle \(\theta_1+\theta_2\), ce qui s'écrit :
</p>

<p>
\[Q(\theta_1+\theta_2) = Q(\theta_2) \cdot Q(\theta_1)\]
</p>

<p>
On en déduit directement que :
</p>

<p>
\[Q(\theta) \cdot Q(-\theta) = Q(\theta - \theta) = Q(0) = I\]
</p>

<p>
Comme \(Q(\theta)\) est carrée, on a :
</p>

<p>
\[Q(-\theta) = Q(\theta)^{-1} = Q(\theta)^\dual\]
</p>

<p>
Au niveau des composantes, la propriété d'additivité implique que :
</p>

<div class="org-center">
<p>
\(
</p>

\begin{Matrix}{cc}
\cos(\theta_2) & -\sin(\theta_2) \\
\sin(\theta_2) & \cos(\theta_2)
\end{Matrix}

<p>
&sdot;
</p>

\begin{Matrix}{cc}
\cos(\theta_1) & -\sin(\theta_1) \\
\sin(\theta_1) & \cos(\theta_1)
\end{Matrix}

<p>
=
</p>

\begin{Matrix}{cc}
\cos(\theta_1+\theta_2) & -\sin(\theta_1+\theta_2) \\
\sin(\theta_1+\theta_2) & \cos(\theta_1+\theta_2)
\end{Matrix}

<p>
\)
</p>
</div>

<p>
En effectuant le produit matriciel et en comparant composante par composante, on obtient
les formules suivantes :
</p>

<div class="org-center">
<p>
\(
\cos(\theta_1+\theta_2) = \cos(\theta_1) \ \cos(\theta_2)-\sin(\theta_1) \ \sin(\theta_2) \\
\sin(\theta_1+\theta_2) = \sin(\theta_1) \ \cos(\theta_2)+\cos(\theta_1) \ \sin(\theta_2)
\)
</p>
</div>
</div>
</div>


<div id="outline-container-orge4072cf" class="outline-3">
<h3 id="orge4072cf"><span class="section-number-3">6.7</span> Dérivées</h3>
<div class="outline-text-3" id="text-6-7">
<p>
La dérivée de la fonction \(\cos\) s'écrit :
</p>

<p>
\[\OD{\cos}{\theta}(\theta) = \lim_{\delta\to 0} \frac{ \cos(\theta+\delta)-\cos(\theta)  }{  \delta } \\\]
</p>

<p>
En appliquant les formules d'additivité ci-dessus avec \(\theta_1 = \theta\) et \(\theta_2  = \delta\),
et en se rappelant les propriétés des fonctions \(\cos\) et \(\sin\) pour des angles \(\delta\to 0\),
on obtient :
</p>

\begin{align}
\OD{\cos}{\theta}(\theta)
&= \lim_{\delta\to 0} \frac{ \cos(\theta) \ \cos(\delta) - \sin(\theta) \ \sin(\delta) - \cos(\theta) }{ \delta } \\
&= \lim_{\delta\to 0} \frac{ \cos(\theta) \ (\cos(\delta) - 1) - \sin(\theta) \ \sin(\delta) }{ \delta } \\
&= -\sin(\theta)
\end{align}

<p>
La dérivée de la fonction \(\sin\) s'écrit :
</p>

<p>
\[\OD{\sin}{\theta}(\theta) = \lim_{\delta\to 0} \frac{\sin(\theta+\delta)-\sin(\theta)}{\delta} \\\]
</p>

<p>
En procédant comme précédemment, on arrive à :
</p>

\begin{align}
\OD{\sin}{\theta}(\theta)
&= \lim_{\delta\to 0} \frac{\sin(\theta) \ \cos(\delta) + \cos(\theta) \ \sin(\delta) - \sin(\theta)}{\delta} \\
&= \lim_{\delta\to 0} \frac{\sin(\theta) \ (\cos(\delta) - 1) + \cos(\theta) \ \sin(\delta)}{\delta} \\
&= \cos(\theta)
\end{align}

<p>
On a donc :
</p>

<div class="org-center">
<p>
\(
\OD{\cos}{\theta}(\theta) = -\sin(\theta) \\ \\
\OD{\sin}{\theta}(\theta) = \cos(\theta)
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org8cd7ddb" class="outline-3">
<h3 id="org8cd7ddb"><span class="section-number-3">6.8</span> Équations différentielles</h3>
<div class="outline-text-3" id="text-6-8">
<p>
La dérivée seconde de la fonction \(\cos\) s'écrit :
</p>

<p>
\[\OOD{\cos}{\theta}(\theta) = \OD{(-\sin)}{\theta}(\theta) = -\cos(\theta)\]
</p>

<p>
On a aussi \(\cos(0) = 1\) et :
</p>

<p>
\[\OD{\cos}{\theta}(0) = -\sin(0) = 0\]
</p>

<p>
La fonction \(\cos\) est donc l'unique solution \(u : \setR \mapsto \setR\) du problème différentiel :
</p>

\begin{align}
\partial^2 u(t) &= -u(t) \\
u(0) &= 1 \\
\partial u(0) &= 0
\end{align}

<p>
vérifié pour tout \(t \in \setR\). La dérivée seconde de la fonction \(\sin\) s'écrit :
</p>

<p>
\[\OOD{\sin}{\theta}(\theta) = \OD{\cos}{\theta}(\theta) = -\sin(\theta)\]
</p>

<p>
On a aussi \(\sin(0) = 0\) et :
</p>

<p>
\[\OD{\sin}{\theta}(0) = \cos(0) = 1\]
</p>

<p>
La fonction \(\sin\) est donc l'unique solution \(v : \setR \mapsto \setR\) du problème différentiel :
</p>

\begin{align}
\partial^2 v(t) &= -v(t) \\
v(0) &= 0 \\
\partial v(0) &= 1
\end{align}

<p>
vérifié pour tout \(t \in \setR\).
</p>
</div>
</div>


<div id="outline-container-org6fde53d" class="outline-3">
<h3 id="org6fde53d"><span class="section-number-3">6.9</span> Racines</h3>
<div class="outline-text-3" id="text-6-9">
<p>
Nous allons maintenant nous occuper du problème des éventuelles racines
des fonctions trigonométriques. Soit :
</p>

<div class="org-center">
<p>
\(
u(t) = \cos(t) \\
v(t) = \sin(t)
\)
</p>
</div>

<p>
La fonction \(u\) vérifie :
</p>

<div class="org-center">
<p>
\(
u(0) = 1 \\
\partial u = -v
\)
</p>
</div>

<p>
La fonction \(v\) vérifie :
</p>

<div class="org-center">
<p>
\(
v(0) = 0 \\
\partial v = u
\)
</p>
</div>

<p>
Soit \(\varphi\) l'infimum des réels positifs donnant une valeur négative à la fonction \(u\) :
</p>

<p>
\[\varphi = \inf\{ x \in \setR : x \ge 0, \ u(x) < 0  \}\]
</p>

<p>
Nous allons montrer que \(\varphi\) est un réel, c'est-à-dire que \(\varphi < +\infty\). Le théorème
fondamental du calcul différentiel et intégral nous dit que :
</p>

<div class="org-center">
<p>
\(
u(t) - u(0) = \int_0^t \OD{u}{t}(s) \ ds \\
v(t) - v(0) = \int_0^t \OD{v}{t}(s) \ ds
\)
</p>
</div>

<p>
En tenant compte des propriétés de \(u, v\), ces relations se réécrivent :
</p>

<div class="org-center">
<p>
\(
u(t) - 1 = - \int_0^t v(s) ds \\
v(t) - 0 = \int_0^t u(s) ds
\)
</p>
</div>

<p>
On a donc :
</p>

<div class="org-center">
<p>
\(
u(t) = 1 - \int_0^t v(s) ds \\
v(t) = \int_0^t u(s) ds
\)
</p>
</div>

<p>
Comme \(u\) est dérivable, elle est continue et on peut trouver un \(\epsilon\in \intervalleouvert{0}{\varphi}\) tel que, pour tout \(t\in \intervalleouvert{0}{\epsilon}\) :
</p>

<p>
\[\abs{u(t)-u(0)} = \abs{u(t) - 1} \strictinferieur 1\]
</p>

<p>
On en déduit que :
</p>

<p>
\[1 - u(t) \strictinferieur 1\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[u(t) \strictsuperieur 0\]
</p>

<p>
La positivité de \(u\) entraîne celle de \(v\) :
</p>

<p>
\[v(t) = \int_0^t u(s) ds > 0\]
</p>

<p>
pour tout \(t \in \intervalleouvert{0}{\epsilon}\).
</p>

<p>
Pour \(t\in \intervalleouvert{\epsilon}{\varphi}\), la définition de \(\varphi\) nous dit que \(u \ge 0\) sur \(\intervalleouvert{0}{\varphi}\) et donc :
</p>

\begin{align}
v(t) &= \int_0^t u(s) ds = \int_0^\epsilon u(s) ds  + \int_\epsilon^t u(s) ds \\
&\ge \int_0^\epsilon u(s) ds > 0
\end{align}

<p>
On pose :
</p>

<p>
\[\delta = \int_0^\epsilon u(s) ds\]
</p>

<p>
pour alléger les notations. Toujours avec \(t \in \intervalleouvert{\epsilon}{\varphi}\), il vient :
</p>

\begin{align}
u(t) &= 1 - \int_0^t v(s) ds \le 1 - \int_\epsilon^t v(s) ds \\
&\le 1 - (t-\epsilon) \ \delta
\end{align}

<p>
On peut donc trouver \(t\) tel que \(u(t) \le 0\). En effet, l'égalité :
</p>

<p>
\[1 - (t-\epsilon) \ \delta = 0\]
</p>

<p>
est équivalente à :
</p>

<p>
\[t = \unsur{\delta} + \epsilon < +\infty\]
</p>

<p>
donc :
</p>

<p>
\[u\left(\unsur{\delta} + \epsilon\right) \le 0\]
</p>

<p>
Comme \(u\) est continue, elle ne peut pas devenir négative sans
passer par \(0\) et il existe au moins un :
</p>

<p>
\[\psi \le \unsur{\delta} + \epsilon\]
</p>

<p>
tel que \(u(\psi) = 0\). Donc :
</p>

<p>
\[\varphi \le \unsur{\delta} + \epsilon < +\infty\]
</p>
</div>
</div>


<div id="outline-container-org1580aec" class="outline-3">
<h3 id="org1580aec"><span class="section-number-3">6.10</span> Périodicité</h3>
<div class="outline-text-3" id="text-6-10">
<p>
Nous allons à présent montrer d'importantes propriétés de périodicité des fonctions trigonométriques. Considérons la plus petite racine positive de \(u\) :
</p>

<p>
\[\psi = \min\{ x \ge 0 : u(x) = 0 \}\]
</p>

<p>
Vu que \(u^2+v^2 = 1\), on doit avoir \(v(\psi)^2 = 1 - u(\psi)^2 = 1\).
Donc \(v(\psi)=\pm 1\). Mais \(v \ge \delta > 0\) sur l'intervalle \((\epsilon,\psi)\)
et par continuité :
</p>

<p>
\[v(\psi) = \lim_{x\to\psi} v(x) \ge 0\]
</p>

<p>
La seule solution acceptable est donc \(v(\psi) = 1\). Donc \(v\)
est solution du problème :
</p>

<div class="org-center">
<p>
\(
\OOD{v}{t} = -v \\
v(\psi) = 1 \\
\OD{v}{t}(\psi) = 0
\)
</p>
</div>

<p>
Mais la fonction définie par \(f(t) = u(t-\psi)\) vérifie également ce problème.
Par unicité, on en déduit :
</p>

<p>
\[u(t-\psi) = v(t)\]
</p>

<p>
En particulier, en \(t = 2 \psi\), on a :
</p>

<p>
\[v(2\psi) = u(\psi) = 0\]
</p>

<p>
Donc \(u(2\psi)^2 = 1 - v(2\psi)^2 = 1\). Quel est le signe de \(u(2\psi)\) ?
Choisissons \(s\in [\psi,2\psi]\) et \(t = s-\psi \in [0,\psi]\). On a :
</p>

<p>
\[v(s) = u(t) \ge 0\]
</p>

<p>
par définition de \(\psi\) et continuité de \(u\) (la fonction de peut pas devenir
négative avant de passer par \(0\)). Donc :
</p>

<p>
\[u(t) = -\int_\psi^t v(s) ds \le 0\]
</p>

<p>
et par continuité  \(u(2\psi) = -1\). Par unicité de la solution de :
</p>

<div class="org-center">
<p>
\(
\OOD{}{t}(-u) = -(-u) \\
-u(0) = -1 \\
\OD{}{t}(-u)(0) = 0
\)
</p>
</div>

<p>
on a :
</p>

<p>
\[u(t-2\psi) = -u(t)\]
</p>

<p>
Répétant le même procédé, on obtient successivement :
</p>

<div class="org-center">
<p>
\(
u(0) = 1 \qquad v(0) = 0 \\
u(\psi) = 0 \qquad v(\psi) = 1 \\
u(2\psi) = -1 \qquad v(2\psi) = 0 \\
u(3\psi) = 0 \qquad v(3\psi) = -1 \\
u(4\psi) = 1 \qquad v(4\psi) = 0
\)
</p>
</div>
</div>


<div id="outline-container-orgf66d570" class="outline-4">
<h4 id="orgf66d570"><span class="section-number-4">6.10.1</span> Extension</h4>
<div class="outline-text-4" id="text-6-10-1">
<p>
Donc \(u(4\psi) = u(0)\) et \(v(4\psi) = v(0)\). On en déduit
que \(Q(4\psi)=Q(0)=I\). Mais, par additivité des rotations,
</p>

<p>
\[Q(t + 4\psi) = Q(t) \ Q(4\psi) = Q(t)\]
</p>

<p>
Et donc :
</p>

<div class="org-center">
<p>
\(
u(t+4\psi) = u(t) \\
v(t+4\psi) = v(t)
\)
</p>
</div>

<p>
pour tout \(t\in\setR\). Définissant le nombre \(\pi\) par :
</p>

<p>
\[\pi = 2\psi\]
</p>

<p>
on peut écrire la périodicité des fonctions trigonométriques :
</p>

<div class="org-center">
<p>
\(
\cos(\theta+2\pi) = \cos(\theta) \\
\sin(\theta+2\pi) = \sin(\theta)
\)
</p>
</div>

<p>
On en déduit directement que :
</p>

<div class="org-center">
<p>
\(
\cos(\theta+2 k\pi) = ... = \cos(\theta) \\
\sin(\theta+2 k\pi) = ... = \sin(\theta)
\)
</p>
</div>

<p>
pour tout \(k\in\setZ\).
</p>
</div>
</div>
</div>


<div id="outline-container-org60d5dff" class="outline-3">
<h3 id="org60d5dff"><span class="section-number-3">6.11</span> Angle double</h3>
<div class="outline-text-3" id="text-6-11">
<p>
L'additivité nous donne :
</p>

<p>
\[\cos(2 \ x) = \cos(x + x) = \cos(x) \cdot \cos(x) - \sin(x) \cdot \sin(x)\]
</p>

<p>
On a donc :
</p>

<p>
\[\cos(2 \ x) = \cos(x)^2 - \sin(x)^2\]
</p>
</div>


<div id="outline-container-orgaa712aa" class="outline-4">
<h4 id="orgaa712aa"><span class="section-number-4">6.11.1</span> Alternative</h4>
<div class="outline-text-4" id="text-6-11-1">
<p>
En utilisant :
</p>

<p>
\[\cos(x)^2 + \sin(x)^2 = 1\]
</p>

<p>
on dispose des formulations alternatives :
</p>

<p>
\[\cos(2 \ x) = 2 \cos(x)^2 - 1\]
</p>

<p>
et :
</p>

<p>
\[\cos(2 \ x) = 1 - 2 \sin(x)^2\]
</p>
</div>
</div>


<div id="outline-container-org6a54d58" class="outline-4">
<h4 id="org6a54d58"><span class="section-number-4">6.11.2</span> Relations inverses</h4>
<div class="outline-text-4" id="text-6-11-2">
<p>
Il est aisé d'inverser ces deux relations, on a :
</p>

<p>
\[\cos(x)^2 = \frac{\cos(2 \ x) + 1}{2}\]
</p>

<p>
et :
</p>

<p>
\[\sin(x)^2 = \frac{1 - \cos(2 \ x)}{2}\]
</p>
</div>
</div>
</div>


<div id="outline-container-orgccc580c" class="outline-3">
<h3 id="orgccc580c"><span class="section-number-3">6.12</span> Intégrale</h3>
<div class="outline-text-3" id="text-6-12">
<p>
Comme \(\sin\) est une primitive de \(\cos\), on a :
</p>

<p>
\[\int_a^b \cos(t) \ dt = \sin(b) - \sin(a)\]
</p>

<p>
Comme \(\cos\) est une primitive de \(-\sin\), on a :
</p>

<p>
\[-\int_a^b \sin(t) \ dt = \cos(b) - \cos(a)\]
</p>

<p>
ou :
</p>

<p>
\[\int_a^b \sin(t) \ dt = \cos(a) - \cos(b)\]
</p>
</div>
</div>


<div id="outline-container-orgd0e2691" class="outline-3">
<h3 id="orgd0e2691"><span class="section-number-3">6.13</span> Tangente</h3>
<div class="outline-text-3" id="text-6-13">
<p>
La tangente \(\tan\) est définie par :
</p>

<p>
\[\tan(x) = \frac{\sin(x)}{\cos(x)}\]
</p>

<p>
pour tout \(x \in \setR\).
</p>
</div>


<div id="outline-container-orgde3769b" class="outline-4">
<h4 id="orgde3769b"><span class="section-number-4">6.13.1</span> Dérivée</h4>
<div class="outline-text-4" id="text-6-13-1">
<p>
On a :
</p>

<p>
\[\OD{\tan}{x}(x) = \frac{\cos(x)}{\cos(x)} - \frac{\sin(x) \cdot \big(-\sin(x)\big)}{\cos(x)^2} = 1 + \tan(x)^2\]
</p>
</div>
</div>


<div id="outline-container-org4e26d14" class="outline-4">
<h4 id="org4e26d14"><span class="section-number-4">6.13.2</span> Problème différentiel</h4>
<div class="outline-text-4" id="text-6-13-2">
<p>
Comme :
</p>

<p>
\[\tan(0) = \frac{\sin(0)}{\cos(0)} = \frac{0}{1} = 0\]
</p>

<p>
la tangente est solution \(u : \setR \mapsto \setR\) du problème différentiel :
</p>

\begin{align}
\partial u(t) &= 1 + u(t)^2 \\
u(0) &= 0
\end{align}

<p>
vérifié pour tout \(t \in \setR\).
</p>
</div>
</div>
</div>


<div id="outline-container-org3e13fd8" class="outline-3">
<h3 id="org3e13fd8"><span class="section-number-3">6.14</span> Angle entre vecteurs</h3>
<div class="outline-text-3" id="text-6-14">
<p>
Dans le cas où le produit scalaire est réel, on peut trouver un réel
\(\theta\in [0,\pi]\) tel que :
</p>

<p>
\[-1 \le \cos(\theta) = \frac{ \scalaire{x}{y} }{ \norme{x}\ \norme{y} } \le 1\]
</p>

<p>
On dit alors que \(\theta\) est l'angle formé par les deux vecteurs \(x\) et \(y\).
</p>
</div>
</div>


<div id="outline-container-orgcb5c1fe" class="outline-3">
<h3 id="orgcb5c1fe"><span class="section-number-3">6.15</span> Angles entre espaces</h3>
<div class="outline-text-3" id="text-6-15">
<p>
Autre application des valeurs singulières, les angles entres espaces vectoriels
générés par les vecteurs colonnes orthonormés des matrices :
</p>

<div class="org-center">
<p>
\(
X \in \matrice(\setR, k, n) \\
Y \in \matrice(\setR, l, n)
\)
</p>
</div>

<p>
On a donc :
</p>

<div class="org-center">
<p>
\(
X^\dual \cdot X = I_k \\
Y^\dual \cdot Y = I_l
\)
</p>
</div>

<p>
Les valeurs singulières de la matrice des produits scalaires :
</p>

<p>
\[Y^\dual \cdot X\]
</p>

<p>
nous donne les cosinus de ces angles.
</p>
</div>
</div>


<div id="outline-container-orgb7e9aaf" class="outline-3">
<h3 id="orgb7e9aaf"><span class="section-number-3">6.16</span> Coordonnées polaires</h3>
<div class="outline-text-3" id="text-6-16">
<p>
AFAIRE : CLARIFIER LA FIN DU CHAPITRE
</p>

<p>
Soit les vecteurs \((c_1,c_2)\) formant une base orthonormée de \(\setR^2\) :
</p>

<p>
\[\scalaire{c_i}{c_j} = \delta_{ij}\]
</p>

<p>
et ne dépendant pas de la position :
</p>

<p>
\[\deriveepartielle{c_i}{x_j} = 0\]
</p>

<p>
Soit le changement de variable vers \(y = (R,\theta)\), exprimé par :
</p>

<div class="org-center">
<p>
\(
x_1 = R \cdot \cos(\theta) \\
x_2 = R \cdot \sin(\theta)
\)
</p>
</div>

<div class="org-center">
<p>
\(
r = x_1 \cdot c_1 + x_2 \cdot c_2 \\
dr = e_R \ dR + e_\theta \ d\theta
\)
</p>
</div>

<div class="org-center">
<p>
\(
e_R = \deriveepartielle{r}{R} = \cos(\theta) \cdot c_1 + \sin(\theta) \cdot c_2 \\
e_\theta = \deriveepartielle{r}{\theta} = -R \cdot \sin(\theta) c_1 + R \cdot \cos(\theta) \cdot c_2
\)
</p>
</div>

<div class="org-center">
<p>
\(
\deriveepartielle{e_R}{R} = 0 \\
\deriveepartielle{e_R}{\theta} = -\sin(\theta) \cdot c_1 + \cos(\theta) \cdot c_2 = \unsur{R} \cdot e_\theta \\
\deriveepartielle{e_\theta}{R} = -\sin(\theta) \cdot c_1 + \cos(\theta) \cdot c_2 = \unsur{R} \cdot e_\theta \\
\deriveepartielle{e_\theta}{\theta} = -R \cdot \cos(\theta) \cdot c_1 - R \cdot \sin(\theta) \cdot c_2 = -R \cdot e_R
\)
</p>
</div>

<div class="org-center">
<p>
\(
de_R = \deriveepartielle{e_R}{R} \ dR + \deriveepartielle{e_R}{\theta} \ d\theta =
\unsur{R} \ d\theta \ e_\theta \\
de_\theta = \deriveepartielle{e_\theta}{R} \ dR + \deriveepartielle{e_\theta}{\theta} \ d\theta =
\unsur{R} \ dR \ e\theta - R \ d\theta
\)
</p>
</div>

<div class="org-center">
<p>
\(
a = a^R \cdot e_R + a^\theta \cdot e_\theta \\
da = \deriveepartielle{a^R}{R} \cdot e_R \ dR + \left( \deriveepartielle{a^R}{\theta} - R \cdot a^\theta \right)  \cdot e_R \ d\theta + \\
\left( \deriveepartielle{a^\theta}{R} + \frac{a^\theta}{R} \right) \cdot e_\theta \ dR + \left( \deriveepartielle{a^\theta}{\theta} + \frac{a^R}{R} \right) \cdot e_\theta \ d\theta
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org3375da3" class="outline-2">
<h2 id="org3375da3"><span class="section-number-2">7</span> Fonctions trigonométriques inverses</h2>
<div class="outline-text-2" id="text-7">
<p>
Les fonctions trigonométriques ne sont pas inversible. Soit \(y \in \setR\) et \(s \in \setR\) une solution
du problème :
</p>

<p>
\[\sin(s) = y\]
</p>

<p>
alors, pour tout \(k \in \setN\), on a :
</p>

<p>
\[\sin(x + 2 \ k \ \pi) = \sin(x) = y\]
</p>

<p>
L'ensemble des solutions :
</p>

<p>
$$S(x) = \{ x &isin; \setR
</p>

<p>
De même pour la fonction \(\cos\). Par contre, elles sont localement inversible,
et on peut définir les fonctions \(\arcsin\), \(\arccos\), \(\arctan\) par :
</p>

<div class="org-center">
<p>
\(
\arcsin(y) = x \\
\Leftrightarrow\\
y = \sin(x) \\
x \in [-\pi/2,\pi/2]
\)
</p>
</div>

<div class="org-center">
<p>
\(
\arccos(y) = x \\
\Leftrightarrow\\
y = \cos(x) \\
x \in [0,\pi]
\)
</p>
</div>

<div class="org-center">
<p>
\(
\arctan(y) = x \\
\Leftrightarrow\\
y = \tan(x) \\
x \in [-\pi/2,\pi/2]
\)
</p>
</div>
</div>
</div>


<div id="outline-container-orgf38d075" class="outline-2">
<h2 id="orgf38d075"><span class="section-number-2">8</span> Equations aux dérivées partielles</h2>
<div class="outline-text-2" id="text-8">
<div id="text-table-of-contents">
<ul>
<li><a href="#org6527121">8.1. Courbes caractéristiques</a></li>
<li><a href="#org8988085">8.2. Fonction de Green</a></li>
</ul>
</div>

<p>
\label{chap:pde}
</p>
</div>


<div id="outline-container-org6527121" class="outline-3">
<h3 id="org6527121"><span class="section-number-3">8.1</span> Courbes caractéristiques</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Soit \(u \in F = \continue^1(\setR^2,\setR)\) et l'équation aux dérivées partielles à résoudre sur \(\Omega\subseteq\setR^2\) :
</p>

<p>
\[a(x,y,u) \ u_x(x,y) + b(x,y,u) \ u_y(x,y) = c(x,y,u)\]
</p>

<p>
où nous introduisons les notations :
</p>

<div class="org-center">
<p>
\(
u_x(x,y) = \deriveepartielle{u}{x}(x,y) \\
u_y(x,y) = \deriveepartielle{u}{y}(x,y)
\)
</p>
</div>

<p>
Les coefficients \(a,b,c\) sont en général des fonctions de \(x,y,u\) mais ne peuvent
pas dépendre de \(u_x\) ni de \(u_y\). Soit à présent la courbe \(\Gamma\) définie par :
</p>

<p>
\[\Gamma = \{ \left(w_x(t),w_y(t)\right) : t \in\setR \}\]
</p>

<p>
où \(w_x\) et \(w_y\) sont des fonctions dérivables. Définissons la restriction
de \(u\) à \(\Gamma\) :
</p>

<p>
\[\varphi(t) = u\left(w_x(t),w_y(t)\right)\]
</p>

<p>
Si on s'arrange pour que :
</p>

<div class="org-center">
<p>
\(
\OD{w_x}{t}(t) = a(w_x(t),w_y(t),u(w_x(t),w_y(t))) \\
\OD{w_y}{t}(t) = b(w_x(t),w_y(t),u(w_x(t),w_y(t)))
\)
</p>
</div>

<p>
On a alors :
</p>

<p>
\[\OD{\varphi}{t} = u_x \ a + u_y \ b = c\]
</p>

<p>
Définissons alors :
</p>

<p>
\[f : (t,u) \mapsto c\left(w_x(t),w_y(t),u\right)\]
</p>

<p>
On a :
</p>

<p>
\[\OD{\varphi}{t}(t) = f(t,u(t))\]
</p>

<p>
qui est une équation différentielle ordinaire en \(t\). On peut donc connaître \(\varphi\) et
donc \(u\) sur \(\Gamma\) si on ajoute la condition initiale :
</p>

<p>
\[\varphi(0) = u_0\]
</p>

<p>
On dit alors que \(\Gamma\) est une courbe caractéristique de l'équation aux dérivées partielles.
</p>
</div>
</div>


<div id="outline-container-org8988085" class="outline-3">
<h3 id="org8988085"><span class="section-number-3">8.2</span> Fonction de Green</h3>
<div class="outline-text-3" id="text-8-2">
<p>
Soit un espace fonctionnel \(F \subseteq \Leb^2(\setR^n,\setR)\) et une forme \(\forme{}{} : F^D \times F \mapsto \setR\) à laquelle on associe par abus de notation :
</p>

<p>
\[\int_A u(x) \cdot v(x) \ dx = \forme{u}{v}\]
</p>

<p>
où \(A \subseteq \setR^n\).
</p>

<p>
Soit un opérateur \(L : F \mapsto \Leb^2(\setR^n,\setR)\) qui vérifie :
</p>

<p>
\[\forme{u}{L(v)} = \forme{L(u)}{v}\]
</p>

<p>
pour tout \(u,v\in F\). On dit d'un tel opérateur qu'il est auto-adjoint.
</p>

<p>
Nous nous intéressons à l'équation différentielle :
</p>

<p>
\[L(u) = f\]
</p>

<p>
où \(f \in F\).
</p>

<p>
Introduisons la distribution \(\delta\) de Dirac :
</p>

<p>
\[\int_A \delta(x-a) \ f(x) \ dx = f(a)\]
</p>

<p>
et définissons la famille de solutions \(v_x\) telles que :
</p>

<p>
\[L(v_x)(y)=\delta(y-x)\]
</p>

<p>
On peut alors définir la fonction de Green \(G\) :
</p>

<p>
\[G(x,y)=v_x(y)\]
</p>

<p>
Mais les propriétés de \(L\) nous permettent d'écrire :
</p>

<p>
\[\forme{L(v_x)}{u} = \forme{v_x}{L(u)}\]
</p>

<p>
Si \(u\) est la solution de \(L(u) = f\), l'équation précédente peut se formeuler comme :
</p>

<p>
\[\int_A \delta(y-x) \ u(y) \ dy = \int_A v_x(y) \ f(y) \ dy\]
</p>

<p>
et finalement :
</p>

<p>
\[u(x) = \int_A G(x,y) \ f(y) \ dy\]
</p>
</div>


<div id="outline-container-orgc0be7bf" class="outline-4">
<h4 id="orgc0be7bf"><span class="section-number-4">8.2.1</span> Exemple d'opérateur auto-adjoint</h4>
<div class="outline-text-4" id="text-8-2-1">
<p>
Comme exemple d'opérateur auto-adjoint, citons :
</p>

<p>
\[L : u \mapsto \lapl u = \sum_i \dfdxdx{u}{x_i}\]
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org60bf838" class="outline-2">
<h2 id="org60bf838"><span class="section-number-2">9</span> Algorithmes de résolution d'EDO</h2>
<div class="outline-text-2" id="text-9">
<div id="text-table-of-contents">
<ul>
<li><a href="#org1acdce5">9.1. Introduction</a></li>
</ul>
</div>

<p>
\label{chap:algoedo}
</p>
</div>


<div id="outline-container-org1acdce5" class="outline-3">
<h3 id="org1acdce5"><span class="section-number-3">9.1</span> Introduction</h3>
<div class="outline-text-3" id="text-9-1">
<p>
AFAIRE : ARRANGER LE CHAPITRE
</p>

<p>
Le but est de calculer une approximation de la solution \(y\) de
</p>

<div class="org-center">
<p>
\(
\OD{y}{x}(x) = f(x,y(x)) \\
y(0) = y_0
\)
</p>
</div>

<p>
Pour cela, on choisit \(n\) points \(x_i\), et on tente de progresser en évaluant les approximations successives \(y_{i+1} \approx y(x_{i+1})\) à partir de \(y_i\), pour $i=0,1,2,&#x2026;$. On pose :
</p>

<p>
\[h_i = x_{i+1} - x_i\]
</p>
</div>


<div id="outline-container-orgbdf091e" class="outline-4">
<h4 id="orgbdf091e"><span class="section-number-4">9.1.1</span> Euler</h4>
<div class="outline-text-4" id="text-9-1-1">
<p>
On se sert de la formulation intégrale correspondant à l'équation différentielle que l'on veut résoudre :
</p>

<p>
\[y_{i+1} = y_i + \int_{x_i}^{x_{i+1}} f(x,y(x)) \ dx\]
</p>

<p>
Si \(h_i\) est suffisamment petit, la fonction \(y\) sera plus ou moins constante sur l'intervalle \([x_i,x_{i+1}]\) et on peut approximer la formulation intégrale par :
</p>

<p>
\[y_{i+1} = y_i + h_i \cdot f(x_i,y_i)\]
</p>

<p>
Cette méthode se nomme Euler explicite.
</p>

<p>
\label{page:euler_expl}
</p>
</div>
</div>


<div id="outline-container-org4d63bbb" class="outline-4">
<h4 id="org4d63bbb"><span class="section-number-4">9.1.2</span> Predicteur - Correcteur</h4>
<div class="outline-text-4" id="text-9-1-2">
<p>
On part de nouveau de :
</p>

<p>
\[y_{i+1} = y_i + \int_{x_i}^{x_{i+1}} f(x,y(x)) \ dx\]
</p>

<p>
On commence par calculer une première estimation de \(y(x_{i+1})\) en utilisant la méthode d'Euler explicite :
</p>

<p>
\[y_{i+1}^* = y_i + h_i \cdot f(x_i,y_i)\]
</p>

<p>
La valeur \(y_{i+1}^*\) ainsi obtenue est nommé prédicteur.
</p>

<p>
Une fois cette première estimation évaluée, on construit une meilleure approximation de l'intégrale en supposant que, pour \(t\in [0,1]\) :
</p>

<p>
\[f\left(x_i + t \cdot h_i,y(x_i + t h_i)\right) \approx f_i + t \cdot (f^*_{i+1} - f_i)\]
</p>

<p>
avec :
</p>

<div class="org-center">
<p>
\(
f_i = f(x_i,y_i) \\
f^*_{i+1} = f(x_{i+1},y^*_{i+1})
\)
</p>
</div>

<p>
On obtient :
</p>

\begin{align}
\int_{x_i}^{x_{i+1}} f(x,y(x)) \ dx &\approx&
h_i \int_0^1 \left[ f_i + t \cdot (f^*_{i+1} - f_i) \right] dt \\
&\approx&
\frac{h_i}{2} \cdot \left( f_i + f^*_{i+1} \right)
\end{align}

<p>
L'étape correctrice s'écrit donc :
</p>

<p>
\[y_{i+1} = y_i + \frac{h_i}{2} \cdot [f(x_i,y_i) + f(x_{i+1},y_{i+1}^*)]\]
</p>
</div>
</div>


<div id="outline-container-org760ff1a" class="outline-4">
<h4 id="org760ff1a"><span class="section-number-4">9.1.3</span> Taylor</h4>
<div class="outline-text-4" id="text-9-1-3">
<p>
Partant des dérivées de la fonction \(y(x) = f(x,y(x))\) :
</p>

\begin{align}
\OD{y}{x} &= f \\
\frac{d^2 y}{dx^2} &= \deriveepartielle{f}{x}+\deriveepartielle{f}{y}\OD{y}{x} =
\deriveepartielle{f}{x}+\deriveepartielle{f}{y} f \\
\frac{d^3 y}{dx^3} &= ...
\end{align}

<p>
on peut écrire le développement en série de Taylor de \(y\)
autour de \(x_i\) :
</p>

<p>
\[y_{i+1} = y_i + f(x_i,h_i) \ h_i + \OD{f}{x}(x_i,y_i) \ \frac{h_i^2}{2} + ...\]
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orgb269bba" class="outline-2">
<h2 id="orgb269bba"><span class="section-number-2">10</span> Algorithmes de résolution d'EDP</h2>
<div class="outline-text-2" id="text-10">
<div id="text-table-of-contents">
<ul>
<li><a href="#org834a090">10.1. Résolution par les caractéristiques</a></li>
<li><a href="#org47e05ab">10.2. Différences finies</a></li>
<li><a href="#org97f2b11">10.3. Eléments finis</a></li>
</ul>
</div>

<p>
\label{chap:algoedp}
</p>
</div>


<div id="outline-container-org834a090" class="outline-3">
<h3 id="org834a090"><span class="section-number-3">10.1</span> Résolution par les caractéristiques</h3>
<div class="outline-text-3" id="text-10-1">
<p>
AFAIRE : ARRANGER LE CHAPITRE
</p>

<p>
Soit une équation du premier ordre à résoudre :
</p>

<p>
\[a(x,y,u) \ u_x(x,y) + b(x,y,u) \ u_y(x,y) = c(x,y,u)\]
</p>

<p>
Supposons que l'on connaisse la valeur de la solution :
</p>

<p>
\[u_{i0} = u(x_{i0},y_{i0})\]
</p>

<p>
pour \(i = 1,2,...,n\). Les équations :
</p>

<p>
\[\OD{x}{t} = a \qquad \OD{y}{t} = b \qquad \OD{u}{t} = c\]
</p>

<p>
nous permettent de construire simultanément les courbes
caractéristiques et la solution. Par exemple, si on utilise
le schéma d'Euler explicite, on a :
</p>

<div class="org-center">
<p>
\(
x_{i,k+1} = x_{ik} + h_k \ a(x_{ik},y_{ik},u_{ik}) \\
y_{i,k+1} = y_{ik} + h_k \ b(x_{ik},y_{ik},u_{ik}) \\
u_{i,k+1} = u_{ik} + h_k \ c(x_{ik},y_{ik},u_{ik})
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org47e05ab" class="outline-3">
<h3 id="org47e05ab"><span class="section-number-3">10.2</span> Différences finies</h3>
<div class="outline-text-3" id="text-10-2">
<p>
On vérifie sur le développement de Taylor de \(u\) que :
</p>

<div class="org-center">
<p>
\(
u_x(x,y) \approx \frac{u(x+h,y) - u(x-h,y)}{2 h} \\
u_y(x,y) \approx \frac{u(x,y+h) - u(x,y-h)}{2 h}
\)
</p>
</div>

<p>
pour les dérivées premières et :
</p>

<div class="org-center">
<p>
\(
u_{xx}(x,y) \approx \unsur{h^2} \ \left(u(x+h,y)-2 u(x,y) + u(x-h,y)\right) \\
u_{yy}(x,y) \approx \unsur{h^2} \ \left(u(x,y+h)-2 u(x,y) + u(x,y-h)\right) \\
u_{xy}(x,y) \approx \unsur{4h^2} \ \left(u(x+h,y+h) + u(x-h,y-h) \right\relax \\
\qquad\qquad \left\relax - u(x+h,y-h) - u(x-h,y+h)\right)
\)
</p>
</div>

<p>
pour les dérivées secondes. L'erreur converge vers \(0\) aussi vite que
\(h^2\). Posons :
</p>

<p>
\[U_{ij} = u(i h, j h)\]
</p>

<p>
Les dérivées approximatives s'écrivent :
</p>

<div class="org-center">
<p>
\(
u_x \approx \Delta_x U_{ij} = \unsur{2 h} \ (U_{i+1,j} - U_{i-1,j}) \\
u_y \approx \Delta_y U_{ij} = \unsur{2 h} \ (U_{i,j+1} - U_{i,j-1})
\)
</p>
</div>

<p>
et :
</p>

<div class="org-center">
<p>
\(
u_{xx} \approx \Delta_x^2 U_{ij} = \unsur{h^2} \ (U_{i+1,j} - 2 U_{ij} + U_{i-1,j}) \\
u_{yy} \approx \Delta_y^2 U_{ij} = \unsur{h^2} \ (U_{i,j+1} - 2 U_{ij} + U_{i,j-1}) \\
u_{xy} \approx \Delta_x\Delta_y U_{ij} =
\unsur{4 h^2} \ (U_{i+1,j+1} - U_{i+1,j-1} - U_{i-1,j+1} + U_{i-1,j-1})
\)
</p>
</div>

<p>
On substitue alors ces expressions dans l'équation :
</p>

<p>
\[F(x,y,u,u_x,u_y,u_{xx},u_{xy},u_{yy}) = 0\]
</p>

<p>
et on obtient un système linéaire à résoudre en les \(U_{ij}\).
</p>
</div>
</div>


<div id="outline-container-org97f2b11" class="outline-3">
<h3 id="org97f2b11"><span class="section-number-3">10.3</span> Eléments finis</h3>
<div class="outline-text-3" id="text-10-3">
<p>
\label{sec:elements_finis}
</p>

<p>
Soient des espaces fonctionnels \(F,H\subset\fonction(\Omega,\setR)\) et un
opérateur linéaire :
</p>

<p>
\[L \in \lineaire(F,H)\]
</p>

<p>
Nous cherchons à résoudre de manière approchée l'équation
différentielle associée :
</p>

<p>
\[L(u) = f\]
</p>

<p>
où \(f\) est une fonction de \(H\). La méthode des éléments finis consiste à imposer l'annulation de l'intégrale du résidu \(L(u)\), pondéré par des fonctions
\(\psi_i\) :
</p>

<p>
\[\int_\Omega \left[L(u)(x)-f(x)] \ \psi_i(x) \ dx = 0\]
</p>

<p>
pour \(i = 1,2,...,n\). Afin de résoudre ce problème, on discrétise
la solution approchée \(u\) :
</p>

<p>
\[u(x) = \sum_{i=1}^n U_i \ \varphi_i(x)\]
</p>

<p>
où les \(U_i\) sont des réels et les \(\varphi_i\) des fonctions de \(F\).
On définit les grandeurs :
</p>

<div class="org-center">
<p>
\(
A_{ij} = \int_\Omega L(\varphi_i)(x) \ \psi_i(x) \ dx \\
F_i = \int_\Omega f(x) \ \psi_i(x) \ dx
\)
</p>
</div>

<p>
et les matrices :
</p>

<div class="org-center">
<p>
\(
U = (U_i)_i \\
A = (A_{ij})_{i,j} \\
F = (F_i)_i
\)
</p>
</div>

<p>
En utilisant la linéarité de \(L\), l'équation des résidus pondérés :
</p>

<p>
\[\int_\Omega L(u)(x) \ \psi_i(x) \ dx = \int_\Omega f(x) \ \psi_i(x) \ dx\]
</p>

<p>
devient :
</p>

<p>
\[A \ U = F\]
</p>

<p>
soit un système linéaire à résoudre en \(U\) :
</p>

<p>
\[U = A^{-1} \ F\]
</p>

<p>
ce qui nous donne une forme approchée \(u\) de la solution exacte.
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2019-05-07 mar 08:20</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
