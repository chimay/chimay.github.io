<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2019-10-01 mar 12:19 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat 13 : Probabilit√© - 2</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="chimay" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Eclats de vers : Matemat 13 : Probabilit√© - 2</h1>
<p>
<a href="index.html">Index des Grimoires</a>
</p>

<p>
<a href="file:///home/david/racine/site/orgmode/index.html">Retour √† l‚Äôaccueil</a>
</p>

<div id="table-of-contents">
<h2>Table des mati√®res</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga6d6054">1. Statistiques</a></li>
<li><a href="#orgb563fcd">2. Calcul stochastique</a></li>
</ul>
</div>
</div>

<p>
\( \newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\relax \ ] #1 , #2 [ \ \relax}
\newcommand{\intervallesemiouvertgauche}[2]{\relax \ ] #1 , #2 ]}
\newcommand{\intervallesemiouvertdroite}[2]{[ #1 , #2 [ \ \relax}
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\newcommand{\strictinferieur}{\ < \ }
\newcommand{\strictsuperieur}{\ > \ }
\newcommand{\ensinferieur}{\eqslantless}
\newcommand{\enssuperieur}{\eqslantgtr}
\newcommand{\esssuperieur}{\gtrsim}
\newcommand{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\newcommand{\pgcd}{pgcd}
\newcommand{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \left|\right\relax #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \right| #2 \left| #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \right| #3 \left| #5 \right\rangle_{#2,#4}}
\newcommand{\major}{major}
\newcommand{\minor}{minor}
\newcommand{\maxim}{maxim}
\newcommand{\minim}{minim}
\newcommand{\argument}{arg}
\newcommand{\argmin}{arg\ min}
\newcommand{\argmax}{arg\ max}
\newcommand{\supessentiel}{ess\ sup}
\newcommand{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\newcommand{\adh}{adh}
\newcommand{\interieur}{int}
\newcommand{\frontiere}{\partial}
\newcommand{\image}{im}
\newcommand{\domaine}{dom}
\newcommand{\noyau}{ker}
\newcommand{\support}{supp}
\newcommand{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\newcommand{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\newcommand{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\newcommand{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\newcommand{\composante}{comp}
\newcommand{\bloc}{bloc}
\newcommand{\ligne}{ligne}
\newcommand{\colonne}{colonne}
\newcommand{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\newcommand{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\newcommand{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)} \)
</p>

<div id="outline-container-orga6d6054" class="outline-2">
<h2 id="orga6d6054"><span class="section-number-2">1</span> Statistiques</h2>
<div class="outline-text-2" id="text-1">
<div id="text-table-of-contents">
<ul>
<li><a href="#orgbbaf286">1.1. Echantillons</a></li>
<li><a href="#orga1a01a4">1.2. L'in√©galit√© de Markov</a></li>
<li><a href="#orgdab69c0">1.3. La loi des grands nombres</a></li>
<li><a href="#org047f888">1.4. Fr√©quence et probabilit√©</a></li>
<li><a href="#org7c6a3f4">1.5. Estimateurs non biais√©s</a></li>
<li><a href="#orgf134a65">1.6. Estimation des esp√©rance et des variances</a></li>
<li><a href="#org7eceab2">1.7. Maximum de vraisemblance</a></li>
<li><a href="#orgccc7ab5">1.8. Echantillon de densit√© donn√©e</a></li>
</ul>
</div>

<p>
\label{chap:stat}
</p>
</div>


<div id="outline-container-org9f08779" class="outline-4">
<h4 id="org9f08779"><span class="section-number-4">1.0.1</span> Ind√©pendance</h4>
<div class="outline-text-4" id="text-1-0-1">
<p>
On dit que les variables al√©atoires \(X_1\), \(X_2\), &#x2026;, \(X_N\) sont ind√©pendantes si¬†:
</p>

<p>
\[\esperof{\prod_i X_i} = \prod_i \esperof{X_i}\]
</p>

<p>
On en d√©duit que¬†:
</p>

<p>
\[\cov{X_i}{X_j} = \var{X_i} \ \indicatrice_{ij}\]
</p>

<p>
et donc¬†:
</p>

<p>
\[\var{\sum_i X_i} = \sum_i \var{X_i}\]
</p>
</div>
</div>


<div id="outline-container-orgbbaf286" class="outline-3">
<h3 id="orgbbaf286"><span class="section-number-3">1.1</span> Echantillons</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Nous nous int√©ressons dans la suite de ce chapitre √† des √©chantillons de \(N\) variables al√©atoires ind√©pendantes \(X_1,...,X_N\) telles que¬†:
</p>

<div class="org-center">
<p>
\(
\esperof{X_i} = \mu \\
\cov{X_i}{X_j} = \sigma \ \indicatrice_{ij}
\)
</p>
</div>
</div>
</div>


<div id="outline-container-orga1a01a4" class="outline-3">
<h3 id="orga1a01a4"><span class="section-number-3">1.2</span> L'in√©galit√© de Markov</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Soit une variable al√©atoire \(X\). On d√©finit la variable associ√©e¬†:
</p>

<div class="org-center">
<p>
\(
Y =
\begin{cases}
a^2 & \mbox{ si } \abs{X-b} \ge a \\
0 & \mbox{ si } \abs{X-b} < a
\end{cases} \\
\)
</p>
</div>

<p>
Comme¬†:
</p>

<p>
\[Y \le (X-b)^2\]
</p>

<p>
on a \(\esperof{Y} \le \esperof{(X-b)^2}\). D'un autre cot√©¬†:
</p>

<p>
\[\esperof{Y} = a^2 \ \probaof{\abs{X-b} \ge a}\]
</p>

<p>
Rassemblant ces deux r√©sultats, on obtient la propri√©t√©¬†:
</p>

<p>
\[\probaof{\abs{X-b} \ge a} \le \unsur{a^2} \ \esperof{(X-b)^2}\]
</p>

<p>
connue sous le nom d'in√©galit√© de Markov.
</p>

<p>
Le cas particulier \(b = \esperof{X}\) nous donne¬†:
</p>

<p>
\[\probaof{\abs{X-\esperof{X}} \ge a} \le \unsur{a^2} \ \var{X}\]
</p>
</div>
</div>


<div id="outline-container-orgdab69c0" class="outline-3">
<h3 id="orgdab69c0"><span class="section-number-3">1.3</span> La loi des grands nombres</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Soit la moyenne¬†:
</p>

<p>
\[M_N = \unsur{N} \sum_{i=1}^N X_i\]
</p>

<p>
On a¬†:
</p>

<p>
\[\esperof{M_N} = \unsur{N} \ N \ \mu = \mu\]
</p>

<p>
L'ind√©pendance entre les variables nous am√®ne √†¬†:
</p>

\begin{align}
\var{M_N} &= \unsur{N^2} \var{\sum_i X_i} \\
&= \unsur{N^2} \sum_i \var{X_i} \\
&= \unsur{N^2} \ N \ \sigma^2
\end{align}

<p>
et donc¬†:
</p>

<p>
\[\var{M_N} = \frac{\sigma^2}{N}\]
</p>

<p>
Soit \(a > 0\). L'in√©galit√© de Markov nous dit que¬†:
</p>

<p>
\[\probaof{\abs{M_N - \mu} \ge a} \le \frac{\sigma^2}{a^2 N}\]
</p>

<p>
Soit √† pr√©sent \(\epsilon > 0\). Si on veut¬†:
</p>

<p>
\[\probaof{\abs{M_N - \mu} \ge a} \le \frac{\sigma^2}{a^2 N} \strictinferieur \epsilon\]
</p>

<p>
il suffit de choisir¬†:
</p>

<p>
\[N > \frac{\sigma^2}{a^2 \epsilon}\]
</p>

<p>
On en conclut que¬†:
</p>

<p>
\[\lim_{N \to +\infty} \probaof{M_N = \mu} = 1\]
</p>
</div>
</div>


<div id="outline-container-org047f888" class="outline-3">
<h3 id="org047f888"><span class="section-number-3">1.4</span> Fr√©quence et probabilit√©</h3>
<div class="outline-text-3" id="text-1-4">
<p>
Appliquons la loi des grands nombres √† la fonction indicatrice \(\indicatrice_A\).
On a alors \(X_i = 1\) lorsque \(\omega \in A\) et \(X_i = 0\) lorsque \(\omega \notin A\).
La moyenne s'√©crit donc¬†:
</p>

<p>
\[M_N = \frac{n(A)}{N}\]
</p>

<p>
o√π \(n(A)\) est le nombre de \(X_i\) valant 1, autrement dit le nombre d'√©v√©nements
\(\omega\) appartenant √† \(A\). Comme¬†:
</p>

<p>
\[\mu = \esperof{\indicatrice_A} = \probaof{A}\]
</p>

<p>
on en d√©duit que la fr√©quence \(n(A) / N\) converge vers la probabilit√© de \(A\)¬†:
</p>

<p>
\[\lim_{N \to +\infty} \probaof{\frac{n(A)}{N} = \probaof{A}} = 1\]
</p>
</div>
</div>


<div id="outline-container-org7c6a3f4" class="outline-3">
<h3 id="org7c6a3f4"><span class="section-number-3">1.5</span> Estimateurs non biais√©s</h3>
<div class="outline-text-3" id="text-1-5">
<p>
Soit une fonction \(G : \setR^n \mapsto \setR\)¬†:
</p>

<p>
\[G : (X_1,...,X_N) \mapsto G(X_1,...,X_N)\]
</p>

<p>
On dit que \(\hat{G} : \setR^n \mapsto \setR\) est un estimateur non biais√© de \(G\) si¬†:
</p>

<p>
\[\esperof{\hat{G}} = \esperof{G}\]
</p>
</div>
</div>


<div id="outline-container-orgf134a65" class="outline-3">
<h3 id="orgf134a65"><span class="section-number-3">1.6</span> Estimation des esp√©rance et des variances</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Soit¬†:
</p>

<p>
\[M_N(X_1,...,X_N) = \unsur{N} \sum_{i=1}^N X_i\]
</p>

<p>
La loi des grands nombres nous dit que¬†:
</p>

<p>
\[\esperof{M_N} = \mu\]
</p>

<p>
La moyenne \(M_N\) est donc un estimateur non biais√© de l'esp√©rance \(\mu\).
</p>

<p>
Soit les variables √† esp√©rances nulles¬†:
</p>

<div class="org-center">
<p>
\(
X_i^* = X_i - \mu \\
M_N^* = M_N - \mu
\)
</p>
</div>

<p>
On obtient directement¬†:
</p>

<p>
\[M_N^* = \unsur{N} \sum_i X_i^*\]
</p>

<p>
On voit √©galement que¬†:
</p>

<p>
\[X_i - M_N = X_i - \mu + \mu - M_N = X_i^* - M_N^*\]
</p>

<p>
Donc¬†:
</p>

<p>
\[\esperof{\sum_i (X_i - M_N)^2} = \esperof{\sum_i \left( X_i^* - M_N^* \right)^2}\]
</p>

<p>
En d√©veloppant, on obtient successivement¬†:
</p>

\begin{align}
\esperof{\sum_i (X_i - M_N)^2} &= \esperof{ \sum_i \left( X_i^* \right)^2 } - 2 \ \esperof{M_N^* \sum_i X_i^*} + \esperof{ \left( M_N^* \right)^2 } \\
&= \sum_i \esperof{ \left( X_i^* \right)^2 } - 2 \ N \ \esperof{ \left( M_N^* \right)^2 } + \esperof{ \left( M_N^* \right)^2 }
\end{align}

<p>
Mais comme¬†:
</p>

<div class="org-center">
<p>
\(
\var{M_N^*} = \esperof{ \left( M_N^* \right)^2 } = \frac{\sigma^2}{N} \\
\esperof{ \left( X_i^* \right)^2 } = \var{X_i} = \sigma^2
\)
</p>
</div>

<p>
l'expression devient¬†:
</p>

<p>
\[\esperof{\sum_i (X_i - M_N)^2} = (N - 2 + 1) \ \sigma^2 = (N-1) \ \sigma^2\]
</p>

<p>
On en conclut que¬†:
</p>

<p>
\[S^2 = \unsur{N-1} \sum_{i=1}^{N} (X_i - M_N)^2\]
</p>

<p>
est un estimateur non biais√© de la variance¬†:
</p>

<p>
\[\esperof{S^2} = \sigma^2\]
</p>
</div>
</div>


<div id="outline-container-org7eceab2" class="outline-3">
<h3 id="org7eceab2"><span class="section-number-3">1.7</span> Maximum de vraisemblance</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Il s'agit de trouver les param√®tres \(\hat{\theta}\) (esp√©rance, variance, &#x2026;) qui maximisent la vraisemblance¬†:
</p>

<p>
\[V(\hat{\theta}) = \prod_i  \probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} }\]
</p>

<p>
Notons que cela revient √† maximiser¬†:
</p>

<p>
\[\ln\prod_{i=1}^N  \probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} } = \sum_{i=1}^N  \ln\probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} }\]
</p>

<p>
ce qui est souvent plus facile.
</p>

<p>
En pratique, lorsque la fonction de densit√© \(f_\theta\) est connue, on maximise¬†:
</p>

<p>
\[\phi(\theta) = \sum_i \ln f_\theta(x_i)\]
</p>

<p>
en imposant¬†:
</p>

<p>
\[\deriveepartielle{\phi}{\theta}(\hat{\theta}) = 0\]
</p>
</div>
</div>


<div id="outline-container-orgccc7ab5" class="outline-3">
<h3 id="orgccc7ab5"><span class="section-number-3">1.8</span> Echantillon de densit√© donn√©e</h3>
<div class="outline-text-3" id="text-1-8">
<p>
Il s'agit d'un algorithme permettant de g√©n√©rer \(N\) nombres al√©atoires¬†:
</p>

<p>
\[\{ x_1, ..., x_N \}\]
</p>

<p>
suivant la densit√© \(f\). Soit \(\epsilon \ge 0\) une erreur maximale et \([a,b]\) tel que :
</p>

<p>
\[\int_a^b f(x) \ dx = 1 - \epsilon\]
</p>

<p>
Soit :
</p>

<p>
\[M = \sup_{x \in [a,b]} f(x)\]
</p>

<p>
et la g√©n√©ratrice¬†:
</p>

<p>
\[\rand(a,b)\]
</p>

<p>
qui renvoie des variables al√©atoires de densit√© uniforme sur \([a,b]\).
</p>

<p>
On part de \(A_0 = \emptyset\). A chaque it√©ration, on g√©n√©re deux nombres de densit√©s uniformes¬†:
</p>

<div class="org-center">
<p>
\(
x = \rand(a,b) \\
y = \rand(0,M)
\)
</p>
</div>

<p>
Afin de modifier cette densit√©, on n'ajoute \(x\) √† la liste d√©j√† obtenue¬†:
</p>

<p>
\[A_i = A_{i-1} \cup \{ x \}\]
</p>

<p>
que si \(y < f(x)\). Autrement, on ne fait rien et on passe √† l'it√©ration suivante.
</p>

<p>
La comparaison de \(y\) et de \(f(x)\) sert donc de filtre √† l'algorithme.
</p>
</div>
</div>
</div>


<div id="outline-container-orgb563fcd" class="outline-2">
<h2 id="orgb563fcd"><span class="section-number-2">2</span> Calcul stochastique</h2>
<div class="outline-text-2" id="text-2">
<div id="text-table-of-contents">
<ul>
<li><a href="#org815fec9">2.1. Processus stochastique</a></li>
<li><a href="#org4470070">2.2. Int√©grale d'Ito</a></li>
<li><a href="#org369758b">2.3. Variation quadratique</a></li>
<li><a href="#org8ba7ba7">2.4. Variation conjointe</a></li>
<li><a href="#orgb78e284">2.5. Relations variations quadratiques - conjointes</a></li>
<li><a href="#org1643d64">2.6. Variation d'ordre quelconque</a></li>
<li><a href="#org6d46279">2.7. Calcul d'Ito</a></li>
<li><a href="#org620b614">2.8. Mouvement Brownien</a></li>
</ul>
</div>

<p>
\label{chap:stocha}
</p>
</div>


<div id="outline-container-org815fec9" class="outline-3">
<h3 id="org815fec9"><span class="section-number-3">2.1</span> Processus stochastique</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Un processus stochastique est une fonction¬†:
</p>

<p>
\[X : [0,+\infty) \times \Omega \mapsto \setR, \quad (t,\omega) \mapsto X(t,\omega)\]
</p>

<p>
On sous-entend souvent l'√©v√©nement \(\omega\), et on note \(X(t)=X(t,\omega)\).
</p>
</div>
</div>


<div id="outline-container-org4470070" class="outline-3">
<h3 id="org4470070"><span class="section-number-3">2.2</span> Int√©grale d'Ito</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Il s'agit d'une int√©grale utilisant un processus stochastique \(X\) comme mesure¬†:
</p>

<p>
\[I(t) = \int_0^t f(s) \ dX(s) = \lim_{\delta \to 0} \sum_k f(t_k) (X(t_{k+1}) - X(t_k))\]
</p>
</div>
</div>


<div id="outline-container-org369758b" class="outline-3">
<h3 id="org369758b"><span class="section-number-3">2.3</span> Variation quadratique</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Soit \(\delta \strictsuperieur 0\) et les \(N\) temps \(t_k = k \cdot \delta\) o√π \(k = 0,...,\arrondisup{\frac{T}{\delta}}\). On d√©finit la variation quadratique d'une fonction \(f\)¬†:
</p>

<p>
\[\variation{f}(T) = \lim_{\delta \to 0} \sum_k (f(t_{k+1}) - f(t_k))^2\]
</p>

<p>
Si la d√©riv√©e de \(f\) existe, la variation quadratique s'annule car¬†:
</p>

<p>
\[(f(t_{k+1}) - f(t_k))^2 \to \delta^2 \ \OD{f}{t}(t_k)^2\]
</p>

<p>
Comme \(\delta^2 \to \delta \ ds\), on a¬†:
</p>

<p>
\[\variation{f}(T) = \lim_{\delta \to 0} \delta \int_0^T \left(\OD{f}{t}(s)\right)^2 ds = 0\]
</p>
</div>
</div>


<div id="outline-container-org8ba7ba7" class="outline-3">
<h3 id="org8ba7ba7"><span class="section-number-3">2.4</span> Variation conjointe</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Consid√©rons maintenant deux processus stochastiques \(X,Y\). Nous d√©finissons la variation conjointe \(\variation{X,Y}\)¬†:
</p>

<p>
\[\variation{X,Y}(T) = \lim_{\delta \to 0} \sum_k (X(t_{k+1}) - X(t_k)) \ (Y(t_{k+1}) - Y(t_k))\]
</p>

<p>
Dans le cas o√π les d√©riv√©es de \(X\) et de \(Y\) existent, on a √©videmment : \(\variation{X,Y} = 0\).
</p>

<p>
Pour une fonction \(f : \setR^2 \mapsto \setR\) quelconque, nous avons¬†:
</p>

<p>
\[df(X,Y) = f(X + \ dX,Y + dY) - f(X,Y)\]
</p>

<p>
Dans le cas particulier o√π \(f(X,Y)=X \cdot Y\), cette expression se r√©duit √†¬†:
</p>

\begin{align}
d(X \cdot Y) &= (X + \ dX) \cdot (Y + dY) - X \cdot Y \\
&= \ dX \cdot Y + X \cdot dY + \ dX \cdot dY
\end{align}

<p>
Mais comme¬†:
</p>

<p>
\[\variation{X,Y}(t) = \int_0^t \ dX \cdot dY\]
</p>

<p>
on a en d√©finitive¬†:
</p>

\begin{align}
X(t) Y(t) - X(0) Y(0) &= \int_0^t d(X Y)(s) \\
&= \int_0^t X(s) \ dY(s) + \int_0^t Y(s) \ dX(s) + \variation{X,Y}(t)
\end{align}
</div>
</div>


<div id="outline-container-orgb78e284" class="outline-3">
<h3 id="orgb78e284"><span class="section-number-3">2.5</span> Relations variations quadratiques - conjointes</h3>
<div class="outline-text-3" id="text-2-5">
<p>
La d√©finition nous donne directement¬†:
</p>

<p>
\[\variation{X} = \variation{X,X}\]
</p>

<p>
On peut aussi v√©rifier que¬†:
</p>

<p>
\[(X + Y)^2 - (X - Y)^2 = 4 \ X \ Y\]
</p>

<p>
d'o√π l'on d√©duit¬†:
</p>

<p>
\[\variation{X,Y} = \unsur{4} ( \variation{X + Y} - \variation{X - Y} )\]
</p>
</div>
</div>


<div id="outline-container-org1643d64" class="outline-3">
<h3 id="org1643d64"><span class="section-number-3">2.6</span> Variation d'ordre quelconque</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Soit \(\delta \strictsuperieur 0\) et les temps \(t_k = k \delta\) o√π \(k = 0,...,\arrondisup{\frac{T}{\delta}}\). On d√©finit la variation d'ordre \(n\) d'une fonction \(f\)¬†:
</p>

<p>
\[\variation{f}^n(T) = \lim_{\delta \to 0} \sum_k (f(t_{k+1}) - f(t_k))^n\]
</p>
</div>
</div>


<div id="outline-container-org6d46279" class="outline-3">
<h3 id="org6d46279"><span class="section-number-3">2.7</span> Calcul d'Ito</h3>
<div class="outline-text-3" id="text-2-7">
<p>
Soit une fonction \(F : \setR^n \mapsto \setR\) et \(N\) processus stochastiques \(X_i\) dont les variations d'ordre \(n \ge 3\) s'annulent. Soit \(X=(X_1,...,X_N)\). On peut √©crire le d√©veloppement en s√©rie de Taylor d'ordre 2¬†:
</p>

<p>
\[F(X + \Delta) - F(X) \approx \deriveepartielle{F}{X}(X) \Delta + \unsur{2} \Delta^T \dblederiveepartielle{F}{X}(X) \Delta\]
</p>

<p>
En faisant tendre \(\Delta \to 0\), on obtient¬†:
</p>

<p>
\[dF = \deriveepartielle{F}{X} \ dX + \unsur{2} \ dX^T \dblederiveepartielle{F}{X} \ dX\]
</p>

<p>
On a donc la formule de Ito pour une fonction $f : \setR<sup>n</sup> \mapsto \setR $¬†:
</p>

<p>
\[dF = \sum_i \deriveepartielle{F}{X_i} \ dX_i + \unsur{2} \sum_{i,j} \dfdxdy{F}{X_i}{X_j} \ dX_i \ dX_j\]
</p>

<p>
Ce qui nous permet d'√©valuer une variation de \(F\)¬†:
</p>

<div class="org-center">
<p>
\(
F(X(t)) - F(X(0)) =  \sum_i \int_0^t \deriveepartielle{F}{X_i}(X(s)) \ dX_i(s) + \\
\unsur{2} \sum_{i,j} \int_0^t \dfdxdy{F}{X_i}{X_j}(X(s)) \ d\variation{X_i,X_j}(s)
\)
</p>
</div>
</div>


<div id="outline-container-org26f0edf" class="outline-4">
<h4 id="org26f0edf"><span class="section-number-4">2.7.1</span> D√©riv√©es ordinaires</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
Dans le cas d'une seule variable, on a¬†:
</p>

<p>
\[dF = \sum_i \OD{F}{X} \ dX + \unsur{2} \OOD{F}{X} \ dX \ dX\]
</p>

<p>
Ce qui nous permet d'√©valuer une variation de \(F\)¬†:
</p>

<div class="org-center">
<p>
\(
F(X(t)) - F(X(0)) = \sum_i \int_0^t \OD{F}{X}(X(s)) \ dX(s) + \\
\unsur{2} \int_0^t \OOD{F}{X}(X(s)) d\variation{X}(s)
\)
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org620b614" class="outline-3">
<h3 id="org620b614"><span class="section-number-3">2.8</span> Mouvement Brownien</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Un mouvement brownien est un processus stochastique¬†:
</p>

<p>
\[B : [0,+\infty) \times \Omega \mapsto \setR, \quad (t,\omega) \mapsto B(t,\omega)\]
</p>

<p>
continu par rapport √† \(t\)¬†:
</p>

<p>
\[B_\omega : t \mapsto B(t,\omega) \in \Cont([0,+\infty))\]
</p>

<p>
De plus, si on d√©finit¬†:
</p>

<p>
\[\mathcal{B}_t : \omega \mapsto B(t,\omega)\]
</p>

<p>
on a la propri√©t√© d'ind√©pendance des variations temporelles¬†:
</p>

<p>
\[\cov{\mathcal{B}_u - \mathcal{B}_t}{\mathcal{B}_t - \mathcal{B}_s} = 0\]
</p>

<p>
pour tout \(s \strictinferieur t \strictinferieur u\) positifs. On demande aussi qu'une variation \(\mathcal{B}_t - \mathcal{B}_s\) suive une loi normale d'esp√©rance nulle et de variance \(t-s\)¬†:
</p>

<div class="org-center">
<p>
\(
\esperof{\mathcal{B}_t - \mathcal{B}_s}=0 \\
\var{\mathcal{B}_t - \mathcal{B}_s} = t - s
\)
</p>
</div>
</div>


<div id="outline-container-org106fbaf" class="outline-4">
<h4 id="org106fbaf"><span class="section-number-4">2.8.1</span> Variation quadratique</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
Si les mouvements browniens sont continus, ils ne sont pas d√©rivables. Comme les variations sont normalement distribu√©es avec une moyenne nulle et une variance \(t - s\), on en d√©duit (en utilisant par exemple le moment g√©n√©rateur des densit√©s normales)¬†:
</p>

<div class="org-center">
<p>
\(
\esperof{(\mathcal{B}_t - \mathcal{B}_s)^2} = t - s \\
\var{(\mathcal{B}_t - \mathcal{B}_s)^2} = 2 \ (t - s)^2
\)
</p>
</div>

<p>
La variation quadratique des mouvement browniens peut s'√©crire¬†:
</p>

<p>
\[\variation{B_\omega}(T) = \lim_{\delta \to 0} \sum_k (B_\omega(t_{k+1}) - B_\omega(t_k))^2\]
</p>

<p>
Lorsque \(\delta \to 0\), on a \(N \to +\infty\) et la loi des grands nombres nous dit que
chaque terme de la somme de droite converge vers la variance \(\delta\). Comme on a \(N\)
termes, on obtient¬†:
</p>

<p>
\[\sum_k B_\omega(t_{k+1}) - B_\omega(t_k) \to N \delta = T\]
</p>

<p>
On a donc¬†:
</p>

<p>
\[\variation{\mathcal{B}_\omega}(T) = T\]
</p>

<p>
Ce que l'on note symboliquement sous forme diff√©rentielle par¬†:
</p>

<p>
\[dB(t) \cdot dB(t) = dt\]
</p>
</div>
</div>


<div id="outline-container-org2052264" class="outline-4">
<h4 id="org2052264"><span class="section-number-4">2.8.2</span> Variations d'ordre quelconque</h4>
<div class="outline-text-4" id="text-2-8-2">
<p>
Les variations \(\variation{B}^n\) d'un mouvement brownien s'annulent pour \(n \ge 3\).
</p>
</div>
</div>


<div id="outline-container-org214723d" class="outline-4">
<h4 id="org214723d"><span class="section-number-4">2.8.3</span> Multidimensionnel</h4>
<div class="outline-text-4" id="text-2-8-3">
<p>
Nous d√©finissons un mouvement Brownien de dimension \(n\) comme une collection de \(n\) mouvements Browniens \(B_i\) ind√©pendants et v√©rifiant¬†:
</p>

<p>
\[\variation{B_i,B_j}(t) = \indicatrice_{ij} \cdot t\]
</p>
</div>
</div>


<div id="outline-container-org3b2faaf" class="outline-4">
<h4 id="org3b2faaf"><span class="section-number-4">2.8.4</span> Calul d'Ito</h4>
<div class="outline-text-4" id="text-2-8-4">
<p>
Dans le cas de \(N\) mouvement browniens \(B_i\), les √©quations d'Ito deviennent¬†:
</p>

<p>
\[dF = \sum_i \deriveepartielle{F}{X_i} dB_i + \unsur{2} \sum_{i,j} \dfdxdy{F}{X_i}{X_j} \ dB_i \ dB_j\]
</p>

<p>
Mais comme \(dB_i dB_j = d\variation{B_i,B_j} = \indicatrice_{ij} \ dt\), on a¬†:
</p>

<p>
\[dF = \sum_i \deriveepartielle{F}{X_i} \ dB_i + \unsur{2} \sum_i \dfdxdy{F}{X_i}{X_i} \ dt\]
</p>

<p>
Ce qui nous permet d'√©valuer une variation de \(F\)¬†:
</p>

<div class="org-center">
<p>
\(
F(X(t)) - F(X(0)) = \sum_i \int_0^t \deriveepartielle{F}{X_i}(X(s)) \ dX_i(s) + \\
\unsur{2} \sum_i \int_0^t \dfdxdy{F}{X_i}{X_i}(X(s)) \ ds
\)
</p>
</div>
</div>
</div>


<div id="outline-container-org599a77b" class="outline-4">
<h4 id="org599a77b"><span class="section-number-4">2.8.5</span> D√©riv√©e ordinaire</h4>
<div class="outline-text-4" id="text-2-8-5">
<p>
Le cas particulier unidimensionnel nous donne¬†:
</p>

<p>
\[dF(B) = \OD{F}{X}(B) \ dB + \unsur{2}\OOD{F}{X}(B) \ dB \cdot dB\]
</p>

<p>
Mais comme¬†:
</p>

<p>
\[d\variation{B} = dB \cdot dB = dt\]
</p>

<p>
on a¬†:
</p>

<p>
\[dF(B) = \OD{F}{X}(B) \ dB + \unsur{2}\OOD{F}{X}(B) \ dt\]
</p>

<p>
et¬†:
</p>

<p>
\[F(B(t))-F(B(0)) = \int_0^t \OD{F}{X}(B(s)) \ dB(s) + \unsur{2} \int_0^t \OOD{F}{X}(B(s)) \ ds\]
</p>

<p>
AFAIRE : PROCESSUS DE POISSON
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2019-10-01 mar 12:19</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
