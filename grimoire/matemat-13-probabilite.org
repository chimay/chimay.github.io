
#+STARTUP: showall

#+TITLE: Eclats de vers : Matemat 13 : Probabilité
#+AUTHOR: chimay
#+EMAIL: or du val chez gé courriel commercial
#+LANGUAGE: fr
#+LINK_HOME: file:../index.html
#+LINK_UP: file:index.html
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../style/defaut.css" />

#+OPTIONS: H:6
#+OPTIONS: toc:nil

#+TAGS: noexport(n)

[[file:index.org][Index des Grimoires]]

#+INCLUDE: "../include/navigan-1.org"

#+TOC: headlines 1

#+INCLUDE: "../include/commandes-tex.org"

* Probabilité

#+TOC: headlines 1 local

\label{chap:proba}


** Probabilité

Une probabilité $\proba$ sur un ensemble d'événements $\Omega$ est une mesure définie sur $\mathcal{S}=\{ A : A \subseteq \Omega \}$ et à valeurs dans $[0,1]$ :

$$\proba : \mathcal{S} \mapsto [0,1] \quad$$

Cette probabilité doit vérifier la normalisation :

$$\probaof{\Omega} = 1$$

ainsi que l'additivité :

$$\probaof{\bigcup_i \Phi_i} = \sum_i \probaof{\Phi_i}$$

lorsque les ensembles $\Phi_i$ sont disjoints deux à deux :

#+BEGIN_CENTER
\(
\Phi_i \cap \Phi_j =
\begin{cases}
\Phi_i & i = j \\
\emptyset & i \ne j
\end{cases}
\)
#+END_CENTER

On en déduit directement que :

$$\probaof{\Phi} = \probaof{\Phi \cup \emptyset} = \probaof{\Phi} + \probaof{\emptyset}$$

d'où $\probaof{\emptyset} = 0$.

La grandeur $\probaof{\Phi}$ peut s'interpréter comme la probabilité que l'un des événements de $\Phi$ se réalise.


** Variable aléatoire

Une variable aléatoire $X$ associe une valeur réelle a chaque élément de $\Omega$. On a donc $X : \Omega \mapsto \setR$.


** Mesure induite

Etant donné une variable aléatoire $X$, on peut définir une mesure induite $\mathcal{L}_X : \sousens(\setR) \mapsto [0,1]$, qui exprime la probabilité qu'un événement $\omega \in \Omega$ donne une valeur appartenant à un sous-ensemble $U \subseteq \setR$ :

$$\mathcal{L}_X(U) = \probaof{X^{-1}(U)} = \probaof{ \{ \omega\in\Omega : X(\omega) \in U \} }$$


*** Variables conjointes

La mesure induite par deux variables aléatoires $X$ et $Y$ se définit par :

$$\mathcal{L}_{X,Y}(D) = \probaof{ \{ \omega\in\Omega : (X(\omega),Y(\omega)) \in D \} }$$

pour tout $D \subseteq\setR^2$.

On voit clairement que :

#+BEGIN_CENTER
\(
\mathcal{L}_X(U) = \mathcal{L}_{X,Y}(U \times \setR) \\
\mathcal{L}_Y(U) = \mathcal{L}_{X,Y}(\setR \times U)
\)
#+END_CENTER


** Collection induite

Soit $X$ une variable aléatoire et $U \subseteq \setR$. On définit le sous-ensemble de $\Omega$ :

$$\Theta(X,U) = \{ \omega \in \Omega : X(\omega) \in U \}$$

ou de manière équivalente en utilisant la relation inverse $X^{-1}$ :

$$\Theta(X,U) = X^{-1}(U)$$

La collection $\Lambda(X)$ induite par $X$ est un ensemble regroupant les $\Theta(X,U)$ pour tous les sous-ensembles de $\setR$ :

$$\Lambda(X) = \{ \Theta(X,U) : U \subseteq \setR \}$$

Comme :

#+BEGIN_CENTER
\(
\Theta(X,\emptyset) = \emptyset \\
\Theta(X,\setR) = \Omega
\)
#+END_CENTER

il est clair que l'on a $\emptyset, \Omega \in \Lambda(X)$ quelle que soit la variable aléatoire $X$.


*** Fonctions indicatrices

Si $\Phi \subseteq \Omega$ et $X = \indicatrice_\Phi$, on a :

#+BEGIN_CENTER
\(
\Theta(\indicatrice_\Phi, \{1\}) = \{ \omega : \indicatrice_\Phi(\omega) = 1 \} = \Phi \\
\Theta(\indicatrice_\Phi, \{0\}) = \{ \omega : \indicatrice_\Phi(\omega) = 0 \} = \Omega \setminus \Phi
\)
#+END_CENTER

De même, si un ensemble $U \subseteq \setR$ :

  - ne contient ni $1$ ni $0$, on a $\Theta(\indicatrice_\Phi,U) = \emptyset$
  - contient $1$ et $0$, on a $\Theta(\indicatrice_\Phi,U) = \Omega$
  - contient $1$ et pas $0$, on a $\Theta(\indicatrice_\Phi,U) = \Phi$
  - contient $0$ et pas $1$, on a $\Theta(\indicatrice_\Phi,U) = \Omega \setminus \Phi$

On a donc :

$$\Lambda(\indicatrice_\Phi) = \{ \emptyset, \Omega, \Phi, \Omega \setminus \Phi \}$$


** Espérance

L'espérance d'une variable aléatoire $X$ est simplement une moyenne pondérée par les probablités que $X$
prennent telle ou telle valeur :

$$\esperof{X} = \int_{\Omega} X(\omega) \ d\proba(\omega)$$


*** Indicatrice

Notons que pour tout $\Phi \subseteq \Omega$, on a :

\begin{align}
\esperof{\indicatrice_\Phi} &= \int_\Omega \indicatrice_\Phi \ d\proba \\
&= \int_\Phi \ d\proba
\end{align}

et donc :

$$\esperof{\indicatrice_\Phi} = \probaof{\Phi}$$


*** Fonction d'une variable aléatoire

Pour toute fonction $G : \setR \mapsto \setR$, on a bien évidemment $G \circ X : \Omega \mapsto \setR$ et on peut définir :

$$\esperof{G(X)} = \int_\Omega (G \circ X)(\omega) \ d\proba(\omega)$$


*** Fonction de plusieurs variables aléatoires

De même, si $X$ et $Y$ sont deux variables aléatoires, pour toute fonction $G : \setR^2 \mapsto \setR$, on a évidemment $G(X,Y) \in \setR$ et on peut définir :

$$\esperof{G(X,Y)} = \int_\Omega G\left(X(\omega),Y(\omega)\right) \ d\proba(\omega)$$

Le cas particulier $G(X,Y) = a \ X + b \ Y$, où $a,b \in \setR$, nous montre la linéarité de l'espérance, qui découle directement de celle de l'intégrale :

$$\esperof{a \ X + b \ Y} = a \ \esperof{X} + b \ \esperof{Y}$$


** Espérance et mesure induite

Soit une variable aléatoire $X$ et la fonction étagée $G : \setR \mapsto \setR$ définie
pour tout $x \in \setR$ par :

$$G(x) = \sum_i g_i \ \indicatrice_{A_i}(x)$$

où les $A_i$ forment une partition de $\setR$ et où les $g_i$ sont supposés sans
perte de généralité être des réels distincts. Soit la partition de $\Omega$ constituée
des ensembles :

$$\Omega_i = X^{-1}(A_i) = \{ \omega \in \Omega : X(\omega) \in A_i \}$$

On voit que $(G \circ X)(\omega) = g_i$ pour tout $\omega \in \Omega_i$.
Calculons l'espérance de $G(X)$ :

\begin{align}
\esperof{G(X)} &= \int_\Omega (G \circ X)(\omega) \ d\proba(\omega) \\
&= \sum_i \int_{\Omega_i} (G \circ X)(\omega) \ d\proba(\omega) \\
&= \sum_i \int_{\Omega_i} g_i \ d\proba(\omega) \\
&= \sum_i g_i \int_{\Omega_i} \ d\proba(\omega) \\
&= \sum_i g_i \ \probaof{\Omega_i}
\end{align}

Par définition de la mesure induite, on a :

$$\mathcal{L}_X(A_i) = \probaof{X^{-1}(A_i)} = \probaof{\Omega_i}$$

L'espérance de $G(X)$ peut donc s'exprimer comme :

$$\esperof{G(X)} = \sum_i g_i \ \mathcal{L}_X(A_i)$$

Mais le membre de droite n'est autre que l'intégrale de $G$ sur $\setR$
utilisant la mesure $\mathcal{L}_X$ :

$$\esperof{G(X)} = \int_\setR G(x) \ d\mathcal{L}_X(x)$$

Comme cette expression doit être valable pour toute fonction en escalier, on en conclut que :

$$\esperof{G(X)} = \int_\setR G(x) \ d\mathcal{L}_X(x)$$

pour toute fonction intégrable $G$.


*** Identité

Le cas particulier $G = \identite$ nous donne :

$$\esperof{X} = \int_\setR x \ d\mathcal{L}_X(x)$$


*** Densité

Si il existe une fonction $f_X : \setR \mapsto \setR$ telle que $d\mathcal{L}_X = f_X \ dx$,
où $dx$ correspond à la mesure de Lebesgue sur $\setR$, on a :

$$\esperof{G(X)} = \int_\setR G(x) \ f_X(x) \ dx$$

ainsi que :

$$\esperof{X} = \int_\setR x \ f_X(x) \ dx$$

On nomme cette fonction $f_X$ la densité de la variable aléatoire $X$.

Remarquons que $f_X$ est positive par positivité de la mesure. Comme :

$$\esperof{1} = 1$$

on obtient la propriété de normalité :

$$\int_\setR f_X(x) \ dx = 1$$


**** Variable aléatoire gaussienne

Une variable aléatoire est dite normale de paramètres $\mu$, $\sigma$ si sa fonction
densité vérifie :

$$f_{X}(x) = \frac{1}{ \sigma\sqrt{2 \pi} } \exp\left(-\frac{(x-\mu)^2}{2 \sigma^2}\right)$$


*** Variables conjointes

Soit les variables aléatoires $X, Y$ et la fonction étagée $G : \setR^2 \mapsto \setR$ définie
pour tout $x, y \in \setR$ par :

$$G(x,y) = \sum_i g_i \ \indicatrice_{A_i}(x,y)$$

où les $A_i$ forment une partition de $\setR^2$ et où les $g_i$ sont supposés sans
perte de généralité être des réels distincts. Soit la partition de $\Omega$ constituée
des ensembles :

$$\Omega_i = \{ \omega \in \Omega : (X(\omega), Y(\omega)) \in A_i \}$$

On voit que $G(X(\omega), Y(\omega)) = g_i$ pour tout $\omega \in \Omega_i$.
Calculons l'espérance de $G(X,Y)$ :

\begin{align}
\esperof{G(X,Y)} &= \int_\Omega G(X(\omega), Y(\omega)) \ d\proba(\omega) \\
&= \sum_i \int_{\Omega_i} G(X(\omega), Y(\omega)) \ d\proba(\omega) \\
&= \sum_i \int_{\Omega_i} g_i \ d\proba(\omega) \\
&= \sum_i g_i \int_{\Omega_i} \ d\proba(\omega) \\
&= \sum_i g_i \ \probaof{\Omega_i}
\end{align}

Par définition de la mesure induite, on a :

$$\mathcal{L}_{X,Y}(A_i) = \probaof{\Omega_i}$$

L'espérance de $G(X)$ peut donc s'exprimer comme :

$$\esperof{G(X,Y)} = \sum_i g_i \ \mathcal{L}_{X,Y}(A_i)$$

Mais le membre de droite n'est autre que l'intégrale de $G$ sur $\setR^2$
utilisant la mesure $\mathcal{L}_{X,Y}$ :

$$\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ d\mathcal{L}_{X,Y}(x,y)$$

Comme cette expression doit être valable pour toute fonction en escalier, on en conclut que :

$$\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ d\mathcal{L}_{X,Y}(x,y)$$

pour toute fonction intégrable $G$.


*** Densité conjointe

Si il existe une fonction $f_{X,Y} : \setR^2 \mapsto \setR$ telle que
$d\mathcal{L}_{X,Y} = f_{X,Y} \ dx \ dy$, où $dx \ dy$ correspond à la mesure de Lebesgue
sur $\setR^2$, on a :

$$\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ f_{X,Y}(x,y) \ dx \ dy$$

En considérant le cas particulier $G(X,Y) = X$, on obtient :

\begin{align}
\esperof{X} &= \int_{\setR^2} x \ f_{X,Y}(x,y) \ dx \ dy \\
&= \int_\setR x \ \left[\int_\setR f_{X,Y}(x,y) \ dy\right] \ dx
\end{align}

En définissant la fonction associée $f_X$ par :

$$f_X(x) = \int_\setR f_{X,Y}(x,y) \ dy$$

on peut dès lors écrire l'espérance de $X$ comme :

$$\esperof{X} = \int_\setR x \ f_X(x) \ dx$$

En suivant le même déroulement pour $\esperof{Y}$, et en définissant :

$$f_Y(y) = \int_\setR f_{X,Y}(x,y) \ dx$$

on peut écrire l'espérance de $Y$ comme :

$$\esperof{Y} = \int_\setR y \ f_Y(y) \ dy$$


**** Distribution normale

On dit que les variables aléatoires $X_1, ..., X_N$ présentent une distribution normale multivariée si il existe :

#+BEGIN_CENTER
\(
\mu = \left( \mu_i \right)_i \\
\Theta = \left( \sigma_{ij} \right)_{i,j}
\)
#+END_CENTER

tels que la fonction densité associée à $X = (X_1, ..., X_N)^T$ s'écrive :

$$\f_X(x) = \unsur{2 \pi^{n/2} \det{A}} \exp\left(-\unsur{2} (x-\mu)^T \cdot \Theta^{-1} \cdot (x-\mu) \right)$$

pour tout $x \in \setR^N$. On a alors :

#+BEGIN_CENTER
\(
\esperof{X_i} = \mu_i \\
\cov{X_i}{X_j} = \sigma_{ij}
\)
#+END_CENTER

On a aussi la fonction génératrice :

$$\Psi_X(u) = \exp\left(u^T \cdot \mu + \unsur{2} u^T \cdot \Theta^{-1} \cdot u\right)$$

pour tout $u \in \setR^N$.

** Fonction génératrice des moments

On définit le moment générateur d'une densité par :

$$\Psi_X(u) = \esperof{\exp(X \cdot u)}$$

L'intérêt de cette fonction est qu'elle permet de calculer facilement
les espérances des puissances naturelles de $X$. En effet :

$$\frac{d^k \Psi_X}{du^k}(u) = \esperof{X^k \ \exp(X \cdot u)}$$

et donc :

$$\OD{\Psi}{u}(0) = \esperof{X^k \ \exp(0)} = \esperof{X^k}$$


*** Variable gaussienne

A titre d'exemple, nous calculons le  moment générateur associé à une densité gaussienne :

$$\Psi(u) = \unsur{\sqrt{2 \pi} \sigma} \int_\setR \exp(x u) \exp\left(-\frac{(x-\mu)^2}{2 \sigma^2}\right) dx$$

On obtient en développant :

\begin{align}
\Psi(u) &= \unsur{\sqrt{2 \pi} \sigma} \int_\setR \exp\left(x u - \frac{(x-\mu)^2}{2 \sigma^2}\right) dx \\
&= \unsur{\sqrt{2 \pi} \sigma} \exp(\mu u + \unsur{2} u^2 \sigma^2) \int_\setR \exp\left(- \frac{(x-(\mu + u \sigma^2) )^2}{2 \sigma^2}\right) dx
\end{align}

Comme l'intégrale vaut $\sqrt{2 \pi} \sigma$, on obtient finalement :

$$\Psi(u) = \exp(u \mu + \unsur{2} u^2 \sigma^2)$$


** Variance

La variance de $X$ est la variation carrée moyenne de $X$ autour de son espérance $\esperof{X}$ :

$$\var{X} = \esperof{\left(X-\esperof{X}\right)^2}$$

Comme la variable $Z = \left(X-\esperof{X}\right)^2$ est positive, son espérance doit également etre positive et $\var{X} \ge 0$.

En développant la définition et en utilisant la linéarité de l'espérance, on obtient :

\begin{align}
\var{X} &= \esperof{X^2 - 2 \ X \cdot \esperof{X} + \esperof{X}^2} \\
&= \esperof{X^2} - 2 \ \esperof{X} \cdot \esperof{X} + \esperof{X}^2 \cdot \esperof{1} \\
&= \esperof{X^2} - 2 \ \esperof{X}^2 + \esperof{X}^2
\end{align}

soit :

$$\var{X} = \esperof{X^2} - \esperof{X}^2$$


*** Invariance sous translation

Notons que si $X,Y$ sont deux variables aléatoires reliées par :

$$Y = X + a$$

où $a \in \setR$, on a :

\begin{align}
\var{Y} &= \esperof{\left(Y-\esperof{Y}\right)^2} \\
&= \esperof{\left(X + a -\esperof{X+a}\right)^2} \\
&= \esperof{\left(X + a -\esperof{X} - a\right)^2} \\
&= \esperof{\left(X -\esperof{X}\right)^2} \\
&= \var{X}
\end{align}

La variance est donc invariante sous translation :

$$\var{X+a} = \var{X}$$


** Covariance

La covariance de deux variables aléatoire $X,Y$ se définit par :

$$\cov{X}{Y} = \esperof{(X-\esperof{X}) \cdot (Y-\esperof{Y})}$$

En développant et en utilisant la linéarité de l'espérance, on obtient :

\begin{align}
\cov{X}{Y} &= \esperof{X \cdot Y} - \esperof{X} \cdot \esperof{Y} - \esperof{Y} \cdot \esperof{X} + \esperof{X} \cdot \esperof{Y} \\
&= \esperof{X \cdot Y} - \esperof{X} \cdot \esperof{Y}
\end{align}

On voit également que la variance d'une variable aléatoire $X$ n'est rien d'autre que sa covariance avec elle-même :

$$\var{X} = \cov{X}{X}$$


*** Invariance sous translation

Suivant le même raisonnement que pour la variance, on considère les variables aléatoires $W,X,Y,Z$ reliées par :

#+BEGIN_CENTER
\(
W = X + a \\
Z = Y + b
\)
#+END_CENTER

où $a,b \in \setR$. La covariance entre $W$ et $Z$ s'exprime alors :

\begin{align}
\cov{W}{Z} &= \esperof{(W - \esperof{W})(Z - \esperof{Z})} \\
&= \esperof{(X + a - \esperof{X} - a)(Y + b - \esperof{Y} - b)} \\
&= \esperof{(X - \esperof{X})(Y - \esperof{Y})} \\
&= \cov{X}{Y}
\end{align}

La covariance est donc invariante sous translation :

$$\cov{X+a}{Y+b} = \cov{X}{Y}$$


** Variance d'une combinaison linéaire

Nous utilisons la notation :

$$X_0 = X - \esperof{X}$$

pour toute variable aléatoire $X$. Cette variables aléatoire $X_0$ a la propriété
d'avoir une espérance nulle car :

$$\esperof{X_0} = \esperof{X - \esperof{X} } = \esperof{X} - \esperof{X} = 0$$

La variance d'une telle variable peut s'écrire :

$$\var{X_0} = \esperof{X_0^2} - \esperof{X_0}^2 = \esperof{X_0^2}$$

Quant à la covariance, elle s'écrit :

$$\cov{X_0}{Y_0} = \esperof{X_0 \ Y_0} - \esperof{X_0} \ \esperof{Y_0} = \esperof{X_0 \ Y_0}$$

Soit les réels $a,b$. Par linéarité de l'espérance, on a :

$$\esperof{a \ X + b \ Y} = a \ \esperof{X} + b \ \esperof{Y}$$

La variance de la combinaison linéaire $a \ X + b \ Y$ s'écrit :

\begin{align}
\var{a \ X + b \ Y} &= \esperof{(a \ X + b \ Y - \esperof{a \ X + b \ Y})^2} \\
&= \esperof{(a \ X + b \ Y - a \ \esperof{X} - b \ \esperof{Y})^2} \\
&= \esperof{(a \ X_0 + b \ Y_0)^2}
\end{align}

En développant, on arrive à :

\begin{align}
\var{a \ X + b \ Y} &= \esperof{a^2 \ X_0^2 + 2 \ a \ b \ X_0 \ Y_0 + b^2 \ Y_0^2} \\
&= a^2 \ \esperof{X_0^2} + 2 \ a \ b \ \esperof{X_0 \ Y_0} + b^2 \ \esperof{Y_0^2}
\end{align}

et donc :

$$\var{a \ X + b \ Y} = a^2 \ \var{X_0} + 2 \ a \ b \ \cov{X_0}{Y_0} + b^2 \ \var{Y_0}$$

L'invariance sous translation nous permet alors d'écrire :

$$\var{a \ X + b \ Y} = a^2 \ \var{X} + 2 \ a \ b \ \cov{X}{Y} + b^2 \ \var{Y}$$


** Produit scalaire

Nous allons voir que la covariance est un produit scalaire. Nous utilisons la notation :

$$X_0 = X - \esperof{X}$$

pour toute variable aléatoire $X$. Cette variables aléatoire $X_0$ a la propriété
d'avoir une espérance nulle car :

$$\esperof{X_0} = \esperof{X - \esperof{X} } = \esperof{X} - \esperof{X} = 0$$

On en déduit que :

$$\cov{X_0}{Y_0} = \esperof{X_0 \ Y_0} - \esperof{X_0} \ \esperof{Y_0} = \esperof{X_0 \ Y_0}$$

La symétrie est vérifiée :

$$\cov{Y_0}{X_0} = \esperof{Y_0 \cdot X_0} = \esperof{X_0 \cdot Y_0} = \cov{X_0}{Y_0}$$

En ce qui concerne le caractère défini positif, on a :

$$\cov{X_0}{X_0} = \esperof{X_0^2} \ge 0$$

De plus, si $X_0$ est tel que $\cov{X_0}{X_0} = 0$, on a :

$$\int_\Omega X_0^2 \ d\proba(\omega) = 0$$

ce qui entraîne la nullité essentielle $X_0 \essegal 0$ sur $\Omega$.

Soit les réels $a,b$. On voit que la linéarité est bien respectée :

\begin{align}
\cov{X_0}{a \ Y_0 + b \ Z_0} &= \esperof{X_0 \ (a \ Y_0 + b \ Z_0)} \\
&= a \ \esperof{X_0 \ Y_0} + b \ \esperof{X_0 \ Z_0} \\
&= a \ \cov{X_0}{Y_0} + b \ \cov{X_0}{Z_0}
\end{align}

Nous venons de montrer que la covariance est essentiellement un produit scalaire
pour toute variable aléatoires à espérance nulles $X_0, Y_0$. Comme la covariance
est invariante sous translation, on voit que :

$$\cov{X}{Y} = \cov{X_0}{Y_0}$$

est également un produit scalaire pour toutes variables aléatoires $X,Y$.


*** Cauchy-Schwartz

En appliquant l'inégalité de Cauchy-Schwartz à ce produit scalaire, on obtient :

$$\cov{X}{Y}^2 \le \cov{X}{X} \ \cov{Y}{Y} = \var{X} \ \var{Y}$$

où, en prenant la racine :

$$\cov{X}{Y} \le \sqrt{\var{X} \ \var{Y}}$$


** Probabilité conditionnelle

\label{sec:proba_cond}

On définit une nouvelle famille de probabilités :

$$\probaof{A | B} = \frac{ \probaof{A \cap B} }{ \probaof{B} }$$

où $A,B$ sont des sous-ensembles quelconque de $\Omega$, et où $B$ est tel que :

$$\probaof{B} > 0$$

Comme $B \cap B = B$, on a :

$$\probaof{ B | B } = 1$$

On est donc certain qu'un événement de $B$ va se produire. En fait, pour tout ensemble $C$ tel que $B \subseteq C$, on a $C \cap B = B$ et :

$$\probaof{ C | B } = 1$$

On déduit de l'inégalité :

$$\probaof{A \cap B} \le \probaof{B}$$

que :

$$\probaof{A | B} \le 1$$

D'un autre coté, comme $\probaof{B} \le 1$, on a :

$$\probaof{A | B} \ge \probaof{A \cap B} \ge 0$$

L'additivité est également satisfaite :

\begin{align}
\probaof{ \cup_i A_i | B} &= \frac{ \probaof{(\cup_i A_i) \cap B} }{ \probaof{B} } \\
&= \frac{ \probaof{\cup_i (A_i \cap B)} }{ \probaof{B} } \\
&= \sum_i \frac{ \probaof{A_i \cap B} }{ \probaof{B} } = \sum_i \probaof{ A_i | B}
\end{align}

pour toute famille de $A_i$ disjoints deux à deux. Les fonctions :

$$\proba_B\left[ A \right] = \probaof{A | B}$$

forment donc bien une famille de probabilités. On dit que $\probaof{A | B}$ est la probabilité conditionnelle de $A$ sachant $B$.

Lorsque $B = \Omega$, on retrouve d'ailleurs :

$$\probaof{A | \Omega} = \probaof{A}$$


*** Indépendance

On dit que deux ensembles d'événements $A$ et $B$ sont indépendants si :

$$\probaof{A | B} = \probaof{A}$$

c'est-à-dire si :

$$\probaof{A \cap B} = \probaof{A} \cdot \probaof{B}$$


*** Application

Une technique fréquemment employée pour évaluer $\probaof{A}$ est d'utiliser
une partition $B_1,...,B_n$ de $\Omega$. Utilisant $A = A \cup \Omega$, on a alors :

$$\probaof{A} = \sum_i \probaof{A \cap B_i} = \sum_i \probaof{A | B_i} \cdot \probaof{B_i}$$


** Espérance conditionnelle à un ensemble

Soit $A \subseteq \Omega$. On a vu que :

$$\esperof{\indicatrice_A} = \probaof{A}$$

pour toute fonction indicatrice d'un sous-ensemble $A$ de $\Omega$. Par analogie, on aimerait bien obtenir une expression d'une espérance conditionnelle vérifiant :

$$\esperof{\indicatrice_A | B} = \probaof{A | B}$$

pour un ensemble $B \subseteq \Omega$ donné vérifiant $\probaof{B} > 0$.

Soit $\Omega_1, ..., \Omega_N$ une partition de $\Omega$ et $Z$ une variable aléatoire en escalier :

$$Z(\omega) = \sum_i Z_i \ \indicatrice_{\Omega_i}(\omega)$$

On voit que :

\begin{align}
\esperof{Z | B} &= \sum_i Z_i\ \esperof{\indicatrice_{\Omega_i} | B} \\
&= \sum_i Z_i\ \probaof{\Omega_i | B}
\end{align}

Or :

$$\probaof{\Omega_i | B} = \frac{ \probaof{\Omega_i \cap B} }{ \probaof{B} }$$

On a donc :

$$\esperof{Z | B} = \unsur{ \probaof{B} } \sum_i Z_i\ \probaof{\Omega_i \cap B}$$

Considérons la nouvelle partition :

#+BEGIN_CENTER
\(
\Phi_i^+ = \Omega_i \cap B \\
\Phi_i^- = \Omega_i \cap (\Omega \setminus B)
\)
#+END_CENTER

Comme $\Phi_i^+ \cup \Phi_i^- = \Omega_i$, on a clairement $\indicatrice_{\Phi_i^+} + \indicatrice_{\Phi_i^-} = \indicatrice_{\Omega_i}$ et on peut réexprimer $Z$ comme :

$$Z(\omega) = \sum_i Z_i\ \indicatrice_{\Phi_i^+}(\omega) + \sum_i Z_i\ \indicatrice_{\Phi_i^-}(\omega)$$

L'expression de l'espérance conditionelle devient :

$$\esperof{Z | B} = \unsur{ \probaof{B} } \left[ \sum_i Z_i\ \probaof{\Phi_i^+ \cap B} + \sum_i Z_i\ \probaof{\Phi_i^- \cap B} \right]$$

Remarquons que par construction :

#+BEGIN_CENTER
\(
\Phi_i^+ \cap B = \Phi_i^+ \\
\Phi_i^- \cap B = \emptyset
\)
#+END_CENTER

Par conséquent, les termes en $\probaof{\Phi_i^- \cap B}$ s'annulent et on a :

$$\esperof{Z | B} = \unsur{ \probaof{B} } \sum_i Z_i\ \probaof{\Phi_i^+}$$

Mais comme $\bigcup_i \Phi_i^+ = B$, les $\Phi_i^+$ forment une partition de $B$ et on peut écrire cette expression sous la forme intégrale :

$$\esperof{Z | B} = \frac{ \int_B Z\ \ d\proba }{ \int_B \ d\proba }$$

Comme cette relation doit être valable pour toute variable aléatoire en escalier $Z$, elle l'est également pour une variable aléatoire quelconque $X$ :

$$\esperof{X | B} = \frac{ \int_B X\ \ d\proba }{ \int_B \ d\proba }$$


*** Densité conditionnelle

Soient $X,Y$ deux variables aléatoires. Un cas particulier important d'espérance conditionnelle est celui où :

$$B_y = \{ \omega : Y(\omega) = y \}$$

On note alors :

$$\esperof{X | Y = y} = \esperof{X | B_y}$$

On remarque que :

$$(X,Y)(B_y) = \{ (x,y) \in \setR^2 : x \in \setR \}$$

Par conséquent, si il existe une fonction densité $f_{X,Y}$ associée à $X,Y$, on peut écrire :

\begin{align}
\int_{B_y} X \ d\proba &= \int_{(X,Y)(B_y)} x \ f_{X,Y}(x,y) \ dx \ dy \\
&= \int_\setR x \ f_{X,Y}(x,y) \ dx
\end{align}

ainsi que :

$$\int_{B_y} \ d\proba = \int_\setR f_{X,Y}(x,y) \ dx$$

L'espérance conditionnelle s'écrit alors :

$$\esperof{X | Y = y} = \frac{\int_\setR x \ f_{X,Y}(x,y) \ dx}{\int_\setR f_{X,Y}(x,y) \ dx}$$

Donc, si on définit :

$$f_{X | Y}(x,y) = \frac{f_{X,Y}(x,y)}{ \int_\setR f_{X,Y}(x,y) \ dx}$$

on a tout simplement :

$$\esperof{X | Y = y} = \int_\setR x \ f_{X | Y}(x,y) \ dx$$


** Espérance conditionnelle à une tribu


*** Tribu et espace fonctionnel

Soit $\Gamma \subseteq \sousens(\Omega)$ une collection de sous-ensembles de $\Omega$ formant une tribu sur $\Omega$ (voir section \ref{sec:tribu}),
et $\mathcal{F}(\Gamma)$ l'ensemble des variables aléatoires $W$ telles que :

$$\Lambda(W) \subseteq \Gamma$$

où $\Lambda(W)$ est la collection induite par $W$.


*** Minimisation

L'espérance conditionnelle est construite comme le meilleur estimateur au sens des moindres carrés d'une variable aléatoire $X$ sur $\mathcal{F}(\Gamma)$. Soit la fonctionnelle $I : \mathcal{F}(\Gamma) \mapsto \setR$ représentant l'erreur :

$$I(Z) = \int_\Omega \left[ Z(\omega) - X(\omega) \right]^2 \ d\proba(\omega)$$

Nous allons minimiser $I$ sur $\mathcal{F}(\Gamma)$. Pour ce faire, on utilise la technique du calcul variationnel (voir chapitre \ref{chap:varia}). On commence par définir :

$$J_W(\epsilon) = I(Z^* + \epsilon W) = \int_\Omega (Z^* + \epsilon W - X)^2 \ d\proba$$

où la variable aléatoire $Z^*$ est l'optimum recherché, et où $W \in \mathcal{F}(\Gamma)$, $\epsilon \in \setR$. La dérivée s'écrit :

$$\OD{J_W}{\epsilon}(\epsilon) = \int_\Omega 2 (Z^* +\epsilon W - X) W \ d\proba = 0$$

Comme celle-ci doit s'annuler en $\epsilon = 0$, on a :

$$\OD{J_W}{\epsilon}(0) = \int_\Omega 2 (Z^* - X) W \ d\proba = 0$$

Autrement dit :

$$\int_\Omega W Z^* \ d\proba = \int_\Omega W X \ d\proba$$

équation qui doit être vérifiée pour tout $W \in \mathcal{F}(\Gamma)$.


*** Unicité

Nous supposons dorénavant que $\mathcal{F}(\Gamma)$ est un espace vectoriel. Soient $Z_1, Z_2 \in \mathcal{F}(\Gamma)$ des variables aléatoires qui minimisent tous deux la fonctionnelle $I$. On a :

$$\int_\Omega W Z_1 \ d\proba = \int_\Omega W Z_2 \ d\proba = \int_\Omega W X \ d\proba$$

pour tout $W \in \mathcal{F}(\Gamma)$. Donc :

$$\int_\Omega W (Z_1 - Z_2) \ d\proba = 0$$

Mais comme $Z_1 - Z_2 \in \mathcal{F}(\Gamma)$, il suffit de considérer le cas $W = Z_1 - Z_2$ pour avoir :

$$\int_\Omega (Z_1 - Z_2)^2 \ d\proba = 0$$

On en conclut que $Z_1 = Z_2$ presque partout sur $\Omega$. L'espérance conditionnelle est donc unique pour $X$ et $\Gamma$ donnés.


*** Définition

Forts de ces résultats, on définit l'espérance de $X$ conditionnellement à la tribu $\Gamma$ comme étant :

$$\esperof{X | \Gamma} = \arg\min_{Z \in \mathcal{F}(\Gamma) } \int_{\Omega} \left[ Z - X \right]^2 \ d\proba$$

On a donc :

$$\int_\Omega W\ \esperof{X | \Gamma} \ d\proba = \int_\Omega W\ X \ d\proba$$

pour tout $W \in \mathcal{F}(\Gamma)$.


*** Fonctions indicatrices

Soit un ensemble $\Phi \in \Gamma$. Les propriétés de $\Gamma$ nous disent que $\Omega \setminus \Phi \in \Gamma$. Donc :

$$\Lambda(\indicatrice_\Phi) = \{ \emptyset, \Omega, \Phi, \Omega \setminus \Phi \} \subseteq \Gamma$$

et $\indicatrice_\Phi \in \mathcal{F}(\Gamma)$. On en déduit que :

$$\int_\Omega \indicatrice_\Phi \ \esperof{X | \Gamma} \ d\proba = \int_\Omega \indicatrice_\Phi \ X \ d\proba$$

c'est-à-dire :

$$\int_\Phi \esperof{X | \Gamma} \ d\proba = \int_\Phi X \ d\proba$$

pour tout $\Phi \in \Gamma$.

Comme $\Omega \in \Gamma$, on a en particulier :

$$\int_\Omega \esperof{X | \Gamma} \ d\proba = \int_\Omega X \ d\proba$$

c'est-à-dire :

$$\esperof{ \esperof{X | \Gamma} } = \esperof{X}$$


*** Variable aléatoire dans l'espace fonctionnel

Une conséquence directe de la définition de l'espérance conditionnelle est que si $Z \in \mathcal{F}(\Gamma)$, on a :

$$\int_\Omega (Z - Z)^2 \ d\proba = 0$$

Par conséquent, $Z$ minimise la fonctionnelle :

$$I(Y) = \int_\Omega (Y - Z)^2 \ d\proba \ge 0$$

sur $\mathcal{F}(\Gamma)$ et :

$$\esperof{Z | \Gamma} = Z$$


*** Tour

Soit la tribu $\Delta \subseteq \Gamma$ et $X$ une variable aléatoire et $W \in \mathcal{F}(\Delta)$. On a :

$$\Lambda(W) \subseteq \Delta \subseteq \Gamma$$

Par conséquent $W \in \mathcal{F}(\Gamma)$ et les équations suivantes sont vérifiées :

#+BEGIN_CENTER
\(
\int_\Omega W\ \esperof{X | \Delta} \ d\proba = \int_\Omega W\ X \ d\proba \\
\int_\Omega W\ \esperof{X | \Gamma} \ d\proba = \int_\Omega W\ X \ d\proba
\)
#+END_CENTER

On en déduit que :

$$\int_\Omega W\ \esperof{X | \Delta} \ d\proba = \int_\Omega W\ \esperof{X | \Gamma} \ d\proba$$

Comme cette dernière équation est valable pour tout $W \in \mathcal{F}(\Delta)$, on en déduit que $\esperof{X | \Delta}$ est le meilleur estimateur de $\esperof{X | \Gamma}$ sur $\mathcal{F}(\Delta)$. Ce qui revient à dire que :

$$\esperof{ \esperof{X | \Gamma} | \Delta } = \esperof{X | \Delta}$$


*** Couple de variables aléatoires

Etant donné deux variables aléatoires $X,Y$, on définit :

$$\esperof{X | Y} = \esperof{X | \Lambda(Y)}$$

Comme $\Gamma = \Lambda(Y)$, l'espace $\mathcal{F}(\Gamma)$ est l'ensemble des variables aléatoires $W$ telles que :

$$\Lambda(W) \subseteq \Lambda(Y)$$


** Ensemble discret

Nous allons à présent considérer le cas particulier où l'ensemble des événements peut s'écrire
comme :

$$\Omega = \{ \omega_i : i \in \setN \}$$

Nous notons $p_i$ les probabilités associées aux singletons :

$$p_i = \probaof{ \{\omega_i\} }$$

Étant donnée une variable aléatoire $X$, on note :

$$x_i = X(\omega_i)$$

L'espérance d'une telle variable s'écrit simplement :

$$\esperof{X} = \sum_i x_i \ p_i$$

* Statistiques

#+TOC: headlines 1 local

\label{chap:stat}


*** Indépendance

On dit que les variables aléatoires $X_1$, $X_2$, ..., $X_N$ sont indépendantes si :

$$\esperof{\prod_i X_i} = \prod_i \esperof{X_i}$$

On en déduit que :

$$\cov{X_i}{X_j} = \var{X_i} \ \indicatrice_{ij}$$

et donc :

$$\var{\sum_i X_i} = \sum_i \var{X_i}$$


** Echantillons

Nous nous intéressons dans la suite de ce chapitre à des échantillons de $N$ variables aléatoires indépendantes $X_1,...,X_N$ telles que :

#+BEGIN_CENTER
\(
\esperof{X_i} = \mu \\
\cov{X_i}{X_j} = \sigma \ \indicatrice_{ij}
\)
#+END_CENTER


** L'inégalité de Markov

Soit une variable aléatoire $X$. On définit la variable associée :

#+BEGIN_CENTER
\(
Y =
\begin{cases}
a^2 & \mbox{ si } \abs{X-b} \ge a \\
0 & \mbox{ si } \abs{X-b} < a
\end{cases} \\
\)
#+END_CENTER

Comme :

$$Y \le (X-b)^2$$

on a $\esperof{Y} \le \esperof{(X-b)^2}$. D'un autre coté :

$$\esperof{Y} = a^2 \ \probaof{\abs{X-b} \ge a}$$

Rassemblant ces deux résultats, on obtient la propriété :

$$\probaof{\abs{X-b} \ge a} \le \unsur{a^2} \ \esperof{(X-b)^2}$$

connue sous le nom d'inégalité de Markov.

Le cas particulier $b = \esperof{X}$ nous donne :

$$\probaof{\abs{X-\esperof{X}} \ge a} \le \unsur{a^2} \ \var{X}$$


** La loi des grands nombres

Soit la moyenne :

$$M_N = \unsur{N} \sum_{i=1}^N X_i$$

On a :

$$\esperof{M_N} = \unsur{N} \ N \ \mu = \mu$$

L'indépendance entre les variables nous amène à :

\begin{align}
\var{M_N} &= \unsur{N^2} \var{\sum_i X_i} \\
&= \unsur{N^2} \sum_i \var{X_i} \\
&= \unsur{N^2} \ N \ \sigma^2
\end{align}

et donc :

$$\var{M_N} = \frac{\sigma^2}{N}$$

Soit $a > 0$. L'inégalité de Markov nous dit que :

$$\probaof{\abs{M_N - \mu} \ge a} \le \frac{\sigma^2}{a^2 N}$$

Soit à présent $\epsilon > 0$. Si on veut :

$$\probaof{\abs{M_N - \mu} \ge a} \le \frac{\sigma^2}{a^2 N} \strictinferieur \epsilon$$

il suffit de choisir :

$$N > \frac{\sigma^2}{a^2 \epsilon}$$

On en conclut que :

$$\lim_{N \to +\infty} \probaof{M_N = \mu} = 1$$


** Fréquence et probabilité

Appliquons la loi des grands nombres à la fonction indicatrice $\indicatrice_A$.
On a alors $X_i = 1$ lorsque $\omega \in A$ et $X_i = 0$ lorsque $\omega \notin A$.
La moyenne s'écrit donc :

$$M_N = \frac{n(A)}{N}$$

où $n(A)$ est le nombre de $X_i$ valant 1, autrement dit le nombre d'événements
$\omega$ appartenant à $A$. Comme :

$$\mu = \esperof{\indicatrice_A} = \probaof{A}$$

on en déduit que la fréquence $n(A) / N$ converge vers la probabilité de $A$ :

$$\lim_{N \to +\infty} \probaof{\frac{n(A)}{N} = \probaof{A}} = 1$$


** Estimateurs non biaisés

Soit une fonction $G : \setR^n \mapsto \setR$ :

$$G : (X_1,...,X_N) \mapsto G(X_1,...,X_N)$$

On dit que $\hat{G} : \setR^n \mapsto \setR$ est un estimateur non biaisé de $G$ si :

$$\esperof{\hat{G}} = \esperof{G}$$


** Estimation des espérance et des variances

Soit :

$$M_N(X_1,...,X_N) = \unsur{N} \sum_{i=1}^N X_i$$

La loi des grands nombres nous dit que :

$$\esperof{M_N} = \mu$$

La moyenne $M_N$ est donc un estimateur non biaisé de l'espérance $\mu$.

Soit les variables à espérances nulles :

#+BEGIN_CENTER
\(
X_i^* = X_i - \mu \\
M_N^* = M_N - \mu
\)
#+END_CENTER

On obtient directement :

$$M_N^* = \unsur{N} \sum_i X_i^*$$

On voit également que :

$$X_i - M_N = X_i - \mu + \mu - M_N = X_i^* - M_N^*$$

Donc :

$$\esperof{\sum_i (X_i - M_N)^2} = \esperof{\sum_i \left( X_i^* - M_N^* \right)^2}$$

En développant, on obtient successivement :

\begin{align}
\esperof{\sum_i (X_i - M_N)^2} &= \esperof{ \sum_i \left( X_i^* \right)^2 } - 2 \ \esperof{M_N^* \sum_i X_i^*} + \esperof{ \left( M_N^* \right)^2 } \\
&= \sum_i \esperof{ \left( X_i^* \right)^2 } - 2 \ N \ \esperof{ \left( M_N^* \right)^2 } + \esperof{ \left( M_N^* \right)^2 }
\end{align}

Mais comme :

#+BEGIN_CENTER
\(
\var{M_N^*} = \esperof{ \left( M_N^* \right)^2 } = \frac{\sigma^2}{N} \\
\esperof{ \left( X_i^* \right)^2 } = \var{X_i} = \sigma^2
\)
#+END_CENTER

l'expression devient :

$$\esperof{\sum_i (X_i - M_N)^2} = (N - 2 + 1) \ \sigma^2 = (N-1) \ \sigma^2$$

On en conclut que :

$$S^2 = \unsur{N-1} \sum_{i=1}^{N} (X_i - M_N)^2$$

est un estimateur non biaisé de la variance :

$$\esperof{S^2} = \sigma^2$$


** Maximum de vraisemblance

Il s'agit de trouver les paramètres $\hat{\theta}$ (espérance, variance, ...) qui maximisent la vraisemblance :

$$V(\hat{\theta}) = \prod_i  \probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} }$$

Notons que cela revient à maximiser :

$$\ln\prod_{i=1}^N  \probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} } = \sum_{i=1}^N  \ln\probaof{ \{\omega : X_i(\omega) = x_i \} | \theta = \hat{\theta} }$$

ce qui est souvent plus facile.

En pratique, lorsque la fonction de densité $f_\theta$ est connue, on maximise :

$$\phi(\theta) = \sum_i \ln f_\theta(x_i)$$

en imposant :

$$\deriveepartielle{\phi}{\theta}(\hat{\theta}) = 0$$


** Echantillon de densité donnée

Il s'agit d'un algorithme permettant de générer $N$ nombres aléatoires :

$$\{ x_1, ..., x_N \}$$

suivant la densité $f$. Soit $\epsilon \ge 0$ une erreur maximale et $[a,b]$ tel que :

$$\int_a^b f(x) \ dx = 1 - \epsilon$$

Soit :

$$M = \sup_{x \in [a,b]} f(x)$$

et la génératrice :

$$\rand(a,b)$$

qui renvoie des variables aléatoires de densité uniforme sur $[a,b]$.

On part de $A_0 = \emptyset$. A chaque itération, on génére deux nombres de densités uniformes :

#+BEGIN_CENTER
\(
x = \rand(a,b) \\
y = \rand(0,M)
\)
#+END_CENTER

Afin de modifier cette densité, on n'ajoute $x$ à la liste déjà obtenue :

$$A_i = A_{i-1} \cup \{ x \}$$

que si $y < f(x)$. Autrement, on ne fait rien et on passe à l'itération suivante.

La comparaison de $y$ et de $f(x)$ sert donc de filtre à l'algorithme.


* Calcul stochastique

#+TOC: headlines 1 local

\label{chap:stocha}


** Processus stochastique

Un processus stochastique est une fonction :

$$X : [0,+\infty) \times \Omega \mapsto \setR, \quad (t,\omega) \mapsto X(t,\omega)$$

On sous-entend souvent l'événement $\omega$, et on note $X(t)=X(t,\omega)$.


** Intégrale d'Ito

Il s'agit d'une intégrale utilisant un processus stochastique $X$ comme mesure :

$$I(t) = \int_0^t f(s) \ dX(s) = \lim_{\delta \to 0} \sum_k f(t_k) (X(t_{k+1}) - X(t_k))$$


** Variation quadratique

Soit $\delta \strictsuperieur 0$ et les $N$ temps $t_k = k \cdot \delta$ où $k = 0,...,\arrondisup{\frac{T}{\delta}}$. On définit la variation quadratique d'une fonction $f$ :

$$\variation{f}(T) = \lim_{\delta \to 0} \sum_k (f(t_{k+1}) - f(t_k))^2$$

Si la dérivée de $f$ existe, la variation quadratique s'annule car :

$$(f(t_{k+1}) - f(t_k))^2 \to \delta^2 \ \OD{f}{t}(t_k)^2$$

Comme $\delta^2 \to \delta \ ds$, on a :

$$\variation{f}(T) = \lim_{\delta \to 0} \delta \int_0^T \left(\OD{f}{t}(s)\right)^2 ds = 0$$


** Variation conjointe

Considérons maintenant deux processus stochastiques $X,Y$. Nous définissons la variation conjointe $\variation{X,Y}$ :

$$\variation{X,Y}(T) = \lim_{\delta \to 0} \sum_k (X(t_{k+1}) - X(t_k)) \ (Y(t_{k+1}) - Y(t_k))$$

Dans le cas où les dérivées de $X$ et de $Y$ existent, on a évidemment : $\variation{X,Y} = 0$.

Pour une fonction $f : \setR^2 \mapsto \setR$ quelconque, nous avons :

$$df(X,Y) = f(X + \ dX,Y + dY) - f(X,Y)$$

Dans le cas particulier où $f(X,Y)=X \cdot Y$, cette expression se réduit à :

\begin{align}
d(X \cdot Y) &= (X + \ dX) \cdot (Y + dY) - X \cdot Y \\
&= \ dX \cdot Y + X \cdot dY + \ dX \cdot dY
\end{align}

Mais comme :

$$\variation{X,Y}(t) = \int_0^t \ dX \cdot dY$$

on a en définitive :

\begin{align}
X(t) Y(t) - X(0) Y(0) &= \int_0^t d(X Y)(s) \\
&= \int_0^t X(s) \ dY(s) + \int_0^t Y(s) \ dX(s) + \variation{X,Y}(t)
\end{align}


** Relations variations quadratiques - conjointes

La définition nous donne directement :

$$\variation{X} = \variation{X,X}$$

On peut aussi vérifier que :

$$(X + Y)^2 - (X - Y)^2 = 4 \ X \ Y$$

d'où l'on déduit :

$$\variation{X,Y} = \unsur{4} ( \variation{X + Y} - \variation{X - Y} )$$


** Variation d'ordre quelconque

Soit $\delta \strictsuperieur 0$ et les temps $t_k = k \delta$ où $k = 0,...,\arrondisup{\frac{T}{\delta}}$. On définit la variation d'ordre $n$ d'une fonction $f$ :

$$\variation{f}^n(T) = \lim_{\delta \to 0} \sum_k (f(t_{k+1}) - f(t_k))^n$$


** Calcul d'Ito

Soit une fonction $F : \setR^n \mapsto \setR$ et $N$ processus stochastiques $X_i$ dont les variations d'ordre $n \ge 3$ s'annulent. Soit $X=(X_1,...,X_N)$. On peut écrire le développement en série de Taylor d'ordre 2 :

$$F(X + \Delta) - F(X) \approx \deriveepartielle{F}{X}(X) \Delta + \unsur{2} \Delta^T \dblederiveepartielle{F}{X}(X) \Delta$$

En faisant tendre $\Delta \to 0$, on obtient :

$$dF = \deriveepartielle{F}{X} \ dX + \unsur{2} \ dX^T \dblederiveepartielle{F}{X} \ dX$$

On a donc la formule de Ito pour une fonction $f : \setR^n \mapsto \setR $ :

$$dF = \sum_i \deriveepartielle{F}{X_i} \ dX_i + \unsur{2} \sum_{i,j} \dfdxdy{F}{X_i}{X_j} \ dX_i \ dX_j$$

Ce qui nous permet d'évaluer une variation de $F$ :

#+BEGIN_CENTER
\(
F(X(t)) - F(X(0)) =  \sum_i \int_0^t \deriveepartielle{F}{X_i}(X(s)) \ dX_i(s) + \\
\unsur{2} \sum_{i,j} \int_0^t \dfdxdy{F}{X_i}{X_j}(X(s)) \ d\variation{X_i,X_j}(s)
\)
#+END_CENTER


*** Dérivées ordinaires

Dans le cas d'une seule variable, on a :

$$dF = \sum_i \OD{F}{X} \ dX + \unsur{2} \OOD{F}{X} \ dX \ dX$$

Ce qui nous permet d'évaluer une variation de $F$ :

#+BEGIN_CENTER
\(
F(X(t)) - F(X(0)) = \sum_i \int_0^t \OD{F}{X}(X(s)) \ dX(s) + \\
\unsur{2} \int_0^t \OOD{F}{X}(X(s)) d\variation{X}(s)
\)
#+END_CENTER


** Mouvement Brownien

Un mouvement brownien est un processus stochastique :

$$B : [0,+\infty) \times \Omega \mapsto \setR, \quad (t,\omega) \mapsto B(t,\omega)$$

continu par rapport à $t$ :

$$B_\omega : t \mapsto B(t,\omega) \in \Cont([0,+\infty))$$

De plus, si on définit :

$$\mathcal{B}_t : \omega \mapsto B(t,\omega)$$

on a la propriété d'indépendance des variations temporelles :

$$\cov{\mathcal{B}_u - \mathcal{B}_t}{\mathcal{B}_t - \mathcal{B}_s} = 0$$

pour tout $s \strictinferieur t \strictinferieur u$ positifs. On demande aussi qu'une variation $\mathcal{B}_t - \mathcal{B}_s$ suive une loi normale d'espérance nulle et de variance $t-s$ :

#+BEGIN_CENTER
\(
\esperof{\mathcal{B}_t - \mathcal{B}_s}=0 \\
\var{\mathcal{B}_t - \mathcal{B}_s} = t - s
\)
#+END_CENTER


*** Variation quadratique

Si les mouvements browniens sont continus, ils ne sont pas dérivables. Comme les variations sont normalement distribuées avec une moyenne nulle et une variance $t - s$, on en déduit (en utilisant par exemple le moment générateur des densités normales) :

#+BEGIN_CENTER
\(
\esperof{(\mathcal{B}_t - \mathcal{B}_s)^2} = t - s \\
\var{(\mathcal{B}_t - \mathcal{B}_s)^2} = 2 \ (t - s)^2
\)
#+END_CENTER

La variation quadratique des mouvement browniens peut s'écrire :

$$\variation{B_\omega}(T) = \lim_{\delta \to 0} \sum_k (B_\omega(t_{k+1}) - B_\omega(t_k))^2$$

Lorsque $\delta \to 0$, on a $N \to +\infty$ et la loi des grands nombres nous dit que
chaque terme de la somme de droite converge vers la variance $\delta$. Comme on a $N$
termes, on obtient :

$$\sum_k B_\omega(t_{k+1}) - B_\omega(t_k) \to N \delta = T$$

On a donc :

$$\variation{\mathcal{B}_\omega}(T) = T$$

Ce que l'on note symboliquement sous forme différentielle par :

$$dB(t) \cdot dB(t) = dt$$


*** Variations d'ordre quelconque

Les variations $\variation{B}^n$ d'un mouvement brownien s'annulent pour $n \ge 3$.


*** Multidimensionnel

Nous définissons un mouvement Brownien de dimension $n$ comme une collection de $n$ mouvements Browniens $B_i$ indépendants et vérifiant :

$$\variation{B_i,B_j}(t) = \indicatrice_{ij} \cdot t$$


*** Calul d'Ito

Dans le cas de $N$ mouvement browniens $B_i$, les équations d'Ito deviennent :

$$dF = \sum_i \deriveepartielle{F}{X_i} dB_i + \unsur{2} \sum_{i,j} \dfdxdy{F}{X_i}{X_j} \ dB_i \ dB_j$$

Mais comme $dB_i dB_j = d\variation{B_i,B_j} = \indicatrice_{ij} \ dt$, on a :

$$dF = \sum_i \deriveepartielle{F}{X_i} \ dB_i + \unsur{2} \sum_i \dfdxdy{F}{X_i}{X_i} \ dt$$

Ce qui nous permet d'évaluer une variation de $F$ :

#+BEGIN_CENTER
\(
F(X(t)) - F(X(0)) = \sum_i \int_0^t \deriveepartielle{F}{X_i}(X(s)) \ dX_i(s) + \\
\unsur{2} \sum_i \int_0^t \dfdxdy{F}{X_i}{X_i}(X(s)) \ ds
\)
#+END_CENTER


*** Dérivée ordinaire

Le cas particulier unidimensionnel nous donne :

$$dF(B) = \OD{F}{X}(B) \ dB + \unsur{2}\OOD{F}{X}(B) \ dB \cdot dB$$

Mais comme :

$$d\variation{B} = dB \cdot dB = dt$$

on a :

$$dF(B) = \OD{F}{X}(B) \ dB + \unsur{2}\OOD{F}{X}(B) \ dt$$

et :

$$F(B(t))-F(B(0)) = \int_0^t \OD{F}{X}(B(s)) \ dB(s) + \unsur{2} \int_0^t \OOD{F}{X}(B(s)) \ ds$$

AFAIRE : PROCESSUS DE POISSON
