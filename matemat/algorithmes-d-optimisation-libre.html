<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-11-20 jeu 14:19 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat : Algorithmes d’optimisation libre</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat : Algorithmes d’optimisation libre</h1>
<p>
<a href="index.html">Index mathématique</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org4e208f5">1. Introduction</a></li>
<li><a href="#org0d6ae96">2. Minimum dans une direction</a></li>
<li><a href="#org5a8c8c4">3. Méthode de la plus grande descente</a></li>
<li><a href="#org0977e66">4. Newton</a></li>
<li><a href="#org6914c39">5. Gradients conjugués</a></li>
<li><a href="#orgb166e1b">6. Moindres carrés</a></li>
<li><a href="#org627af60">7. Levenberg-Marquardt</a></li>
</ul>
</div>
</div>

<p>
\(
\newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\DeclareMathOperator*{\cardinal}{\mathrm{card}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\left] #1 , #2 \right[}
\newcommand{\intervallesemiouvertgauche}[2]{ \left] #1 , #2 \right]}
\newcommand{\intervallesemiouvertdroite}[2]{\left[ #1 , #2 \right[ }
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\DeclareMathOperator*{\strictinferieur}{\ < \ }
\DeclareMathOperator*{\strictsuperieur}{\ > \ }
\DeclareMathOperator*{\ensinferieur}{\eqslantless}
\DeclareMathOperator*{\enssuperieur}{\eqslantgtr}
\DeclareMathOperator*{\esssuperieur}{\gtrsim}
\DeclareMathOperator*{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\DeclareMathOperator*{\pgcd}{pgcd}
\DeclareMathOperator*{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \vert #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \vert #2 \vert #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \vert #3 \vert #5 \right\rangle_{#2,#4}}
\DeclareMathOperator*{\major}{major}
\DeclareMathOperator*{\minor}{minor}
\DeclareMathOperator*{\maxim}{maxim}
\DeclareMathOperator*{\minim}{minim}
\DeclareMathOperator*{\argument}{arg}
\DeclareMathOperator*{\argmin}{arg\ min}
\DeclareMathOperator*{\argmax}{arg\ max}
\DeclareMathOperator*{\supessentiel}{ess\ sup}
\DeclareMathOperator*{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\DeclareMathOperator*{\adh}{adh}
\DeclareMathOperator*{\interieur}{int}
\newcommand{\frontiere}{\partial}
\DeclareMathOperator*{\image}{im}
\DeclareMathOperator*{\domaine}{dom}
\DeclareMathOperator*{\noyau}{ker}
\DeclareMathOperator*{\support}{supp}
\DeclareMathOperator*{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\DeclareMathOperator*{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\DeclareMathOperator*{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PD}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\DeclareMathOperator*{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\DeclareMathOperator*{\composante}{comp}
\DeclareMathOperator*{\bloc}{bloc}
\DeclareMathOperator*{\ligne}{ligne}
\DeclareMathOperator*{\colonne}{colonne}
\DeclareMathOperator*{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\DeclareMathOperator*{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\DeclareMathOperator*{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)}
\)
</p>

<p>
\(
\newenvironment{Eqts}
{ \begin{equation*} \begin{gathered} }
{ \end{gathered} \end{equation*} }
\newenvironment{Matrix}
{\left[ \begin{array}}
{\end{array} \right]}
\)
</p>

<p>
\label{chap:algoptim}
</p>
<div id="outline-container-org4e208f5" class="outline-2">
<h2 id="org4e208f5"><span class="section-number-2">1.</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
Nous allons présenter des algorithmes permettant de résoudre approximativement des problèmes de minimisation d'une fonction \(\varphi\) sur \(\setR^n\). Ces algorithmes partent d'un point initial \(x_0 \in \Omega\) et itèrent schématiquement comme suit :
</p>

<p>
\[x_{k + 1} = I(x_k) = x_k + p_k\]
</p>

<p>
pour un certain \(p_k \in \setR^n\). On espère bien entendu que la suite converge et que :
</p>

<p>
\[x_N \approx \lim_{k \to \infty} x_k = \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
pour \(N\) assez grand. Nous adoptons les notations :
</p>

<p>
\[J = (\partial \varphi)^\dual\]
</p>

<p>
pour le gradient, de taille \((n,1)\), et :
</p>

<p>
\[H = \partial^2 \varphi\]
</p>

<p>
pour la hessienne, de taille \((n,n)\). On note également :
</p>

<p>
\[\Phi_k = \Phi(x_k)\]
</p>

<p>
pour toute fonction \(\Phi\) (par exemple, \(\Phi \in \{\varphi,J,H\}\)).
</p>
</div>
</div>
<div id="outline-container-org0d6ae96" class="outline-2">
<h2 id="org0d6ae96"><span class="section-number-2">2.</span> Minimum dans une direction</h2>
<div class="outline-text-2" id="text-2">
<p>
Soit l'itération :
</p>

<p>
\[x_{k+1} = x_k - \alpha_k \cdot p_k\]
</p>

<p>
où \(\alpha_k \in \setR\) et \(p_k \in \setR^n\). On choisit généralement le paramètre \(\alpha_k\) de façon à minimiser le développement d'ordre deux :
</p>

<p>
\[\varphi_{k + 1} \approx \varphi_k - \alpha_k \cdot J_k^\dual \cdot p_k + \frac{\alpha_k^2}{2} \cdot p_k^\dual \cdot H_k \cdot p_k\]
</p>

<p>
En imposant l'annulation de la dérivée de ce développement par rapport à \(\alpha_k\), on en déduit que :
</p>

<p>
\[- J_k^\dual \cdot p_k + \alpha_k \cdot p_k^\dual \cdot H_k \cdot p_k = 0\]
</p>

<p>
La valeur optimale de \(\alpha_k\) s'écrit :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot p_k}{p_k^\dual \cdot H_k \cdot p_k}\]
</p>
</div>
</div>
<div id="outline-container-org5a8c8c4" class="outline-2">
<h2 id="org5a8c8c4"><span class="section-number-2">3.</span> Méthode de la plus grande descente</h2>
<div class="outline-text-2" id="text-3">
<p>
La méthode de la plus grande pente consiste à partir à chaque itération
du point \(x^{(k)}\) et à suivre la direction \(\delta_k\) où \(\varphi\)
descend le plus rapidement dans le voisinage immédiat. En première approximation, si :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot \delta_k\]
</p>

<p>
pour un certain \(\alpha_k \in \setR\), on a :
</p>

<p>
\[\varphi_{k+1} \approx \varphi_k + \alpha_k \cdot J_k^\dual \cdot \delta_k\]
</p>

<p>
Nous choisissons le vecteur \(\delta_k\) qui minimise \(J_k^\dual \cdot \delta_k = \scalaire{J_k}{\delta_k}\) sur \(\boule(0,\norme{J_k})\), c'est-à-dire :
</p>

<p>
\[\delta_k = - J_k\]
</p>

<p>
On a alors :
</p>

<p>
\[x_{k + 1} = x_k - \alpha_k \cdot J_k\]
</p>

<p>
La valeur optimale de \(\alpha_k\) s'écrit donc :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot J_k}{J_k^\dual \cdot H_k \cdot J_k}\]
</p>
</div>
</div>
<div id="outline-container-org0977e66" class="outline-2">
<h2 id="org0977e66"><span class="section-number-2">4.</span> Newton</h2>
<div class="outline-text-2" id="text-4">
<p>
Il s'agit ici d'optimiser le pas \(s_k\) :
</p>

<p>
\[x_{k + 1} = x_k + s_k\]
</p>

<p>
pour minimiser le développement :
</p>

<p>
\[\varphi_{k+1} \approx \varphi_k + J_k^\dual \cdot s_k + \unsur{2} \cdot s_k^\dual \cdot H_k \cdot s_k\]
</p>

<p>
Mais comme \(H = H^\dual\), l'annulation du gradient par rappord à \(s_k\) nous donne :
</p>

<p>
\[J_k + H_k \cdot s_k \approx 0\]
</p>

<p>
On en déduit la valeur optimale :
</p>

<p>
\[s_k = - H_k^{-1} \cdot J_k\]
</p>
</div>
</div>
<div id="outline-container-org6914c39" class="outline-2">
<h2 id="org6914c39"><span class="section-number-2">5.</span> Gradients conjugués</h2>
<div class="outline-text-2" id="text-5">
<p>
Soit l'itération :
</p>

<p>
\[x_{k + 1} = x_k - \alpha_k \cdot p_k\]
</p>

<p>
où \(\alpha_k \in \setR\) et \(p_k \in \setR^n\). On a comme d'habitude :
</p>

<p>
\[\alpha_k = \frac{J_k^\dual \cdot p_k}{p_k^\dual \cdot H_k \cdot p_k}\]
</p>

<p>
Lorsque \(k = 0\), on prend le gradient comme direction :
</p>

<p>
\[p_0 = J_0\]
</p>

<p>
Pour \(k \ge 1\), on choisit \(p_k\) comme combinaison linéaire du gradient \(J_k\) et du pas précédent \(p_{k - 1}\) :
</p>

<p>
\[p_k = J_k - \beta_k \cdot p_{k-1}\]
</p>

<p>
où \(\beta_k \in \setR\). L'idée des gradients conjugué est de construire une suite de \(p_k\) orthogonaux entre-eux afin de minimiser la fonction dans toutes les directions. Au bout de \(n\) itérations, on espère avoir construit une base de \(\setR^n\) et être très proche du minimum global. En fait, nous n'allons pas vérifier que toutes les directions sont orthogonales, mais seulement que deux directions successives le sont. On demande donc l'orthogonalité au sens du produit scalaire défini par \(H\) :
</p>

<p>
\[p_k^\dual \cdot H_k \cdot p_{k - 1} = J_k^\dual \cdot H_k \cdot p_{k - 1} - \beta_k \cdot p_{k - 1}^\dual \cdot H_k \cdot p_{k - 1} = 0\]
</p>

<p>
On en déduit la valeur de \(\beta_k\) :
</p>

<p>
\[\beta_k = \frac{J_k^\dual \cdot H_k \cdot p_{k - 1}}{p_{k - 1}^\dual \cdot H_k \cdot p_{k - 1}}\]
</p>

<p>
Nous allons à présent obtenir une valeur approximative de \(\beta_k\) en fonction des variations du gradient. Le développement d'ordre un de \(J\) s'écrit :
</p>

<p>
\[J_k - J_{k - 1} \approx H_k \cdot (x_k - x_{k - 1}) = - \alpha_k \cdot H_k \cdot p_{k - 1}\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\beta_k \approx \frac{J_k^\dual \cdot (J_k - J_{k - 1})}{p_{k - 1}^\dual \cdot (J_k - J_{k - 1})}\]
</p>
</div>
</div>
<div id="outline-container-orgb166e1b" class="outline-2">
<h2 id="orgb166e1b"><span class="section-number-2">6.</span> Moindres carrés</h2>
<div class="outline-text-2" id="text-6">
<p>
Soit la fonction \(f : \setR^n \mapsto \setR^m\). On cherce à minimiser la fonction \(\varphi = f^\dual \cdot f / 2\). Le problème de minimisation s'écrit alors :
</p>

<p>
\[\arg\min_x \unsur{2} f(x)^\dual \cdot f(x)\]
</p>

<p>
Dans ce cas, si on définit :
</p>

<p>
\[D = \partial f\]
</p>

<p>
le gradient s'écrit :
</p>

<p>
\[J = D^\dual \cdot f\]
</p>

<p>
Si on suppose que les dérivées secondes de \(f\) sont négligeables par rapport
aux dérivées premières, on a :
</p>

<p>
\[H \approx D^\dual \cdot D\]
</p>

<p>
La méthode de Newton devient dans ce cas :
</p>

<p>
\[x_{k+1} = x_k + s_k\]
</p>

<p>
avec :
</p>

<p>
\[s_k = -[D_k^\dual \cdot D_k]^{-1} \cdot D_k^\dual \cdot f_k\]
</p>
</div>
<div id="outline-container-org9619fb3" class="outline-3">
<h3 id="org9619fb3"><span class="section-number-3">6.1.</span> Zéros</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Si \(S = \noyau f \ne \emptyset\), soit \(\gamma \in S\). On a alors :
</p>

<p>
\[0 \le \min \unsur{2} f(x)^\dual \cdot f(x) \le  \unsur{2} f(\gamma)^\dual \cdot f(\gamma) = 0\]
</p>

<p>
On en déduit que tout \(x \in \setR^n\) minimisant \(\varphi\) vérifiera \(f(x) = 0\). La méthode de minimisation nous fournit donc une approximation d'un tel \(x\).
</p>
</div>
</div>
</div>
<div id="outline-container-org627af60" class="outline-2">
<h2 id="org627af60"><span class="section-number-2">7.</span> Levenberg-Marquardt</h2>
<div class="outline-text-2" id="text-7">
<p>
C'est une variante de la méthode des moindres carrés, utile dans les cas où
\(D_k^\dual \cdot D_k\) est numériquement proche d'une matrice non inversible. On
ajoute alors la matrice identité multipliée par un scalaire \(\lambda\)
sur la diagonale :
</p>

<p>
\[s_k = -[D_k^\dual \cdot D_k+ \lambda_k \cdot I]^{-1} \cdot D_k^\dual \cdot f_k\]
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-11-20 jeu 14:19</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
