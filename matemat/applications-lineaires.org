
#+STARTUP: showall

#+TITLE: Eclats de vers : Matemat : Applications linéaires
#+AUTHOR: chimay
#+EMAIL: or du val chez gé courriel commercial
#+LANGUAGE: fr
#+LINK_HOME: file:../index.html
#+LINK_UP: file:index.html
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../style/defaut.css" />

#+OPTIONS: H:6
#+OPTIONS: toc:nil

#+TAGS: noexport(n)

[[file:index.org][Index mathématique]]

#+INCLUDE: "../include/navigan-1.org"

#+TOC: headlines 1

#+INCLUDE: "../include/latex/latex.org"

\label{chap:lineaire}

* Dépendances

  - Chapitre \ref{chap:fonction} : Les fonctions

* Définition

Soit les espaces vectoriels $E$ et $F$ sur $\corps$. Une application
linéaire $f$ est une fonction linéaire $f : E \mapsto F$.

* Norme des applications linéaires

La norme d'une application linéaire est définie comme étant l'extension maximale qu'elle produit :

$$\norme{f} = \sup \left\{ \frac{ \norme{f(x)} }{ \norme{x} } : x \in E, \ x \ne 0 \right\}$$

On a donc :

$$\norme{f(x)} \le \norme{f} \cdot \norme{x}$$

pour tout $x \in E \setminus \{ 0 \}$.


** Vérification

Nous allons vérifier qu'il s'agit bien d'une norme. On a $\norme{f} \ge 0$ par positivité de la norme sur $E$ et $F$. La condition $\norme{f} = 0$ implique $\norme{f(x)} = 0$ et donc $f(x) = 0$ pour tout $x \ne 0$. Comme $f$ est linéaire, on a aussi $f(0) = 0$ et $f = 0$.

Si $f,g$ sont linéaires, on a :

$$\norme{f(x) + g(x)} \le \norme{f(x)} + \norme{g(x)} \le \norme{f} \cdot \norme{x} + \norme{g} \cdot \norme{x} = (\norme{f} + \norme{g}) \cdot \norme{x}$$

pour tout $x \ne 0$. En divisant par $\norme{x}$ et en passant au supremum, on obtient :

$$\norme{f + g} \le \norme{f} + \norme{g}$$

Enfin, si $\alpha \in \corps$, on a :

$$\frac{ \norme{\alpha \cdot f(x)} }{ \norme{x} } = \abs{\alpha} \cdot \frac{ \norme{f(x)} }{ \norme{x} }$$

En passant au supremum, on obtient :

$$\norme{\alpha \cdot f} = \abs{\alpha} \cdot \norme{f}$$


** Notation

Lorsqu'il est nécessaire de différentier la norme au sens des applications linéaires d'autres types de normes utilisées, on note :

$$\norme{f}_\lineaire = \sup \left\{ \frac{ \norme{f(x)} }{ \norme{x} } : x \in E, \ x \ne 0 \right\}$$

** Définition alternative

Soit $N \in \corps$, avec $N \strictsuperieur 0$ et :

$$B = \{ u \in E : \norme{u} = N \}$$

Soit $x \in E$ avec $x \ne 0$ et :

$$\lambda = \frac{ \norme{x} }{N}$$

Définissons :

$$u = \frac{x}{\lambda}$$

On voit que :

$$\norme{u} = \norme{\unsur{\lambda} \cdot x} = \unsur{\lambda} \cdot \norme{x} = \frac{N}{ \norme{x} } \cdot \norme{x} = N$$

On a donc $u \in B$. Le rapport des normes s'écrit :

$$\frac{ \norme{f(x)} }{ \norme{x} } = \frac{ \norme{f(x)} }{ N \cdot \lambda } = \unsur{N} \norme{ \frac{f(x)}{ \lambda } } = \unsur{ \norme{u} } \cdot \norme{ f\left( \frac{x}{ \lambda } \right) } = \frac{ \norme{f(u)} }{ \norme{u} }$$

On en conclut que :

$$\frac{ \norme{f(x)} }{ \norme{x} } = \frac{ \norme{f(u)} }{ \norme{u} } \le \sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\}$$

Comme ce doit être valable quelque soit $x \ne 0$, on obtient :

$$\norme{f} \le \sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\}$$

en passant au supremum sur $x$.

Choisissons à présent $u \in B$. On a alors :

$$\frac{ \norme{f(u)} }{ \norme{u} } \le \norme{f}$$

En passant au supremum sur $u$, on obtient :

$$\sup \Big\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \Big\} \le \norme{f}$$

On en conclut que les deux supremums sont égaux :

$$\sup \left\{ \frac{ \norme{f(v)} }{ \norme{v} } : v \in B \right\} = \norme{f}$$


** Norme unitaire

Une conséquence importante du résultat ci-dessus est le cas particulier $N = 1$. On a alors :

$$\norme{f} = \sup \left\{ \norme{f(v)} : v \in E, \ \norme{v} = 1 \right\}$$


* Norme d'une composée

Soit $f : E \mapsto F$ et $g : F \mapsto G$ deux applications linéaires de normes finies. Si $x \in E$ avec $x \ne 0$ on a $f(x) \in F$ et :

$$\norme{g \circ f(x)} \le \norme{g} \cdot \norme{f(x)} \le \norme{g} \cdot \norme{f} \cdot \norme{x}$$

En divisant par $\norme{x} \ne 0$ :

$$\frac{ \norme{g \circ f(x)} }{ \norme{x} } \le \norme{g} \cdot \norme{f}$$

et en passant au supremum sur $x \ne 0$, on en conclut que :

$$\norme{g \circ f} \le \norme{g} \cdot \norme{f}$$


* Norme d'une puissance

On a clairement :

$$\norme{f^n} = \norme{f \circ ... \circ f} \le \norme{f}^n$$


* Continuité

Nous allons montrer que, pour tout $f \in \lineaire(A,B)$, on a l'équivalence entre l'hypothèse d'une norme de $f$ finie et l'hypothèse de $f$ continue.

Si la norme est finie, on a :

$$\norme{f(x) - f(a)} = \norme{f(x - a)} \le \norme{f} \cdot \norme{x-a}$$

qui tend bien vers $0$ lorsque $x$ tend vers $a$. Inversément, si $f$ est continue, on peut trouver un $\delta \strictsuperieur 0$ tel que :

$$\norme{f(x) - f(0)} \le 1$$

pour tout $x$ vérifiant $\distance(x,0) = \norme{x} \le \delta$. Posons $B = \{ x \in A : \norme{x} = \delta \}$. On a alors :

$$\sup_{x \in B} \frac{\norme{f(x)}}{\norme{x}} = \unsur{\delta} \sup_{x \in B} \norme{f(x) - f(0)} \le \unsur{\delta}$$

La norme est donc finie :

$$\norme{f} = \sup_{x \in B} \frac{\norme{f(x)}}{\norme{x}} \le \unsur{\delta} \strictinferieur +\infty$$


* n-linéarité

On dit que la fonction $f : E_1 \times ... \times E_n \mapsto F$ est
n-linéaire si elle est linéaire par rapport à chacune des composantes
de son argument, les autres composantes restant inchangées :

$$f(...,\alpha x + \beta y,...) = \alpha \cdot f(...,x,...) + \beta \cdot f(...,y,...)$$

pour tout $\alpha,\beta \in \corps$ et $x,y \in E$. On note
$\lineaire_n(E_1,...,E_n,F)$ l'ensemble des fonctions n-linéaires de
$E_1 \times ... \times E_n$ vers $F$.

** Norme

La norme est définie dans ce cas par :

$$\norme{f} = \sup \left\{ \frac{ \norme{f(x_1,...,x_n)} }{ \prod_{i = 1}^n \norme{x_i} } : (x_1,...,x_n) \in E_1 \times ... \times E_n \right\}$$

Si cette norme est finie, on a :

$$\norme{f(x_1,...,x_n)} \le \norme{f} \cdot \prod_{i = 1}^n \norme{x_i}$$

pour tout $(x_1,...,x_n) \in E_1 \times ... \times E_n$.


** Bilinéarité

On dit aussi des fonctions $2$-linéaires qu'elles sont bilinéaires. La norme d'une fonction $f : E_1 \times E_2 \mapsto F$ bilinéaire est définie par :

$$\norme{f} = \sup \left\{ \frac{ \norme{f(u,v)} }{ \norme{u} \cdot \norme{v} } : (u,v) \in E_1 \times E_2 \right\}$$

Si cette norme est finie, on a :

$$\norme{f(u,v)} \le \norme{f} \cdot \norme{u} \cdot \norme{v}$$

pour tout $(u,v) \in E_1 \times E_2$.


* Représentation matricielle

#+TOC: headlines 1 local

** Norme

La norme d'une matrice est la norme de l'application linéaire associée, c'est-à-dire :

$$\norme{A}_2 = \sup \left\{ \frac{ \norme{A \cdot x} }{ \norme{x} } : x \in \corps^n, \ x \ne 0 \right\}$$

Soit :

$$M = \max_{i,j} \abs{\composante_{ij} A}$$

On a alors :

$$\norme{A \cdot x} \le M \cdot m \cdot n \cdot \max_i x_i \le M \cdot m \cdot n \cdot \norme{x}$$

ce qui montre que :

$$\norme{A} \le M \cdot m \cdot n \strictinferieur \infty$$

La norme d'une matrice finie ($m,n \strictinferieur \infty$) existe toujours.


** Image

L'image d'une matrice est l'image de l'application linéaire associée, c'est-à-dire :

$$\image A = \{ A \cdot x : x \in \corps^n \}$$

Si $c_i = \colonne_i A$, on a :

$$A = [ c_1 \ c_2 \ ... \ c_n ]$$

On voit que :

$$A \cdot x = \sum_i c_i \cdot x_i$$

autrement dit l'image de $A$ est l'espace vectoriel engendré par ses colonnes :

$$\image A = \combilin{c_1,c_2,...,c_n}$$

** Noyau

Le noyau d'une matrice est le noyau de l'application linéaire associée, c'est-à-dire :

$$\noyau A = \{ x \in \corps^n : A \cdot x = 0 \}$$
