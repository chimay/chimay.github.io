<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-11-20 jeu 14:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat : Calcul variationnel</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat : Calcul variationnel</h1>
<p>
<a href="index.html">Index mathématique</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org9f9c388">1. Méthode des variations</a></li>
<li><a href="#org4ed20ba">2. Discrétisation</a></li>
<li><a href="#org3c83418">3. Moindres carrés</a></li>
<li><a href="#org90ce889">4. Lax-Milgram</a></li>
<li><a href="#org73d56cb">5. Valeurs propres</a></li>
</ul>
</div>
</div>

<p>
\(
\newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\DeclareMathOperator*{\cardinal}{\mathrm{card}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\left] #1 , #2 \right[}
\newcommand{\intervallesemiouvertgauche}[2]{ \left] #1 , #2 \right]}
\newcommand{\intervallesemiouvertdroite}[2]{\left[ #1 , #2 \right[ }
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\DeclareMathOperator*{\strictinferieur}{\ < \ }
\DeclareMathOperator*{\strictsuperieur}{\ > \ }
\DeclareMathOperator*{\ensinferieur}{\eqslantless}
\DeclareMathOperator*{\enssuperieur}{\eqslantgtr}
\DeclareMathOperator*{\esssuperieur}{\gtrsim}
\DeclareMathOperator*{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\DeclareMathOperator*{\pgcd}{pgcd}
\DeclareMathOperator*{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \vert #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \vert #2 \vert #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \vert #3 \vert #5 \right\rangle_{#2,#4}}
\DeclareMathOperator*{\major}{major}
\DeclareMathOperator*{\minor}{minor}
\DeclareMathOperator*{\maxim}{maxim}
\DeclareMathOperator*{\minim}{minim}
\DeclareMathOperator*{\argument}{arg}
\DeclareMathOperator*{\argmin}{arg\ min}
\DeclareMathOperator*{\argmax}{arg\ max}
\DeclareMathOperator*{\supessentiel}{ess\ sup}
\DeclareMathOperator*{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\DeclareMathOperator*{\adh}{adh}
\DeclareMathOperator*{\interieur}{int}
\newcommand{\frontiere}{\partial}
\DeclareMathOperator*{\image}{im}
\DeclareMathOperator*{\domaine}{dom}
\DeclareMathOperator*{\noyau}{ker}
\DeclareMathOperator*{\support}{supp}
\DeclareMathOperator*{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\DeclareMathOperator*{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\DeclareMathOperator*{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PD}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\DeclareMathOperator*{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\DeclareMathOperator*{\composante}{comp}
\DeclareMathOperator*{\bloc}{bloc}
\DeclareMathOperator*{\ligne}{ligne}
\DeclareMathOperator*{\colonne}{colonne}
\DeclareMathOperator*{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\DeclareMathOperator*{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\DeclareMathOperator*{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)}
\)
</p>

<p>
\(
\newenvironment{Eqts}
{ \begin{equation*} \begin{gathered} }
{ \end{gathered} \end{equation*} }
\newenvironment{Matrix}
{\left[ \begin{array}}
{\end{array} \right]}
\)
</p>

<p>
\label{chap:varia}
</p>
<div id="outline-container-org9f9c388" class="outline-2">
<h2 id="org9f9c388"><span class="section-number-2">1.</span> Méthode des variations</h2>
<div class="outline-text-2" id="text-1">
<p>
Soit l'espace fonctionnel \(\mathcal{F}\) et la forme \(I : \mathcal{F} \mapsto \setR\). Un problème variationnel consiste à chercher une fonction \(u\) qui minimise \(I\) sur \(\mathcal{F}\) :
</p>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v\in\mathcal{F}\). L'astuce consiste à transformer ce problème en considérant la famille de fonctions \(\{ J_w : w \in \mathcal{F} \}\) définies par :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). Comme \(\mathcal{F}\) est un espace vectoriel, \(u + \epsilon \cdot w \in \mathcal{F}\). On en déduit que :
</p>

<p>
\[J_w(0) = I(u) \le J_w(\epsilon)\]
</p>

<p>
Si les fonctions \(J_w\) sont dérivables, les propriétés des extrema des fonctions \(\setR \mapsto \setR\) nous disent que :
</p>

<p>
\[\OD{J_w}{\epsilon}(0) = 0\]
</p>

<p>
pour toute variation \(w \in \mathcal{F}\). Si la dérivée seconde existe, on doit également avoir :
</p>

<p>
\[\OOD{J_w}{\epsilon}(0) \ge 0\]
</p>

<p>
Ces équations nous permettent de caractériser la solution \(u\) de notre problème variationnel.
</p>
</div>
</div>
<div id="outline-container-org4ed20ba" class="outline-2">
<h2 id="org4ed20ba"><span class="section-number-2">2.</span> Discrétisation</h2>
<div class="outline-text-2" id="text-2">
<p>
Une technique couramment employée pour résoudre les problèmes variationnels
est de choisir une suite de fonctions \(\varphi_i \in \mathcal{F}\) linéairement indépendantes et de minimiser sur l'espace vectoriel \(\mathcal{F}_n = \combilin{\varphi_1,\varphi_2,...,\varphi_n} \subseteq \mathcal{F}\). On espère que la solution obtenue sera proche de la solution exacte. Ce sera par exemple le cas si on a schématiquement :
</p>

<p>
\[\lim_{n \to \infty} \adh \mathcal{F}_n = \mathcal{F}\]
</p>

<p>
au sens de la distance \(\distance\) définie sur \(\mathcal{F}\). Pour toute précision \(\epsilon > 0\), on pourra alors trouver un \(n \in \setN\) assez grand et un \(u_n\in \mathcal{F}_n\) tels que :
</p>

<p>
\[\distance(u_n,u) \le \epsilon\]
</p>
</div>
</div>
<div id="outline-container-org3c83418" class="outline-2">
<h2 id="org3c83418"><span class="section-number-2">3.</span> Moindres carrés</h2>
<div class="outline-text-2" id="text-3">
<p>
Soit \(f : A \mapsto \setR\) et le sous-ensemble \(\mathcal{F} \subseteq \fonction(A,\setR)\). On cherche la fonction \(u \in \mathcal{F}\) qui se rapproche le plus possible de \(f\) au sens intégral des moindres carrés. On cherche donc le \(u\) qui minimise la fonctionnelle :
</p>

<p>
\[I(u) = \int_A \Big[ u(x) - f(x) \Big]^2 dx\]
</p>

<p>
Afin de résoudre ce problème, on pose :
</p>

<p>
\[J_v(\epsilon) = I(u + \epsilon \cdot v) = \int_A \Big[ u(x) + \epsilon \cdot v(x) - f(x) \Big]^2 dx\]
</p>

<p>
pour tout \(\epsilon \in \setR\) et \(v \in \mathcal{F}\). La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \int_A 2 \big[ u(x) + \epsilon \cdot v(x) - f(x) \big] \cdot v(x) \ dx\]
</p>

<p>
Comme elle doit s'annuler en \(\epsilon = 0\), on a :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = 2 \int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
donc :
</p>

<p>
\[\int_A \big[ u(x) - f(x) \big] \cdot v(x) \ dx = 0\]
</p>

<p>
pour tout \(v \in F\).
</p>
</div>
<div id="outline-container-org4a4a4fe" class="outline-3">
<h3 id="org4a4a4fe"><span class="section-number-3">3.1.</span> Discrétisation</h3>
<div class="outline-text-3" id="text-3-1">
<p>
On résout approximativement ce problème en posant :
</p>

<p>
\[u_n(x) = \sum_{i = 1}^n U_i \cdot \varphi_i(x)\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont des fonctions connues et où les \(U_i\) sont des réels à déterminer. Comme on désire que \(u_n \approx u\), on impose :
</p>

<p>
\[\int_A (u_n(x) - f(x)) \cdot \varphi_i(x) \ dx = 0\]
</p>

<p>
On a alors :
</p>

<p>
\[\int_A \varphi_i \sum_j U_j \cdot \varphi_j \ dx = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
ou :
</p>

<p>
\[\sum_j \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right] \cdot U_j = \int_A \varphi_i \cdot f \ dx\]
</p>

<p>
Définissons les matrices \(A \in \matrice(\setR,n,n)\), \(B \in \matrice(\setR,n,1)\) et \(U \in \matrice(\setR,n,1)\) :
</p>

\begin{align}
A &= \left[ \int_A \varphi_i \cdot \varphi_j \ dx \right]_{i,j} \)

\(
B &= \left[ \int_A \varphi_i \cdot f \ dx \right]_i \)

\(
U &= \left[ U_i \right]_i
\end{align}

<p>
Le problème peut alors s'exprimer sous forme matricielle :
</p>

<p>
\[A \cdot U = B\]
</p>

<p>
Si la matrice \(A\) est inversible, la solution est donnée par :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
et nous en déduisons notre approximation \(u_n = \sum_i U_i \cdot \varphi_i\).
</p>
</div>
</div>
</div>
<div id="outline-container-org90ce889" class="outline-2">
<h2 id="org90ce889"><span class="section-number-2">4.</span> Lax-Milgram</h2>
<div class="outline-text-2" id="text-4">
<p>
Soit un espace fonctionnel de Hilbert \(\mathcal{F}\). Nous considérons une forme bilinéaire \(a : \mathcal{F} \times \mathcal{F} \mapsto \setR\), de norme finie, coercive et symétrique :
</p>

<p>
\[\biforme{u}{a}{v} = \biforme{v}{a}{u}\]
</p>

<p>
pour tout \(u,v \in F\). Nous considérons également une forme linéaire continue \(b : \mathcal{F} \mapsto \setR\) et nous définissons la fonctionnelle \(I : \mathcal{F} \mapsto \setR\) par :
</p>

<p>
\[I(v) = \unsur{2} \biforme{v}{a}{v} - \forme{b}{v}\]
</p>


<ul class="org-ul">
<li>Supposons que \(I\) atteigne un minimum global en \(u\). On a alors :</li>
</ul>

<p>
\[I(u) \le I(v)\]
</p>

<p>
pour tout \(v \in F\). Choisissons un quelconque \(w \in \mathcal{F}\) et posons :
</p>

<p>
\[J_w(\epsilon) = I(u + \epsilon \cdot w)\]
</p>

<p>
pour tout \(\epsilon \in \setR\). Tenant compte des propriétés de \(a\) et \(b\), on obtient :
</p>

<p>
\[J_w(\epsilon) = \unsur{2} \biforme{u}{a}{u} + \epsilon \cdot \biforme{u}{a}{w} + \frac{\epsilon^2}{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \epsilon \cdot \forme{b}{w}\]
</p>

<p>
La dérivée s'écrit :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = \biforme{u}{a}{w} + \epsilon \cdot \biforme{w}{a}{w} - \forme{b}{w}\]
</p>

<p>
La condition extrémale sur \(u\) nous dit que \(J_w(0) \le J_w(\epsilon)\) pour tout \(\epsilon \in \setR\). On doit donc avoir :
</p>

<p>
\[\OD{J_v}{\epsilon}(0) = \biforme{u}{a}{w} - \forme{b}{w} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Le théorème de Lax-Milgram nous dit qu'il existe un unique \(u \in  \mathcal{F}\) vérifiant cette condition.
</p>

<ul class="org-ul">
<li>Supposons à présent que \(u \in \mathcal{F}\) soit l'unique élément de \(\mathcal{F}\) vérifiant :</li>
</ul>

<p>
\[\biforme{u}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{F}\). Choisissons \(v \in \mathcal{F}\) et posons \(w = v - u\). Comme \(\biforme{u}{a}{w} = \forme{b}{w}\), on a :
</p>

\begin{align}
I(v) &= I(u + w) \)

\(
&= \unsur{2} \biforme{u}{a}{u} + \biforme{u}{a}{w} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} - \forme{b}{w} \)

\(
&= \unsur{2} \biforme{u}{a}{u} + \unsur{2} \cdot \biforme{w}{a}{w} - \forme{b}{u} \)

\(
&= I(u) + \unsur{2} \biforme{w}{a}{w} \ge I(u)
\end{align}

<p>
On a donc :
</p>

<p>
\[u = \arg\min_{ v \in \mathcal{F} } I(v)\]
</p>
</div>
<div id="outline-container-org7ea819a" class="outline-3">
<h3 id="org7ea819a"><span class="section-number-3">4.1.</span> Orthogonalité</h3>
<div class="outline-text-3" id="text-4-1">
<p>
Soit le sous-espace vectoriel \(\mathcal{G} \subseteq \mathcal{F}\) et :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } I(z)\]
</p>

<p>
On a alors :
</p>

<p>
\[\biforme{v}{a}{w} = \forme{b}{w}\]
</p>

<p>
pour tout \(w \in \mathcal{G}\).
</p>

<p>
Supposons que \(u \in \mathcal{F}\) minimise \(I\) sur \(\mathcal{F}\) et posons \(e = v - u\). On a :
</p>

<p>
\[\biforme{e}{a}{w} = \biforme{v}{a}{w} - \biforme{u}{a}{w} = \forme{b}{w} - \forme{b}{w} = 0\]
</p>

<p>
Cette propriété est similaire aux propriétés d'orthogonalité vue dans les projections. On est tenté d'en déduire que le \(v\) en question minimise la « norme » de l'écart \(e\) au sens de \(a\). Soit \(z \in \mathcal{G}\) et \(\delta = z - v\). On a \(z - u = z - v + v - u = \delta + e\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + 2 \biforme{e}{a}{\delta} + \biforme{e}{a}{e}\]
</p>

<p>
Mais comme \(\delta \in \mathcal{G}\), on a \(\biforme{e}{a}{\delta} = 0\) et :
</p>

<p>
\[\biforme{z - u}{a}{z - u} = \biforme{\delta}{a}{\delta} + \biforme{e}{a}{e} \ge \biforme{e}{a}{e}\]
</p>

<p>
ce qui prouve que :
</p>

<p>
\[v \in \arg\min_{ z \in \mathcal{G} } \biforme{z - u}{a}{z - u}\]
</p>
</div>
</div>
<div id="outline-container-orgfa4f348" class="outline-3">
<h3 id="orgfa4f348"><span class="section-number-3">4.2.</span> Borne inférieure</h3>
<div class="outline-text-3" id="text-4-2">
<p>
Comme \(a\) est coercive, on peut trouver un réel \(\varrho \strictsuperieur 0\) tel que :
</p>

<p>
\[a(u,u) \ge \varrho \cdot \norme{u}^2\]
</p>

<p>
pour tout \(u \in \mathcal{F}\). On sait aussi que :
</p>

<p>
\[\norme{b} = \sup \{ \abs{b(u)} : u \in \mathcal{F}, \ \norme{u} = 1 \} \strictinferieur +\infty\]
</p>

<p>
Posons :
</p>

<p>
\[K(\epsilon) = I(\epsilon \cdot v) = \frac{\epsilon^2}{2} \cdot \biforme{v}{a}{v} - \epsilon \cdot \forme{b}{v}\]
</p>

<p>
et cherchons la valeur de \(\epsilon = \gamma\) qui minimise cette fonction. On trouve :
</p>

<p>
\[\OD{K}{\epsilon}(\gamma) = \gamma \cdot \biforme{v}{a}{v} - \forme{b}{v} = 0\]
</p>

<p>
Donc :
</p>

<p>
\[\gamma = \frac{ \forme{b}{v} }{ \biforme{v}{a}{v} }\]
</p>

<p>
et :
</p>

<p>
\[K(\gamma) = \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } - \frac{ \forme{b}{v}^2 }{ \biforme{v}{a}{v} } = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
On en déduit que :
</p>

<p>
\[I(v) = K(1) \ge K(\gamma) = - \frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} }\]
</p>

<p>
Mais comme :
</p>

<div class="org-center">
<p>
\(
\forme{b}{v}^2 \le \norme{b}^2 \cdot \norme{v}^2 \)
</p>

<p>
\(
\biforme{v}{a}{v} \ge \varrho \cdot \norme{v}^2
\)
</p>
</div>

<p>
on a :
</p>

<p>
\[\frac{ \forme{b}{v}^2 }{ 2 \biforme{v}{a}{v} } \le \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
et :
</p>

<p>
\[I(v) \ge - \frac{\norme{b}^2}{2 \varrho}\]
</p>

<p>
Ce résultat étant valable pour tout \(v \in \mathcal{F}\), on a la borne inférieure :
</p>

<p>
\[\inf_{ v \in \mathcal{F} } I(v) \ge - \frac{\norme{b}^2}{2\varrho}\]
</p>
</div>
</div>
<div id="outline-container-org9f5de82" class="outline-3">
<h3 id="org9f5de82"><span class="section-number-3">4.3.</span> Discrétisation</h3>
<div class="outline-text-3" id="text-4-3">
<p>
Afin de trouver une approximation \(u_n \approx u\), on pose :
</p>

<p>
\[u_n = \sum_{i = 1}^n U_i \cdot \varphi_i\]
</p>

<p>
où les \(\varphi_i \in \mathcal{F}\) sont connues et où les \(U_i\) sont des réels à déterminer. La linéarité de \(a\) et \(b\) nous permet de développer :
</p>

<p>
\[I(u_n) = \unsur{2} \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j - \sum_{i=1}^n \forme{b}{\varphi_i} U_i\]
</p>

<p>
Si nous définissons les matrices :
</p>

\begin{align}
A &= \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \)

\(
B &= \left[ \forme{b}{\varphi_i} \right]_i \)

\(
U &= \left[ U_i \right]_i
\end{align}

<p>
on peut réécrire \(I(u_n)\) sous forme matricielle :
</p>

<p>
\[I(u_n) = J(U) = \unsur{2} U^\dual \cdot A \cdot U - U^\dual \cdot B\]
</p>

<p>
La condition \(\partial J(U) = 0\) nous amène à :
</p>

<p>
\[A \cdot U - B = 0\]
</p>

<p>
Si la matrice \(A\) est inversible, on en déduit :
</p>

<p>
\[U = A^{-1} \cdot B\]
</p>

<p>
ce qui nous donne \(U\) et donc \(u_n\).
</p>
</div>
</div>
</div>
<div id="outline-container-org73d56cb" class="outline-2">
<h2 id="org73d56cb"><span class="section-number-2">5.</span> Valeurs propres</h2>
<div class="outline-text-2" id="text-5">
<p>
Soit un espace vectoriel \(E\) et les formes bilinéaires \(a,b : E \times E \mapsto \setR\). Nous supposons que \(a,b\) sont symétriques et définies positives. Nous allons tenter de minimiser la fonctionnelle :
</p>

<p>
\[I(v) = \biforme{v}{a}{v}\]
</p>

<p>
sur l'ensemble :
</p>

<p>
\[\Omega = \{ v \in E : \biforme{v}{b}{v} = 1 \}\]
</p>

<p>
L'espace \(\Omega\) n'est malheureusement pas un sous-espace vectoriel. Par exemple, si \(u\) appartient à \(\Omega\), on a :
</p>

<p>
\[\biforme{2 u}{b}{2 u} = 4 \biforme{u}{b}{u} = 4 \ne 1\]
</p>

<p>
Donc \(2 u \notin \Omega\). Par conséquent, nous ne pouvons pas utiliser les techniques de projection sur un espace vectoriel pour résoudre ce problème. Nous allons donc employer les techniques de minimisation sous contraintes. Définissons le lagrangien :
</p>

<p>
\[\lagrangien(v,y) = \biforme{v}{a}{v} + y \cdot (1 - \biforme{v}{b}{v})\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). La fonction \(u\) minimisant \(I\) sur \(\Omega\) peut dès lors s'obtenir via le point de selle \((u,\lambda)\) :
</p>

<p>
\[\lagrangien(u,y) \le \lagrangien(u,\lambda) \le \lagrangien(v,\lambda)\]
</p>

<p>
pour tout \((v,y) \in E \times \setR\). Nous allons évaluer le minimum sur \(v\) en utilisant la méthode des variations. Soit \(w \in E\) et \(\epsilon \in \setR\). On pose :
</p>

\begin{align}
J_v(\epsilon) &= \lagrangien(u + \epsilon \cdot w, \lambda) \)

\(
&= \biforme{u + \epsilon \cdot w}{a}{u + \epsilon \cdot w} + \lambda \cdot [ 1 - \biforme{u + \epsilon \cdot w}{b}{u + \epsilon \cdot w} ]
\end{align}

<p>
Utilisant les propriétés de \(a,b\) et la contrainte \(\biforme{u}{b}{u} = 1\), il vient :
</p>

<div class="org-center">
<p>
\(
J_v(\epsilon) = \biforme{u}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{u} + \epsilon^2 \cdot \biforme{w}{a}{w} \)
</p>

<p>
\(
\qquad - \lambda \cdot [ 2 \epsilon \cdot \biforme{w}{b}{u} + \epsilon^2 \cdot \biforme{w}{b}{w} ]
\)
</p>
</div>

<p>
Les propriétés du point de selle en \((u,\lambda)\) nous garantissent que :
</p>

<p>
\[J_v(0) \le J_v(\epsilon)\]
</p>

<p>
pour tout \(\epsilon\in\setR\). La dérivée :
</p>

<p>
\[\OD{J_v}{\epsilon}(\epsilon) = 2 \biforme{w}{a}{u} + 2 \epsilon \cdot \biforme{w}{a}{w} - 2 \lambda \cdot [ \biforme{w}{b}{u} + \epsilon \cdot \biforme{w}{b}{w} ]\]
</p>

<p>
doit donc s'annuler en \(\epsilon = 0\) :
</p>

<p>
\[\OD{J_v^\lambda}{\epsilon}(0) = 2 \biforme{w}{a}{u} - 2 \lambda \cdot \biforme{w}{b}{u} = 0\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\biforme{w}{a}{u} = \lambda \cdot \biforme{w}{b}{u}\]
</p>

<p>
pour tout \(w \in E\). On dit alors que \(\lambda\) est valeur propre de
\(a,b\) correspondant à la fonction propre \(u\). On remarque également
que cela donne un rapport de Rayleigh généralisé :
</p>

<p>
\[\lambda = \frac{\biforme{w}{a}{u}}{\biforme{w}{b}{u}}\]
</p>
</div>
<div id="outline-container-orgf92440e" class="outline-3">
<h3 id="orgf92440e"><span class="section-number-3">5.1.</span> Propriétés extrémales</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Si nous choisissons \(w = u\), nous obtenons :
</p>

<p>
\[\biforme{u}{a}{u} = \lambda \cdot \biforme{u}{b}{u} = \lambda\]
</p>

<p>
La valeur propre est donc la valeur minimale de \(I\) sur \(\Omega\) :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \min_{v \in \Omega} \biforme{v}{a}{v}\]
</p>
</div>
</div>
<div id="outline-container-orgfd79b23" class="outline-3">
<h3 id="orgfd79b23"><span class="section-number-3">5.2.</span> Rapport de Rayleigh</h3>
<div class="outline-text-3" id="text-5-2">
<p>
Supposons que \(b\) soit strictement définie positive. Posons \(x = \alpha \cdot u\), pour un certain \(\alpha \in \setR\) non nul. On a \(\biforme{x}{a}{x} = \alpha^2 \cdot \biforme{u}{a}{u}\) et \(\biforme{x}{b}{x} = \alpha^2 \cdot \biforme{u}{b}{u} = \alpha^2\). Donc :
</p>

<p>
\[\lambda = \biforme{u}{a}{u} = \frac{ \biforme{x}{a}{x} }{ \biforme{x}{b}{x} }\]
</p>

<p>
Considérons la même expression pour un quelconque \(z \in E\) non nul :
</p>

<p>
\[R(z) = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} }\]
</p>

<p>
On dit que \(R(z)\) est le rapport de Rayleigh de \(z\). Soit \(v = z / \sqrt{ \biforme{z}{b}{z} }\). On a :
</p>

<p>
\[\biforme{v}{a}{v} = \frac{ \biforme{z}{a}{z} }{ \biforme{z}{b}{z} } = R(z)\]
</p>

<p>
et :
</p>

<p>
\[\biforme{v}{b}{v} = \frac{ \biforme{z}{b}{z} }{ \biforme{z}{b}{z} } = 1\]
</p>

<p>
ce qui prouve que \(v \in \Omega\). On a donc :
</p>

<p>
\[\lambda = R(x) \le \biforme{v}{a}{v} = R(z)\]
</p>

<p>
On en conclut que \(x\) minimise le rapport de Rayleigh sur \(E_0 = E \setminus \{0\}\) :
</p>

<p>
\[\lambda = R(x) = \arg\min_{z \in E_0} R(z) = \arg\min_{z \ne 0} R(z)\]
</p>

<p>
Comme \(\Omega \subseteq F\), on en conclut que la réciproque est vraie : si \(x\) minimise \(R\) sur \(E_0\), le vecteur \(x/\sqrt{ \biforme{x}{b}{x} }\) minimise la fonctionnelle \(I\) sur \(\Omega\). Les deux problèmes de minimisation sont donc équivalents.
</p>
</div>
</div>
<div id="outline-container-org169a68b" class="outline-3">
<h3 id="org169a68b"><span class="section-number-3">5.3.</span> Suite de vecteurs propres</h3>
<div class="outline-text-3" id="text-5-3">
<p>
On peut en fait définir une suite de vecteurs et de valeurs propres. Soit \(\Omega_1 = \Omega\) et \(e_1 = u\). On pose récursivement :
</p>

<p>
\[\Omega_{n + 1} = \{ v \in \Omega : \biforme{v}{b}{e_1} = ... = \biforme{v}{b}{e_n} = 0 \}\]
</p>

<p>
et :
</p>

<p>
\[e_{n + 1} \in \arg\min_{ v \in \Omega_{n + 1} } \biforme{v}{a}{v}\]
</p>

<p>
On aura alors bien sûr \(\Omega_{n + 1} \subseteq \Omega_n \subseteq ... \Omega_1\). Les propriétés extrémales des valeurs propres nous montrent que \(\lambda_{n + 1} \ge \lambda_n \ge ... \ge \lambda_1\).
</p>
</div>
</div>
<div id="outline-container-orgbb9eb30" class="outline-3">
<h3 id="orgbb9eb30"><span class="section-number-3">5.4.</span> Discrétisation</h3>
<div class="outline-text-3" id="text-5-4">
<p>
On pose :
</p>

<p>
\[u_n = \sum_{i=1}^n U_i \cdot \varphi_i\]
</p>

<p>
On a alors :
</p>

<div class="org-center">
<p>
\(
\biforme{u_n}{a}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{a}{\varphi_j} \cdot U_j \)
</p>

<p>
\(
\biforme{u_n}{b}{u_n} = \sum_{i,j = 1}^n U_i \cdot \biforme{\varphi_i}{b}{\varphi_j} \cdot U_j
\)
</p>
</div>

<p>
Avec les matrices :
</p>

<div class="org-center">
<p>
\(
A = \left[ \biforme{\varphi_i}{a}{\varphi_j} \right]_{i,j} \)
</p>

<p>
\(
B = \left[ \biforme{\varphi_i}{b}{\varphi_j} \right]_{i,j}
\)
</p>
</div>

<p>
le lagrangien peut s'écrire :
</p>

<p>
\[\lagrangien(u_n,y) = U^\dual \cdot A \cdot U + y \cdot \left[ 1 - U^\dual \cdot B \cdot U \right]\]
</p>

<p>
Les conditions :
</p>

<div class="org-center">
<p>
\(
\partial_v \lagrangien(u_n,\lambda) = 2 A \cdot U - 2 \lambda \cdot B \cdot U = 0 \)
</p>

<p>
\(
\partial_y \lagrangien(u_n,\lambda) = 1 - U^\dual \cdot B \cdot U = 0
\)
</p>
</div>

<p>
nous amènent au problème :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot B \cdot U \)
</p>

<p>
\(
U^\dual \cdot B \cdot U = 1
\)
</p>
</div>

<p>
à résoudre en \(U\). Notons que si on choisit les \(\varphi_i\) « orthonormées » dans le sens du pseudo-produit scalaire introduit par \(b\), on a :
</p>

<p>
\[\biforme{\varphi_i}{b}{\varphi_j} = \delta_{ij}\]
</p>

<p>
et \(B = I\). On peut par exemple construire une telle suite de \(\varphi_i\) en utilisant la méthode de Gram-Schmidt. Le problème se simplifie alors en :
</p>

<div class="org-center">
<p>
\(
A \cdot U = \lambda \cdot U \)
</p>

<p>
\(
U^\dual \cdot U = 1
\)
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-11-20 jeu 14:20</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
