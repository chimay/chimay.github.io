
#+STARTUP: showall

#+TITLE: Eclats de vers : Matemat : Différentielles
#+AUTHOR: chimay
#+EMAIL: or du val chez gé courriel commercial
#+LANGUAGE: fr
#+LINK_HOME: file:../index.html
#+LINK_UP: file:index.html
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../style/defaut.css" />

#+OPTIONS: H:6
#+OPTIONS: toc:nil

#+TAGS: noexport(n)

[[file:index.org][Index des Grimoires]]

#+INCLUDE: "../include/navigan-1.org"

#+TOC: headlines 1

#+INCLUDE: "../include/latex/latex.org"

\label{chap:differentielles}

* Dépendances

  - Chapitre \ref{chap:lineaire} : Les fonctions linéaires

* Définition

Soit les espaces vectoriels $\Omega, F$ sur $\corps$.

L'idée à la base de la notion de différentielles est de linéariser localement une fonction $f : \Omega \mapsto F$ autour d'un point $a \in \Omega$. Pour tout $h \in \Omega$ suffisamment petit, on veut donc avoir :

$$f(a + h) - f(a) \approx \differentielle{f}{a}(h)$$

où $\differentielle{f}{a}$ est une application linéaire de $\Omega$
vers $F$. On suppose que la norme de $\differentielle{f}{a}$ existe,
de sorte que nous puissions écrire :

$$\norme{ \differentielle{f}{a}(h) } \le \norme{ \differentielle{f}{a} } \cdot \norme{h}$$

On demande que la norme de l'erreur donnée par :

$$E(h) = f(a + h) - f(a) - \differentielle{f}{a}(h)$$

devienne négligeable par rapport à :

$$\norme{ \differentielle{f}{a} } \cdot \norme{h}$$

lorsque $h$ tend vers $0$. Comme la norme de la différentielle ne varie pas, il nous suffit d'imposer que :

$$\lim_{ \substack{ h \to 0 \\ h \ne 0 } } \frac{ \norme{E(h)} }{ \norme{h} } = 0$$

Si ces conditions sont vérifiées, on dit que $f$ est différentiable en $a$ et que $\differentielle{f}{a}$ est la différentielle de $f$ en $a$. On a alors :

$$f(a + h) - f(a) = \differentielle{f}{a}(h) + E(h)$$

ou encore :

$$f(a + h) = f(a) + \differentielle{f}{a}(h) + E(h)$$

** Notation

Tout au long de ce chapitre, nous notons :

$$ \lim_{h \to 0} = \lim_{ \substack{ h \to 0 \\ h \ne 0 } } $$

$$ \lim_{b \to a} = \lim_{ \substack{ b \to a \\ b \ne a } } $$

* Continuité

L'expression de $f(a + h)$ peut donc s'écrire :

$$f(a + h) = f(a) + \differentielle{f}{a}(h) + E(h)$$

En prenant la limite quand $h \to 0$, on a :

$$ \lim_{h \to 0} f(a + h) = f(a) + \lim_{h \to 0} \differentielle{f}{a}(h) + \lim_{h \to 0} E(h) $$

La norme de la différentielle étant finie :

$$ \lim_{h \to 0} \norme{ \differentielle{f}{a}(h) } \le \lim_{h \to 0} \norme{ \differentielle{f}{a} } \cdot \norme{h}$$

elle tend vers zéro avec $h$ :

$$ \lim_{h \to 0} \norme{ \differentielle{f}{a}(h) }
\le \norme{ \differentielle{f}{a} } \cdot \lim_{h \to 0} \norme{h}
= \norme{ \differentielle{f}{a} } \cdot \norme{0}
= 0$$

et donc :

$$ \lim_{h \to 0} \differentielle{f}{a}(h) = 0 $$

On a aussi :

$$\lim_{h \to 0} \norme{E(h)} = \norme{h} \cdot \lim_{ h \to 0} \frac{ \norme{E(h)} }{ \norme{h} } = 0$$

et donc :

$$\lim_{h \to 0} E(h) = 0$$

L’expression de $f(a+h)$ devient :

$$ \lim_{h \to 0} f(a + h) = f(a) + 0 + 0 = f(a) $$

Si $a$ est différentiable en $a$, elle est forcément continue en $a$.

* Dérivées partielles

Nous allons à présent voir comment obtenir les composantes de la différentielle dans le cas d'espaces de dimensions finies. Nous disposons donc d'une base $(\varpi_1,...,\varpi_n)$ de $\Omega$ et d'une base $(\phi_1,...,\phi_m)$ de $F$. Nous introduisons les composantes $f_1,...,f_m : \Omega \mapsto F$ de $f$ telles que :

$$f(x) = \sum_{i = 1}^m f_i(x) \cdot \phi_i$$

pour tout $x \in \Omega$. Nous procédons de même pour l'erreur :

$$E(h) = \sum_{i = 1}^m E_i(h) \cdot \phi_i$$

pour tout $h \in \Omega$. Nous allons également utiliser les coordonnées $h_1,...,h_n \in \corps$ de $h$ :

$$h = \sum_{i = 1}^n h_i \cdot \varpi_i$$

Par linéarité :

$$f(a + h) - f(a) = \sum_{j = 1}^n \differentielle{f}{a}(\varpi_j) \cdot h_j + E(h)$$

Mais on peut trouver des $\Delta_{ij} \in \corps$ tels que :

$$\differentielle{f}{a}(\varpi_j) = \sum_{i = 1}^m \Delta_{ij} \cdot \phi_i$$

Injectons les expressions des composantes dans $F$. On obtient :

$$\sum_i \phi_i \cdot \left[ f_i(a + h) - f_i(a) - E_i(h) - \sum_{j = 1}^n \Delta_{ij} \cdot h_j \right] = 0$$

Par indépendance linéaire des $\phi_i$, on a alors :

$$f_i(a + h) - f_i(a) = \sum_{j = 1}^n \Delta_{ij} \cdot h_j + E_i(h)$$

pour tout $i \in \setZ(1,m)$. On nomme $\Delta_{ij}$ la dérivée partielle de $f_i$ par rapport à $\varpi_j$. On la note :

$$\partial_j f_i(a) = \deriveepartielle{f_i}{x_j}(a) = \Delta_{ij}$$

** Attention

Ne pas confondre la frontière $\frontiere A$ d'un ensemble $A$ avec la dérivée $\partial f$ d'une fonction $f$.

* Dérivées et limites

Soit $\lambda \in \corps$. Si l'on choisit $h = \lambda \ \varpi_j$, on a $h_k = \lambda \ \indicatrice_{jk}$ et :

$$ f_i(a + \lambda \ \varpi_j) - f_i(a) = \sum_{k = 1}^n \partial_k f_i(a) \cdot \lambda \cdot \indicatrice_{jk} +  E_i(h) $$

$$ f_i(a + \lambda \ \varpi_j) - f_i(a) = \lambda \cdot \partial_j f_i(a)  +  E_i(h) $$

En divisant l'équation ci-dessus par $\lambda$ puis en faisant tendre $\lambda$ vers 0, on obtient :

$$\partial_j f_i(a) = \lim_{\lambda \to 0} \left[ \frac{f_i(a + \lambda \ \varpi_j) - f_i(a)}{\lambda} - \frac{E_i(h)}{\lambda} \right]$$

Comme l'erreur doit converger plus vite vers zéro que la norme $\norme{h} = \lambda$, la limite du second terme du membre de droite s'annule et on a :

$$\partial_j f_i(a) = \lim_{\lambda \to 0} \frac{f_i(a + \lambda \ \varpi_j) - f_i(a)}{\lambda}$$

Ce qui montre que la dérivée partielle $\partial_j f_i$ est la variation de $f_i$ obtenue lorsqu'on fait varier la $j^{ème}$ variable (celle correspondant à $\varpi_j$).

* Matrice Jacobienne

On associe à la différentielle $\differentielle{f}{a}$ la matrice Jacobienne $\partial f(a)$ de $f$ en $a$ définie par :

$$\partial f(a) = \Big( \partial_j f_i(a) \Big)_{i,j}$$

On peut alors écrire la linéarisation de $f$ sous forme de produit matriciel :

$$f(a + h) - f(a) = \partial f(a) \cdot h + E(h)$$

où $f,h,E$ sont les vecteurs colonnes associés aux grandeurs du même nom.


** Vecteurs associés

On dispose de $n$ vecteurs représentant chacun la dérivée des composantes de $f$ par rapport à la $j^{ème}$ variable :

$$\partial_j f(a) = \Big( \partial_j f_i(a) \Big)_i$$

et de $m$ vecteurs représentant chacun les dérivées de la $i^{ème}$ composante de $f$ :

$$\partial f_i(a) = \Big( \partial_j f_i(a) \Big)_j$$


** Notation

Dans le cas où la variable porte un nom par défaut, comme par exemple :

$$f : x \mapsto f(x)$$

on note aussi :

$$\deriveepartielle{f}{x}(a) = \partial f(a)$$

*** Plusieurs sous-variables

Lorsque plusieurs sous variables portent un nom par défaut, comme par exemple :

$$f : (x,y) \mapsto f(x,y)$$

on note aussi :

$$\deriveepartielle{f}{x}(a) = \partial_x f(a)$$

pour la Jacobienne par rapport aux variables $x = (x_1,...,x_s)$ et :

$$\deriveepartielle{f}{y}(a) = \partial_y f(a)$$

pour la Jacobienne par rapport aux variables $y = (y_1,...,y_t)$


*** Symbolique

On a aussi les notations symboliques :

$$ df = \deriveepartielle{f}{x^T} \ dx $$

$$ df_i = \sum_j \deriveepartielle{f_i}{x_j} \ dx_j $$

où $df$ représente une petite variation de $f$ suite à une petite variation $dx$ de $x$.

On utilise parfois la transposée de la Jacobienne :

$$\Big[ \partial f(x) \Big]^T = \deriveepartielle{f^T}{x} = \left( \deriveepartielle{f}{x^T} \right)^T$$

** Gradient

Pour des fonctions du type $f : \setR^n \mapsto \setR$, la Jacobienne se réduit à un vecteur matriciel. On dit alors que $\partial f$ est le gradient de $f$.


* Dérivées ordinaires

Dans le cas où $m = n = 1$, il n'y a qu'une dérivée partielle, $\partial_1 f_1$, que l'on appelle alors dérivée ordinaire. On a les équivalences :

$$\lambda \ \phi_1 \quad \Leftrightarrow \quad \lambda \quad \Leftrightarrow \quad \lambda \ \epsilon_1$$

On peut considérer $\Omega$ et $F$ comme équivalents à $\corps$ et se restreindre à des fonctions $f : \corps \mapsto \corps$ sans perte de généralité. La dérivée ordinaire est alors simplement :

$$\partial f(a) = \lim_{\lambda \to 0} \frac{f(a + \lambda) - f(a)}{\lambda}$$


** Notation

On note aussi :

$$\OD{f}{x}(a) = \lim_{\lambda \to 0} \frac{f(a + \lambda) - f(a)}{\lambda}$$

On a alors :

$$f(a + h) = f(a) + \OD{f}{x}(a) \cdot h + E(h)$$

et :

$$\lim_{\lambda \to 0} \frac{E(\lambda)}{\lambda} = \lim_{\lambda \to 0} \left[ \frac{f(a + \lambda) - f(a)}{\lambda} - \OD{f}{x}(a) \right] = 0$$


** Définition équivalente

Si on pose $b = a + \lambda$, on voit que $\lambda = b - a$ et que la convergence $h \to 0$ est équivalente à $b \to a$. On a donc :

$$\OD{f}{x}(a) = \lim_{b \to a} \frac{f(b) - f(a)}{b - a}$$


* L'application dérivée

Si $f$ est différentiable en tout vecteur $a$ de $A \subseteq \Omega$, on dit que $f$ est différentiable sur $A$. On peut alors définir une application dérivée $\partial f : A \mapsto \matrice(\corps,m,n)$ définie par :

$$\partial f : a \mapsto \partial f(a)$$

pour tout $a \in A$. Si cette nouvelle application $\partial f$ est également continue, on dit que $f$ est continûment différentiable. On note $\continue^1(A,F)$ l'ensemble des fonctions continûment différentiables de $A$ vers $F$.


* Hessienne

Soit $f : \Omega \mapsto \corps$ avec $\Omega$ de dimension finie $n$. Supposons que $f$ est différentiable sur $A \subseteq \Omega$. La dimension de $\corps$ sur $\corps$ étant $1$, la Jacobienne $\partial f(a)$ se réduit à un vecteur matriciel de composantes $\partial_i f$. Si la dérivée $\partial f : A \mapsto \corps^n$ est elle-même différentiable, on nomme l'application définie par :

$$\partial^2 f = \partial \left( \partial f \right)$$

la dérivée seconde de $f$. Il s'agit d'une fonction qui transforme un élément de $A$ en un « vecteur matriciel de vecteurs matriciels » appartenant à $\matrice(\corps^n,n,1)$. On peut assimiler cet objet à une matrice équivalente de taille $(n,n)$ dont les composantes sont des éléments de $\corps$. En définitive, nous avons $\partial^2 f(a) \in \matrice(\corps,n,n)$ pour tout $a \in A$. Cette matrice est appellée hessienne de $f$ en $a$. Ses composantes sont données par :

$$\partial_{ij}^2 f(a) = \partial_i \left( \partial_j f \right)(a)$$


** Notation

On note aussi :

$$\dfdxdy{f}{x_i}{x_j}(a) = \partial_{ij}^2 f(a)$$

Lorsque $i = j$, on note :

$$\dfdxdx{f}{x_i} = \dfdxdy{f}{x_i}{x_i} = \partial_{ii}^2 f(a)$$

En termes matriciels, cela donne :

$$\dblederiveepartielle{f}{x}(a) = \partial^2 f(a)$$


** Dérivée ordinaire

Dans le cas où la dimension de $\Omega$ est un $1$, on peut l'assimiler à $\corps$, on a alors une fonction $f : \corps \mapsto \corps$ possédant une seule dérivée seconde, que l'on note :

$$\OOD{f}{t}(a) = \partial^2 f(a)$$


** Continuité

On note $\continue^2(A,\corps)$ l'ensemble des fonctions dont la dérivée seconde est continue sur $A$.


* Dérivée d'ordre $k$

Soit $f : \corps \mapsto \corps$ et $k \in \setN$. Pour autant que la fonction $f$ soit suffisamment dérivable, on définit par récurrence la fonction $\partial^k f : \corps \mapsto \corps$ :

$$ \partial^0 f = f $$

$$ \partial^k f = \partial \big( \partial^{k-1} f \big) $$

La dérivée d'ordre $k$  de $f$ est donc la fonction obtenue lorsqu'on applique un nombre $k$ de fois l'opérateur de dérivation $\partial$ à la fonction $f$ :

$$\partial^k f = (\partial \circ ... \circ \partial)(f)$$


** Ensembles

On note $\continue^k(A,\corps)$ l'ensemble des fonctions $f : A \mapsto \corps$ dont la dérivée d'ordre $k$ :

$$\partial^k f : A \mapsto \corps$$

existe et est continue sur $A$.


*** Infini

Si la dérivée $\partial^k f$ existe pour tout $k \in \setN$, on dit que $f$ est indéfiniment dérivable. On note $\continue^\infty(A,\corps)$ l'ensemble des fonctions indéfiniment dérivables.


*** Ordre $0$

On voit que $\continue^0 = \continue$.


** Homéomorphisme

On note $\homeomorphisme^k(A,\corps)$ l'ensemble des bijections $f$ de $\continue^k$ telles que la fonction $f^{-1}$ soit aussi dans $\continue^k$.


** Notations

Pour $\alpha = (\alpha_1, \alpha_2, ..., \alpha_n)$, on écrit également :

#+BEGIN_CENTER
\(
\partial^\alpha f = \partial^{\alpha_1 ... \alpha_n} f =
\partial_1^{\alpha_1} ... \partial_n^{\alpha_n} f
\)
#+END_CENTER


* Fonctions à intégrale continue

Soit une fonction $u : A \mapsto B$. Si la fonction $v$ définie par :

$$v(x) = \int_a^x u(x) d\mu(x)$$

est continue, on dit que $u$ est à intégrale continue. On note $\continue_{\mu}^{-1}(A,B)$ l'ensemble des fontions à intégrale continue.


* Différentiabilité uniforme

On dit qu'une fonction $f$ est uniformément différentiable sur $A$ si pour tout $\epsilon \strictsuperieur 0$, on peut trouver un $\delta \strictsuperieur 0$ tel que :

$$\abs{f(s) - f(t) - \partial f(t) \cdot (s - t)} \le \epsilon \cdot \abs{s - t}$$

quel que soit $s,t \in A$ vérifiant $\abs{s - t} \le \delta$.


