<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-11-30 dim 13:45 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat : Optimisation sous contrainte</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat : Optimisation sous contrainte</h1>
<p>
<a href="index.html">Index mathématique</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org9c423aa">1. Introduction</a></li>
<li><a href="#orgcc086d5">2. Problème de minimisation sous contrainte</a></li>
<li><a href="#orgdcc6315">3. Convexité</a></li>
<li><a href="#orgac4091d">4. Frontière</a></li>
<li><a href="#org3440dc4">5. Pénalité</a></li>
<li><a href="#orgfde5f1b">6. Lagrangien</a></li>
<li><a href="#org07df137">7. Conditions de Kuhn-Tucker</a></li>
<li><a href="#org70380e6">8. Point de selle</a></li>
<li><a href="#org6a96cae">9. Solution</a></li>
<li><a href="#org0884d53">10. Problème de maximisation sous contrainte</a></li>
<li><a href="#orga987389">11. Contraintes d'égalité</a></li>
<li><a href="#orgeb8e8c2">12. Récapitulation</a></li>
<li><a href="#org7bd1e6d">13. Découplage</a></li>
<li><a href="#org3eb021f">14. Dualité en optimisation linéaire</a></li>
<li><a href="#org195c15a">15. Minimisation de la norme sous contraintes linéaires</a></li>
</ul>
</div>
</div>

<script>
MathJax = {
  tex: {
    packages: {'[+]': ['base','ams','braket']},
    macros: {
      parentheses: ["\\left(#1\\right)", 1],
      crochets: ["\\left[#1\\right]", 1],
      accolades: ["\\left\\{#1\\right\\}", 1],
      ensemble: ["\\left\\{#1\\right\\}", 1],
      cardinal: ["\\mathop{\\mathrm{card}\\ }\\limits",0],
      identite: "\\mathrm{Id}",
      indicatrice: "\\boldsymbol{\\delta}",
      dirac: "\\delta",
      moinsun: "-1",
      inverse: "\\ddagger",
      pinverse: "\\dagger",
      topologie: "\\mathfrak{T}",
      ferme: "\\mathfrak{F}",
      img: "\\mathbf{i}",
      binome: ["\\left\\{ \\begin{array}{c} #1 \\\\ #2 \\\\ \\end{array} \\right\\}", 2],
      canonique: "\\mathfrak{c}",
      tenseuridentite: "\\boldsymbol{\\mathcal{I}}",
      permutation: "\\boldsymbol{\\epsilon}",
      matriceZero: "\\mathfrak{0}",
      matriceUn: "\\mathfrak{1}",
      christoffel: ["\\left\\{ \\begin{array}{c} #1 \\\\ #2 \\\\ \\end{array} \\right\\}", 2],
      lagrangien: "\\mathfrak{L}",
      sousens: "\\mathfrak{P}",
      partition: "\\mathrm{Partition}",
      tribu: "\\mathrm{Tribu}",
      topologies: "\\mathrm{Topo}",
      setB: "\\mathbb{B}",
      setN: "\\mathbb{N}",
      setZ: "\\mathbb{Z}",
      setQ: "\\mathbb{Q}",
      setR: "\\mathbb{R}",
      setC: "\\mathbb{C}",
      corps: "\\mathbb{K}",
      boule: "\\mathfrak{B}",
      intervalleouvert: ["\\left] #1 , #2 \\right[", 2],
      intervallesemiouvertgauche: ["\\left] #1 , #2 \\right]", 2],
      intervallesemiouvertdroite: ["\\left[ #1 , #2 \\right[", 2],
      fonction: "\\mathbb{F}",
      bijection: "\\mathrm{Bij}",
      polynome: "\\mathrm{Poly}",
      lineaire: "\\mathrm{Lin}",
      continue: "\\mathrm{Cont}",
      homeomorphisme: "\\mathrm{Hom}",
      etagee: "\\mathrm{Etagee}",
      lebesgue: "\\mathrm{Leb}",
      lipschitz: "\\mathrm{Lip}",
      suitek: "\\mathrm{Suite}",
      matrice: "\\mathbb{M}",
      krylov: "\\mathrm{Krylov}",
      tenseur: "\\mathbb{T}",
      essentiel: "\\mathfrak{E}",
      relation: "\\mathrm{Rel}",
      strictinferieur: "<",
      strictsuperieur: ">",
      ensinferieur: "\\eqslantless",
      enssuperieur: "\\eqslantgtr",
      esssuperieur: "\\gtrsim",
      essinferieur: "\\lesssim",
      essegal: "\\eqsim",
      union: "\\cup",
      intersection: "\\cap",
      opera: "\\divideontimes",
      autreaddition: "\\boxplus",
      autremultiplication: "\\circledast",
      commutateur: ["\\left[ #1 , #2 \\right]", 2],
      convolution: "\\circledcirc",
      correlation: "\\natural",
      diventiere: "\\div",
      modulo: "\\bmod",
      pgcd: ["\\mathop{\\mathrm{pgcd}\\ }\\limits",0],
      ppcm: ["\\mathop{\\mathrm{ppcm}\\ }\\limits",0],
      produitscalaire: ["\\left\\langle #1 \\vert #2 \\right\\rangle", 2],
      scalaire: ["\\left\\langle #1 \\| #2 \\right\\rangle", 2],
      braket: ["\\left\\langle #1 \\vert #2 \\vert #3 \\right\\rangle", 3],
      orthogonal: "\\bot",
      forme: ["\\left\\langle #1 , #2 \\right\\rangle", 2],
      biforme: ["\\left\\langle #1 , #2 , #3 \\right\\rangle", 3],
      contraction: ["\\left\\langle #1 \\odot #3 \\right\\rangle_{#2}", 3],
      dblecont: ["\\left\\langle #1 \\vert #3 \\vert #5 \\right\\rangle_{#2,#4}", 5],
      major: ["\\mathop{\\mathrm{major}\\ }\\limits",0],
      minor: ["\\mathop{\\mathrm{minor}\\ }\\limits",0],
      maxim: ["\\mathop{\\mathrm{maxim}\\ }\\limits",0],
      minim: ["\\mathop{\\mathrm{minim}\\ }\\limits",0],
      argument: ["\\mathop{\\mathrm{arg}\\ }\\limits",0],
      argmin: ["\\mathop{\\mathrm{arg\\,min}\\ }\\limits",0],
      argmax: ["\\mathop{\\mathrm{arg\\,max}\\ }\\limits",0],
      supessentiel: ["\\mathop{\\mathrm{ess\\,sup}\\ }\\limits",0],
      infessentiel: ["\\mathop{\\mathrm{ess\\,inf}\\ }\\limits",0],
      dual: "\\star",
      vardual: "\\circledast",
      distance: "\\mathfrak{dist}",
      norme: ["\\left\\lVert #1 \\right\\rVert", 1],
      normetrois: ["\\left|\\left\\| #1 \\right\\|\\right|", 1],
      adh: ["\\mathop{\\mathrm{adh}\\ }\\limits",0],
      interieur: ["\\mathop{\\mathrm{int}\\ }\\limits",0],
      frontiere: "\\partial",
      image: ["\\mathop{\\mathrm{im}\\ }\\limits",0],
      domaine: ["\\mathop{\\mathrm{dom}\\ }\\limits",0],
      noyau: ["\\mathop{\\mathrm{ker}\\ }\\limits",0],
      support: ["\\mathop{\\mathrm{supp}\\ }\\limits",0],
      signe: ["\\mathop{\\mathrm{sign}\\ }\\limits",0],
      abs: ["\\left\\lvert #1 \\right\\rvert", 1],
      unsur: ["\\frac{1}{#1}", 1],
      arrondisup: ["\\lceil #1 \\rceil", 1],
      arrondiinf: ["\\lfloor #1 \\rfloor", 1],
      conjugue: "\\mathrm{conj\\ }",
      conjaccent: ["\\overline{#1}", 1],
      division: "division",
      difference: "\\boldsymbol{\\Delta}",
      differentielle: ["\\mathfrak{D}^{#1}_{#2}", 2],
      OD: ["\\frac{d #1}{d #2}", 2],
      OOD: ["\\frac{d^2 #1}{d #2^2}", 2],
      NOD: ["\\frac{d^{#3} #1}{d #2^{#3}}", 3],
      deriveepartielle: ["\\frac{\\partial #1}{\\partial #2}", 2],
      PD: ["\\frac{\\partial #1}{\\partial #2}", 2],
      dblederiveepartielle: ["\\frac{\\partial^2 #1}{\\partial #2 \\partial #2}", 2],
      dfdxdy: ["\\frac{\\partial^2 #1}{\\partial #2 \\partial #3}", 3],
      dfdxdx: ["\\frac{\\partial^2 #1}{\\partial #2^2}", 2],
      gradient: "\\mathbf{\\nabla}",
      combilin: ["\\mathrm{span}\\{ #1 \\}", 1],
      trace: "tr",
      proba: "\\mathbb{P}",
      probaof: ["\\mathbb{P}\\left[#1\\right]", 1],
      esperof: ["\\mathbb{E}\\left[#1\\right]", 1],
      cov: ["\\mathrm{cov} ( #1 , #2 )", 2],
      var: ["\\mathrm{var} ( #1 )", 1],
      rand: "\\mathrm{rand}",
      variation: ["\\left\\langle #1 \\right\\rangle", 1],
      composante: ["\\mathop{\\mathrm{comp}\\ }\\limits",0],
      bloc: ["\\mathop{\\mathrm{bloc}\\ }\\limits",0],
      ligne: ["\\mathop{\\mathrm{ligne}\\ }\\limits",0],
      colonne: ["\\mathop{\\mathrm{colonne}\\ }\\limits",0],
      diagonale: ["\\mathop{\\mathrm{diag}\\ }\\limits",0],
      matelementaire: "\\mathrm{Elem}",
      matpermutation: ["\\mathop{\\mathrm{permut}\\ }\\limits",0],
      matunitaire: "\\mathrm{Unitaire}",
      gaussjordan: "\\mathrm{GaussJordan}",
      householder: "\\mathrm{Householder}",
      rang: "rang",
      schur: "\\mathrm{Schur}",
      singuliere: "\\mathrm{DVS}",
      convexe: "\\mathrm{Convexe}",
      petito: ["o(#1)", 1],
      grando: ["O(#1)", 1]
    }
  }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<p>
\(
\newenvironment{Eqts}
{ \begin{equation*} \begin{gathered} }
{ \end{gathered} \end{equation*} }
\newenvironment{Matrix}
{\left[ \begin{array}}
{\end{array} \right]}
\)
</p>

<p>
\label{chap:lagrange}
</p>
<div id="outline-container-org9c423aa" class="outline-2">
<h2 id="org9c423aa"><span class="section-number-2">1.</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
Ce chapitre traite de la résolution numérique de problèmes d'optimisation sous contraintes, ainsi que de leurs fondements théoriques. Les applications de ces méthodes sont nombreuses : maximisation du profit sous contrainte de ne pas dépasser un certain budget, maximiser la solidité d'une structure sans dépasser un certain poids, &#x2026;
</p>
</div>
</div>
<div id="outline-container-orgcc086d5" class="outline-2">
<h2 id="orgcc086d5"><span class="section-number-2">2.</span> Problème de minimisation sous contrainte</h2>
<div class="outline-text-2" id="text-2">
<p>
Soit les fonctions convexes et et deux fois continument différentiables \(\omega_1,\omega_2,...,\omega_m : \setR^n \mapsto \setR\) et la fonction \(\omega : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\omega(x) = (\omega_1(x), \omega_2(x), ..., \omega_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Omega = \{ x \in \setR^n : \omega(x) \le 0 \}\]
</p>

<p>
Par définition de l'ordre partiel sur \(\setR^m\), tout \(x \in \Omega\) doit donc vérifier les \(m\) contraintes :
</p>

\begin{align}
\omega_1(x) &\le 0 \)

\(
\omega_2(x) &\le 0 \)

\(
\dots & & \)

\(
\omega_m(x) &\le 0
\end{align}

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Omega\) qui minimise la fonction convexe et et deux fois continument différentiable \(\varphi : \setR^n \mapsto \setR\) sur \(\Omega\) :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
Nous avons donc un problème de minimisation à \(n\) paramètres :
</p>

<p>
\[x = (x_1,...,x_n)\]
</p>

<p>
et \(m\) contraintes correspondant aux \(\omega_i\). On dit que \(\varphi\) est la fonction objectif et \(\omega\) la fonction contraignante.
</p>
</div>
<div id="outline-container-org8c342c1" class="outline-3">
<h3 id="org8c342c1"><span class="section-number-3">2.1.</span> Lien avec la minimisation libre</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Il est important de se rendre compte que si \(\xi\) est la solution de :
</p>

<p>
\[\partial \varphi(\xi) = 0\]
</p>

<p>
on sait que :
</p>

<p>
\[\xi \in \arg\min_{x \in \setR^n} \varphi(x)\]
</p>

<p>
mais rien ne nous dit que \(\xi\) respecte les contraintes exigées ! On ne peut donc pas dans le cas général appliquer la technique classique de la minimisation libre pour résoudre des problèmes de minimisation contraints.
</p>
</div>
</div>
</div>
<div id="outline-container-orgdcc6315" class="outline-2">
<h2 id="orgdcc6315"><span class="section-number-2">3.</span> Convexité</h2>
<div class="outline-text-2" id="text-3">
<p>
Soit \(u,v \in \Omega\) et \(s,t \in \setR\) tels que \(s,t \ge 0\) et \(s + t = 1\). On a alors par convexité des \(\omega_i\) :
</p>

<p>
\[\omega(s \cdot u + t \cdot v) \le s \cdot \omega(u) + t \cdot \omega(v) \le 0\]
</p>

<p>
On en conclut que \(w = s \cdot u + t \cdot v \in \Omega\). On a donc \(\convexe(\Omega) = \Omega\). L'ensemble \(\Omega\) est convexe.
</p>
</div>
</div>
<div id="outline-container-orgac4091d" class="outline-2">
<h2 id="orgac4091d"><span class="section-number-2">4.</span> Frontière</h2>
<div class="outline-text-2" id="text-4">
<p>
Soit \(x \in \frontiere \Omega\). Comme \(x \in \adh \Omega\), on a \(\distance(x,\Omega) = 0\). On peut donc construire une suite \(u_n \in \Omega\) convergeant vers \(x\). La continuité des \(\omega_i\) et la définition de \(\Omega\) nous disent que :
</p>

<p>
\[\omega_i(x) = \lim_{n \to \infty} \omega_i(u_n) \le \limsup_{n \to \infty} \omega_i(u_n) \le 0\]
</p>

<p>
pour tout \(i \in \{1,...,m\}\). Comme \(x \notin \interieur \Omega\), on a aussi \(\distance(x,\setR^n \setminus \Omega) = 0\) et on peut construire une suite \(v_n \in \setR^n \setminus \Omega\) convergeant vers \(x\). On peut alors trouver un \(i \in \{1,...,m\}\) tel que :
</p>

<p>
\[\omega_i(x) = \lim_{n \to \infty} \omega_i(v_n) \ge \liminf_{n \to \infty} \omega_i(v_n) \ge 0\]
</p>

<p>
Ces deux inégalités nous disent que, pour tout \(x \in \frontiere \Omega\), il existe un \(i\) tel que \(\omega_i(x) = 0\).
</p>
</div>
</div>
<div id="outline-container-org3440dc4" class="outline-2">
<h2 id="org3440dc4"><span class="section-number-2">5.</span> Pénalité</h2>
<div class="outline-text-2" id="text-5">
<p>
L'idée est de laisser l'objectif inchangé sur \(\Omega\) mais de l'augmenter suffisamment en dehors pour que le minimum sur \(\Omega\) soit également le minimum global. On utilise une fonction \(p\) convexe et différentiable vérifiant :
</p>

\begin{align}
p(x) &= 0 \text{ pour tout } x \in \Omega \)

\(
p(x) &\strictsuperieur& 0 \text{ pour tout } x \in \setR^n \setminus \Omega
\end{align}

<p>
et on construit donc un nouvel objectif \(\psi\) par :
</p>

<p>
\[\psi(x) = \varphi(x) + p(x)\]
</p>

<p>
On dit alors que \(p(x)\) est un terme de pénalité. On a :
</p>

<p>
\[\min_{x \in \Omega} \psi(x) = \min_{x \in \Omega} \varphi(x) = \varphi(\gamma)\]
</p>

<p>
Choisissons :
</p>

<p>
\[\chi \in \arg\min_{x \in \setR^n \setminus \Omega} \psi(x)\]
</p>

<p>
Si \(p\) est assez élevée en dehors de \(\Omega\) pour avoir \(\psi(\chi) \ge \varphi(\gamma)\), on a :
</p>

<p>
\[\min_{x \in \setR^n} \psi(x) = \min \{ \psi(\chi) , \varphi(\gamma) \} = \varphi(\gamma)\]
</p>

<p>
Si de plus \(\psi(\chi) \strictsuperieur \varphi(\gamma)\), aucun minimum global ne pourra être en dehors de \(\Omega\) (sinon il serait minimisé par \(\varphi(\gamma)\)). On aura donc :
</p>

<p>
\[\arg\min_{x \in \setR^n} \psi(x) \subseteq \Omega\]
</p>

<p>
et il suffit de choisir :
</p>

<p>
\[\gamma \in \arg\min_{x \in \setR^n} \psi(x)\]
</p>

<p>
pour obtenir une solution à notre problème. De par les propriétés des fonctions convexes, \(\gamma\) sera une solution de \(\partial \psi(\gamma) = 0\).
</p>
</div>
</div>
<div id="outline-container-orgfde5f1b" class="outline-2">
<h2 id="orgfde5f1b"><span class="section-number-2">6.</span> Lagrangien</h2>
<div class="outline-text-2" id="text-6">
<p>
Par définition de \(\Omega\), on peut trouver au moins un \(\omega_i(x) \strictsuperieur 0\) pour tout \(x \notin \Omega\). Il est donc possible de s'en servir pour former un terme de pénalité. Comme chaque \(\omega_i\) est convexe, \(y_i \cdot \omega_i\) le sera aussi pour tout \(y_i \in \setR\) tel que \(y_i \ge 0\) (si \(y_i\) était strictement négatif, on aurait \(y_i \cdot \omega_i\) concave). Posons :
</p>

<p>
\[\mathcal{P} = \{ y \in \setR^m : y \ge 0 \}\]
</p>

<p>
L'objectif modifié s'écrit alors :
</p>

<p>
\[\lagrangien(x,y) = \varphi(x) + \sum_{i = 1}^m y_i \cdot \omega_i(x)\]
</p>

<p>
pour tout \(x \in \setR^n\) et tout \(y = (y_1,...,y_m) \in \mathcal{P}\). On dit que les \(y_i\) sont les multiplicateurs de Lagrange et que \(\lagrangien\) est le lagrangien associé au problème de minimisation. Utilisant la notation du produit scalaire entre vecteurs colonnes, on le note sous la forme schématique :
</p>

<p>
\[\lagrangien(x,y) = \varphi(x) + y^\dual \cdot \omega(x)\]
</p>
</div>
</div>
<div id="outline-container-org07df137" class="outline-2">
<h2 id="org07df137"><span class="section-number-2">7.</span> Conditions de Kuhn-Tucker</h2>
<div class="outline-text-2" id="text-7">
<p>
Nous allons à présent essayer de caractériser un choix \(y = \lambda\) tel que \(\gamma\) minimise globalement \(\lagrangien(x,\lambda)\) :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \min_{x \in \setR^n} \lagrangien(x,\lambda)\]
</p>

<p>
Puisqu'il s'agit d'un problème de minimisation libre, on sait que la dérivée doit s'annuler en \(\gamma\) :
</p>

<p>
\[\deriveepartielle{\lagrangien}{x}(\gamma,\lambda) = \partial \varphi(\gamma) + \lambda^\dual \cdot \partial \omega(\gamma) = 0\]
</p>

<p>
En terme de composantes, on a donc :
</p>

<p>
\[\partial \varphi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \omega_i(\gamma) = 0\]
</p>

<p>
D'un autre coté, \(\gamma\) doit appartenir à \(\Omega\), où le terme de pénalité doit également s'annuler :
</p>

<p>
\[\lambda^\dual \cdot \omega(\gamma) = 0\]
</p>

<p>
On a donc :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \varphi(\gamma) + \lambda^\dual \cdot \omega(\gamma) = \varphi(\gamma) + 0 = \varphi(\gamma)\]
</p>

<p>
En terme de composantes, la condition d'annulation du terme de pénalité s'écrit :
</p>

<p>
\[\sum_i \lambda_i \cdot \omega_i(\gamma) = 0\]
</p>

<p>
Mais comme \(\lambda_i \ge 0\) et \(\omega_i(\gamma) \le 0\), on en déduit que \(\lambda_i \cdot \omega_i(\gamma) \le 0\). Que se passerait-il si on pouvait trouver un \(k\) tel que \(\lambda_k \cdot \omega_k(\gamma) \strictinferieur 0\) ? On aurait :
</p>

<p>
\[\sum_i \lambda_i \cdot \omega_i(\gamma) \le \lambda_k \cdot \omega_k(\gamma) \strictinferieur 0\]
</p>

<p>
ce qui est incompatible avec la condition d'annulation du terme de pénalité. On a donc :
</p>

<p>
\[\lambda_i^\dual \cdot \omega_i(\gamma) = 0\]
</p>

<p>
pour tout \(i \in \{1,2,...,m\}\). Les conditions :
</p>

<div class="org-center">
<p>
\(
\partial \varphi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \omega_i(\gamma) = 0 \\ \)
</p>

<p>
\(
\lambda_i^\dual \cdot \omega_i(\gamma) = 0 \\ \)
</p>

<p>
\(
\omega(\gamma) \le 0
\)
</p>
</div>

<p>
sont appellées conditions de Kuhn-Tucker.
</p>
</div>
</div>
<div id="outline-container-org70380e6" class="outline-2">
<h2 id="org70380e6"><span class="section-number-2">8.</span> Point de selle</h2>
<div class="outline-text-2" id="text-8">
<p>
Supposons que \((\gamma,\lambda) \in \Omega \times \mathcal{P}\) vérifie les conditions de Kuhn-Tucker. Choisissons \(x \in \setR^n\) et \(y \in \mathcal{P}\). L'annulation du gradient (\(\partial_x \lagrangien(\gamma,\lambda) = 0\)) et la convexité du lagrangien par rapport à la variable \(x\) nous assurent que :
</p>

<p>
\[\lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
D'un autre coté, on a \(\lambda^\dual \cdot \omega(\gamma) = 0\) et \(\lagrangien(\gamma,\lambda) = \varphi(\gamma)\). On sait aussi que \(y \ge 0\) et que \(\omega(\gamma) \le 0\). Donc \(y^\dual \cdot \omega(\gamma) \le 0\) et :
</p>

<p>
\[\lagrangien(\gamma,y) = \varphi(\gamma) + y^\dual \cdot \omega(\gamma) \le \varphi(\gamma) = \lagrangien(\gamma,\lambda)\]
</p>

<p>
On voit que \(\lambda\) maximise le lagrangien par rapport à la variable \(y\). Ces deux propriétés extrémales nous montrent que \((\gamma,\lambda)\) est un point de selle :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>
</div>
<div id="outline-container-org3a495d1" class="outline-3">
<h3 id="org3a495d1"><span class="section-number-3">8.1.</span> Réciproque</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Nous venons de voir que les conditions de Kuhn-Tucker remplies sur \(\Omega \times \mathcal{P}\) nous offraient un point de selle sur \(\setR^n \times \mathcal{P}\). Nous allons voir que la réciproque est également vraie. Supposons que \((\gamma,\lambda) \in \setR^n \times \mathcal{P}\) soit un point de selle du lagrangien :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,y) \in \setR^n \times \mathcal{P}\). On a :
</p>

<p>
\[\lagrangien(\gamma,y) - \lagrangien(\gamma,\lambda) = (y - \lambda)^\dual \cdot \omega(\gamma) \le 0\]
</p>

<p>
relation qui doit être valable pour tout \(y \ge 0\). Fixons \(i \in \{1,2,...,m\}\) et choisissons :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \)

\(
0 & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
on en déduit que \((y - \lambda)^\dual \cdot \omega(\gamma) = -\lambda_i \cdot \omega_i(\gamma) \le 0\), c'est-à-dire :
</p>

<p>
\[\lambda_i \cdot \omega_i(\gamma) \ge 0\]
</p>

<p>
Considérons à présent le choix :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \)

\(
2 \lambda_i & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
On en déduit alors que :
</p>

<p>
\[(y - \lambda)^\dual \cdot \omega(\gamma) = \lambda_i \cdot \omega_i(\gamma) \le 0\]
</p>

<p>
On conclut de ces deux inégalités que :
</p>

<p>
\[\lambda_i \cdot \omega_i(\gamma) = 0\]
</p>

<p>
Enfin, si nous prenons :
</p>

<div class="org-center">
<p>
\(
y<sub>k</sub> =
</p>
\begin{cases}
\lambda_k & \text{ si } k \ne i \)

\(
\lambda_i + 1 & \text{ si } k = i
\end{cases}
<p>
\)
</p>
</div>

<p>
on voit que :
</p>

<p>
\[(y - \lambda)^\dual \cdot \omega(\gamma) = 1 \cdot \omega_i(\gamma) = \omega_i(\gamma) \le 0\]
</p>

<p>
ce qui nous montre que \(\gamma \in \Omega\).
</p>

<p>
De plus, comme :
</p>

<p>
\[\gamma \in \arg\min_{x \in \setR^n} \lagrangien(x,\lambda)\]
</p>

<p>
les propriétés des fonctions dérivables nous imposent que \(\partial_x \lagrangien(\gamma,\lambda) = 0\).
</p>
</div>
</div>
</div>
<div id="outline-container-org6a96cae" class="outline-2">
<h2 id="org6a96cae"><span class="section-number-2">9.</span> Solution</h2>
<div class="outline-text-2" id="text-9">
<p>
Supposons que \((\gamma,\lambda)\) soit un point de selle du lagrangien. Choisissons \(x \in \Omega\). On a \(\omega(x) \le 0\) et \(\lambda^\dual \cdot \omega(x) \le 0\). On en déduit que :
</p>

<p>
\[\lagrangien(x,\lambda) = \varphi(x) + \lambda^\dual \cdot \omega(x) \le \varphi(x)\]
</p>

<p>
On a donc bien :
</p>

<p>
\[\varphi(\gamma) = \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda) \le \varphi(x)\]
</p>

<p>
ce qui prouve que \(\gamma\) minimise \(\varphi\) sur \(\Omega\). La solution du problème de point de selle du lagrangien contient donc la solution de notre problème de minimisation sous contrainte.
</p>
</div>
<div id="outline-container-org584800e" class="outline-3">
<h3 id="org584800e"><span class="section-number-3">9.1.</span> Généralisation</h3>
<div class="outline-text-3" id="text-9-1">
<p>
Remarquons que nous n'avons pas utilisé la convexité de \(\varphi\) ou de \(\omega\) pour démontrer que \(\gamma\) est bien la solution de notre problème. On peut donc appliquer la technique du point de selle du lagrangien à une classe de fonctions beaucoup plus générale.
</p>

<p>
Attention, si \(\varphi\) et/ou \(\omega\) ne sont plus supposées convexes, le point de selle impliquera toujours les conditions de Kuhn-Tucker mais l'inverse ne sera plus vrai. En pratique, on essaiera malgré tout de trouver une solution aux conditions de Kuhn-Tucker, et on déterminera a posteriori :
</p>

<ul class="org-ul">
<li>si le minimum trouvé est bien un minimum local (test de la Hessienne définie positive au \(\gamma\) obtenu)</li>
<li>si ce minimum local est aussi un minimum sur \(\Omega\)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0884d53" class="outline-2">
<h2 id="org0884d53"><span class="section-number-2">10.</span> Problème de maximisation sous contrainte</h2>
<div class="outline-text-2" id="text-10">
<p>
Soit les fonctions {\em concaves} et deux fois continument différentiables \(\vartheta_1,\vartheta_2,...,\vartheta_m : \setR^n \mapsto \setR\) et la fonction \(\vartheta : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\vartheta(x) = (\vartheta_1(x), \vartheta_2(x), ..., \vartheta_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Theta = \{ x \in \setR^n : \vartheta(x) \ge 0 \}\]
</p>

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Theta\) qui maximise la fonction concave et et deux fois continument différentiable \(\psi : \setR^n \mapsto \setR\) sur \(\Theta\) :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \psi(x)\]
</p>

<p>
On note que ce problème est équivalent au suivant :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} (-\psi(x))\]
</p>

<p>
où :
</p>

<p>
\[\Omega = \{ x \in \setR^n : -\vartheta(x) \le 0 \}\]
</p>
</div>
<div id="outline-container-org101a116" class="outline-3">
<h3 id="org101a116"><span class="section-number-3">10.1.</span> Lagrangien</h3>
<div class="outline-text-3" id="text-10-1">
<p>
On sait que maximiser \(\psi\) revient à minimiser \(-\psi\). Comme \(-\psi\) et \(-\vartheta\) sont convexes, on peut utiliser le lagrangien défini par :
</p>

<p>
\[\lagrangien_{\min}(x,y) = \Big[-\psi(x)\Big] + y^\dual \cdot \Big[-\vartheta(x)\Big] =  -\psi(x) - y^\dual \cdot \vartheta(x)\]
</p>

<p>
pour tout \((x,y) \in \setR^n \times \mathcal{P}\). La solution \((\gamma,\lambda)\) vérifie alors :
</p>

<p>
\[\lagrangien_{\min}(\gamma,y) \le \lagrangien_{\min}(\gamma,\lambda) \le \lagrangien_{\min}(x,\lambda)\]
</p>

<p>
On voit que la fonction opposée :
</p>

<p>
\[\lagrangien_{\max}(x,y) = - \lagrangien_{\min}(x,y) = \psi(x) + y^\dual \cdot \vartheta(x)\]
</p>

<p>
vérifie les conditions du point de selle inversées :
</p>

<p>
\[\lagrangien_{\max}(x,\lambda) \le \lagrangien_{\max}(\gamma,\lambda) \le \lagrangien_{\max}(\gamma,y)\]
</p>

<p>
Il s'agit du lagrangien natif du problème de maximisation. Il est maximisé par rapport à \(x\) et minimisé par rapport aux multiplicateurs de Lagrange.
</p>
</div>
</div>
<div id="outline-container-orgf50c4dd" class="outline-3">
<h3 id="orgf50c4dd"><span class="section-number-3">10.2.</span> Kuhn-Tucker</h3>
<div class="outline-text-3" id="text-10-2">
<p>
Les conditions de Kuhn-Tucker associées à \(\lagrangien_{\min}\) s'écrivent :
</p>

<div class="org-center">
<p>
\(
</p>
<ul class="org-ul">
<li>&part; &psi;(&gamma;) - &sum;<sub>i = 1</sub><sup>m</sup> &lambda;<sub>i</sub> &sdot; &part; &thetasym;<sub>i</sub>(&gamma;) = 0 \\ \)</li>
</ul>

<p>
\(
</p>
<ul class="org-ul">
<li>&lambda;<sub>i</sub>^\dual &sdot; &thetasym;<sub>i</sub>(&gamma;) = 0 \\ \)</li>
</ul>

<p>
\(
</p>
<ul class="org-ul">
<li>&thetasym;(&gamma;) &le; 0</li>
</ul>
<p>
\)
</p>
</div>

<p>
Elles sont équivalentes aux conditions analogues associées à \(\lagrangien_{\max}\) :
</p>

<div class="org-center">
<p>
\(
\partial \psi(\gamma) + \sum_{i = 1}^m \lambda_i \cdot \partial \vartheta_i(\gamma) = 0 \\ \)
</p>

<p>
\(
\lambda_i^\dual \cdot \vartheta_i(\gamma) = 0 \\ \)
</p>

<p>
\(
\vartheta(\gamma) \ge 0
\)
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga987389" class="outline-2">
<h2 id="orga987389"><span class="section-number-2">11.</span> Contraintes d'égalité</h2>
<div class="outline-text-2" id="text-11">
<p>
Soit les fonctions deux fois continument différentiables \(\varrho_1,\varrho_2,...,\varrho_m : \setR^n \mapsto \setR\) et la fonction \(\varrho : \setR^n \mapsto \setR^m\) définie par :
</p>

<p>
\[\varrho(x) = (\varrho_1(x), \varrho_2(x), ..., \varrho_m(x))\]
</p>

<p>
pour tout \(x \in \setR^n\). On considère l'ensemble associé :
</p>

<p>
\[\Phi = \{ x \in \setR^n : \varrho(x) = 0 \}\]
</p>

<p>
Nous considérons le problème général suivant : trouver un \(\gamma \in \Phi\) qui minimise la fonction deux fois continument différentiable \(\varphi : \setR^n \mapsto \setR\) sur \(\Phi\) :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Phi} \varphi(x)\]
</p>
</div>
<div id="outline-container-org8098af9" class="outline-3">
<h3 id="org8098af9"><span class="section-number-3">11.1.</span> Lagrangien</h3>
<div class="outline-text-3" id="text-11-1">
<p>
On peut réécrire l'ensemble \(\Phi\) sous la forme :
</p>

<p>
\[\Phi = \{ x \in \setR^n : \varrho(x) \le 0, \ \varrho(x) \ge 0 \}\]
</p>

<p>
On introduit donc deux séries de multiplicateurs et le lagrangien défini par :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \varrho(x) + z^\dual \cdot (-\varrho(x))\]
</p>

<p>
pour tout \((x,y,z) \in \setR^n \times \mathcal{P} \times \mathcal{P}\). On constate qu'il ne dépend que de \(x\) et de \(y - z\) :
</p>

<p>
\[L(x,y,z) = \varphi(x) + (y - z)^\dual \cdot \varrho(x)\]
</p>

<p>
On voit que \(u = y - z\) est libre d'aller où il veut dans \(\setR^m\). On pose :
</p>

<p>
\[\lagrangien(x,u) = \varphi(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,u) \in \setR^n \times \setR^m\).
</p>
</div>
</div>
<div id="outline-container-orgb02f7fd" class="outline-3">
<h3 id="orgb02f7fd"><span class="section-number-3">11.2.</span> Kuhn-Tucker</h3>
<div class="outline-text-3" id="text-11-2">
<p>
Comme on veut que \(\gamma\) minimise \(\lagrangien\) par rapport à la variable \(x\) sur \(\setR^n\), on impose \(\partial_x \lagrangien(\gamma,\lambda) = 0\). On doit avoir aussi \(\varrho(x) = 0\). Mais comme \(\partial_u \lagrangien(x,u) = \varrho(x)\), on se retrouve finalement avec les conditions nécessaires de Kuhn-Tucker :
</p>

<div class="org-center">
<p>
\(
\partial_x \lagrangien(\gamma,\lambda) = 0 \\ \)
</p>

<p>
\(
\partial_u \lagrangien(\gamma,\lambda) = 0
\)
</p>
</div>
</div>
</div>
<div id="outline-container-orgadf4929" class="outline-3">
<h3 id="orgadf4929"><span class="section-number-3">11.3.</span> Point de selle</h3>
<div class="outline-text-3" id="text-11-3">
<p>
Nous allons montrer que tout point de selle est solution du problème de minimisation. Soit \((\gamma,\lambda)\) tel que :
</p>

<p>
\[\lagrangien(\gamma,u) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,u) \in \setR^n \times \setR^m\). On en déduit que :
</p>

<p>
\[\lagrangien(\gamma,u) - \lagrangien(\gamma,\lambda) \le 0\]
</p>

<p>
pour tout \(u \in \setR^m\), c'est-à-dire :
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) \le 0\]
</p>

<p>
Considérons la base canonique \((\canonique_1,...,\canonique_m)\) de \(\setR^m\). Si on prend \(u = \lambda + \canonique_i\), on obtient la condition
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) = \varrho_i(\gamma) \le 0\]
</p>

<p>
Mais comme \(u\) n'est pas forcément positif, on peut aussi prendre \(u = \lambda - \canonique_i\). On obtient alors la condition :
</p>

<p>
\[(u - \lambda)^\dual \cdot \varrho(\gamma) = -\varrho_i(\gamma) \le 0\]
</p>

<p>
On déduit de ces deux inégalités que \(\varrho(\gamma) = 0\), c'est à dire \(\gamma \in \Phi\).
</p>

<p>
A présent, soit \(x \in \Phi\). Comme \(\varrho(\gamma) = \varrho(x) = 0\), on a :
</p>

<p>
\[\varphi(\gamma) = \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda) = \varphi(x)\]
</p>

<p>
Le \(\gamma\) issu du point de selle est donc bien la solution de notre problème de minimisation contraint.
</p>
</div>
</div>
</div>
<div id="outline-container-orgeb8e8c2" class="outline-2">
<h2 id="orgeb8e8c2"><span class="section-number-2">12.</span> Récapitulation</h2>
<div class="outline-text-2" id="text-12">
<p>
Considérons l'ensemble :
</p>

<p>
\[\Omega = \{ x \in \setR^n : \omega(x) \le 0, \ \vartheta(x) \ge 0, \ \varrho(x) = 0 \}\]
</p>
</div>
<div id="outline-container-orge152c40" class="outline-3">
<h3 id="orge152c40"><span class="section-number-3">12.1.</span> Minimisation</h3>
<div class="outline-text-3" id="text-12-1">
<p>
Si on veut minimiser \(\varphi\) sur \(\Omega\), on utilisera le lagrangien défini par :
</p>

<p>
\[\lagrangien(x,y,z,u) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot \vartheta(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,y,z,u)\) tels que \(y,z \ge 0\). Le point de selle \((\gamma,\lambda,\mu,\nu)\) vérifiera :
</p>

<p>
\[\lagrangien(\gamma,y,z,u) \le \lagrangien(\gamma,\lambda,\mu,\nu) \le \lagrangien(x,\lambda,\mu,\nu)\]
</p>

<p>
Les conditions de Kuhn-Tucker s'écriront :
</p>

<div class="org-center">
<p>
\(
\partial \varphi(\gamma) + \sum_i \left[ \lambda_i \cdot \partial \omega_i(x) - \mu_i \cdot \partial \vartheta_i(x) + \nu_i \cdot \partial \varrho_i(x) \right] = 0 \\ \)
</p>

<p>
\(
\lambda_i \cdot \omega_i(x) = 0 \\ \)
</p>

<p>
\(
\mu_i \cdot \vartheta_i(x) = 0 \\ \)
</p>

<p>
\(
\omega_i(x) \le 0 \\ \)
</p>

<p>
\(
\vartheta_i(x) \ge 0 \\ \)
</p>

<p>
\(
\varrho_i(x) = 0
\)
</p>
</div>
</div>
</div>
<div id="outline-container-orgf3a23bf" class="outline-3">
<h3 id="orgf3a23bf"><span class="section-number-3">12.2.</span> Maximisation</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Si on veut maximiser \(\psi\) sur \(\Omega\), on utilisera le lagrangien défini par :
</p>

<p>
\[\lagrangien(x,y,z,u) = \psi(x) - y^\dual \cdot \omega(x) + z^\dual \cdot \vartheta(x) + u^\dual \cdot \varrho(x)\]
</p>

<p>
pour tout \((x,y,z,u)\) tels que \(y,z \ge 0\). Le point de selle \((\gamma,\lambda,\mu,\nu)\) vérifiera :
</p>

<p>
\[\lagrangien(x,\lambda,\mu,\nu) \le \lagrangien(\gamma,\lambda,\mu,\nu) \le \lagrangien(\gamma,y,z,u)\]
</p>

<p>
Les conditions de Kuhn-Tucker s'écriront :
</p>

<div class="org-center">
<p>
\(
\partial \psi(\gamma) + \sum_i \left[ -\lambda_i \cdot \partial \omega_i(x) + \mu_i \cdot \partial \vartheta_i(x) + \nu_i \cdot \partial \varrho_i(x) \right] = 0 \\ \)
</p>

<p>
\(
\lambda_i \cdot \omega_i(x) = 0 \\ \)
</p>

<p>
\(
\mu_i \cdot \vartheta_i(x) = 0 \\ \)
</p>

<p>
\(
\omega_i(x) \le 0 \\ \)
</p>

<p>
\(
\vartheta_i(x) \ge 0 \\ \)
</p>

<p>
\(
\varrho_i(x) = 0
\)
</p>
</div>
</div>
</div>
<div id="outline-container-orga80b591" class="outline-3">
<h3 id="orga80b591"><span class="section-number-3">12.3.</span> Equivalence</h3>
<div class="outline-text-3" id="text-12-3">
<p>
On exprime parfois ces problèmes en utilisant des contraintes équivalentes. Si on pose \(s = - \omega(x)\), on a \(s \ge 0\). De même, on pose \(t = \vartheta(x) \ge 0\). On définit alors \(\Gamma\) comme l'ensemble des \((x,s,t)\) vérifiant les conditions :
</p>

\begin{align}
s,t &\ge 0 \)

\(
s + \omega(x) &= 0 \)

\(
t - \vartheta(x) &= 0 \)

\(
\varrho(x) &= 0
\end{align}

<p>
Et on minimise \(\varphi(x)\) (ou on maximise \(\psi(x)\)) sur les \((x,s,t) \in \Gamma\).
</p>
</div>
</div>
</div>
<div id="outline-container-org7bd1e6d" class="outline-2">
<h2 id="org7bd1e6d"><span class="section-number-2">13.</span> Découplage</h2>
<div class="outline-text-2" id="text-13">
</div>
<div id="outline-container-org963b471" class="outline-3">
<h3 id="org963b471"><span class="section-number-3">13.1.</span> Minimisation</h3>
<div class="outline-text-3" id="text-13-1">
<p>
Soit le problème de minimisation :
</p>

<p>
\[\gamma \in \arg\min_{x \in \Omega} \varphi(x)\]
</p>

<p>
où :
</p>

<p>
\[\Omega^+ = \{ x \in \corps^n : \omega(x) \le 0, \ x \ge 0 \}\]
</p>

<p>
La condition \(x \ge 0\) est équivalente à \(-x \le 0\). On définit le lagrangien :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot x\]
</p>

<p>
La solution de notre problème vérifie les conditions du point de selle :
</p>

<p>
\[L(\gamma,y,z) \le L(\gamma,\lambda,\mu) \le L(x,\lambda,\mu)\]
</p>

<p>
pour tout \(x \in \setR^n\) et \(y,z \ge 0\). Si \(x \ge 0\), on a :
</p>

<p>
\[-z^\dual \cdot x \le 0\]
</p>

<p>
par positivité de \(z\). On a alors :
</p>

<p>
\[L(x,y,z) = \varphi(x) + y^\dual \cdot \omega(x) - z^\dual \cdot x \le \varphi(x) + y^\dual \cdot \omega(x) = L(x,y,0)\]
</p>

<p>
On en conclut qu'un choix permettant de maximiser \(L\) par rapport à son troisième argument est \(\mu = 0\). Introduisons le lagrangien modifié :
</p>

<p>
\[\lagrangien(x,y) = L(x,y,0) = \varphi(x) + y^\dual \cdot \omega(x)\]
</p>

<p>
Le problème du point de selle est équivalent à trouver \((\gamma,\lambda) \ge 0\) tel que :
</p>

<p>
\[\lagrangien(\gamma,y) \le \lagrangien(\gamma,\lambda) \le \lagrangien(x,\lambda)\]
</p>

<p>
pour tout \((x,y) \ge 0\). La différence est qu'on ne fait plus apparaître explicitement la contrainte de positivité de \(x\) dans le lagrangien.
</p>
</div>
</div>
<div id="outline-container-orgf365d51" class="outline-3">
<h3 id="orgf365d51"><span class="section-number-3">13.2.</span> Maximisation</h3>
<div class="outline-text-3" id="text-13-2">
<p>
Soit le problème de minimisation :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \psi(x)\]
</p>

<p>
où :
</p>

<p>
\[\Theta = \{ x \in \corps^n : \vartheta(x) \ge 0, \ x \ge 0 \}\]
</p>

<p>
On pose le lagrangien :
</p>

<p>
\[L(x,y,z) = \psi(x) + y^\dual \cdot \omega(x) + z^\dual \cdot x\]
</p>

<p>
La solution de notre problème vérifie les conditions du point de selle inversé :
</p>

<p>
\[L(x,\lambda,\mu) \le L(\gamma,\lambda,\mu) \le L(\gamma,y,z)\]
</p>

<p>
pour tout \(x \in \setR^n\) et \(y,z \ge 0\). Si \(x \ge 0\), on a :
</p>

<p>
\[z^\dual \cdot x \ge 0\]
</p>

<p>
par positivité de \(z\). On a alors :
</p>

<p>
\[L(x,y,z) \ge L(x,y,0)\]
</p>

<p>
On en conclut qu'un choix permettant de minimiser \(L\) par rapport à son troisième argument est \(\mu = 0\). Introduisons le lagrangien modifié :
</p>

<p>
\[\lagrangien(x,y) = L(x,y,0) = \psi(x) + y^\dual \cdot \vartheta(x)\]
</p>

<p>
Le problème du point de selle est équivalent à trouver \((\gamma,\lambda) \ge 0\) tel que :
</p>

<p>
\[\lagrangien(x,\lambda) \le \lagrangien(\gamma,\lambda) \le \lagrangien(\gamma,y)\]
</p>

<p>
pour tout \((x,y) \ge 0\).
</p>
</div>
</div>
</div>
<div id="outline-container-org3eb021f" class="outline-2">
<h2 id="org3eb021f"><span class="section-number-2">14.</span> Dualité en optimisation linéaire</h2>
<div class="outline-text-2" id="text-14">
</div>
<div id="outline-container-org799391c" class="outline-3">
<h3 id="org799391c"><span class="section-number-3">14.1.</span> Problème primal</h3>
<div class="outline-text-3" id="text-14-1">
<p>
Soit une matrice réelle \(A\) de taille \((m,n)\), l'ensemble :
</p>

<p>
\[\Theta = \{ x \in \setR^n : A \cdot x \le b, \ x \ge 0 \}\]
</p>

<p>
et le vecteur \(c \in \setR^n\). Nous nous intéressons au problème de maximisation linéaire sous contrainte :
</p>

<p>
\[\gamma \in \arg\max_{x \in \Theta} \big[ c^\dual \cdot x \big]\]
</p>
</div>
</div>
<div id="outline-container-org7059960" class="outline-3">
<h3 id="org7059960"><span class="section-number-3">14.2.</span> Lagrangien</h3>
<div class="outline-text-3" id="text-14-2">
<p>
La contrainte \(A \cdot x \le b\) est équivalente à :
</p>

<p>
\[b - A \cdot x \ge 0\]
</p>

<p>
On introduit donc le lagrangien :
</p>

\begin{align}
\lagrangien(x,y) &= c^\dual \cdot x + y^\dual \cdot (b - A \cdot x) \)

\(
&= c^\dual \cdot x + y^\dual \cdot b - y^\dual \cdot A \cdot x
\end{align}

<p>
défini pour tout \((x,y) \ge 0\).
</p>
</div>
</div>
<div id="outline-container-orgce8c0d9" class="outline-3">
<h3 id="orgce8c0d9"><span class="section-number-3">14.3.</span> Dualité</h3>
<div class="outline-text-3" id="text-14-3">
<p>
Comme on travaille dans les réels, on a par symétrie du produit scalaire :
</p>

\begin{align}
c^\dual \cdot x &= x^\dual \cdot c \)

\(
y^\dual \cdot b &= b^\dual \cdot y \)

\(
y^\dual \cdot A \cdot x &= (A \cdot x)^\dual \cdot y = x^\dual \cdot A^\dual \cdot y
\end{align}

<p>
Le lagrangien du problème primal peut donc se réécrire :
</p>

\begin{align}
\lagrangien(x,y) &= x^\dual \cdot c + b^\dual \cdot y - x^\dual \cdot A^\dual \cdot y \)

\(
&= b^\dual \cdot y + x^\dual \cdot (c - A^\dual \cdot y)
\end{align}

<p>
On voit que la fonction duale définie par :
</p>

<p>
\[\lagrangien^\dual(y,x) = \lagrangien(x,y) = b^\dual \cdot y + x^\dual \cdot (c - A^\dual \cdot y)\]
</p>

<p>
pour tout \((y,x) \ge 0\) peut également être considérée comme un lagrangien formé à partir de l'objectif \(y \mapsto b^\dual \cdot y\) et d'une des deux contraintes suivantes :
</p>

<div class="org-center">
<p>
\(
?
</p>
\begin{cases}
c - A^\dual \cdot y \le 0 \)

\(
c - A^\dual \cdot y \ge 0
\end{cases}
<p>
\)
</p>
</div>

<p>
Résoudre le problème primal revient à trouver un point \((\gamma,\lambda) \ge 0\) vérifiant :
</p>

<p>
\[\lagrangien(x,\lambda) \le \lagrangien(\gamma,\lambda) \le \lagrangien(\gamma,y)\]
</p>

<p>
pour tout \(x,y \ge 0\). En utilisant la définition de \(\lagrangien^\dual\), ces conditions se réécrivent :
</p>

<p>
\[\lagrangien^\dual(\lambda,x) \le \lagrangien^\dual(\lambda,\gamma) \le \lagrangien^\dual(y,\gamma)\]
</p>

<p>
Le couple \((\lambda,\gamma)\) est donc solution d'un problème de minimisation en \(y\). Dans un problème de minimisation, les contraintes associées aux multiplicateurs de lagrange doivent être négatives. On a donc \(c - A^\dual \cdot y \le 0\), autrement dit :
</p>

<p>
\[A^\dual \cdot y \ge c\]
</p>

<p>
Le problème primal est donc équivalent au problème dual suivant.
</p>
</div>
</div>
<div id="outline-container-orge16ae03" class="outline-3">
<h3 id="orge16ae03"><span class="section-number-3">14.4.</span> Problème dual</h3>
<div class="outline-text-3" id="text-14-4">
<p>
Trouver :
</p>

<p>
\[\lambda \in \arg\min_{y \in \Omega} (b^\dual \cdot y)\]
</p>

<p>
où :
</p>

<p>
\[\Omega = \{ y \in \setR^m : A^\dual \cdot y \ge c, \ y \ge 0 \}\]
</p>
</div>
</div>
<div id="outline-container-orgf4db76e" class="outline-3">
<h3 id="orgf4db76e"><span class="section-number-3">14.5.</span> Valeurs extrémales</h3>
<div class="outline-text-3" id="text-14-5">
<p>
Les conditions de Khun-Tucker des problèmes primal et dual impliquent :
</p>

<div class="org-center">
<p>
\(
\lambda^\dual \cdot (b - A \cdot \gamma) = 0 \\ \)
</p>

<p>
\(
\gamma^\dual \cdot (c - A^\dual \cdot \lambda) = 0
\)
</p>
</div>

<p>
Les valeurs des lagrangiens aux points de selle s'écrivent donc :
</p>

<div class="org-center">
<p>
\(
\lagrangien(\gamma,\lambda) = c^\dual \cdot \gamma + \lambda^\dual \cdot (b - A \cdot \gamma) = c^\dual \cdot \gamma \\ \)
</p>

<p>
\(
\lagrangien^\dual(\lambda,\gamma) = b^\dual \cdot \lambda + \gamma^\dual \cdot (c - A^\dual \cdot \lambda) = b^\dual \cdot \lambda
\)
</p>
</div>

<p>
La définition du lagrangien dual implique que :
</p>

<p>
\[\lagrangien(\gamma,\lambda) = \lagrangien^\dual(\lambda,\gamma)\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[c^\dual \cdot \gamma = b^\dual \cdot \lambda\]
</p>

<p>
Le maximum de \(x \mapsto c^\dual \cdot x\) sur \(\Theta\) est donc égal au minimum de \(y \mapsto b^\dual \cdot y\) sur \(\Omega\). Dans la suite, on note :
</p>

<p>
\[V = \max_{x \in \Theta} (c^\dual \cdot x) = \min_{y \in \Omega} (b^\dual \cdot y)\]
</p>
</div>
</div>
<div id="outline-container-org8535bda" class="outline-3">
<h3 id="org8535bda"><span class="section-number-3">14.6.</span> Bornes</h3>
<div class="outline-text-3" id="text-14-6">
<p>
Par définition des maxima et minima, on a :
</p>

<p>
\[c^\dual \cdot x \le V \le b^\dual \cdot y\]
</p>

<p>
pour tout \(x \in \Theta\) et \(y \in \Omega\). Si les deux valeurs \(c^\dual \cdot x\) et \(b^\dual \cdot y\) sont proches, les éléments \(x\) et \(y\) sont presque optimaux.
</p>
</div>
</div>
<div id="outline-container-org8489103" class="outline-3">
<h3 id="org8489103"><span class="section-number-3">14.7.</span> Attention</h3>
<div class="outline-text-3" id="text-14-7">
<p>
Ne pas confondre la notion de dualité \(\max - \min\) avec la dualité au sens des applications linéaires.
</p>
</div>
</div>
</div>
<div id="outline-container-org195c15a" class="outline-2">
<h2 id="org195c15a"><span class="section-number-2">15.</span> Minimisation de la norme sous contraintes linéaires</h2>
<div class="outline-text-2" id="text-15">
<p>
Soit la matrice \(A \in \matrice(\setR,m,n)\), le vecteur colonne \(b \in \matrice(\setR,m,1)\) et l'ensemble :
</p>

<p>
\[\Phi = \{ x \in \matrice(\setR,n,1) : A \cdot x = b \}\]
</p>

<p>
On veut trouver le \(\gamma \in \Phi\) qui minimise la norme usuelle \(\norme{x} = \sqrt{x^\dual \cdot x}\) sur \(\Phi\). Comme la fonction $\norme{x} \mapsto \norme{x}<sup>2</sup> /2 $ est une fonction monotone strictement croissante sur \(\norme{x} \in \setR^+\), cela revient à minimiser :
</p>

<p>
\[\gamma = \arg\min_{x \in \Phi} \left( \unsur{2} \cdot x^\dual \cdot x \right)\]
</p>

<p>
Afin de résoudre ce problème, on introduit le lagrangien :
</p>

<p>
\[\lagrangien(x,u) = \unsur{2} \cdot x^\dual \cdot x + u^\dual \cdot (b - A \cdot x)\]
</p>

<p>
On impose les conditions de Kuhn-Tucker :
</p>

<div class="org-center">
<p>
\(
\partial_x \lagrangien(\gamma,\lambda) = \gamma - A^\dual \cdot \lambda = 0 \\ \)
</p>

<p>
\(
\partial_u \lagrangien(\gamma,\lambda) = b - A \cdot \gamma = 0
\)
</p>
</div>

<p>
On en déduit que \(\gamma = A^\dual \cdot \lambda\) et que :
</p>

<p>
\[A \cdot A^\dual \cdot \lambda = b\]
</p>

<p>
Si \(A \cdot A^\dual\) est inversible, on a donc :
</p>

<p>
\[\lambda = \left( A \cdot A^\dual \right)^{-1} \cdot b\]
</p>

<p>
et :
</p>

<p>
\[\gamma = A^\dual \cdot \left( A \cdot A^\dual \right)^{-1} \cdot b\]
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-11-30 dim 13:45</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
