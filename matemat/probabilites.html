<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-12-30 mar 11:27 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat : Probabilités</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat : Probabilités</h1>
<p>
<a href="index.html">Index mathématique</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgf59ecd0">1. Probabilité</a></li>
<li><a href="#orga0eee47">2. Variable aléatoire</a></li>
<li><a href="#org4e59f3c">3. Mesure induite</a></li>
<li><a href="#orga8dbf36">4. Collection induite</a></li>
<li><a href="#org0491f6f">5. Espérance</a></li>
<li><a href="#orgc2875a9">6. Espérance et mesure induite</a></li>
<li><a href="#org2ff0b69">7. Fonction génératrice des moments</a></li>
<li><a href="#orgc421449">8. Variance</a></li>
<li><a href="#orgc700691">9. Covariance</a></li>
<li><a href="#org63e5f4b">10. Variance d'une combinaison linéaire</a></li>
<li><a href="#org69eaacc">11. Produit scalaire</a></li>
<li><a href="#org4367b9b">12. Probabilité conditionnelle</a></li>
<li><a href="#org5ffabcc">13. Espérance conditionnelle à un ensemble</a></li>
<li><a href="#orgacb831c">14. Espérance conditionnelle à une tribu</a></li>
<li><a href="#org00b7616">15. Ensemble discret</a></li>
</ul>
</div>
</div>

<script>
MathJax = {
  tex: {
    packages: {'[+]': ['base','ams','braket']},
    macros: {
      parentheses: ["\\left(#1\\right)", 1],
      crochets: ["\\left[#1\\right]", 1],
      accolades: ["\\left\\{#1\\right\\}", 1],
      ensemble: ["\\left\\{#1\\right\\}", 1],
      cardinal: ["\\mathop{\\mathrm{card}\\ }\\limits",0],
      identite: "\\mathrm{Id}",
      indicatrice: "\\boldsymbol{\\delta}",
      dirac: "\\delta",
      moinsun: "-1",
      inverse: "\\ddagger",
      pinverse: "\\dagger",
      topologie: "\\mathfrak{T}",
      ferme: "\\mathfrak{F}",
      img: "\\mathbf{i}",
      binome: ["\\left\\{ \\begin{array}{c} #1 \\\\ #2 \\\\ \\end{array} \\right\\}", 2],
      canonique: "\\mathfrak{c}",
      tenseuridentite: "\\boldsymbol{\\mathcal{I}}",
      permutation: "\\boldsymbol{\\epsilon}",
      matriceZero: "\\mathfrak{0}",
      matriceUn: "\\mathfrak{1}",
      christoffel: ["\\left\\{ \\begin{array}{c} #1 \\\\ #2 \\\\ \\end{array} \\right\\}", 2],
      lagrangien: "\\mathfrak{L}",
      sousens: "\\mathfrak{P}",
      partition: "\\mathrm{Partition}",
      tribu: "\\mathrm{Tribu}",
      topologies: "\\mathrm{Topo}",
      setB: "\\mathbb{B}",
      setN: "\\mathbb{N}",
      setZ: "\\mathbb{Z}",
      setQ: "\\mathbb{Q}",
      setR: "\\mathbb{R}",
      setC: "\\mathbb{C}",
      corps: "\\mathbb{K}",
      boule: "\\mathfrak{B}",
      intervalleouvert: ["\\left] #1 , #2 \\right[", 2],
      intervallesemiouvertgauche: ["\\left] #1 , #2 \\right]", 2],
      intervallesemiouvertdroite: ["\\left[ #1 , #2 \\right[", 2],
      fonction: "\\mathbb{F}",
      bijection: "\\mathrm{Bij}",
      polynome: "\\mathrm{Poly}",
      lineaire: "\\mathrm{Lin}",
      continue: "\\mathrm{Cont}",
      homeomorphisme: "\\mathrm{Hom}",
      etagee: "\\mathrm{Etagee}",
      lebesgue: "\\mathrm{Leb}",
      lipschitz: "\\mathrm{Lip}",
      suitek: "\\mathrm{Suite}",
      matrice: "\\mathbb{M}",
      krylov: "\\mathrm{Krylov}",
      tenseur: "\\mathbb{T}",
      essentiel: "\\mathfrak{E}",
      relation: "\\mathrm{Rel}",
      strictinferieur: "<",
      strictsuperieur: ">",
      ensinferieur: "\\eqslantless",
      enssuperieur: "\\eqslantgtr",
      esssuperieur: "\\gtrsim",
      essinferieur: "\\lesssim",
      essegal: "\\eqsim",
      union: "\\cup",
      intersection: "\\cap",
      opera: "\\divideontimes",
      autreaddition: "\\boxplus",
      autremultiplication: "\\circledast",
      commutateur: ["\\left[ #1 , #2 \\right]", 2],
      convolution: "\\circledcirc",
      correlation: "\\natural",
      diventiere: "\\div",
      modulo: "\\bmod",
      pgcd: ["\\mathop{\\mathrm{pgcd}\\ }\\limits",0],
      ppcm: ["\\mathop{\\mathrm{ppcm}\\ }\\limits",0],
      produitscalaire: ["\\left\\langle #1 \\vert #2 \\right\\rangle", 2],
      scalaire: ["\\left\\langle #1 \\| #2 \\right\\rangle", 2],
      braket: ["\\left\\langle #1 \\vert #2 \\vert #3 \\right\\rangle", 3],
      orthogonal: "\\bot",
      forme: ["\\left\\langle #1 , #2 \\right\\rangle", 2],
      biforme: ["\\left\\langle #1 , #2 , #3 \\right\\rangle", 3],
      contraction: ["\\left\\langle #1 \\odot #3 \\right\\rangle_{#2}", 3],
      dblecont: ["\\left\\langle #1 \\vert #3 \\vert #5 \\right\\rangle_{#2,#4}", 5],
      major: ["\\mathop{\\mathrm{major}\\ }\\limits",0],
      minor: ["\\mathop{\\mathrm{minor}\\ }\\limits",0],
      maxim: ["\\mathop{\\mathrm{maxim}\\ }\\limits",0],
      minim: ["\\mathop{\\mathrm{minim}\\ }\\limits",0],
      argument: ["\\mathop{\\mathrm{arg}\\ }\\limits",0],
      argmin: ["\\mathop{\\mathrm{arg\\,min}\\ }\\limits",0],
      argmax: ["\\mathop{\\mathrm{arg\\,max}\\ }\\limits",0],
      supessentiel: ["\\mathop{\\mathrm{ess\\,sup}\\ }\\limits",0],
      infessentiel: ["\\mathop{\\mathrm{ess\\,inf}\\ }\\limits",0],
      dual: "\\star",
      vardual: "\\circledast",
      distance: "\\mathfrak{dist}",
      norme: ["\\left\\lVert #1 \\right\\rVert", 1],
      normetrois: ["\\left|\\left\\| #1 \\right\\|\\right|", 1],
      adh: ["\\mathop{\\mathrm{adh}\\ }\\limits",0],
      interieur: ["\\mathop{\\mathrm{int}\\ }\\limits",0],
      frontiere: "\\partial",
      image: ["\\mathop{\\mathrm{im}\\ }\\limits",0],
      domaine: ["\\mathop{\\mathrm{dom}\\ }\\limits",0],
      noyau: ["\\mathop{\\mathrm{ker}\\ }\\limits",0],
      support: ["\\mathop{\\mathrm{supp}\\ }\\limits",0],
      signe: ["\\mathop{\\mathrm{sign}\\ }\\limits",0],
      abs: ["\\left\\lvert #1 \\right\\rvert", 1],
      unsur: ["\\frac{1}{#1}", 1],
      arrondisup: ["\\lceil #1 \\rceil", 1],
      arrondiinf: ["\\lfloor #1 \\rfloor", 1],
      conjugue: "\\mathrm{conj\\ }",
      conjaccent: ["\\overline{#1}", 1],
      division: "division",
      difference: "\\boldsymbol{\\Delta}",
      differentielle: ["\\mathfrak{D}^{#1}_{#2}", 2],
      OD: ["\\frac{d #1}{d #2}", 2],
      OOD: ["\\frac{d^2 #1}{d #2^2}", 2],
      NOD: ["\\frac{d^{#3} #1}{d #2^{#3}}", 3],
      deriveepartielle: ["\\frac{\\partial #1}{\\partial #2}", 2],
      PD: ["\\frac{\\partial #1}{\\partial #2}", 2],
      dblederiveepartielle: ["\\frac{\\partial^2 #1}{\\partial #2 \\partial #2}", 2],
      dfdxdy: ["\\frac{\\partial^2 #1}{\\partial #2 \\partial #3}", 3],
      dfdxdx: ["\\frac{\\partial^2 #1}{\\partial #2^2}", 2],
      gradient: "\\mathbf{\\nabla}",
      combilin: ["\\mathrm{span}\\{ #1 \\}", 1],
      trace: "tr",
      proba: "\\mathbb{P}",
      probaof: ["\\mathbb{P}\\left[#1\\right]", 1],
      esperof: ["\\mathbb{E}\\left[#1\\right]", 1],
      cov: ["\\mathrm{cov} ( #1 , #2 )", 2],
      var: ["\\mathrm{var} ( #1 )", 1],
      rand: "\\mathrm{rand}",
      variation: ["\\left\\langle #1 \\right\\rangle", 1],
      composante: ["\\mathop{\\mathrm{comp}\\ }\\limits",0],
      bloc: ["\\mathop{\\mathrm{bloc}\\ }\\limits",0],
      ligne: ["\\mathop{\\mathrm{ligne}\\ }\\limits",0],
      colonne: ["\\mathop{\\mathrm{colonne}\\ }\\limits",0],
      diagonale: ["\\mathop{\\mathrm{diag}\\ }\\limits",0],
      matelementaire: "\\mathrm{Elem}",
      matpermutation: ["\\mathop{\\mathrm{permut}\\ }\\limits",0],
      matunitaire: "\\mathrm{Unitaire}",
      gaussjordan: "\\mathrm{GaussJordan}",
      householder: "\\mathrm{Householder}",
      rang: "rang",
      schur: "\\mathrm{Schur}",
      singuliere: "\\mathrm{DVS}",
      convexe: "\\mathrm{Convexe}",
      petito: ["o(#1)", 1],
      grando: ["O(#1)", 1]
    }
  }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<p>
\(
\renewenvironment{Eqts}
{ \begin{equation*} \begin{gathered} }
{ \end{gathered} \end{equation*} }
\renewenvironment{Matrix}
{\left[ \begin{array}}
{\end{array} \right]}
\)
</p>

<p>
\label{chap:proba}
</p>
<div id="outline-container-orgf59ecd0" class="outline-2">
<h2 id="orgf59ecd0"><span class="section-number-2">1.</span> Probabilité</h2>
<div class="outline-text-2" id="text-1">
<p>
Une probabilité \(\proba\) sur un ensemble d'événements \(\Omega\) est une mesure définie sur \(\mathcal{S}=\{ A : A \subseteq \Omega \}\) et à valeurs dans \([0,1]\) :
</p>

<p>
\[\proba : \mathcal{S} \mapsto [0,1] \quad\]
</p>

<p>
Cette probabilité doit vérifier la normalisation :
</p>

<p>
\[\probaof{\Omega} = 1\]
</p>

<p>
ainsi que l'additivité :
</p>

<p>
\[\probaof{\bigcup_i \Phi_i} = \sum_i \probaof{\Phi_i}\]
</p>

<p>
lorsque les ensembles \(\Phi_i\) sont disjoints deux à deux :
</p>

<div class="org-center">
<p>
\(
&Phi;<sub>i</sub> &cap; &Phi;<sub>j</sub> =
</p>
\begin{cases}
\Phi_i & i = j \)

\(
\emptyset & i \ne j
\end{cases}
<p>
\)
</p>
</div>

<p>
On en déduit directement que :
</p>

<p>
\[\probaof{\Phi} = \probaof{\Phi \cup \emptyset} = \probaof{\Phi} + \probaof{\emptyset}\]
</p>

<p>
d'où \(\probaof{\emptyset} = 0\).
</p>

<p>
La grandeur \(\probaof{\Phi}\) peut s'interpréter comme la probabilité que l'un des événements de \(\Phi\) se réalise.
</p>
</div>
</div>
<div id="outline-container-orga0eee47" class="outline-2">
<h2 id="orga0eee47"><span class="section-number-2">2.</span> Variable aléatoire</h2>
<div class="outline-text-2" id="text-2">
<p>
Une variable aléatoire \(X\) associe une valeur réelle a chaque élément de \(\Omega\). On a donc \(X : \Omega \mapsto \setR\).
</p>
</div>
</div>
<div id="outline-container-org4e59f3c" class="outline-2">
<h2 id="org4e59f3c"><span class="section-number-2">3.</span> Mesure induite</h2>
<div class="outline-text-2" id="text-3">
<p>
Etant donné une variable aléatoire \(X\), on peut définir une mesure induite \(\mathcal{L}_X : \sousens(\setR) \mapsto [0,1]\), qui exprime la probabilité qu'un événement \(\omega \in \Omega\) donne une valeur appartenant à un sous-ensemble \(U \subseteq \setR\) :
</p>

<p>
\[\mathcal{L}_X(U) = \probaof{X^{-1}(U)} = \probaof{ \{ \omega\in\Omega : X(\omega) \in U \} }\]
</p>
</div>
<div id="outline-container-orgd2263fc" class="outline-3">
<h3 id="orgd2263fc"><span class="section-number-3">3.1.</span> Variables conjointes</h3>
<div class="outline-text-3" id="text-3-1">
<p>
La mesure induite par deux variables aléatoires \(X\) et \(Y\) se définit par :
</p>

<p>
\[\mathcal{L}_{X,Y}(D) = \probaof{ \{ \omega\in\Omega : (X(\omega),Y(\omega)) \in D \} }\]
</p>

<p>
pour tout \(D \subseteq\setR^2\).
</p>

<p>
On voit clairement que :
</p>

<div class="org-center">
<p>
\(
\mathcal{L}_X(U) = \mathcal{L}_{X,Y}(U \times \setR) \)
</p>

<p>
\(
\mathcal{L}_Y(U) = \mathcal{L}_{X,Y}(\setR \times U)
\)
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga8dbf36" class="outline-2">
<h2 id="orga8dbf36"><span class="section-number-2">4.</span> Collection induite</h2>
<div class="outline-text-2" id="text-4">
<p>
Soit \(X\) une variable aléatoire et \(U \subseteq \setR\). On définit le sous-ensemble de \(\Omega\) :
</p>

<p>
\[\Theta(X,U) = \{ \omega \in \Omega : X(\omega) \in U \}\]
</p>

<p>
ou de manière équivalente en utilisant la relation inverse \(X^{-1}\) :
</p>

<p>
\[\Theta(X,U) = X^{-1}(U)\]
</p>

<p>
La collection \(\Lambda(X)\) induite par \(X\) est un ensemble regroupant les \(\Theta(X,U)\) pour tous les sous-ensembles de \(\setR\) :
</p>

<p>
\[\Lambda(X) = \{ \Theta(X,U) : U \subseteq \setR \}\]
</p>

<p>
Comme :
</p>

<div class="org-center">
<p>
\(
\Theta(X,\emptyset) = \emptyset \)
</p>

<p>
\(
\Theta(X,\setR) = \Omega
\)
</p>
</div>

<p>
il est clair que l'on a \(\emptyset, \Omega \in \Lambda(X)\) quelle que soit la variable aléatoire \(X\).
</p>
</div>
<div id="outline-container-org033a212" class="outline-3">
<h3 id="org033a212"><span class="section-number-3">4.1.</span> Fonctions indicatrices</h3>
<div class="outline-text-3" id="text-4-1">
<p>
Si \(\Phi \subseteq \Omega\) et \(X = \indicatrice_\Phi\), on a :
</p>

<div class="org-center">
<p>
\(
\Theta(\indicatrice_\Phi, \{1\}) = \{ \omega : \indicatrice_\Phi(\omega) = 1 \} = \Phi \)
</p>

<p>
\(
\Theta(\indicatrice_\Phi, \{0\}) = \{ \omega : \indicatrice_\Phi(\omega) = 0 \} = \Omega \setminus \Phi
\)
</p>
</div>

<p>
De même, si un ensemble \(U \subseteq \setR\) :
</p>

<ul class="org-ul">
<li>ne contient ni \(1\) ni \(0\), on a \(\Theta(\indicatrice_\Phi,U) = \emptyset\)</li>
<li>contient \(1\) et \(0\), on a \(\Theta(\indicatrice_\Phi,U) = \Omega\)</li>
<li>contient \(1\) et pas \(0\), on a \(\Theta(\indicatrice_\Phi,U) = \Phi\)</li>
<li>contient \(0\) et pas \(1\), on a \(\Theta(\indicatrice_\Phi,U) = \Omega \setminus \Phi\)</li>
</ul>

<p>
On a donc :
</p>

<p>
\[\Lambda(\indicatrice_\Phi) = \{ \emptyset, \Omega, \Phi, \Omega \setminus \Phi \}\]
</p>
</div>
</div>
</div>
<div id="outline-container-org0491f6f" class="outline-2">
<h2 id="org0491f6f"><span class="section-number-2">5.</span> Espérance</h2>
<div class="outline-text-2" id="text-5">
<p>
L'espérance d'une variable aléatoire \(X\) est simplement une moyenne pondérée par les probablités que \(X\)
prennent telle ou telle valeur :
</p>

<p>
\[\esperof{X} = \int_{\Omega} X(\omega) \ d\proba(\omega)\]
</p>
</div>
<div id="outline-container-orgb95a801" class="outline-3">
<h3 id="orgb95a801"><span class="section-number-3">5.1.</span> Indicatrice</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Notons que pour tout \(\Phi \subseteq \Omega\), on a :
</p>

\begin{align}
\esperof{\indicatrice_\Phi} &= \int_\Omega \indicatrice_\Phi \ d\proba \)

\(
&= \int_\Phi \ d\proba
\end{align}

<p>
et donc :
</p>

<p>
\[\esperof{\indicatrice_\Phi} = \probaof{\Phi}\]
</p>
</div>
</div>
<div id="outline-container-org37e3e35" class="outline-3">
<h3 id="org37e3e35"><span class="section-number-3">5.2.</span> Fonction d'une variable aléatoire</h3>
<div class="outline-text-3" id="text-5-2">
<p>
Pour toute fonction \(G : \setR \mapsto \setR\), on a bien évidemment \(G \circ X : \Omega \mapsto \setR\) et on peut définir :
</p>

<p>
\[\esperof{G(X)} = \int_\Omega (G \circ X)(\omega) \ d\proba(\omega)\]
</p>
</div>
</div>
<div id="outline-container-orge0ef85c" class="outline-3">
<h3 id="orge0ef85c"><span class="section-number-3">5.3.</span> Fonction de plusieurs variables aléatoires</h3>
<div class="outline-text-3" id="text-5-3">
<p>
De même, si \(X\) et \(Y\) sont deux variables aléatoires, pour toute fonction \(G : \setR^2 \mapsto \setR\), on a évidemment \(G(X,Y) \in \setR\) et on peut définir :
</p>

<p>
\[\esperof{G(X,Y)} = \int_\Omega G\left(X(\omega),Y(\omega)\right) \ d\proba(\omega)\]
</p>

<p>
Le cas particulier \(G(X,Y) = a \ X + b \ Y\), où \(a,b \in \setR\), nous montre la linéarité de l'espérance, qui découle directement de celle de l'intégrale :
</p>

<p>
\[\esperof{a \ X + b \ Y} = a \ \esperof{X} + b \ \esperof{Y}\]
</p>
</div>
</div>
</div>
<div id="outline-container-orgc2875a9" class="outline-2">
<h2 id="orgc2875a9"><span class="section-number-2">6.</span> Espérance et mesure induite</h2>
<div class="outline-text-2" id="text-6">
<p>
Soit une variable aléatoire \(X\) et la fonction étagée \(G : \setR \mapsto \setR\) définie
pour tout \(x \in \setR\) par :
</p>

<p>
\[G(x) = \sum_i g_i \ \indicatrice_{A_i}(x)\]
</p>

<p>
où les \(A_i\) forment une partition de \(\setR\) et où les \(g_i\) sont supposés sans
perte de généralité être des réels distincts. Soit la partition de \(\Omega\) constituée
des ensembles :
</p>

<p>
\[\Omega_i = X^{-1}(A_i) = \{ \omega \in \Omega : X(\omega) \in A_i \}\]
</p>

<p>
On voit que \((G \circ X)(\omega) = g_i\) pour tout \(\omega \in \Omega_i\).
Calculons l'espérance de \(G(X)\) :
</p>

\begin{align}
\esperof{G(X)} &= \int_\Omega (G \circ X)(\omega) \ d\proba(\omega) \)

\(
&= \sum_i \int_{\Omega_i} (G \circ X)(\omega) \ d\proba(\omega) \)

\(
&= \sum_i \int_{\Omega_i} g_i \ d\proba(\omega) \)

\(
&= \sum_i g_i \int_{\Omega_i} \ d\proba(\omega) \)

\(
&= \sum_i g_i \ \probaof{\Omega_i}
\end{align}

<p>
Par définition de la mesure induite, on a :
</p>

<p>
\[\mathcal{L}_X(A_i) = \probaof{X^{-1}(A_i)} = \probaof{\Omega_i}\]
</p>

<p>
L'espérance de \(G(X)\) peut donc s'exprimer comme :
</p>

<p>
\[\esperof{G(X)} = \sum_i g_i \ \mathcal{L}_X(A_i)\]
</p>

<p>
Mais le membre de droite n'est autre que l'intégrale de \(G\) sur \(\setR\)
utilisant la mesure \(\mathcal{L}_X\) :
</p>

<p>
\[\esperof{G(X)} = \int_\setR G(x) \ d\mathcal{L}_X(x)\]
</p>

<p>
Comme cette expression doit être valable pour toute fonction en escalier, on en conclut que :
</p>

<p>
\[\esperof{G(X)} = \int_\setR G(x) \ d\mathcal{L}_X(x)\]
</p>

<p>
pour toute fonction intégrable \(G\).
</p>
</div>
<div id="outline-container-orgabbda52" class="outline-3">
<h3 id="orgabbda52"><span class="section-number-3">6.1.</span> Identité</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Le cas particulier \(G = \identite\) nous donne :
</p>

<p>
\[\esperof{X} = \int_\setR x \ d\mathcal{L}_X(x)\]
</p>
</div>
</div>
<div id="outline-container-org525c1e8" class="outline-3">
<h3 id="org525c1e8"><span class="section-number-3">6.2.</span> Densité</h3>
<div class="outline-text-3" id="text-6-2">
<p>
Si il existe une fonction \(f_X : \setR \mapsto \setR\) telle que \(d\mathcal{L}_X = f_X \ dx\),
où \(dx\) correspond à la mesure de Lebesgue sur \(\setR\), on a :
</p>

<p>
\[\esperof{G(X)} = \int_\setR G(x) \ f_X(x) \ dx\]
</p>

<p>
ainsi que :
</p>

<p>
\[\esperof{X} = \int_\setR x \ f_X(x) \ dx\]
</p>

<p>
On nomme cette fonction \(f_X\) la densité de la variable aléatoire \(X\).
</p>

<p>
Remarquons que \(f_X\) est positive par positivité de la mesure. Comme :
</p>

<p>
\[\esperof{1} = 1\]
</p>

<p>
on obtient la propriété de normalité :
</p>

<p>
\[\int_\setR f_X(x) \ dx = 1\]
</p>
</div>
<div id="outline-container-org8afe22a" class="outline-4">
<h4 id="org8afe22a"><span class="section-number-4">6.2.1.</span> Variable aléatoire gaussienne</h4>
<div class="outline-text-4" id="text-6-2-1">
<p>
Une variable aléatoire est dite normale de paramètres \(\mu\), \(\sigma\) si sa fonction
densité vérifie :
</p>

<p>
\[f_{X}(x) = \frac{1}{ \sigma\sqrt{2 \pi} } \exp\left(-\frac{(x-\mu)^2}{2 \sigma^2}\right)\]
</p>
</div>
</div>
</div>
<div id="outline-container-org48f9812" class="outline-3">
<h3 id="org48f9812"><span class="section-number-3">6.3.</span> Variables conjointes</h3>
<div class="outline-text-3" id="text-6-3">
<p>
Soit les variables aléatoires \(X, Y\) et la fonction étagée \(G : \setR^2 \mapsto \setR\) définie
pour tout \(x, y \in \setR\) par :
</p>

<p>
\[G(x,y) = \sum_i g_i \ \indicatrice_{A_i}(x,y)\]
</p>

<p>
où les \(A_i\) forment une partition de \(\setR^2\) et où les \(g_i\) sont supposés sans
perte de généralité être des réels distincts. Soit la partition de \(\Omega\) constituée
des ensembles :
</p>

<p>
\[\Omega_i = \{ \omega \in \Omega : (X(\omega), Y(\omega)) \in A_i \}\]
</p>

<p>
On voit que \(G(X(\omega), Y(\omega)) = g_i\) pour tout \(\omega \in \Omega_i\).
Calculons l'espérance de \(G(X,Y)\) :
</p>

\begin{align}
\esperof{G(X,Y)} &= \int_\Omega G(X(\omega), Y(\omega)) \ d\proba(\omega) \)

\(
&= \sum_i \int_{\Omega_i} G(X(\omega), Y(\omega)) \ d\proba(\omega) \)

\(
&= \sum_i \int_{\Omega_i} g_i \ d\proba(\omega) \)

\(
&= \sum_i g_i \int_{\Omega_i} \ d\proba(\omega) \)

\(
&= \sum_i g_i \ \probaof{\Omega_i}
\end{align}

<p>
Par définition de la mesure induite, on a :
</p>

<p>
\[\mathcal{L}_{X,Y}(A_i) = \probaof{\Omega_i}\]
</p>

<p>
L'espérance de \(G(X)\) peut donc s'exprimer comme :
</p>

<p>
\[\esperof{G(X,Y)} = \sum_i g_i \ \mathcal{L}_{X,Y}(A_i)\]
</p>

<p>
Mais le membre de droite n'est autre que l'intégrale de \(G\) sur \(\setR^2\)
utilisant la mesure \(\mathcal{L}_{X,Y}\) :
</p>

<p>
\[\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ d\mathcal{L}_{X,Y}(x,y)\]
</p>

<p>
Comme cette expression doit être valable pour toute fonction en escalier, on en conclut que :
</p>

<p>
\[\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ d\mathcal{L}_{X,Y}(x,y)\]
</p>

<p>
pour toute fonction intégrable \(G\).
</p>
</div>
</div>
<div id="outline-container-org048ad3d" class="outline-3">
<h3 id="org048ad3d"><span class="section-number-3">6.4.</span> Densité conjointe</h3>
<div class="outline-text-3" id="text-6-4">
<p>
Si il existe une fonction \(f_{X,Y} : \setR^2 \mapsto \setR\) telle que
\(d\mathcal{L}_{X,Y} = f_{X,Y} \ dx \ dy\), où \(dx \ dy\) correspond à la mesure de Lebesgue
sur \(\setR^2\), on a :
</p>

<p>
\[\esperof{G(X,Y)} = \int_{\setR^2} G(x,y) \ f_{X,Y}(x,y) \ dx \ dy\]
</p>

<p>
En considérant le cas particulier \(G(X,Y) = X\), on obtient :
</p>

\begin{align}
\esperof{X} &= \int_{\setR^2} x \ f_{X,Y}(x,y) \ dx \ dy \)

\(
&= \int_\setR x \ \left[\int_\setR f_{X,Y}(x,y) \ dy\right] \ dx
\end{align}

<p>
En définissant la fonction associée \(f_X\) par :
</p>

<p>
\[f_X(x) = \int_\setR f_{X,Y}(x,y) \ dy\]
</p>

<p>
on peut dès lors écrire l'espérance de \(X\) comme :
</p>

<p>
\[\esperof{X} = \int_\setR x \ f_X(x) \ dx\]
</p>

<p>
En suivant le même déroulement pour \(\esperof{Y}\), et en définissant :
</p>

<p>
\[f_Y(y) = \int_\setR f_{X,Y}(x,y) \ dx\]
</p>

<p>
on peut écrire l'espérance de \(Y\) comme :
</p>

<p>
\[\esperof{Y} = \int_\setR y \ f_Y(y) \ dy\]
</p>
</div>
<div id="outline-container-orge119c48" class="outline-4">
<h4 id="orge119c48"><span class="section-number-4">6.4.1.</span> Distribution normale</h4>
<div class="outline-text-4" id="text-6-4-1">
<p>
On dit que les variables aléatoires \(X_1, ..., X_N\) présentent une distribution normale multivariée si il existe :
</p>

<div class="org-center">
<p>
\(
\mu = \left( \mu_i \right)_i \)
</p>

<p>
\(
\Theta = \left( \sigma_{ij} \right)_{i,j}
\)
</p>
</div>

<p>
tels que la fonction densité associée à \(X = (X_1, ..., X_N)^T\) s'écrive :
</p>

<p>
\[\f_X(x) = \unsur{2 \pi^{n/2} \det{A}} \exp\left(-\unsur{2} (x-\mu)^T \cdot \Theta^{-1} \cdot (x-\mu) \right)\]
</p>

<p>
pour tout \(x \in \setR^N\). On a alors :
</p>

<div class="org-center">
<p>
\(
\esperof{X_i} = \mu_i \)
</p>

<p>
\(
\cov{X_i}{X_j} = \sigma_{ij}
\)
</p>
</div>

<p>
On a aussi la fonction génératrice :
</p>

<p>
\[\Psi_X(u) = \exp\left(u^T \cdot \mu + \unsur{2} u^T \cdot \Theta^{-1} \cdot u\right)\]
</p>

<p>
pour tout \(u \in \setR^N\).
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org2ff0b69" class="outline-2">
<h2 id="org2ff0b69"><span class="section-number-2">7.</span> Fonction génératrice des moments</h2>
<div class="outline-text-2" id="text-7">
<p>
On définit le moment générateur d'une densité par :
</p>

<p>
\[\Psi_X(u) = \esperof{\exp(X \cdot u)}\]
</p>

<p>
L'intérêt de cette fonction est qu'elle permet de calculer facilement
les espérances des puissances naturelles de \(X\). En effet :
</p>

<p>
\[\frac{d^k \Psi_X}{du^k}(u) = \esperof{X^k \ \exp(X \cdot u)}\]
</p>

<p>
et donc :
</p>

<p>
\[\OD{\Psi}{u}(0) = \esperof{X^k \ \exp(0)} = \esperof{X^k}\]
</p>
</div>
<div id="outline-container-org47b5a08" class="outline-3">
<h3 id="org47b5a08"><span class="section-number-3">7.1.</span> Variable gaussienne</h3>
<div class="outline-text-3" id="text-7-1">
<p>
A titre d'exemple, nous calculons le  moment générateur associé à une densité gaussienne :
</p>

<p>
\[\Psi(u) = \unsur{\sqrt{2 \pi} \sigma} \int_\setR \exp(x u) \exp\left(-\frac{(x-\mu)^2}{2 \sigma^2}\right) dx\]
</p>

<p>
On obtient en développant :
</p>

\begin{align}
\Psi(u) &= \unsur{\sqrt{2 \pi} \sigma} \int_\setR \exp\left(x u - \frac{(x-\mu)^2}{2 \sigma^2}\right) dx \)

\(
&= \unsur{\sqrt{2 \pi} \sigma} \exp(\mu u + \unsur{2} u^2 \sigma^2) \int_\setR \exp\left(- \frac{(x-(\mu + u \sigma^2) )^2}{2 \sigma^2}\right) dx
\end{align}

<p>
Comme l'intégrale vaut \(\sqrt{2 \pi} \sigma\), on obtient finalement :
</p>

<p>
\[\Psi(u) = \exp(u \mu + \unsur{2} u^2 \sigma^2)\]
</p>
</div>
</div>
</div>
<div id="outline-container-orgc421449" class="outline-2">
<h2 id="orgc421449"><span class="section-number-2">8.</span> Variance</h2>
<div class="outline-text-2" id="text-8">
<p>
La variance de \(X\) est la variation carrée moyenne de \(X\) autour de son espérance \(\esperof{X}\) :
</p>

<p>
\[\var{X} = \esperof{\left(X-\esperof{X}\right)^2}\]
</p>

<p>
Comme la variable \(Z = \left(X-\esperof{X}\right)^2\) est positive, son espérance doit également etre positive et \(\var{X} \ge 0\).
</p>

<p>
En développant la définition et en utilisant la linéarité de l'espérance, on obtient :
</p>

\begin{align}
\var{X} &= \esperof{X^2 - 2 \ X \cdot \esperof{X} + \esperof{X}^2} \)

\(
&= \esperof{X^2} - 2 \ \esperof{X} \cdot \esperof{X} + \esperof{X}^2 \cdot \esperof{1} \)

\(
&= \esperof{X^2} - 2 \ \esperof{X}^2 + \esperof{X}^2
\end{align}

<p>
soit :
</p>

<p>
\[\var{X} = \esperof{X^2} - \esperof{X}^2\]
</p>
</div>
<div id="outline-container-org1200414" class="outline-3">
<h3 id="org1200414"><span class="section-number-3">8.1.</span> Invariance sous translation</h3>
<div class="outline-text-3" id="text-8-1">
<p>
Notons que si \(X,Y\) sont deux variables aléatoires reliées par :
</p>

<p>
\[Y = X + a\]
</p>

<p>
où \(a \in \setR\), on a :
</p>

\begin{align}
\var{Y} &= \esperof{\left(Y-\esperof{Y}\right)^2} \)

\(
&= \esperof{\left(X + a -\esperof{X+a}\right)^2} \)

\(
&= \esperof{\left(X + a -\esperof{X} - a\right)^2} \)

\(
&= \esperof{\left(X -\esperof{X}\right)^2} \)

\(
&= \var{X}
\end{align}

<p>
La variance est donc invariante sous translation :
</p>

<p>
\[\var{X+a} = \var{X}\]
</p>
</div>
</div>
</div>
<div id="outline-container-orgc700691" class="outline-2">
<h2 id="orgc700691"><span class="section-number-2">9.</span> Covariance</h2>
<div class="outline-text-2" id="text-9">
<p>
La covariance de deux variables aléatoire \(X,Y\) se définit par :
</p>

<p>
\[\cov{X}{Y} = \esperof{(X-\esperof{X}) \cdot (Y-\esperof{Y})}\]
</p>

<p>
En développant et en utilisant la linéarité de l'espérance, on obtient :
</p>

\begin{align}
\cov{X}{Y} &= \esperof{X \cdot Y} - \esperof{X} \cdot \esperof{Y} - \esperof{Y} \cdot \esperof{X} + \esperof{X} \cdot \esperof{Y} \)

\(
&= \esperof{X \cdot Y} - \esperof{X} \cdot \esperof{Y}
\end{align}

<p>
On voit également que la variance d'une variable aléatoire \(X\) n'est rien d'autre que sa covariance avec elle-même :
</p>

<p>
\[\var{X} = \cov{X}{X}\]
</p>
</div>
<div id="outline-container-orge877b96" class="outline-3">
<h3 id="orge877b96"><span class="section-number-3">9.1.</span> Invariance sous translation</h3>
<div class="outline-text-3" id="text-9-1">
<p>
Suivant le même raisonnement que pour la variance, on considère les variables aléatoires \(W,X,Y,Z\) reliées par :
</p>

<div class="org-center">
<p>
\(
W = X + a \)
</p>

<p>
\(
Z = Y + b
\)
</p>
</div>

<p>
où \(a,b \in \setR\). La covariance entre \(W\) et \(Z\) s'exprime alors :
</p>

\begin{align}
\cov{W}{Z} &= \esperof{(W - \esperof{W})(Z - \esperof{Z})} \)

\(
&= \esperof{(X + a - \esperof{X} - a)(Y + b - \esperof{Y} - b)} \)

\(
&= \esperof{(X - \esperof{X})(Y - \esperof{Y})} \)

\(
&= \cov{X}{Y}
\end{align}

<p>
La covariance est donc invariante sous translation :
</p>

<p>
\[\cov{X+a}{Y+b} = \cov{X}{Y}\]
</p>
</div>
</div>
</div>
<div id="outline-container-org63e5f4b" class="outline-2">
<h2 id="org63e5f4b"><span class="section-number-2">10.</span> Variance d'une combinaison linéaire</h2>
<div class="outline-text-2" id="text-10">
<p>
Nous utilisons la notation :
</p>

<p>
\[X_0 = X - \esperof{X}\]
</p>

<p>
pour toute variable aléatoire \(X\). Cette variables aléatoire \(X_0\) a la propriété
d'avoir une espérance nulle car :
</p>

<p>
\[\esperof{X_0} = \esperof{X - \esperof{X} } = \esperof{X} - \esperof{X} = 0\]
</p>

<p>
La variance d'une telle variable peut s'écrire :
</p>

<p>
\[\var{X_0} = \esperof{X_0^2} - \esperof{X_0}^2 = \esperof{X_0^2}\]
</p>

<p>
Quant à la covariance, elle s'écrit :
</p>

<p>
\[\cov{X_0}{Y_0} = \esperof{X_0 \ Y_0} - \esperof{X_0} \ \esperof{Y_0} = \esperof{X_0 \ Y_0}\]
</p>

<p>
Soit les réels \(a,b\). Par linéarité de l'espérance, on a :
</p>

<p>
\[\esperof{a \ X + b \ Y} = a \ \esperof{X} + b \ \esperof{Y}\]
</p>

<p>
La variance de la combinaison linéaire \(a \ X + b \ Y\) s'écrit :
</p>

\begin{align}
\var{a \ X + b \ Y} &= \esperof{(a \ X + b \ Y - \esperof{a \ X + b \ Y})^2} \)

\(
&= \esperof{(a \ X + b \ Y - a \ \esperof{X} - b \ \esperof{Y})^2} \)

\(
&= \esperof{(a \ X_0 + b \ Y_0)^2}
\end{align}

<p>
En développant, on arrive à :
</p>

\begin{align}
\var{a \ X + b \ Y} &= \esperof{a^2 \ X_0^2 + 2 \ a \ b \ X_0 \ Y_0 + b^2 \ Y_0^2} \)

\(
&= a^2 \ \esperof{X_0^2} + 2 \ a \ b \ \esperof{X_0 \ Y_0} + b^2 \ \esperof{Y_0^2}
\end{align}

<p>
et donc :
</p>

<p>
\[\var{a \ X + b \ Y} = a^2 \ \var{X_0} + 2 \ a \ b \ \cov{X_0}{Y_0} + b^2 \ \var{Y_0}\]
</p>

<p>
L'invariance sous translation nous permet alors d'écrire :
</p>

<p>
\[\var{a \ X + b \ Y} = a^2 \ \var{X} + 2 \ a \ b \ \cov{X}{Y} + b^2 \ \var{Y}\]
</p>
</div>
</div>
<div id="outline-container-org69eaacc" class="outline-2">
<h2 id="org69eaacc"><span class="section-number-2">11.</span> Produit scalaire</h2>
<div class="outline-text-2" id="text-11">
<p>
Nous allons voir que la covariance est un produit scalaire. Nous utilisons la notation :
</p>

<p>
\[X_0 = X - \esperof{X}\]
</p>

<p>
pour toute variable aléatoire \(X\). Cette variables aléatoire \(X_0\) a la propriété
d'avoir une espérance nulle car :
</p>

<p>
\[\esperof{X_0} = \esperof{X - \esperof{X} } = \esperof{X} - \esperof{X} = 0\]
</p>

<p>
On en déduit que :
</p>

<p>
\[\cov{X_0}{Y_0} = \esperof{X_0 \ Y_0} - \esperof{X_0} \ \esperof{Y_0} = \esperof{X_0 \ Y_0}\]
</p>

<p>
La symétrie est vérifiée :
</p>

<p>
\[\cov{Y_0}{X_0} = \esperof{Y_0 \cdot X_0} = \esperof{X_0 \cdot Y_0} = \cov{X_0}{Y_0}\]
</p>

<p>
En ce qui concerne le caractère défini positif, on a :
</p>

<p>
\[\cov{X_0}{X_0} = \esperof{X_0^2} \ge 0\]
</p>

<p>
De plus, si \(X_0\) est tel que \(\cov{X_0}{X_0} = 0\), on a :
</p>

<p>
\[\int_\Omega X_0^2 \ d\proba(\omega) = 0\]
</p>

<p>
ce qui entraîne la nullité essentielle \(X_0 \essegal 0\) sur \(\Omega\).
</p>

<p>
Soit les réels \(a,b\). On voit que la linéarité est bien respectée :
</p>

\begin{align}
\cov{X_0}{a \ Y_0 + b \ Z_0} &= \esperof{X_0 \ (a \ Y_0 + b \ Z_0)} \)

\(
&= a \ \esperof{X_0 \ Y_0} + b \ \esperof{X_0 \ Z_0} \)

\(
&= a \ \cov{X_0}{Y_0} + b \ \cov{X_0}{Z_0}
\end{align}

<p>
Nous venons de montrer que la covariance est essentiellement un produit scalaire
pour toute variable aléatoires à espérance nulles \(X_0, Y_0\). Comme la covariance
est invariante sous translation, on voit que :
</p>

<p>
\[\cov{X}{Y} = \cov{X_0}{Y_0}\]
</p>

<p>
est également un produit scalaire pour toutes variables aléatoires \(X,Y\).
</p>
</div>
<div id="outline-container-orgb052e8c" class="outline-3">
<h3 id="orgb052e8c"><span class="section-number-3">11.1.</span> Cauchy-Schwartz</h3>
<div class="outline-text-3" id="text-11-1">
<p>
En appliquant l'inégalité de Cauchy-Schwartz à ce produit scalaire, on obtient :
</p>

<p>
\[\cov{X}{Y}^2 \le \cov{X}{X} \ \cov{Y}{Y} = \var{X} \ \var{Y}\]
</p>

<p>
où, en prenant la racine :
</p>

<p>
\[\cov{X}{Y} \le \sqrt{\var{X} \ \var{Y}}\]
</p>
</div>
</div>
</div>
<div id="outline-container-org4367b9b" class="outline-2">
<h2 id="org4367b9b"><span class="section-number-2">12.</span> Probabilité conditionnelle</h2>
<div class="outline-text-2" id="text-12">
<p>
\label{sec:proba_cond}
</p>

<p>
On définit une nouvelle famille de probabilités :
</p>

<p>
\[\probaof{A | B} = \frac{ \probaof{A \cap B} }{ \probaof{B} }\]
</p>

<p>
où \(A,B\) sont des sous-ensembles quelconque de \(\Omega\), et où \(B\) est tel que :
</p>

<p>
\[\probaof{B} > 0\]
</p>

<p>
Comme \(B \cap B = B\), on a :
</p>

<p>
\[\probaof{ B | B } = 1\]
</p>

<p>
On est donc certain qu'un événement de \(B\) va se produire. En fait, pour tout ensemble \(C\) tel que \(B \subseteq C\), on a \(C \cap B = B\) et :
</p>

<p>
\[\probaof{ C | B } = 1\]
</p>

<p>
On déduit de l'inégalité :
</p>

<p>
\[\probaof{A \cap B} \le \probaof{B}\]
</p>

<p>
que :
</p>

<p>
\[\probaof{A | B} \le 1\]
</p>

<p>
D'un autre coté, comme \(\probaof{B} \le 1\), on a :
</p>

<p>
\[\probaof{A | B} \ge \probaof{A \cap B} \ge 0\]
</p>

<p>
L'additivité est également satisfaite :
</p>

\begin{align}
\probaof{ \cup_i A_i | B} &= \frac{ \probaof{(\cup_i A_i) \cap B} }{ \probaof{B} } \)

\(
&= \frac{ \probaof{\cup_i (A_i \cap B)} }{ \probaof{B} } \)

\(
&= \sum_i \frac{ \probaof{A_i \cap B} }{ \probaof{B} } = \sum_i \probaof{ A_i | B}
\end{align}

<p>
pour toute famille de \(A_i\) disjoints deux à deux. Les fonctions :
</p>

<p>
\[\proba_B\left[ A \right] = \probaof{A | B}\]
</p>

<p>
forment donc bien une famille de probabilités. On dit que \(\probaof{A | B}\) est la probabilité conditionnelle de \(A\) sachant \(B\).
</p>

<p>
Lorsque \(B = \Omega\), on retrouve d'ailleurs :
</p>

<p>
\[\probaof{A | \Omega} = \probaof{A}\]
</p>
</div>
<div id="outline-container-orgb2d040c" class="outline-3">
<h3 id="orgb2d040c"><span class="section-number-3">12.1.</span> Indépendance</h3>
<div class="outline-text-3" id="text-12-1">
<p>
On dit que deux ensembles d'événements \(A\) et \(B\) sont indépendants si :
</p>

<p>
\[\probaof{A | B} = \probaof{A}\]
</p>

<p>
c'est-à-dire si :
</p>

<p>
\[\probaof{A \cap B} = \probaof{A} \cdot \probaof{B}\]
</p>
</div>
</div>
<div id="outline-container-orgddc5eda" class="outline-3">
<h3 id="orgddc5eda"><span class="section-number-3">12.2.</span> Application</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Une technique fréquemment employée pour évaluer \(\probaof{A}\) est d'utiliser
une partition \(B_1,...,B_n\) de \(\Omega\). Utilisant \(A = A \cup \Omega\), on a alors :
</p>

<p>
\[\probaof{A} = \sum_i \probaof{A \cap B_i} = \sum_i \probaof{A | B_i} \cdot \probaof{B_i}\]
</p>
</div>
</div>
</div>
<div id="outline-container-org5ffabcc" class="outline-2">
<h2 id="org5ffabcc"><span class="section-number-2">13.</span> Espérance conditionnelle à un ensemble</h2>
<div class="outline-text-2" id="text-13">
<p>
Soit \(A \subseteq \Omega\). On a vu que :
</p>

<p>
\[\esperof{\indicatrice_A} = \probaof{A}\]
</p>

<p>
pour toute fonction indicatrice d'un sous-ensemble \(A\) de \(\Omega\). Par analogie, on aimerait bien obtenir une expression d'une espérance conditionnelle vérifiant :
</p>

<p>
\[\esperof{\indicatrice_A | B} = \probaof{A | B}\]
</p>

<p>
pour un ensemble \(B \subseteq \Omega\) donné vérifiant \(\probaof{B} > 0\).
</p>

<p>
Soit \(\Omega_1, ..., \Omega_N\) une partition de \(\Omega\) et \(Z\) une variable aléatoire en escalier :
</p>

<p>
\[Z(\omega) = \sum_i Z_i \ \indicatrice_{\Omega_i}(\omega)\]
</p>

<p>
On voit que :
</p>

\begin{align}
\esperof{Z | B} &= \sum_i Z_i\ \esperof{\indicatrice_{\Omega_i} | B} \)

\(
&= \sum_i Z_i\ \probaof{\Omega_i | B}
\end{align}

<p>
Or :
</p>

<p>
\[\probaof{\Omega_i | B} = \frac{ \probaof{\Omega_i \cap B} }{ \probaof{B} }\]
</p>

<p>
On a donc :
</p>

<p>
\[\esperof{Z | B} = \unsur{ \probaof{B} } \sum_i Z_i\ \probaof{\Omega_i \cap B}\]
</p>

<p>
Considérons la nouvelle partition :
</p>

<div class="org-center">
<p>
\(
\Phi_i^+ = \Omega_i \cap B \)
</p>

<p>
\(
\Phi_i^- = \Omega_i \cap (\Omega \setminus B)
\)
</p>
</div>

<p>
Comme \(\Phi_i^+ \cup \Phi_i^- = \Omega_i\), on a clairement \(\indicatrice_{\Phi_i^+} + \indicatrice_{\Phi_i^-} = \indicatrice_{\Omega_i}\) et on peut réexprimer \(Z\) comme :
</p>

<p>
\[Z(\omega) = \sum_i Z_i\ \indicatrice_{\Phi_i^+}(\omega) + \sum_i Z_i\ \indicatrice_{\Phi_i^-}(\omega)\]
</p>

<p>
L'expression de l'espérance conditionelle devient :
</p>

<p>
\[\esperof{Z | B} = \unsur{ \probaof{B} } \left[ \sum_i Z_i\ \probaof{\Phi_i^+ \cap B} + \sum_i Z_i\ \probaof{\Phi_i^- \cap B} \right]\]
</p>

<p>
Remarquons que par construction :
</p>

<div class="org-center">
<p>
\(
\Phi_i^+ \cap B = \Phi_i^+ \)
</p>

<p>
\(
\Phi_i^- \cap B = \emptyset
\)
</p>
</div>

<p>
Par conséquent, les termes en \(\probaof{\Phi_i^- \cap B}\) s'annulent et on a :
</p>

<p>
\[\esperof{Z | B} = \unsur{ \probaof{B} } \sum_i Z_i\ \probaof{\Phi_i^+}\]
</p>

<p>
Mais comme \(\bigcup_i \Phi_i^+ = B\), les \(\Phi_i^+\) forment une partition de \(B\) et on peut écrire cette expression sous la forme intégrale :
</p>

<p>
\[\esperof{Z | B} = \frac{ \int_B Z\ \ d\proba }{ \int_B \ d\proba }\]
</p>

<p>
Comme cette relation doit être valable pour toute variable aléatoire en escalier \(Z\), elle l'est également pour une variable aléatoire quelconque \(X\) :
</p>

<p>
\[\esperof{X | B} = \frac{ \int_B X\ \ d\proba }{ \int_B \ d\proba }\]
</p>
</div>
<div id="outline-container-org5459501" class="outline-3">
<h3 id="org5459501"><span class="section-number-3">13.1.</span> Densité conditionnelle</h3>
<div class="outline-text-3" id="text-13-1">
<p>
Soient \(X,Y\) deux variables aléatoires. Un cas particulier important d'espérance conditionnelle est celui où :
</p>

<p>
\[B_y = \{ \omega : Y(\omega) = y \}\]
</p>

<p>
On note alors :
</p>

<p>
\[\esperof{X | Y = y} = \esperof{X | B_y}\]
</p>

<p>
On remarque que :
</p>

<p>
\[(X,Y)(B_y) = \{ (x,y) \in \setR^2 : x \in \setR \}\]
</p>

<p>
Par conséquent, si il existe une fonction densité \(f_{X,Y}\) associée à \(X,Y\), on peut écrire :
</p>

\begin{align}
\int_{B_y} X \ d\proba &= \int_{(X,Y)(B_y)} x \ f_{X,Y}(x,y) \ dx \ dy \)

\(
&= \int_\setR x \ f_{X,Y}(x,y) \ dx
\end{align}

<p>
ainsi que :
</p>

<p>
\[\int_{B_y} \ d\proba = \int_\setR f_{X,Y}(x,y) \ dx\]
</p>

<p>
L'espérance conditionnelle s'écrit alors :
</p>

<p>
\[\esperof{X | Y = y} = \frac{\int_\setR x \ f_{X,Y}(x,y) \ dx}{\int_\setR f_{X,Y}(x,y) \ dx}\]
</p>

<p>
Donc, si on définit :
</p>

<p>
\[f_{X | Y}(x,y) = \frac{f_{X,Y}(x,y)}{ \int_\setR f_{X,Y}(x,y) \ dx}\]
</p>

<p>
on a tout simplement :
</p>

<p>
\[\esperof{X | Y = y} = \int_\setR x \ f_{X | Y}(x,y) \ dx\]
</p>
</div>
</div>
</div>
<div id="outline-container-orgacb831c" class="outline-2">
<h2 id="orgacb831c"><span class="section-number-2">14.</span> Espérance conditionnelle à une tribu</h2>
<div class="outline-text-2" id="text-14">
</div>
<div id="outline-container-orgcb4cb0f" class="outline-3">
<h3 id="orgcb4cb0f"><span class="section-number-3">14.1.</span> Tribu et espace fonctionnel</h3>
<div class="outline-text-3" id="text-14-1">
<p>
Soit \(\Gamma \subseteq \sousens(\Omega)\) une collection de sous-ensembles de \(\Omega\) formant une tribu sur \(\Omega\) (voir section \ref{sec:tribu}),
et \(\mathcal{F}(\Gamma)\) l'ensemble des variables aléatoires \(W\) telles que :
</p>

<p>
\[\Lambda(W) \subseteq \Gamma\]
</p>

<p>
où \(\Lambda(W)\) est la collection induite par \(W\).
</p>
</div>
</div>
<div id="outline-container-orgc1b90a7" class="outline-3">
<h3 id="orgc1b90a7"><span class="section-number-3">14.2.</span> Minimisation</h3>
<div class="outline-text-3" id="text-14-2">
<p>
L'espérance conditionnelle est construite comme le meilleur estimateur au sens des moindres carrés d'une variable aléatoire \(X\) sur \(\mathcal{F}(\Gamma)\). Soit la fonctionnelle \(I : \mathcal{F}(\Gamma) \mapsto \setR\) représentant l'erreur :
</p>

<p>
\[I(Z) = \int_\Omega \left[ Z(\omega) - X(\omega) \right]^2 \ d\proba(\omega)\]
</p>

<p>
Nous allons minimiser \(I\) sur \(\mathcal{F}(\Gamma)\). Pour ce faire, on utilise la technique du calcul variationnel (voir chapitre \ref{chap:varia}). On commence par définir :
</p>

<p>
\[J_W(\epsilon) = I(Z^* + \epsilon W) = \int_\Omega (Z^* + \epsilon W - X)^2 \ d\proba\]
</p>

<p>
où la variable aléatoire \(Z^*\) est l'optimum recherché, et où \(W \in \mathcal{F}(\Gamma)\), \(\epsilon \in \setR\). La dérivée s'écrit :
</p>

<p>
\[\OD{J_W}{\epsilon}(\epsilon) = \int_\Omega 2 (Z^* +\epsilon W - X) W \ d\proba = 0\]
</p>

<p>
Comme celle-ci doit s'annuler en \(\epsilon = 0\), on a :
</p>

<p>
\[\OD{J_W}{\epsilon}(0) = \int_\Omega 2 (Z^* - X) W \ d\proba = 0\]
</p>

<p>
Autrement dit :
</p>

<p>
\[\int_\Omega W Z^* \ d\proba = \int_\Omega W X \ d\proba\]
</p>

<p>
équation qui doit être vérifiée pour tout \(W \in \mathcal{F}(\Gamma)\).
</p>
</div>
</div>
<div id="outline-container-org1d0e205" class="outline-3">
<h3 id="org1d0e205"><span class="section-number-3">14.3.</span> Unicité</h3>
<div class="outline-text-3" id="text-14-3">
<p>
Nous supposons dorénavant que \(\mathcal{F}(\Gamma)\) est un espace vectoriel. Soient \(Z_1, Z_2 \in \mathcal{F}(\Gamma)\) des variables aléatoires qui minimisent tous deux la fonctionnelle \(I\). On a :
</p>

<p>
\[\int_\Omega W Z_1 \ d\proba = \int_\Omega W Z_2 \ d\proba = \int_\Omega W X \ d\proba\]
</p>

<p>
pour tout \(W \in \mathcal{F}(\Gamma)\). Donc :
</p>

<p>
\[\int_\Omega W (Z_1 - Z_2) \ d\proba = 0\]
</p>

<p>
Mais comme \(Z_1 - Z_2 \in \mathcal{F}(\Gamma)\), il suffit de considérer le cas \(W = Z_1 - Z_2\) pour avoir :
</p>

<p>
\[\int_\Omega (Z_1 - Z_2)^2 \ d\proba = 0\]
</p>

<p>
On en conclut que \(Z_1 = Z_2\) presque partout sur \(\Omega\). L'espérance conditionnelle est donc unique pour \(X\) et \(\Gamma\) donnés.
</p>
</div>
</div>
<div id="outline-container-org7a92d22" class="outline-3">
<h3 id="org7a92d22"><span class="section-number-3">14.4.</span> Définition</h3>
<div class="outline-text-3" id="text-14-4">
<p>
Forts de ces résultats, on définit l'espérance de \(X\) conditionnellement à la tribu \(\Gamma\) comme étant :
</p>

<p>
\[\esperof{X | \Gamma} = \arg\min_{Z \in \mathcal{F}(\Gamma) } \int_{\Omega} \left[ Z - X \right]^2 \ d\proba\]
</p>

<p>
On a donc :
</p>

<p>
\[\int_\Omega W\ \esperof{X | \Gamma} \ d\proba = \int_\Omega W\ X \ d\proba\]
</p>

<p>
pour tout \(W \in \mathcal{F}(\Gamma)\).
</p>
</div>
</div>
<div id="outline-container-org31be9b3" class="outline-3">
<h3 id="org31be9b3"><span class="section-number-3">14.5.</span> Fonctions indicatrices</h3>
<div class="outline-text-3" id="text-14-5">
<p>
Soit un ensemble \(\Phi \in \Gamma\). Les propriétés de \(\Gamma\) nous disent que \(\Omega \setminus \Phi \in \Gamma\). Donc :
</p>

<p>
\[\Lambda(\indicatrice_\Phi) = \{ \emptyset, \Omega, \Phi, \Omega \setminus \Phi \} \subseteq \Gamma\]
</p>

<p>
et \(\indicatrice_\Phi \in \mathcal{F}(\Gamma)\). On en déduit que :
</p>

<p>
\[\int_\Omega \indicatrice_\Phi \ \esperof{X | \Gamma} \ d\proba = \int_\Omega \indicatrice_\Phi \ X \ d\proba\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\int_\Phi \esperof{X | \Gamma} \ d\proba = \int_\Phi X \ d\proba\]
</p>

<p>
pour tout \(\Phi \in \Gamma\).
</p>

<p>
Comme \(\Omega \in \Gamma\), on a en particulier :
</p>

<p>
\[\int_\Omega \esperof{X | \Gamma} \ d\proba = \int_\Omega X \ d\proba\]
</p>

<p>
c'est-à-dire :
</p>

<p>
\[\esperof{ \esperof{X | \Gamma} } = \esperof{X}\]
</p>
</div>
</div>
<div id="outline-container-orge2d761e" class="outline-3">
<h3 id="orge2d761e"><span class="section-number-3">14.6.</span> Variable aléatoire dans l'espace fonctionnel</h3>
<div class="outline-text-3" id="text-14-6">
<p>
Une conséquence directe de la définition de l'espérance conditionnelle est que si \(Z \in \mathcal{F}(\Gamma)\), on a :
</p>

<p>
\[\int_\Omega (Z - Z)^2 \ d\proba = 0\]
</p>

<p>
Par conséquent, \(Z\) minimise la fonctionnelle :
</p>

<p>
\[I(Y) = \int_\Omega (Y - Z)^2 \ d\proba \ge 0\]
</p>

<p>
sur \(\mathcal{F}(\Gamma)\) et :
</p>

<p>
\[\esperof{Z | \Gamma} = Z\]
</p>
</div>
</div>
<div id="outline-container-org997b605" class="outline-3">
<h3 id="org997b605"><span class="section-number-3">14.7.</span> Tour</h3>
<div class="outline-text-3" id="text-14-7">
<p>
Soit la tribu \(\Delta \subseteq \Gamma\) et \(X\) une variable aléatoire et \(W \in \mathcal{F}(\Delta)\). On a :
</p>

<p>
\[\Lambda(W) \subseteq \Delta \subseteq \Gamma\]
</p>

<p>
Par conséquent \(W \in \mathcal{F}(\Gamma)\) et les équations suivantes sont vérifiées :
</p>

<div class="org-center">
<p>
\(
\int_\Omega W\ \esperof{X | \Delta} \ d\proba = \int_\Omega W\ X \ d\proba \)
</p>

<p>
\(
\int_\Omega W\ \esperof{X | \Gamma} \ d\proba = \int_\Omega W\ X \ d\proba
\)
</p>
</div>

<p>
On en déduit que :
</p>

<p>
\[\int_\Omega W\ \esperof{X | \Delta} \ d\proba = \int_\Omega W\ \esperof{X | \Gamma} \ d\proba\]
</p>

<p>
Comme cette dernière équation est valable pour tout \(W \in \mathcal{F}(\Delta)\), on en déduit que \(\esperof{X | \Delta}\) est le meilleur estimateur de \(\esperof{X | \Gamma}\) sur \(\mathcal{F}(\Delta)\). Ce qui revient à dire que :
</p>

<p>
\[\esperof{ \esperof{X | \Gamma} | \Delta } = \esperof{X | \Delta}\]
</p>
</div>
</div>
<div id="outline-container-org6fa5d55" class="outline-3">
<h3 id="org6fa5d55"><span class="section-number-3">14.8.</span> Couple de variables aléatoires</h3>
<div class="outline-text-3" id="text-14-8">
<p>
Etant donné deux variables aléatoires \(X,Y\), on définit :
</p>

<p>
\[\esperof{X | Y} = \esperof{X | \Lambda(Y)}\]
</p>

<p>
Comme \(\Gamma = \Lambda(Y)\), l'espace \(\mathcal{F}(\Gamma)\) est l'ensemble des variables aléatoires \(W\) telles que :
</p>

<p>
\[\Lambda(W) \subseteq \Lambda(Y)\]
</p>
</div>
</div>
</div>
<div id="outline-container-org00b7616" class="outline-2">
<h2 id="org00b7616"><span class="section-number-2">15.</span> Ensemble discret</h2>
<div class="outline-text-2" id="text-15">
<p>
Nous allons à présent considérer le cas particulier où l'ensemble des événements peut s'écrire
comme :
</p>

<p>
\[\Omega = \{ \omega_i : i \in \setN \}\]
</p>

<p>
Nous notons \(p_i\) les probabilités associées aux singletons :
</p>

<p>
\[p_i = \probaof{ \{\omega_i\} }\]
</p>

<p>
Étant donnée une variable aléatoire \(X\), on note :
</p>

<p>
\[x_i = X(\omega_i)\]
</p>

<p>
L'espérance d'une telle variable s'écrit simplement :
</p>

<p>
\[\esperof{X} = \sum_i x_i \ p_i\]
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-12-30 mar 11:27</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
