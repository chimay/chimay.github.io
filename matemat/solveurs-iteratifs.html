<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr">
<head>
<!-- 2025-11-16 dim 15:18 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Eclats de vers : Matemat : Solveurs itératifs</title>
<meta name="author" content="chimay" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../style/defaut.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Eclats de vers : Matemat : Solveurs itératifs</h1>
<p>
<a href="index.html">Index mathématique</a>
</p>

<p>
<a href="../index.html">Retour à l’accueil</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table des matières</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgefb381e">1. Dépendances</a></li>
<li><a href="#org4070954">2. Méthodes itératives</a></li>
<li><a href="#org0f7f056">3. Résolution par minimisation</a></li>
<li><a href="#orgd3173f0">4. Espaces de Krylov</a></li>
<li><a href="#org7d79a3c">5. Méthode de projection</a></li>
<li><a href="#org67ebf4c">6. Minimisation du résidu</a></li>
<li><a href="#orgff465dc">7. Gradients biconjugués</a></li>
</ul>
</div>
</div>

<p>
\(
\newcommand{\parentheses}[1]{\left(#1\right)}
\newcommand{\crochets}[1]{\left[#1\right]}
\newcommand{\accolades}[1]{\left\{#1\right\}}
\newcommand{\ensemble}[1]{\left\{#1\right\}}
\newcommand{\identite}{\mathrm{Id}}
\newcommand{\indicatrice}{\boldsymbol{\delta}}
\newcommand{\dirac}{\delta}
\newcommand{\moinsun}{{-1}}
\newcommand{\inverse}{\ddagger}
\newcommand{\pinverse}{\dagger}
\newcommand{\topologie}{\mathfrak{T}}
\newcommand{\ferme}{\mathfrak{F}}
\newcommand{\img}{\mathbf{i}}
\newcommand{\binome}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\canonique}{\mathfrak{c}}
\newcommand{\tenseuridentite}{\boldsymbol{\mathcal{I}}}
\newcommand{\permutation}{\boldsymbol{\epsilon}}
\newcommand{\matriceZero}{\mathfrak{0}}
\newcommand{\matriceUn}{\mathfrak{1}}
\newcommand{\christoffel}[2]{
\left\{ \begin{array}{c}
#1 \\
#2 \\
\end{array} \right\}
}
\newcommand{\lagrangien}{\mathfrak{L}}
\newcommand{\sousens}{\mathfrak{P}}
\newcommand{\partition}{\mathrm{Partition}}
\newcommand{\tribu}{\mathrm{Tribu}}
\newcommand{\topologies}{\mathrm{Topo}}
\newcommand{\setB}{\mathbb{B}}
\newcommand{\setN}{\mathbb{N}}
\newcommand{\setZ}{\mathbb{Z}}
\newcommand{\setQ}{\mathbb{Q}}
\newcommand{\setR}{\mathbb{R}}
\newcommand{\setC}{\mathbb{C}}
\newcommand{\corps}{\mathbb{K}}
\newcommand{\boule}{\mathfrak{B}}
\newcommand{\intervalleouvert}[2]{\left] #1 , #2 \right[}
\newcommand{\intervallesemiouvertgauche}[2]{ \left] #1 , #2 \right]}
\newcommand{\intervallesemiouvertdroite}[2]{\left[ #1 , #2 \right[ }
\newcommand{\fonction}{\mathbb{F}}
\newcommand{\bijection}{\mathrm{Bij}}
\newcommand{\polynome}{\mathrm{Poly}}
\newcommand{\lineaire}{\mathrm{Lin}}
\newcommand{\continue}{\mathrm{Cont}}
\newcommand{\homeomorphisme}{\mathrm{Hom}}
\newcommand{\etagee}{\mathrm{Etagee}}
\newcommand{\lebesgue}{\mathrm{Leb}}
\newcommand{\lipschitz}{\mathrm{Lip}}
\newcommand{\suitek}{\mathrm{Suite}}
\newcommand{\matrice}{\mathbb{M}}
\newcommand{\krylov}{\mathrm{Krylov}}
\newcommand{\tenseur}{\mathbb{T}}
\newcommand{\essentiel}{\mathfrak{E}}
\newcommand{\relation}{\mathrm{Rel}}
\DeclareMathOperator*{\strictinferieur}{\ < \ }
\DeclareMathOperator*{\strictsuperieur}{\ > \ }
\DeclareMathOperator*{\ensinferieur}{\eqslantless}
\DeclareMathOperator*{\enssuperieur}{\eqslantgtr}
\DeclareMathOperator*{\esssuperieur}{\gtrsim}
\DeclareMathOperator*{\essinferieur}{\lesssim}
\newcommand{\essegal}{\eqsim}
\newcommand{\union}{\ \cup \ }
\newcommand{\intersection}{\ \cap \ }
\newcommand{\opera}{\divideontimes}
\newcommand{\autreaddition}{\boxplus}
\newcommand{\autremultiplication}{\circledast}
\newcommand{\commutateur}[2]{\left[ #1 , #2 \right]}
\newcommand{\convolution}{\circledcirc}
\newcommand{\correlation}{\ \natural \ }
\newcommand{\diventiere}{\div}
\newcommand{\modulo}{\bmod}
\DeclareMathOperator*{\pgcd}{pgcd}
\DeclareMathOperator*{\ppcm}{ppcm}
\newcommand{\produitscalaire}[2]{\left\langle #1 \vert #2 \right\rangle}
\newcommand{\scalaire}[2]{\left\langle #1 \| #2 \right\rangle}
\newcommand{\braket}[3]{\left\langle #1 \vert #2 \vert #3 \right\rangle}
\newcommand{\orthogonal}{\bot}
\newcommand{\forme}[2]{\left\langle #1 , #2 \right\rangle}
\newcommand{\biforme}[3]{\left\langle #1 , #2 , #3 \right\rangle}
\newcommand{\contraction}[3]{\left\langle #1 \odot #3 \right\rangle_{#2}}
\newcommand{\dblecont}[5]{\left\langle #1 \vert #3 \vert #5 \right\rangle_{#2,#4}}
\DeclareMathOperator*{\major}{major}
\DeclareMathOperator*{\minor}{minor}
\DeclareMathOperator*{\maxim}{maxim}
\DeclareMathOperator*{\minim}{minim}
\DeclareMathOperator*{\argument}{arg}
\DeclareMathOperator*{\argmin}{arg\ min}
\DeclareMathOperator*{\argmax}{arg\ max}
\DeclareMathOperator*{\supessentiel}{ess\ sup}
\DeclareMathOperator*{\infessentiel}{ess\ inf}
\newcommand{\dual}{\star}
\newcommand{\distance}{\mathfrak{dist}}
\newcommand{\norme}[1]{\left\| #1 \right\|}
\newcommand{\normetrois}[1]{\left|\left\| #1 \right\|\right|}
\DeclareMathOperator*{\adh}{adh}
\DeclareMathOperator*{\interieur}{int}
\newcommand{\frontiere}{\partial}
\DeclareMathOperator*{\image}{im}
\DeclareMathOperator*{\domaine}{dom}
\DeclareMathOperator*{\noyau}{ker}
\DeclareMathOperator*{\support}{supp}
\DeclareMathOperator*{\signe}{sign}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\unsur}[1]{\frac{1}{#1}}
\newcommand{\arrondisup}[1]{\lceil #1 \rceil}
\newcommand{\arrondiinf}[1]{\lfloor #1 \rfloor}
\DeclareMathOperator*{\conjugue}{conj}
\newcommand{\conjaccent}[1]{\overline{#1}}
\DeclareMathOperator*{\division}{division}
\newcommand{\difference}{\boldsymbol{\Delta}}
\newcommand{\differentielle}[2]{\mathfrak{D}^{#1}_{#2}}
\newcommand{\OD}[2]{\frac{d #1}{d #2}}
\newcommand{\OOD}[2]{\frac{d^2 #1}{d #2^2}}
\newcommand{\NOD}[3]{\frac{d^{#3} #1}{d #2^{#3}}}
\newcommand{\deriveepartielle}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\PD}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dblederiveepartielle}[2]{\frac{\partial^2 #1}{\partial #2 \partial #2}}
\newcommand{\dfdxdy}[3]{\frac{\partial^2 #1}{\partial #2 \partial #3}}
\newcommand{\dfdxdx}[2]{\frac{\partial^2 #1}{\partial #2^2}}
\newcommand{\gradient}{\mathbf{\nabla}}
\newcommand{\combilin}[1]{\mathrm{span}\{ #1 \}}
\DeclareMathOperator*{\trace}{tr}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\probaof}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\esperof}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\cov}[2]{\mathrm{cov} \left( #1 , #2 \right) }
\newcommand{\var}[1]{\mathrm{var} \left( #1 \right) }
\newcommand{\rand}{\mathrm{rand}}
\newcommand{\variation}[1]{\left\langle #1 \right\rangle}
\DeclareMathOperator*{\composante}{comp}
\DeclareMathOperator*{\bloc}{bloc}
\DeclareMathOperator*{\ligne}{ligne}
\DeclareMathOperator*{\colonne}{colonne}
\DeclareMathOperator*{\diagonale}{diag}
\newcommand{\matelementaire}{\mathrm{Elem}}
\DeclareMathOperator*{\matpermutation}{permut}
\newcommand{\matunitaire}{\mathrm{Unitaire}}
\newcommand{\gaussjordan}{\mathrm{GaussJordan}}
\newcommand{\householder}{\mathrm{Householder}}
\DeclareMathOperator*{\rang}{rang}
\newcommand{\schur}{\mathrm{Schur}}
\newcommand{\singuliere}{\mathrm{DVS}}
\newcommand{\convexe}{\mathrm{Convexe}}
\newcommand{\petito}[1]{o\left(#1\right)}
\newcommand{\grando}[1]{O\left(#1\right)}
\)
</p>

<p>
\(
\newenvironment{Eqts}
{ \begin{equation*} \begin{gathered} }
{ \end{gathered} \end{equation*} }
\newenvironment{Matrix}
{\left[ \begin{array}}
{\end{array} \right]}
\)
</p>

<p>
\label{chap:solveur}
</p>
<div id="outline-container-orgefb381e" class="outline-2">
<h2 id="orgefb381e"><span class="section-number-2">1.</span> Dépendances</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>Chapitre \ref{chap:matrice} : Les matrices</li>
</ul>
</div>
</div>
<div id="outline-container-org4070954" class="outline-2">
<h2 id="org4070954"><span class="section-number-2">2.</span> Méthodes itératives</h2>
<div class="outline-text-2" id="text-2">
<p>
Il s'agit de résoudre itérativement (et approximativement) en \(x\) un système linéaire \(A \cdot x = b\), où \(A\) est une matrice et \(b\) un vecteur. L'itération générique s'écrit :
</p>

<p>
\[x_{k + 1} = I(x_k)\]
</p>

<p>
et on espère que la suite des \(x_k \in \setR^n\) converge vers la solution. On initialise en général les algorithmes avec \(x_0 = 0\).
</p>
</div>
</div>
<div id="outline-container-org0f7f056" class="outline-2">
<h2 id="org0f7f056"><span class="section-number-2">3.</span> Résolution par minimisation</h2>
<div class="outline-text-2" id="text-3">
<p>
Soit une matrice \(H\) de taille \((n,n)\) hermitienne (\(H = H^\dual\)) et définie positive :
</p>

<p>
\[x^\dual \cdot H \cdot x \ge 0\]
</p>

<p>
pour tout \(x \in \setR^n\). Considérons la fonction définie par :
</p>

<p>
\[\varphi(x) = \unsur{2} x^\dual \cdot H \cdot x - x^\dual \cdot b\]
</p>

<p>
Si un certain \(x\) minimise \(\varphi\) sur \(\setR^n\), on doit avoir :
</p>

<p>
\[\partial \varphi(x) = H \cdot x - b = 0\]
</p>

<p>
ce qui revient à résoudre le système linéaire :
</p>

<p>
\[H \cdot x = b\]
</p>

<p>
Comme \(\partial^2 \varphi = H\) est définie positive, résoudre le système \(H \cdot x = b\) en \(x\) revient donc à minimiser \(\varphi\) sur \(\setR^n\). On peut obtenir une approximation de la solution en utilisant la méthode de la plus grande descente, le gradient étant donné par :
</p>

<p>
\[J = (\partial \varphi)^\dual = H \cdot x - b\]
</p>

<p>
On a donc des itérations \(k\) de la forme :
</p>

<p>
\[x_{k + 1} = x_k + \alpha_k \cdot (b - H \cdot x)\]
</p>

<p>
pour un \(\alpha_k \in \setR\) bien choisi. On peut aussi utiliser un autre algorithme, comme les gradients conjugués par exemple.
</p>
</div>
<div id="outline-container-orgcb607fa" class="outline-3">
<h3 id="orgcb607fa"><span class="section-number-3">3.1.</span> Résidu</h3>
<div class="outline-text-3" id="text-3-1">
<p>
On remarque que la direction de la descente est donné par le résidu :
</p>

<p>
\[-J =  b - H \cdot x\]
</p>
</div>
</div>
<div id="outline-container-orgf7a471f" class="outline-3">
<h3 id="orgf7a471f"><span class="section-number-3">3.2.</span> Newton</h3>
<div class="outline-text-3" id="text-3-2">
<p>
On pourrait bien entendu résoudre par la méthode de Newton, mais cela reviendrait alors à inverser la matrice \(H\) directement, ce que l'on cherche précisément à éviter ici.
</p>
</div>
</div>
<div id="outline-container-orge1bd2e6" class="outline-3">
<h3 id="orge1bd2e6"><span class="section-number-3">3.3.</span> Généralisation</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Soit la matrice \(A\) de taille \((N,n)\), où \(N \ge n\), et \(y \in \setR^N\). Considérons le système général :
</p>

<p>
\[A \cdot x = y\]
</p>

<p>
à résoudre en \(x \in \setR^n\). Si on multiplie à gauche par \(A^\dual\), on obtient :
</p>

<p>
\[A^\dual \cdot A \cdot x = A^\dual \cdot y\]
</p>

<p>
Posons :
</p>

<div class="org-center">
<p>
\(
H = A^\dual \cdot A \)
</p>

<p>
\(
b = A^\dual \cdot y
\)
</p>
</div>

<p>
On est donc amenés à résoudre le système :
</p>

<p>
\[H \cdot x = b\]
</p>

<p>
où \(H\) est clairement hermitienne et définie positive puisque :
</p>

<p>
\[x^\dual \cdot (A^\dual \cdot A) \cdot x = (A \cdot x)^\dual \cdot (A \cdot x) \ge 0\]
</p>

<p>
Cette technique présente deux avantages. Premièrement, si \(H\) est inversible, la solution :
</p>

<p>
\[x = H^{-1} \cdot b = (A^\dual \cdot A)^{-1} \cdot A^\dual \cdot y\]
</p>

<p>
minimise la norme \(\norme{A \cdot x - y}\) même si la solution de \(A \cdot x = y\) n'existe pas. Il est même possible d'utiliser cette méthode avec des matrices \(A\) strictement hautes. Ensuite, les propriétés de \(H\) nous disent qu'une solution du système minimise la fonction \(\varphi\) associée. Il est donc possible de se ramener au problème de minimisation :
</p>

<p>
\[x \in \arg\min_{z \in \setR^n} \left[ \unsur{2} z^\dual \cdot A^\dual \cdot A \cdot z - z^\dual \cdot A^\dual \cdot y \right]\]
</p>

<p>
que l'on peut de nouveau résoudre itérativement en utilisant par exemple la méthode de la plus grande descente ou les gradients conjugués.
</p>
</div>
</div>
</div>
<div id="outline-container-orgd3173f0" class="outline-2">
<h2 id="orgd3173f0"><span class="section-number-2">4.</span> Espaces de Krylov</h2>
<div class="outline-text-2" id="text-4">
<p>
Les espaces de Krylov sont des espaces de vecteurs engendrés par les puissances de la matrice \(A\) appliquées à un vecteur initial \(u\) :
</p>

<p>
\[\krylov_m(A,u) = \combilin{ u, A \cdot u, A^2 \cdot u, ..., A^{m - 1} \cdot u }\]
</p>

<p>
On a donc des éléments \(x \in \krylov_m(A,u)\) de la forme :
</p>

<p>
\[x = \left[ \sum_{i = 0}^{m - 1} \alpha_i \cdot A^i \right] \cdot u\]
</p>

<p>
pour certains \(\alpha_i \in \corps\). Il s'agit donc de polynômes matriciels appliquées à \(u\).
</p>
</div>
</div>
<div id="outline-container-org7d79a3c" class="outline-2">
<h2 id="org7d79a3c"><span class="section-number-2">5.</span> Méthode de projection</h2>
<div class="outline-text-2" id="text-5">
<p>
Soit la matrice \(A\) de taille \((n,n)\), le vecteur \(b \in \setR^n\) et le système \(A \cdot x = b\) à résoudre en \(x \in \setR^n\). On choisit \(m \le n\) beaucoup plus petit que \(n\) et les vecteurs \((v_1,...,v_m)\) de \(\setR^n\). Nous allons tenter de minimiser l'erreur en \(x_{k + 1}\) produite par l'itération générique suivante :
</p>

<p>
\[x_{k + 1} = x_k + \sum_{i = 1}^m v_i \cdot y_i\]
</p>

<p>
où les \(y_i \in \setR\). Posons :
</p>

\begin{align}
V &= [v_1 \ ... \ v_m] \)

\(
y &= [y_1 \ ... \ y_m]^\dual
\end{align}

<p>
On peut réécrire l'itération sous la forme :
</p>

<p>
\[x_{k + 1} = x_k + V \cdot y\]
</p>

<p>
Nous avons vu en résolvant les moindres carrés qu'une condition nécessaire de minimisation était d'imposer l'orthogonalité entre \((A \cdot x - b)\) et les colonnes de \(A\). Nous imposant ici une variante :
</p>

<p>
\[w_i^\dual \cdot (b - A \cdot x_{k + 1}) = 0\]
</p>

<p>
pour certains \(w_1,...,w_m \in \setR^n\). En posant :
</p>

<p>
\[W = [w_1 \ ... \ w_m]\]
</p>

<p>
cette condition peut s'écrire :
</p>

<p>
\[W^\dual \cdot (b - A \cdot x_{k + 1}) = 0\]
</p>

<p>
Posons :
</p>

<p>
\[r_k = b - A \cdot x_k\]
</p>

<p>
On a alors :
</p>

<p>
\[b - A \cdot x_{k + 1} = b - A \cdot x_k - A \cdot V \cdot y = r_k - A \cdot V \cdot y\]
</p>

<p>
La condition d'orthogonalité devient :
</p>

<p>
\[W^\dual \cdot (r_k - A \cdot V \cdot y) = W^\dual \cdot r_k - W^\dual \cdot A \cdot V \cdot y = 0\]
</p>

<p>
Si la matrice \(W^\dual \cdot A \cdot V\) est inversible, on a :
</p>

<p>
\[y = (W^\dual \cdot A \cdot V)^{-1} \cdot W^\dual \cdot r_k\]
</p>

<p>
Comme \(V\) et \(W\) sont de taille \((n,m)\), la matrice \(W^\dual \cdot A \cdot V\) est de taille \((m,m)\), donc beaucoup plus petite que \(A\). Le système correspondant est donc beaucoup plus facile à résoudre.
</p>
</div>
<div id="outline-container-orgacd881c" class="outline-3">
<h3 id="orgacd881c"><span class="section-number-3">5.1.</span> Orthonormés</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Si On choisit \(V = W\) et si les vecteurs \(v_i = w_i\) sont $A$-orthonormés, on a simplement :
</p>

<p>
\[\composante_{ij} W^\dual \cdot A \cdot V = w_i^\dual \cdot A \cdot v_j = v_i^\dual \cdot A \cdot v_j = \indicatrice_{ij}\]
</p>

<p>
et :
</p>

<p>
\[(W^\dual \cdot A \cdot V)^{-1} = W^\dual \cdot A \cdot V = I\]
</p>
</div>
</div>
<div id="outline-container-org48376e4" class="outline-3">
<h3 id="org48376e4"><span class="section-number-3">5.2.</span> Krylov</h3>
<div class="outline-text-3" id="text-5-2">
<p>
On peut par exemple choisir des vecteurs de base de \(\krylov_m(A,r_k)\) pour former les colonnes des matrices \(V\) et \(W\). On peut aussi utiliser aussi des vecteurs de base de \(\krylov_m(A^\dual,r_k)\).
</p>
</div>
</div>
</div>
<div id="outline-container-org67ebf4c" class="outline-2">
<h2 id="org67ebf4c"><span class="section-number-2">6.</span> Minimisation du résidu</h2>
<div class="outline-text-2" id="text-6">
<p>
On tente de minimiser la norme quadratique du résidu :
</p>

<p>
\[\mathcal{E}(y) = (r_k - A \cdot V \cdot y)^\dual \cdot (r_k - A \cdot V \cdot y)\]
</p>

<p>
La condition d'annulation de la dérivée par rapport à \(y\) nous donne la valeur optimale :
</p>

<p>
\[y = (V^\dual \cdot A^\dual \cdot A \cdot V)^{-1} \cdot (V^\dual \cdot A^\dual \cdot r_k)\]
</p>
</div>
</div>
<div id="outline-container-orgff465dc" class="outline-2">
<h2 id="orgff465dc"><span class="section-number-2">7.</span> Gradients biconjugués</h2>
<div class="outline-text-2" id="text-7">
<p>
Soit la matrice \(A\) de taille \((n,n)\) et les vecteurs \(b,c \in \corps^n\). Les gradients biconjugués permettent d'obtenir simultanément les deux solutions \(x,y \in \corps^n\) telles que :
</p>

<div class="org-center">
<p>
\(
A \cdot x = b \quad \text{ (système primal)} \)
</p>

<p>
\(
A^\dual \cdot y = c \quad \text{ (système dual)}
\)
</p>
</div>

<p>
Soit \((x_k,y_k)\) l'estimation de \((x,y)\) obtenues à l'itération \(k\) et les résidus :
</p>

<div class="org-center">
<p>
\(
r_k = b - A \cdot x_k \)
</p>

<p>
\(
s_k = c - A^\dual \cdot y_k
\)
</p>
</div>

<p>
L'algorithme est initialisé par \(x_0 = y_0 = 0\). On a alors \(r_0 = b\) et \(s_0 = c\). L'itération est donnée par :
</p>

<div class="org-center">
<p>
\(
x_{k + 1} = x_k + \alpha_k \cdot p_k \)
</p>

<p>
\(
y_{k + 1} = y_k + \gamma_k \cdot q_k
\)
</p>
</div>

<p>
où \(p_k,q_k \in \corps^n\) et \(\alpha_k,\gamma_k \in \corps\). Par analogie avec la plus grande descente, les premiers pas s'écrivent \(p_0 = r_0\) et \(q_0 = s_0\). On adapte ensuite à chaque itération les \(p_k, q_k\) par :
</p>

<div class="org-center">
<p>
\(
p_{k + 1} = r_{k + 1} + \beta_k \cdot p_k \)
</p>

<p>
\(
q_{k + 1} = s_{k + 1} + \delta_k \cdot q_k
\)
</p>
</div>

<p>
où \(\beta_k,\delta_k \in \corps\). On impose l'orthogonalité des résidus ainsi que l'$A$-orthogonalité
des pas successifs :
</p>

<p>
\[s_k^\dual \cdot r_{k + 1} = r_k^\dual \cdot s_{k + 1} = q_k^\dual \cdot A \cdot p_{k + 1} = p_k^\dual \cdot A^\dual \cdot q_{k + 1} = 0\]
</p>

<p>
On voit que :
</p>

\begin{align}
r_{k + 1} &= b - A \cdot x_{k + 1} \)

\(
&= b - A \cdot x_k - \alpha_k\cdot A\cdot p_k \)

\(
&= r_k - \alpha_k \cdot A \cdot p_k \)

\(
s_{k + 1} &= c - A^\dual \cdot y_{k + 1} \)

\(
&= c - A^\dual \cdot y_k - \gamma_k \cdot A^\dual \cdot q_k \)

\(
&= s_k - \gamma_k \cdot A^\dual \cdot q_k
\end{align}

<p>
Les conditions d'orthogonalité nous donnent donc les valeurs des coefficients
</p>

\begin{align}
\alpha_k = \frac{s_k^\dual \cdot r_k}{s_k^\dual \cdot A \cdot p_k} \ \ && \ \
\gamma_k = \frac{r_k^\dual \cdot s_k}{r_k^\dual \cdot A^\dual \cdot q_k} \\ \)

\(
\beta_k = - \frac{ q_k^\dual \cdot A \cdot r_{k + 1} }{q_k^\dual \cdot A \cdot p_k} \ \ && \ \
\delta_k = - \frac{ p_k^\dual \cdot A^\dual \cdot s_{k + 1} }{p_k^\dual \cdot A^\dual \cdot  q_k}
\end{align}
</div>
<div id="outline-container-org68c700f" class="outline-3">
<h3 id="org68c700f"><span class="section-number-3">7.1.</span> Simplification des coefficients</h3>
<div class="outline-text-3" id="text-7-1">
<p>
Il existe un procédé plus rapide pour évaluer les coefficients. En prenant le dual des relations entre les résidus successifs, on obtient \((s_k - s_{k + 1})^\dual = \conjaccent{\gamma_k} \cdot q_k^\dual \cdot A\). Donc :
</p>

<p>
\[q_k^\dual \cdot A \cdot r_{k + 1} = \unsur{\conjaccent{\gamma_k}} \cdot (s_k - s_{k + 1})^\dual \cdot r_{k + 1} = - \unsur{\conjaccent{\gamma_k}} \cdot s_{k + 1}^\dual \cdot r_{k + 1}\]
</p>

<p>
et :
</p>

\begin{align}
q_k^\dual \cdot A \cdot p_k &= q_k^\dual \cdot A \cdot r_k - \beta_k \cdot q_k^\dual \cdot A \cdot p_{k - 1} = q_k^\dual \cdot A \cdot r_k \)

\(
&=  \unsur{\conjaccent{\gamma_k}} \cdot (s_k - s_{k + 1})^\dual \cdot r_k = \unsur{\conjaccent{\gamma_k}} \cdot s_k^\dual \cdot r_k
\end{align}

<p>
On en conclut que :
</p>

<p>
\[\beta_k = \frac{ s_{k + 1}^\dual \cdot r_{k + 1} }{ s_k^\dual \cdot r_k }\]
</p>

<p>
D'un autre coté, \((r_k - r_{k + 1})^\dual = \conjaccent{\alpha_k} \cdot p_k^\dual \cdot A^\dual\). On obtient en suivant un raisonnement analogue :
</p>

<p>
\[\delta_k = \frac{ r_{k + 1}^\dual \cdot s_{k + 1} }{ r_k^\dual \cdot s_k }\]
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Auteur: chimay</p>
<p class="date">Created: 2025-11-16 dim 15:18</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
