
#+STARTUP: showall

#+TITLE: Eclats de vers : Matemat : Théorème fondamental
#+AUTHOR: chimay
#+EMAIL: or du val chez gé courriel commercial
#+LANGUAGE: fr
#+LINK_HOME: file:../index.html
#+LINK_UP: file:index.html
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../style/defaut.css" />

#+OPTIONS: H:6
#+OPTIONS: toc:nil

#+TAGS: noexport(n)

[[file:index.org][Index des Grimoires]]

#+INCLUDE: "../include/navigan-1.org"

#+TOC: headlines 1

#+INCLUDE: "../include/latex/latex.org"

\label{chap:fonda}

* Dépendances

  - Chapitre \ref{chap:differ} : Les différentielles
  - Chapitre \ref{chap:integral} : Les intégrales


* Dérivée de l'intégrale

\label{sec:derivee_integrale}

Soit une fonction $f \in \continue([\alpha,\beta],\setR)$, un réel $a \in [\alpha,\beta]$ et la fonction intégrale associée $I : [\alpha,\beta] \mapsto \setR$ définie par :

$$I(x) = \int_a^x f(s) \ ds$$

pour tout $x \in [\alpha,\beta]$. On constate que :

$$I(a) = \int_a^a f(s) \ ds = \int_{ \{a\} } f(s) \ ds$$

La mesure de Lebesgue du singleton $\{a\}$ étant nulle, l'intégrale s'annule et on a :

$$I(a) = 0$$

Nous allons chercher à évaluer la dérivée de la fonction intégrale $I$ en un point quelconque $b \in [\alpha,\beta]$.

Nous utilisons dans la suite la notation abrégée :

$$\int_x^y = \int_x^y f(s) \ ds$$

Par additivité, on a :

$$\int_a^{b + h} = \int_a^b + \int_b^{b + h}$$

c'est-à-dire :

$$I(b + h) = I(b) + \int_b^{b + h}$$

pour tout réel $h$ tel que $b + h \in [\alpha,\beta]$. Quelle est la valeur de l'intégrale sur $[b, b + h]$ ? Fixons $\epsilon \strictsuperieur 0$. Par continuité de $f$, on peut choisir $\delta > 0$ tel que :

$$\abs{f(b + s) - f(b)} \le \epsilon$$

pour tout $s$ vérifiant $\abs{s} \le \delta$. Cela n'est possible que si :

$$f(b) - \epsilon \le f(b + s) \le f(b) + \epsilon$$

On a donc :

#+BEGIN_CENTER
\(
\sup \Big\{ f(b + s) : \abs{s} \le \delta \Big\} \le f(b) + \epsilon \)

\(
\inf \Big\{ f(b + s) : \abs{s} \le \delta \Big\} \ge f(b) - \epsilon
\)
#+END_CENTER

Si nous choisissons $h \in (0,\delta)$, l'intégrale peut donc être majorée et minorée par :

$$\int_b^{b + h} \le (f(b) + \epsilon) \cdot \mu_L([a, a + h]) = (f(b) + \epsilon) \cdot h$$

et :

$$\int_b^{b + h} \ge (f(b) - \epsilon) \cdot \mu_L([a, a + h]) = (f(b) - \epsilon) \cdot h$$

Nous disposons donc des inégalités :

$$(f(b) - \epsilon) \cdot h \le \int_b^{b + h} \le (f(b) + \epsilon) \cdot h$$

Autrement dit :

$$f(b) - \epsilon \le \unsur{h} \int_b^{b + h} \le f(b) + \epsilon$$

D'un autre coté, on a :

$$\unsur{h} \int_b^{b + h} f(s) \ ds = \frac{I(b + h) - I(b)}{h}$$

Passons à la limite $\delta \to 0$. On a alors $h \to 0$ et :

$$f(b) - \epsilon \le \lim_{h \to 0} \unsur{h} \int_b^{b + h} \le f(b) + \epsilon$$

Ces inégalités devant être valables pour tout $\epsilon \strictsuperieur 0$, on a forcément :

$$\lim_{h \to 0} \frac{I(b + h) - I(b)}{h} = f(b)$$

On en conclut que $I$ est dérivable et que :

$$\OD{I}{x}(b) = \lim_{h \to 0} \frac{I(b + h) - I(b)}{h} = f(b)$$

Autrement dit :

$$\OD{}{x} \int_a^x f(s) \ ds = f(x)$$


* Intégrale de la dérivée

\label{sec:integrale_derivee}

Soit $\alpha,\beta \in \setR$ avec $\alpha \le \beta$. Soit la fonction $F \in \continue^1([\alpha,\beta],\setR)$ et sa dérivée continue :

$$f = \partial F = \OD{F}{s}$$

Comme $F$ est continument différentiable sur $[\alpha,\beta]$, elle y est uniformément différentiable. De même, $f$ est continue sur $[\alpha,\beta]$. Elle y est donc uniformément continue. Nous allons tenter d'évaluer l'intégrale :

$$\int_a^b f(s) \ ds = \int_a^b \OD{F}{x}(s) \ ds$$

avec $a,b \in [\alpha,\beta]$ et $a \le b$.

Nous utilisons dans la suite la notation abrégée :

$$\int_x^y = \int_x^y f(s) \ ds$$


** L'idée

L'idée intuitive est que :

$$\difference F = \sum_i \difference F_i = \sum_i \frac{ \difference F_i }{ \difference x_i } \cdot \difference x_i$$

En passant à la limite $\difference x_i \to 0$, on soupçonne alors le résultat suivant :

$$\difference F = \int_a^b \OD{F}{x} \ dx$$


** La réalisation

Fixons $\epsilon \strictsuperieur 0$. Comme $f$ est uniformément continue, nous savons qu'il existe $\vartheta \strictsuperieur 0$ tel que :

$$\abs{f(x + h) - f(x)} \le \epsilon$$

pour tout $x,h$ vérifiant $x,x + h \in [\alpha,\beta]$ et $\abs{h} \le \vartheta$. On en déduit que :

#+BEGIN_CENTER
\(
\sup_{\xi \in [x - \vartheta , x + \vartheta]} f(\xi) \le f(x) + \epsilon \)

\(
\inf_{\xi \in [x - \vartheta , x + \vartheta]} f(\xi) \ge f(x) - \epsilon
\)
#+END_CENTER

On a donc les bornes pour l'intégrale :

$$(f(x) - \epsilon) \cdot h \le \int_x^{x + h} \le (f(x) + \epsilon) \cdot h$$

Comme $F$ est uniformément différentiable, nous pouvons trouver $\varpi \strictsuperieur 0$ tel que :

$$\abs{F(x + h) - F(x) - f(x) \cdot h} \le \epsilon \cdot h$$

pour tout $x,h$ vérifiant $x,x + h \in [\alpha,\beta]$ et $\abs{h} \le \varpi$. On en déduit que :

#+BEGIN_CENTER
\(
F(x + h) - F(x) - f(x) \cdot h \le \epsilon \cdot h \)

\(
f(x) \cdot h - (F(x + h) - F(x)) \le \epsilon \cdot h
\)
#+END_CENTER

En considérant ces deux inégalités par rapport au centre $f(x) \cdot h$, on obtient :

$$F(x + h) - F(x) - \epsilon \cdot h \le f(x) \cdot h \le F(x + h) - F(x) + \epsilon \cdot h$$

En soustrayant ou en ajoutant $\epsilon \cdot h$ à ces inégalités, on a :

\begin{align}
F(x + h) - F(x) - 2 \epsilon \cdot h &\le f(x) \cdot h - \epsilon \cdot h \le& F(x + h) - F(x) \)

\(
F(x + h) - F(x) &\le f(x) \cdot h + \epsilon \cdot h \le& F(x + h) - F(x) + 2 \epsilon \cdot h
\end{align}

Si $\abs{h} \le \min \{ \vartheta , \varpi \}$, nous avons de nouvelles bornes pour l'intégrale :

$$F(x + h) - F(x) - 2 \epsilon \cdot h \le \int_x^{x + h} \le F(x + h) - F(x) + 2 \epsilon \cdot h$$

Choisissons à présent $n \in \setN$ tel que :

$$\abs{ \frac{b - a}{n} } \le \min \{ \vartheta , \varpi \}$$

Posons $h = (b - a)/n$ et définissons la série :

$$x_i = a + i \cdot h$$

On a alors $a = x_0 \le x_1 \le ... \le x_n = b$. Les propriétés des sommes nous disent que :

$$\sum_{i = 1}^n (F(x_i) - F(x_{i - 1})) = F(x_n) - F(x_0) = F(b) - F(a)$$

D'un autre coté, on a clairement :

$$\sum_{i = 1}^n \int_{ x_{i - 1} }^{x_i} = \int_a^b$$

Si nous appliquons les bornes précédentes avec $x = x_{i - 1}$, nous avons $x + h = x_i$ et :

$$F(x_i) - F(x_{i - 1}) - 2 \epsilon \cdot h \le \int_{ x_{i - 1} }^{x_i} \le F(x_i) - F(x_{i - 1}) + 2 \epsilon \cdot h$$

En sommant sur $i = 1,2,...,n$, nous obtenons par conséquent :

$$F(b) - F(a) - 2 \epsilon \cdot h \cdot n \le \int_a^b \le F(b) - F(a) + 2 \epsilon \cdot h \cdot n$$

Mais comme $h \cdot n = b - a$, cela devient :

$$F(b) - F(a) - 2 \epsilon \cdot (b - a) \le \int_a^b \le F(b) - F(a) + 2 \epsilon \cdot (b - a)$$

Ces bornes devant être satisfaites pour tout $\epsilon \strictsuperieur 0$, on en déduit que :

$$\int_a^b = F(b) - F(a)$$

On a donc finalement :

$$\int_a^b f(s) \ ds = \int_a^b \OD{F}{s}(s) \ ds = F(b) - F(a)$$


** Primitive

Cette relation permet de calculer l'intégrale d'une fonction continue $f : t \mapsto f(t)$ lorsqu'on connaît une fonction $F$ vérifiant :

$$\OD{F}{t} = f$$

On appelle « primitive » de $f$ une telle fonction $F$.


** Notation

On note aussi :

$$\difference F = \int dF$$


* Polynômes

On sait que :

$$\OD{}{t}\big(t^n\big) = n \cdot t^{n - 1}$$

Comme $n$ est constante, on peut le réécrire :

$$\OD{}{t}\left( \frac{t^n}{n} \right) = t^{n - 1}$$

ou, en posant $m = n - 1$ :

$$\OD{}{t}\left( \frac{t^{m + 1}}{m + 1} \right) = t^m$$

L'intégrale s'écrit donc :

$$\int_a^b t^m \ dt = \frac{ b^{m + 1} - a^{m + 1} }{m + 1}$$

On a en particulier :

$$\int_0^x t^m \ dt = \frac{ x^{m + 1} }{m + 1}$$


** Exemples

$$\int_0^x t \ dt = \frac{ x^2 }{2}$$

$$\int_0^x t^2 \ dt = \frac{ x^3 }{3}$$


* Valeur moyenne


** Accroissements finis

Soit des réels distincts $a,b$ vérifiant $a \strictinferieur b$, la fonction $f \in \continue([a,b],\setR)$ et la fonction $F : [a,b] \mapsto \setR$ définie par :

$$F(x) = \int_a^x f(t) \ dt$$

pour tout $x \in [a,b]$. Comme $F \in \continue^1([a,b],\setR)$, le théorème des accroissements finis nous dit qu'on peut trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$\partial F(c) = \frac{F(b) - F(a)}{b - a}$$

On sait que :

$$\partial F(c) = f(c)$$

On a aussi :

$$F(b) = \int_a^b f(t) \ dt$$

et :

$$F(a) = \int_a^a f(t) \ dt = \int_{ \{ a \} } f(t) \ dt$$

La mesure de Lebesgue du singleton $\{a\}$ étant nulle, l'intégrale s'annule et on a :

$$F(a) = 0$$

On a donc $F(b) - F(a) = F(b)$ et :

$$f(c) = \unsur{b - a} \int_a^b f(t) \ dt$$


** Théorème de Cauchy

Soit des réels distincts $a,b$ vérifiant $a \strictinferieur b$, les fonctions $f,g \in \continue([a,b],\setR)$ et les fonction $F,G : [a,b] \mapsto \setR$ définies par :

\begin{align}
F(x) &= \int_a^x f(t) \ dt \)

\(
G(x) &= \int_a^x g(t) \ dt
\end{align}

pour tout $x \in [a,b]$. Comme $F,G \in \continue^1([a,b],\setR)$, le théorème de Cauchy nous dit qu'on peut trouver un $c \in \intervalleouvert{a}{b}$ tel que :

$$\partial F(c) \cdot \big[G(b) - G(a)\big] = \big[F(b) - F(a)\big] \cdot \partial G(c)$$

On sait que :

#+BEGIN_CENTER
\(
\partial F(c) = f(c) \)

\(
\partial G(c) = g(c)
\)
#+END_CENTER

On a aussi :

\begin{align}
F(b) &= \int_a^b f(t) \ dt \)

\(
G(b) &= \int_a^b g(t) \ dt
\end{align}

et :

\begin{align}
F(a) &= \int_a^a f(t) \ dt = 0 \)

\(
G(a) &= \int_a^a g(t) \ dt = 0
\end{align}

On en conclut que :

$$f(c) \ \int_a^b g(t) \ dt = g(c) \ \int_a^b f(t) \ dt$$

Si l'intégrale de $g$ et $g(c)$ sont non nuls, on peut mettre cette relation sous la forme :

$$\frac{f(c)}{g(c)} = \frac{ \int_a^b f(t) \ dt }{ \int_a^b g(t) \ dt }$$


* Intégration par parties

Soient $f,g \in \continue^1(\setR,\setR)$. On se rappelle que :

$$\partial (f \cdot g) = \partial f \cdot g + f \cdot \partial g$$

et comme on a :

$$\int_a^b \partial (f \cdot g) \ dx = f(b) \cdot g(b) - f(a) \cdot g(a)$$

on obtient la formule d'intégration par parties :

$$\int_a^b f(x) \cdot \partial g(x) \ dx = (f \cdot g)(b) - (f \cdot g)(a) - \int_a^b \partial f(x) \cdot g(x) \ dx$$


** Stieltjes

Le résultat est également valable lorsqu'on utilise les mesures de Stieltjes associées à $f$ et $g$ :

$$\int_a^b f(x) \cdot dg(x) = \difference (f \cdot g) - \int_a^b g(x) \cdot df(x)$$


** Dérivée constante

On considère le cas particulier où $\partial g = 1$. Une exemple de fonction $g$ vérifiant cette propriété est simplement $g = \identite$. On a donc $g(x) = x$ et :

$$\int_a^b f(x) \ dx = \int_a^b f(x) \cdot 1 \ dx = \int_a^b f(x) \cdot \partial g(x) \ dx$$

L'intégration par parties nous donne :

$$\int_a^b f(x) \ dx = f(b) \cdot b - f(a) \cdot a - \int_a^b \partial f(x) \cdot x \ dx$$


* Changement de variable

Considérons une fonction $f \in \continue(\setR,\setR)$ et un changement de variable $x = \varphi(s)$ où $\varphi \in \homeomorphisme^1(\setR,\setR)$. Soit la mesure de lebesgue $\mu([\alpha,\beta]) = \beta - \alpha$.


** L'idée

$$\sum_i f_i \cdot \difference x_i = \sum_i f_i \cdot \frac{\difference x_i}{\difference s_i} \cdot \difference s_i$$

On devrait donc avoir par passage à la limite :

$$\int f \ dx = \int f \ \OD{x}{s} \ ds$$


** La réalisation

On applique le même procédé qu'à la section \ref{sec:integrale_derivee}. Si $x$ est proche de $y$, on a :

$$\int_x^y \approx f(x) \cdot (y - x)$$

Posant $s = \varphi^{-1}(x)$ et $t = \varphi^{-1}(y)$, on a aussi :

$$y - x = \varphi(t) - \varphi(s) = \OD{\varphi}{s}(s) \cdot (t - s) + e(\abs{s - t})$$

où $e$ converge plus vite que $s - t$ vers $0$. On en conclut que :

$$\int_x^y \approx (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s) \cdot (t - s)$$

On remarque que le second membre est une approximation de l'intégrale de la fonction :

$$F(s) = (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s)$$

sur l'intervalle $[s,t] = [\varphi^{-1}(x),\varphi^{-1}(y)]$. Il ne nous reste plus qu'à sommer sur tous les petits intervalles $[x_{i - 1},x_i]$ et à passer à la limite $h = x_i - x_{i - 1} \to 0$ pour obtenir :

$$\int_a^b f(x) \ dx = \int_{\varphi^{-1}(a)}^{\varphi^{-1}(b)} (f \circ \varphi)(s) \cdot \OD{\varphi}{s}(s) \ ds$$


